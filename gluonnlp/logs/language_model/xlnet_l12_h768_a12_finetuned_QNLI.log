2019-11-22 05:24:23,514 - root - INFO - Namespace(accumulate=None, attention_dropout=0.1, batch_size=128, cpu=None, dataset='126gb', dev_batch_size=32, dropout=0.1, early_stop=None, epochs=3, epsilon=1e-06, gpu=8, log_interval=10, lr=4e-05, lr_decay='linear', max_len=128, model_name='xlnet_cased_l12_h768_a12', model_parameters=None, only_inference=False, output_dir='./output_dir', pad=True, seed=49, task_name='QNLI', warmup_ratio=0)
2019-11-22 05:25:02,680 - root - INFO - processing dataset...
2019-11-22 05:25:29,558 - root - INFO - Now we are doing XLNet classification training on [gpu(0), gpu(1), gpu(2), gpu(3), gpu(4), gpu(5), gpu(6), gpu(7)]!
2019-11-22 05:25:53,956 - root - INFO - [Epoch 1 Batch 10/850] loss=0.6905, lr=0.0000399
2019-11-22 05:26:03,498 - root - INFO - [Epoch 1 Batch 20/850] loss=0.6591, lr=0.0000397
2019-11-22 05:26:13,066 - root - INFO - [Epoch 1 Batch 30/850] loss=0.5782, lr=0.0000395
2019-11-22 05:26:22,454 - root - INFO - [Epoch 1 Batch 40/850] loss=0.5365, lr=0.0000394
2019-11-22 05:26:31,965 - root - INFO - [Epoch 1 Batch 50/850] loss=0.5030, lr=0.0000392
2019-11-22 05:26:41,503 - root - INFO - [Epoch 1 Batch 60/850] loss=0.5131, lr=0.0000391
2019-11-22 05:26:51,169 - root - INFO - [Epoch 1 Batch 70/850] loss=0.5163, lr=0.0000389
2019-11-22 05:27:00,599 - root - INFO - [Epoch 1 Batch 80/850] loss=0.4933, lr=0.0000388
2019-11-22 05:27:10,159 - root - INFO - [Epoch 1 Batch 90/850] loss=0.4852, lr=0.0000386
2019-11-22 05:27:20,031 - root - INFO - [Epoch 1 Batch 100/850] loss=0.4809, lr=0.0000384
2019-11-22 05:27:29,434 - root - INFO - [Epoch 1 Batch 110/850] loss=0.4702, lr=0.0000383
2019-11-22 05:27:38,875 - root - INFO - [Epoch 1 Batch 120/850] loss=0.4538, lr=0.0000381
2019-11-22 05:27:48,889 - root - INFO - [Epoch 1 Batch 130/850] loss=0.4709, lr=0.0000380
2019-11-22 05:27:58,383 - root - INFO - [Epoch 1 Batch 140/850] loss=0.4752, lr=0.0000378
2019-11-22 05:28:08,132 - root - INFO - [Epoch 1 Batch 150/850] loss=0.4382, lr=0.0000377
2019-11-22 05:28:17,458 - root - INFO - [Epoch 1 Batch 160/850] loss=0.4230, lr=0.0000375
2019-11-22 05:28:26,889 - root - INFO - [Epoch 1 Batch 170/850] loss=0.4461, lr=0.0000373
2019-11-22 05:28:36,345 - root - INFO - [Epoch 1 Batch 180/850] loss=0.4402, lr=0.0000372
2019-11-22 05:28:45,692 - root - INFO - [Epoch 1 Batch 190/850] loss=0.4403, lr=0.0000370
2019-11-22 05:28:55,326 - root - INFO - [Epoch 1 Batch 200/850] loss=0.4236, lr=0.0000369
2019-11-22 05:29:04,766 - root - INFO - [Epoch 1 Batch 210/850] loss=0.4403, lr=0.0000367
2019-11-22 05:29:14,083 - root - INFO - [Epoch 1 Batch 220/850] loss=0.4167, lr=0.0000366
2019-11-22 05:29:23,566 - root - INFO - [Epoch 1 Batch 230/850] loss=0.4137, lr=0.0000364
2019-11-22 05:29:33,055 - root - INFO - [Epoch 1 Batch 240/850] loss=0.4086, lr=0.0000362
2019-11-22 05:29:42,570 - root - INFO - [Epoch 1 Batch 250/850] loss=0.3968, lr=0.0000361
2019-11-22 05:29:51,929 - root - INFO - [Epoch 1 Batch 260/850] loss=0.3986, lr=0.0000359
2019-11-22 05:30:01,223 - root - INFO - [Epoch 1 Batch 270/850] loss=0.4019, lr=0.0000358
2019-11-22 05:30:10,968 - root - INFO - [Epoch 1 Batch 280/850] loss=0.4405, lr=0.0000356
2019-11-22 05:30:20,664 - root - INFO - [Epoch 1 Batch 290/850] loss=0.4093, lr=0.0000355
2019-11-22 05:30:30,315 - root - INFO - [Epoch 1 Batch 300/850] loss=0.4162, lr=0.0000353
2019-11-22 05:30:39,773 - root - INFO - [Epoch 1 Batch 310/850] loss=0.3759, lr=0.0000351
2019-11-22 05:30:49,244 - root - INFO - [Epoch 1 Batch 320/850] loss=0.4324, lr=0.0000350
2019-11-22 05:30:58,681 - root - INFO - [Epoch 1 Batch 330/850] loss=0.4013, lr=0.0000348
2019-11-22 05:31:08,218 - root - INFO - [Epoch 1 Batch 340/850] loss=0.3618, lr=0.0000347
2019-11-22 05:31:17,730 - root - INFO - [Epoch 1 Batch 350/850] loss=0.3388, lr=0.0000345
2019-11-22 05:31:27,192 - root - INFO - [Epoch 1 Batch 360/850] loss=0.3673, lr=0.0000343
2019-11-22 05:31:36,633 - root - INFO - [Epoch 1 Batch 370/850] loss=0.3802, lr=0.0000342
2019-11-22 05:31:46,189 - root - INFO - [Epoch 1 Batch 380/850] loss=0.3659, lr=0.0000340
2019-11-22 05:31:55,676 - root - INFO - [Epoch 1 Batch 390/850] loss=0.3726, lr=0.0000339
2019-11-22 05:32:05,071 - root - INFO - [Epoch 1 Batch 400/850] loss=0.3576, lr=0.0000337
2019-11-22 05:32:14,808 - root - INFO - [Epoch 1 Batch 410/850] loss=0.4253, lr=0.0000336
2019-11-22 05:32:24,429 - root - INFO - [Epoch 1 Batch 420/850] loss=0.3821, lr=0.0000334
2019-11-22 05:32:34,197 - root - INFO - [Epoch 1 Batch 430/850] loss=0.3771, lr=0.0000332
2019-11-22 05:32:43,799 - root - INFO - [Epoch 1 Batch 440/850] loss=0.3379, lr=0.0000331
2019-11-22 05:32:53,461 - root - INFO - [Epoch 1 Batch 450/850] loss=0.3803, lr=0.0000329
2019-11-22 05:33:03,003 - root - INFO - [Epoch 1 Batch 460/850] loss=0.3630, lr=0.0000328
2019-11-22 05:33:12,555 - root - INFO - [Epoch 1 Batch 470/850] loss=0.3830, lr=0.0000326
2019-11-22 05:33:22,064 - root - INFO - [Epoch 1 Batch 480/850] loss=0.3563, lr=0.0000325
2019-11-22 05:33:31,451 - root - INFO - [Epoch 1 Batch 490/850] loss=0.3583, lr=0.0000323
2019-11-22 05:33:40,817 - root - INFO - [Epoch 1 Batch 500/850] loss=0.3102, lr=0.0000321
2019-11-22 05:33:50,346 - root - INFO - [Epoch 1 Batch 510/850] loss=0.3415, lr=0.0000320
2019-11-22 05:33:59,815 - root - INFO - [Epoch 1 Batch 520/850] loss=0.3402, lr=0.0000318
2019-11-22 05:34:09,346 - root - INFO - [Epoch 1 Batch 530/850] loss=0.3379, lr=0.0000317
2019-11-22 05:34:18,860 - root - INFO - [Epoch 1 Batch 540/850] loss=0.3362, lr=0.0000315
2019-11-22 05:34:28,316 - root - INFO - [Epoch 1 Batch 550/850] loss=0.3593, lr=0.0000314
2019-11-22 05:34:37,859 - root - INFO - [Epoch 1 Batch 560/850] loss=0.3706, lr=0.0000312
2019-11-22 05:34:47,335 - root - INFO - [Epoch 1 Batch 570/850] loss=0.3678, lr=0.0000310
2019-11-22 05:34:57,057 - root - INFO - [Epoch 1 Batch 580/850] loss=0.3283, lr=0.0000309
2019-11-22 05:35:06,775 - root - INFO - [Epoch 1 Batch 590/850] loss=0.3776, lr=0.0000307
2019-11-22 05:35:16,306 - root - INFO - [Epoch 1 Batch 600/850] loss=0.3696, lr=0.0000306
2019-11-22 05:35:25,773 - root - INFO - [Epoch 1 Batch 610/850] loss=0.3286, lr=0.0000304
2019-11-22 05:35:35,433 - root - INFO - [Epoch 1 Batch 620/850] loss=0.4018, lr=0.0000303
2019-11-22 05:35:44,988 - root - INFO - [Epoch 1 Batch 630/850] loss=0.3674, lr=0.0000301
2019-11-22 05:35:54,457 - root - INFO - [Epoch 1 Batch 640/850] loss=0.3305, lr=0.0000299
2019-11-22 05:36:03,955 - root - INFO - [Epoch 1 Batch 650/850] loss=0.3340, lr=0.0000298
2019-11-22 05:36:13,392 - root - INFO - [Epoch 1 Batch 660/850] loss=0.3381, lr=0.0000296
2019-11-22 05:36:22,904 - root - INFO - [Epoch 1 Batch 670/850] loss=0.3259, lr=0.0000295
2019-11-22 05:36:32,389 - root - INFO - [Epoch 1 Batch 680/850] loss=0.3353, lr=0.0000293
2019-11-22 05:36:41,980 - root - INFO - [Epoch 1 Batch 690/850] loss=0.3245, lr=0.0000292
2019-11-22 05:36:51,872 - root - INFO - [Epoch 1 Batch 700/850] loss=0.3162, lr=0.0000290
2019-11-22 05:37:01,553 - root - INFO - [Epoch 1 Batch 710/850] loss=0.3681, lr=0.0000288
2019-11-22 05:37:11,236 - root - INFO - [Epoch 1 Batch 720/850] loss=0.3454, lr=0.0000287
2019-11-22 05:37:20,841 - root - INFO - [Epoch 1 Batch 730/850] loss=0.3476, lr=0.0000285
2019-11-22 05:37:30,472 - root - INFO - [Epoch 1 Batch 740/850] loss=0.3715, lr=0.0000284
2019-11-22 05:37:40,297 - root - INFO - [Epoch 1 Batch 750/850] loss=0.3380, lr=0.0000282
2019-11-22 05:37:49,812 - root - INFO - [Epoch 1 Batch 760/850] loss=0.3883, lr=0.0000281
2019-11-22 05:37:59,368 - root - INFO - [Epoch 1 Batch 770/850] loss=0.3388, lr=0.0000279
2019-11-22 05:38:08,967 - root - INFO - [Epoch 1 Batch 780/850] loss=0.3158, lr=0.0000277
2019-11-22 05:38:18,450 - root - INFO - [Epoch 1 Batch 790/850] loss=0.3039, lr=0.0000276
2019-11-22 05:38:27,940 - root - INFO - [Epoch 1 Batch 800/850] loss=0.2914, lr=0.0000274
2019-11-22 05:38:37,557 - root - INFO - [Epoch 1 Batch 810/850] loss=0.3084, lr=0.0000273
2019-11-22 05:38:47,450 - root - INFO - [Epoch 1 Batch 820/850] loss=0.2867, lr=0.0000271
2019-11-22 05:38:57,053 - root - INFO - [Epoch 1 Batch 830/850] loss=0.2954, lr=0.0000270
2019-11-22 05:39:06,619 - root - INFO - [Epoch 1 Batch 840/850] loss=0.3556, lr=0.0000268
2019-11-22 05:39:16,228 - root - INFO - [Epoch 1 Batch 850/850] loss=0.3132, lr=0.0000266
2019-11-22 05:39:16,229 - root - INFO - Now we are doing evaluation on dev with [gpu(0), gpu(1), gpu(2), gpu(3), gpu(4), gpu(5), gpu(6), gpu(7)].
2019-11-22 05:39:17,846 - root - INFO - [Batch 10/180] loss=0.4056
2019-11-22 05:39:19,409 - root - INFO - [Batch 20/180] loss=0.3481
2019-11-22 05:39:20,974 - root - INFO - [Batch 30/180] loss=0.3822
2019-11-22 05:39:22,538 - root - INFO - [Batch 40/180] loss=0.3520
2019-11-22 05:39:24,091 - root - INFO - [Batch 50/180] loss=0.3425
2019-11-22 05:39:25,656 - root - INFO - [Batch 60/180] loss=0.2856
2019-11-22 05:39:27,214 - root - INFO - [Batch 70/180] loss=0.3240
2019-11-22 05:39:28,773 - root - INFO - [Batch 80/180] loss=0.2274
2019-11-22 05:39:30,334 - root - INFO - [Batch 90/180] loss=0.3050
2019-11-22 05:39:31,895 - root - INFO - [Batch 100/180] loss=0.2652
2019-11-22 05:39:33,460 - root - INFO - [Batch 110/180] loss=0.3512
2019-11-22 05:39:35,027 - root - INFO - [Batch 120/180] loss=0.3423
2019-11-22 05:39:36,587 - root - INFO - [Batch 130/180] loss=0.3463
2019-11-22 05:39:38,159 - root - INFO - [Batch 140/180] loss=0.3311
2019-11-22 05:39:39,718 - root - INFO - [Batch 150/180] loss=0.3889
2019-11-22 05:39:41,289 - root - INFO - [Batch 160/180] loss=0.3089
2019-11-22 05:39:42,852 - root - INFO - [Batch 170/180] loss=0.2890
2019-11-22 05:39:44,346 - root - INFO - [Batch 180/180] loss=0.4028
2019-11-22 05:39:44,400 - root - INFO - validation metrics:accuracy:0.8571
2019-11-22 05:39:44,400 - root - INFO - Time cost=28.17s, throughput=204.46 samples/s
2019-11-22 05:39:45,988 - root - INFO - params saved in: ./output_dir/model_xlnet_QNLI_0.params
2019-11-22 05:39:45,990 - root - INFO - Time cost=856.42s
2019-11-22 05:39:56,319 - root - INFO - [Epoch 2 Batch 10/850] loss=0.3031, lr=0.0000265
2019-11-22 05:40:05,925 - root - INFO - [Epoch 2 Batch 20/850] loss=0.2717, lr=0.0000263
2019-11-22 05:40:15,476 - root - INFO - [Epoch 2 Batch 30/850] loss=0.2560, lr=0.0000262
2019-11-22 05:40:24,956 - root - INFO - [Epoch 2 Batch 40/850] loss=0.2515, lr=0.0000260
2019-11-22 05:40:34,396 - root - INFO - [Epoch 2 Batch 50/850] loss=0.2476, lr=0.0000258
2019-11-22 05:40:43,839 - root - INFO - [Epoch 2 Batch 60/850] loss=0.2444, lr=0.0000257
2019-11-22 05:40:53,314 - root - INFO - [Epoch 2 Batch 70/850] loss=0.2365, lr=0.0000255
2019-11-22 05:41:02,902 - root - INFO - [Epoch 2 Batch 80/850] loss=0.2780, lr=0.0000254
2019-11-22 05:41:12,643 - root - INFO - [Epoch 2 Batch 90/850] loss=0.2655, lr=0.0000252
2019-11-22 05:41:22,243 - root - INFO - [Epoch 2 Batch 100/850] loss=0.2575, lr=0.0000251
2019-11-22 05:41:31,865 - root - INFO - [Epoch 2 Batch 110/850] loss=0.2806, lr=0.0000249
2019-11-22 05:41:41,457 - root - INFO - [Epoch 2 Batch 120/850] loss=0.2521, lr=0.0000247
2019-11-22 05:41:50,920 - root - INFO - [Epoch 2 Batch 130/850] loss=0.2823, lr=0.0000246
2019-11-22 05:42:00,438 - root - INFO - [Epoch 2 Batch 140/850] loss=0.3021, lr=0.0000244
2019-11-22 05:42:10,063 - root - INFO - [Epoch 2 Batch 150/850] loss=0.2681, lr=0.0000243
2019-11-22 05:42:19,595 - root - INFO - [Epoch 2 Batch 160/850] loss=0.2421, lr=0.0000241
2019-11-22 05:42:28,999 - root - INFO - [Epoch 2 Batch 170/850] loss=0.2508, lr=0.0000240
2019-11-22 05:42:38,562 - root - INFO - [Epoch 2 Batch 180/850] loss=0.2246, lr=0.0000238
2019-11-22 05:42:48,034 - root - INFO - [Epoch 2 Batch 190/850] loss=0.2285, lr=0.0000236
2019-11-22 05:42:57,687 - root - INFO - [Epoch 2 Batch 200/850] loss=0.2277, lr=0.0000235
2019-11-22 05:43:07,281 - root - INFO - [Epoch 2 Batch 210/850] loss=0.2459, lr=0.0000233
2019-11-22 05:43:16,724 - root - INFO - [Epoch 2 Batch 220/850] loss=0.2674, lr=0.0000232
2019-11-22 05:43:26,277 - root - INFO - [Epoch 2 Batch 230/850] loss=0.2781, lr=0.0000230
2019-11-22 05:43:35,738 - root - INFO - [Epoch 2 Batch 240/850] loss=0.2279, lr=0.0000229
2019-11-22 05:43:45,291 - root - INFO - [Epoch 2 Batch 250/850] loss=0.2303, lr=0.0000227
2019-11-22 05:43:54,775 - root - INFO - [Epoch 2 Batch 260/850] loss=0.2519, lr=0.0000225
2019-11-22 05:44:04,323 - root - INFO - [Epoch 2 Batch 270/850] loss=0.2278, lr=0.0000224
2019-11-22 05:44:13,855 - root - INFO - [Epoch 2 Batch 280/850] loss=0.2500, lr=0.0000222
2019-11-22 05:44:23,329 - root - INFO - [Epoch 2 Batch 290/850] loss=0.2380, lr=0.0000221
2019-11-22 05:44:32,999 - root - INFO - [Epoch 2 Batch 300/850] loss=0.2711, lr=0.0000219
2019-11-22 05:44:42,622 - root - INFO - [Epoch 2 Batch 310/850] loss=0.2527, lr=0.0000218
2019-11-22 05:44:52,102 - root - INFO - [Epoch 2 Batch 320/850] loss=0.2681, lr=0.0000216
2019-11-22 05:45:01,623 - root - INFO - [Epoch 2 Batch 330/850] loss=0.2783, lr=0.0000214
2019-11-22 05:45:11,243 - root - INFO - [Epoch 2 Batch 340/850] loss=0.2428, lr=0.0000213
2019-11-22 05:45:20,819 - root - INFO - [Epoch 2 Batch 350/850] loss=0.2625, lr=0.0000211
2019-11-22 05:45:30,151 - root - INFO - [Epoch 2 Batch 360/850] loss=0.2821, lr=0.0000210
2019-11-22 05:45:39,735 - root - INFO - [Epoch 2 Batch 370/850] loss=0.2548, lr=0.0000208
2019-11-22 05:45:49,524 - root - INFO - [Epoch 2 Batch 380/850] loss=0.2882, lr=0.0000207
2019-11-22 05:45:58,996 - root - INFO - [Epoch 2 Batch 390/850] loss=0.2427, lr=0.0000205
2019-11-22 05:46:08,420 - root - INFO - [Epoch 2 Batch 400/850] loss=0.2643, lr=0.0000203
2019-11-22 05:46:17,877 - root - INFO - [Epoch 2 Batch 410/850] loss=0.2603, lr=0.0000202
2019-11-22 05:46:27,299 - root - INFO - [Epoch 2 Batch 420/850] loss=0.2394, lr=0.0000200
2019-11-22 05:46:36,913 - root - INFO - [Epoch 2 Batch 430/850] loss=0.2980, lr=0.0000199
2019-11-22 05:46:46,608 - root - INFO - [Epoch 2 Batch 440/850] loss=0.2765, lr=0.0000197
2019-11-22 05:46:56,153 - root - INFO - [Epoch 2 Batch 450/850] loss=0.2412, lr=0.0000196
2019-11-22 05:47:05,753 - root - INFO - [Epoch 2 Batch 460/850] loss=0.2971, lr=0.0000194
2019-11-22 05:47:15,397 - root - INFO - [Epoch 2 Batch 470/850] loss=0.2610, lr=0.0000192
2019-11-22 05:47:24,942 - root - INFO - [Epoch 2 Batch 480/850] loss=0.2560, lr=0.0000191
2019-11-22 05:47:34,385 - root - INFO - [Epoch 2 Batch 490/850] loss=0.2496, lr=0.0000189
2019-11-22 05:47:44,172 - root - INFO - [Epoch 2 Batch 500/850] loss=0.2590, lr=0.0000188
2019-11-22 05:47:53,992 - root - INFO - [Epoch 2 Batch 510/850] loss=0.2588, lr=0.0000186
2019-11-22 05:48:03,742 - root - INFO - [Epoch 2 Batch 520/850] loss=0.3000, lr=0.0000184
2019-11-22 05:48:13,573 - root - INFO - [Epoch 2 Batch 530/850] loss=0.2467, lr=0.0000183
2019-11-22 05:48:23,200 - root - INFO - [Epoch 2 Batch 540/850] loss=0.2610, lr=0.0000181
2019-11-22 05:48:32,756 - root - INFO - [Epoch 2 Batch 550/850] loss=0.1945, lr=0.0000180
2019-11-22 05:48:42,212 - root - INFO - [Epoch 2 Batch 560/850] loss=0.2546, lr=0.0000178
2019-11-22 05:48:51,637 - root - INFO - [Epoch 2 Batch 570/850] loss=0.2598, lr=0.0000177
2019-11-22 05:49:01,125 - root - INFO - [Epoch 2 Batch 580/850] loss=0.2055, lr=0.0000175
2019-11-22 05:49:10,646 - root - INFO - [Epoch 2 Batch 590/850] loss=0.2938, lr=0.0000173
2019-11-22 05:49:20,214 - root - INFO - [Epoch 2 Batch 600/850] loss=0.2393, lr=0.0000172
2019-11-22 05:49:29,926 - root - INFO - [Epoch 2 Batch 610/850] loss=0.2320, lr=0.0000170
2019-11-22 05:49:39,634 - root - INFO - [Epoch 2 Batch 620/850] loss=0.2378, lr=0.0000169
2019-11-22 05:49:49,241 - root - INFO - [Epoch 2 Batch 630/850] loss=0.2366, lr=0.0000167
2019-11-22 05:49:58,950 - root - INFO - [Epoch 2 Batch 640/850] loss=0.2250, lr=0.0000166
2019-11-22 05:50:08,705 - root - INFO - [Epoch 2 Batch 650/850] loss=0.2302, lr=0.0000164
2019-11-22 05:50:18,456 - root - INFO - [Epoch 2 Batch 660/850] loss=0.3047, lr=0.0000162
2019-11-22 05:50:28,204 - root - INFO - [Epoch 2 Batch 670/850] loss=0.2583, lr=0.0000161
2019-11-22 05:50:37,571 - root - INFO - [Epoch 2 Batch 680/850] loss=0.2598, lr=0.0000159
2019-11-22 05:50:47,187 - root - INFO - [Epoch 2 Batch 690/850] loss=0.2508, lr=0.0000158
2019-11-22 05:50:56,755 - root - INFO - [Epoch 2 Batch 700/850] loss=0.2236, lr=0.0000156
2019-11-22 05:51:06,262 - root - INFO - [Epoch 2 Batch 710/850] loss=0.2684, lr=0.0000155
2019-11-22 05:51:15,779 - root - INFO - [Epoch 2 Batch 720/850] loss=0.2565, lr=0.0000153
2019-11-22 05:51:25,343 - root - INFO - [Epoch 2 Batch 730/850] loss=0.2994, lr=0.0000151
2019-11-22 05:51:34,966 - root - INFO - [Epoch 2 Batch 740/850] loss=0.2438, lr=0.0000150
2019-11-22 05:51:44,540 - root - INFO - [Epoch 2 Batch 750/850] loss=0.2721, lr=0.0000148
2019-11-22 05:51:54,178 - root - INFO - [Epoch 2 Batch 760/850] loss=0.2560, lr=0.0000147
2019-11-22 05:52:04,009 - root - INFO - [Epoch 2 Batch 770/850] loss=0.2379, lr=0.0000145
2019-11-22 05:52:13,507 - root - INFO - [Epoch 2 Batch 780/850] loss=0.2464, lr=0.0000144
2019-11-22 05:52:23,223 - root - INFO - [Epoch 2 Batch 790/850] loss=0.2566, lr=0.0000142
2019-11-22 05:52:32,871 - root - INFO - [Epoch 2 Batch 800/850] loss=0.2380, lr=0.0000140
2019-11-22 05:52:42,348 - root - INFO - [Epoch 2 Batch 810/850] loss=0.2452, lr=0.0000139
2019-11-22 05:52:51,900 - root - INFO - [Epoch 2 Batch 820/850] loss=0.3082, lr=0.0000137
2019-11-22 05:53:01,568 - root - INFO - [Epoch 2 Batch 830/850] loss=0.2382, lr=0.0000136
2019-11-22 05:53:10,998 - root - INFO - [Epoch 2 Batch 840/850] loss=0.2575, lr=0.0000134
2019-11-22 05:53:20,800 - root - INFO - [Epoch 2 Batch 850/850] loss=0.2468, lr=0.0000133
2019-11-22 05:53:20,800 - root - INFO - Now we are doing evaluation on dev with [gpu(0), gpu(1), gpu(2), gpu(3), gpu(4), gpu(5), gpu(6), gpu(7)].
2019-11-22 05:53:22,485 - root - INFO - [Batch 10/180] loss=0.3168
2019-11-22 05:53:24,158 - root - INFO - [Batch 20/180] loss=0.3072
2019-11-22 05:53:25,843 - root - INFO - [Batch 30/180] loss=0.3105
2019-11-22 05:53:27,529 - root - INFO - [Batch 40/180] loss=0.3193
2019-11-22 05:53:29,203 - root - INFO - [Batch 50/180] loss=0.2620
2019-11-22 05:53:30,878 - root - INFO - [Batch 60/180] loss=0.2895
2019-11-22 05:53:32,554 - root - INFO - [Batch 70/180] loss=0.3291
2019-11-22 05:53:34,240 - root - INFO - [Batch 80/180] loss=0.2025
2019-11-22 05:53:35,918 - root - INFO - [Batch 90/180] loss=0.2412
2019-11-22 05:53:37,597 - root - INFO - [Batch 100/180] loss=0.2134
2019-11-22 05:53:39,279 - root - INFO - [Batch 110/180] loss=0.3257
2019-11-22 05:53:40,971 - root - INFO - [Batch 120/180] loss=0.3042
2019-11-22 05:53:42,662 - root - INFO - [Batch 130/180] loss=0.3442
2019-11-22 05:53:44,343 - root - INFO - [Batch 140/180] loss=0.2147
2019-11-22 05:53:46,025 - root - INFO - [Batch 150/180] loss=0.3178
2019-11-22 05:53:47,701 - root - INFO - [Batch 160/180] loss=0.2827
2019-11-22 05:53:49,390 - root - INFO - [Batch 170/180] loss=0.2268
2019-11-22 05:53:50,997 - root - INFO - [Batch 180/180] loss=0.3520
2019-11-22 05:53:51,044 - root - INFO - validation metrics:accuracy:0.8866
2019-11-22 05:53:51,045 - root - INFO - Time cost=30.24s, throughput=190.45 samples/s
2019-11-22 05:53:53,302 - root - INFO - params saved in: ./output_dir/model_xlnet_QNLI_1.params
2019-11-22 05:53:53,304 - root - INFO - Time cost=847.31s
2019-11-22 05:54:03,012 - root - INFO - [Epoch 3 Batch 10/850] loss=0.1915, lr=0.0000131
2019-11-22 05:54:12,482 - root - INFO - [Epoch 3 Batch 20/850] loss=0.2174, lr=0.0000129
2019-11-22 05:54:22,018 - root - INFO - [Epoch 3 Batch 30/850] loss=0.1861, lr=0.0000128
2019-11-22 05:54:31,551 - root - INFO - [Epoch 3 Batch 40/850] loss=0.1548, lr=0.0000126
2019-11-22 05:54:40,993 - root - INFO - [Epoch 3 Batch 50/850] loss=0.1733, lr=0.0000125
2019-11-22 05:54:50,633 - root - INFO - [Epoch 3 Batch 60/850] loss=0.1787, lr=0.0000123
2019-11-22 05:55:00,496 - root - INFO - [Epoch 3 Batch 70/850] loss=0.1638, lr=0.0000122
2019-11-22 05:55:10,205 - root - INFO - [Epoch 3 Batch 80/850] loss=0.1755, lr=0.0000120
2019-11-22 05:55:19,648 - root - INFO - [Epoch 3 Batch 90/850] loss=0.1796, lr=0.0000118
2019-11-22 05:55:29,117 - root - INFO - [Epoch 3 Batch 100/850] loss=0.1615, lr=0.0000117
2019-11-22 05:55:38,689 - root - INFO - [Epoch 3 Batch 110/850] loss=0.1525, lr=0.0000115
2019-11-22 05:55:48,224 - root - INFO - [Epoch 3 Batch 120/850] loss=0.2295, lr=0.0000114
2019-11-22 05:55:57,792 - root - INFO - [Epoch 3 Batch 130/850] loss=0.1823, lr=0.0000112
2019-11-22 05:56:07,353 - root - INFO - [Epoch 3 Batch 140/850] loss=0.2288, lr=0.0000111
2019-11-22 05:56:16,808 - root - INFO - [Epoch 3 Batch 150/850] loss=0.1776, lr=0.0000109
2019-11-22 05:56:26,351 - root - INFO - [Epoch 3 Batch 160/850] loss=0.1912, lr=0.0000107
2019-11-22 05:56:35,855 - root - INFO - [Epoch 3 Batch 170/850] loss=0.1601, lr=0.0000106
2019-11-22 05:56:45,281 - root - INFO - [Epoch 3 Batch 180/850] loss=0.1953, lr=0.0000104
2019-11-22 05:56:54,975 - root - INFO - [Epoch 3 Batch 190/850] loss=0.1723, lr=0.0000103
2019-11-22 05:57:04,802 - root - INFO - [Epoch 3 Batch 200/850] loss=0.1755, lr=0.0000101
2019-11-22 05:57:14,623 - root - INFO - [Epoch 3 Batch 210/850] loss=0.1824, lr=0.0000099
2019-11-22 05:57:24,467 - root - INFO - [Epoch 3 Batch 220/850] loss=0.1844, lr=0.0000098
2019-11-22 05:57:34,427 - root - INFO - [Epoch 3 Batch 230/850] loss=0.2063, lr=0.0000096
2019-11-22 05:57:44,103 - root - INFO - [Epoch 3 Batch 240/850] loss=0.1664, lr=0.0000095
2019-11-22 05:57:53,645 - root - INFO - [Epoch 3 Batch 250/850] loss=0.1746, lr=0.0000093
2019-11-22 05:58:03,163 - root - INFO - [Epoch 3 Batch 260/850] loss=0.2052, lr=0.0000092
2019-11-22 05:58:12,606 - root - INFO - [Epoch 3 Batch 270/850] loss=0.2185, lr=0.0000090
2019-11-22 05:58:22,086 - root - INFO - [Epoch 3 Batch 280/850] loss=0.1690, lr=0.0000088
2019-11-22 05:58:31,733 - root - INFO - [Epoch 3 Batch 290/850] loss=0.2140, lr=0.0000087
2019-11-22 05:58:41,573 - root - INFO - [Epoch 3 Batch 300/850] loss=0.1864, lr=0.0000085
2019-11-22 05:58:51,431 - root - INFO - [Epoch 3 Batch 310/850] loss=0.1961, lr=0.0000084
2019-11-22 05:59:01,057 - root - INFO - [Epoch 3 Batch 320/850] loss=0.1962, lr=0.0000082
2019-11-22 05:59:10,614 - root - INFO - [Epoch 3 Batch 330/850] loss=0.1824, lr=0.0000081
2019-11-22 05:59:20,088 - root - INFO - [Epoch 3 Batch 340/850] loss=0.1908, lr=0.0000079
2019-11-22 05:59:29,662 - root - INFO - [Epoch 3 Batch 350/850] loss=0.1887, lr=0.0000077
2019-11-22 05:59:39,249 - root - INFO - [Epoch 3 Batch 360/850] loss=0.1982, lr=0.0000076
2019-11-22 05:59:48,801 - root - INFO - [Epoch 3 Batch 370/850] loss=0.1742, lr=0.0000074
2019-11-22 05:59:58,289 - root - INFO - [Epoch 3 Batch 380/850] loss=0.1682, lr=0.0000073
2019-11-22 06:00:07,898 - root - INFO - [Epoch 3 Batch 390/850] loss=0.1727, lr=0.0000071
2019-11-22 06:00:17,385 - root - INFO - [Epoch 3 Batch 400/850] loss=0.2093, lr=0.0000070
2019-11-22 06:00:26,949 - root - INFO - [Epoch 3 Batch 410/850] loss=0.1697, lr=0.0000068
2019-11-22 06:00:36,405 - root - INFO - [Epoch 3 Batch 420/850] loss=0.1924, lr=0.0000066
2019-11-22 06:00:46,312 - root - INFO - [Epoch 3 Batch 430/850] loss=0.1999, lr=0.0000065
2019-11-22 06:00:56,182 - root - INFO - [Epoch 3 Batch 440/850] loss=0.2115, lr=0.0000063
2019-11-22 06:01:05,751 - root - INFO - [Epoch 3 Batch 450/850] loss=0.1902, lr=0.0000062
2019-11-22 06:01:15,528 - root - INFO - [Epoch 3 Batch 460/850] loss=0.1754, lr=0.0000060
2019-11-22 06:01:25,989 - root - INFO - [Epoch 3 Batch 470/850] loss=0.1598, lr=0.0000059
2019-11-22 06:01:35,765 - root - INFO - [Epoch 3 Batch 480/850] loss=0.1964, lr=0.0000057
2019-11-22 06:01:45,420 - root - INFO - [Epoch 3 Batch 490/850] loss=0.1938, lr=0.0000055
2019-11-22 06:01:54,934 - root - INFO - [Epoch 3 Batch 500/850] loss=0.1992, lr=0.0000054
2019-11-22 06:02:04,352 - root - INFO - [Epoch 3 Batch 510/850] loss=0.2157, lr=0.0000052
2019-11-22 06:02:13,884 - root - INFO - [Epoch 3 Batch 520/850] loss=0.1880, lr=0.0000051
2019-11-22 06:02:23,287 - root - INFO - [Epoch 3 Batch 530/850] loss=0.1491, lr=0.0000049
2019-11-22 06:02:32,808 - root - INFO - [Epoch 3 Batch 540/850] loss=0.1748, lr=0.0000048
2019-11-22 06:02:42,288 - root - INFO - [Epoch 3 Batch 550/850] loss=0.1623, lr=0.0000046
2019-11-22 06:02:51,798 - root - INFO - [Epoch 3 Batch 560/850] loss=0.1999, lr=0.0000044
2019-11-22 06:03:01,282 - root - INFO - [Epoch 3 Batch 570/850] loss=0.1823, lr=0.0000043
2019-11-22 06:03:11,306 - root - INFO - [Epoch 3 Batch 580/850] loss=0.1461, lr=0.0000041
2019-11-22 06:03:20,826 - root - INFO - [Epoch 3 Batch 590/850] loss=0.2296, lr=0.0000040
2019-11-22 06:03:30,545 - root - INFO - [Epoch 3 Batch 600/850] loss=0.1696, lr=0.0000038
2019-11-22 06:03:40,118 - root - INFO - [Epoch 3 Batch 610/850] loss=0.1625, lr=0.0000037
2019-11-22 06:03:49,605 - root - INFO - [Epoch 3 Batch 620/850] loss=0.1918, lr=0.0000035
2019-11-22 06:03:59,141 - root - INFO - [Epoch 3 Batch 630/850] loss=0.2152, lr=0.0000033
2019-11-22 06:04:08,730 - root - INFO - [Epoch 3 Batch 640/850] loss=0.2105, lr=0.0000032
2019-11-22 06:04:18,178 - root - INFO - [Epoch 3 Batch 650/850] loss=0.1574, lr=0.0000030
2019-11-22 06:04:27,607 - root - INFO - [Epoch 3 Batch 660/850] loss=0.1606, lr=0.0000029
2019-11-22 06:04:37,153 - root - INFO - [Epoch 3 Batch 670/850] loss=0.1510, lr=0.0000027
2019-11-22 06:04:46,866 - root - INFO - [Epoch 3 Batch 680/850] loss=0.1618, lr=0.0000026
2019-11-22 06:04:56,601 - root - INFO - [Epoch 3 Batch 690/850] loss=0.1687, lr=0.0000024
2019-11-22 06:05:06,195 - root - INFO - [Epoch 3 Batch 700/850] loss=0.1742, lr=0.0000022
2019-11-22 06:05:15,947 - root - INFO - [Epoch 3 Batch 710/850] loss=0.2292, lr=0.0000021
2019-11-22 06:05:25,551 - root - INFO - [Epoch 3 Batch 720/850] loss=0.1747, lr=0.0000019
2019-11-22 06:05:35,126 - root - INFO - [Epoch 3 Batch 730/850] loss=0.1724, lr=0.0000018
2019-11-22 06:05:44,776 - root - INFO - [Epoch 3 Batch 740/850] loss=0.1500, lr=0.0000016
2019-11-22 06:05:54,331 - root - INFO - [Epoch 3 Batch 750/850] loss=0.1891, lr=0.0000014
2019-11-22 06:06:03,805 - root - INFO - [Epoch 3 Batch 760/850] loss=0.1720, lr=0.0000013
2019-11-22 06:06:13,517 - root - INFO - [Epoch 3 Batch 770/850] loss=0.2337, lr=0.0000011
2019-11-22 06:06:23,237 - root - INFO - [Epoch 3 Batch 780/850] loss=0.1568, lr=0.0000010
2019-11-22 06:06:32,982 - root - INFO - [Epoch 3 Batch 790/850] loss=0.1699, lr=0.0000008
2019-11-22 06:06:42,482 - root - INFO - [Epoch 3 Batch 800/850] loss=0.1582, lr=0.0000007
2019-11-22 06:06:52,134 - root - INFO - [Epoch 3 Batch 810/850] loss=0.1934, lr=0.0000005
2019-11-22 06:07:01,876 - root - INFO - [Epoch 3 Batch 820/850] loss=0.1527, lr=0.0000003
2019-11-22 06:07:11,453 - root - INFO - [Epoch 3 Batch 830/850] loss=0.1612, lr=0.0000002
2019-11-22 06:07:20,957 - root - INFO - [Epoch 3 Batch 840/850] loss=0.1647, lr=0.0000000
2019-11-22 06:07:30,363 - root - INFO - [Epoch 3 Batch 850/850] loss=0.1760, lr=0.0000000
2019-11-22 06:07:30,364 - root - INFO - Now we are doing evaluation on dev with [gpu(0), gpu(1), gpu(2), gpu(3), gpu(4), gpu(5), gpu(6), gpu(7)].
2019-11-22 06:07:32,057 - root - INFO - [Batch 10/180] loss=0.3530
2019-11-22 06:07:33,705 - root - INFO - [Batch 20/180] loss=0.3588
2019-11-22 06:07:35,360 - root - INFO - [Batch 30/180] loss=0.3454
2019-11-22 06:07:37,023 - root - INFO - [Batch 40/180] loss=0.3490
2019-11-22 06:07:38,681 - root - INFO - [Batch 50/180] loss=0.2852
2019-11-22 06:07:40,337 - root - INFO - [Batch 60/180] loss=0.2797
2019-11-22 06:07:41,994 - root - INFO - [Batch 70/180] loss=0.3353
2019-11-22 06:07:43,625 - root - INFO - [Batch 80/180] loss=0.2068
2019-11-22 06:07:45,251 - root - INFO - [Batch 90/180] loss=0.2605
2019-11-22 06:07:46,883 - root - INFO - [Batch 100/180] loss=0.2257
2019-11-22 06:07:48,503 - root - INFO - [Batch 110/180] loss=0.3264
2019-11-22 06:07:50,131 - root - INFO - [Batch 120/180] loss=0.3295
2019-11-22 06:07:51,834 - root - INFO - [Batch 130/180] loss=0.3784
2019-11-22 06:07:53,524 - root - INFO - [Batch 140/180] loss=0.2255
2019-11-22 06:07:55,204 - root - INFO - [Batch 150/180] loss=0.3496
2019-11-22 06:07:56,850 - root - INFO - [Batch 160/180] loss=0.2885
2019-11-22 06:07:58,502 - root - INFO - [Batch 170/180] loss=0.2510
2019-11-22 06:08:00,065 - root - INFO - [Batch 180/180] loss=0.3296
2019-11-22 06:08:00,117 - root - INFO - validation metrics:accuracy:0.8859
2019-11-22 06:08:00,117 - root - INFO - Time cost=29.75s, throughput=193.59 samples/s
2019-11-22 06:08:01,634 - root - INFO - params saved in: ./output_dir/model_xlnet_QNLI_2.params
2019-11-22 06:08:01,636 - root - INFO - Time cost=848.33s
2019-11-22 06:08:02,196 - root - INFO - Best model at epoch 2. Validation metrics:accuracy:0.8866
2019-11-22 06:08:02,196 - root - INFO - Now we are doing testing on test with [gpu(0), gpu(1), gpu(2), gpu(3), gpu(4), gpu(5), gpu(6), gpu(7)].
2019-11-22 06:08:29,487 - root - INFO - Time cost=27.29s, throughput=211.06 samples/s
