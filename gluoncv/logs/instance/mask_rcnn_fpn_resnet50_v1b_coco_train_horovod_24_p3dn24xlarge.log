(base) [ec2-user@ip-172-31-23-81 ~]$ mpirun --allow-run-as-root -np 192 --hostfile $HOME/hosts_24 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib  -mca              btl_tcp_if_include eth0 -x NCCL_SOCKET_IFNAME=eth0 -x SSH_AGENT_PID -x HOROVOD_TIMELINE=/home/ec2-user/hvd_timeline.json -x LESS_TERMCAP_mb -x HOSTNAME -x LESS_TERMCAP_md -x LESS_TERMCAP_me -x TERM -x SHELL -x NCCL_MIN_NRINGS -x HISTSIZE -x EC2_AMITOOL_HOME -x SSH_CLIENT -x CONDA_SHLVL -x HOROVOD_CYCLE_TIME -x MXNET_CUDNN_SUPPLY_NORMCONV_CONSTANTS -x CONDA_PROMPT_MODIFIER -x PYTHON_INSTALL_LAYOUT -x            MXNET_EXEC_BULK_EXEC_MAX_NODE_TRAIN_FWD -x LESS_TERMCAP_ue -x SSH_TTY -x USER -x LD_LIBRARY_PATH -x LS_COLORS -x CONDA_EXE -x EC2_HOME -x SSH_AUTH_SOCK -x _CE_CONDA -x                  LESS_TERMCAP_us -x MAIL -x PATH -x MXNET_HOROVOD_NUM_GROUPS -x CONDA_PREFIX -x PWD -x JAVA_HOME -x AWS_CLOUDWATCH_HOME -x LANG -x MODULEPATH -x LOADEDMODULES -x NCCL_TREE_THRESHOLD -x  NHWC_BATCHNORM_LAUNCH_MARGIN -x HOROVOD_NUM_STREAMS -x _CE_M -x HISTCONTROL -x SHLVL -x HOME -x AWS_PATH -x HOROVOD_FUSION_THRESHOLD -x HOROVOD_HIERARCHICAL_ALLREDUCE -x                AWS_AUTO_SCALING_HOME -x CONDA_PYTHON_EXE -x LOGNAME -x CVS_RSH -x AWS_ELB_HOME -x SSH_CONNECTION -x MODULESHOME -x OMP_NUM_THREADS -x CONDA_DEFAULT_ENV -x LESSOPEN -x                  MXNET_EXEC_BULK_EXEC_MAX_NODE_TRAIN_BWD -x NCCL_DEBUG -x LESS_TERMCAP_se -x _ -x HOROVOD_STALL_CHECK_TIME_SECONDS -x HOROVOD_STALL_SHUTDOWN_TIME_SECONDS -x HOROVOD_NUM_NCCL_STREAMS -x  HOROVOD_MLSL_BGT_AFFINITY -x HOROVOD_CACHE_CAPACITY -x HOROVOD_NUM_NCCL_STREAMS -x NCCL_NSOCKS_PERTHREAD -x NCCL_SOCKET_NTHREADS -x NCCL_BUFFSIZE -x NCCL_NET_GDR_READ -x HOROVOD_TWO_STAGE_LOOP -x HOROVOD_ALLREDUCE_MODE -x HOROVOD_FIXED_PAYLOAD -x HOROVOD_MPI_THREADS_DISABLE --tag-output /home/ec2-user/ompi_bind_DGX1.sh python -u /home/ec2-user/downloads/float16_train_mask_rcnn_1.py --num-workers 8 --horovod --amp --lr-decay-epoch 10,14 --epochs 12 --log-interval 100 --val-interval 1 --batch-size 192 --use-fpn --lr 0.16 --lr-warmup-factor 0.001 --lr-warmup 1600 --dtype float16 --static-alloc --clip-gradient 1.5 --use-ext
[ip-172-31-23-81:78059] Warning: could not find environment variable "HOROVOD_STALL_CHECK_TIME_SECONDS"
[ip-172-31-23-81:78059] Warning: could not find environment variable "HOROVOD_STALL_SHUTDOWN_TIME_SECONDS"
[ip-172-31-23-81:78059] Warning: could not find environment variable "HOROVOD_MLSL_BGT_AFFINITY"
Warning: Permanently added '172.31.31.75' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.18.11' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.23.210' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.20.168' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.25.110' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.27.136' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.30.0' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.28.74' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.26.113' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.24.33' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.31.198' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.31.89' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.25.102' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.29.10' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.21.213' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.18.51' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.29.214' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.19.121' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.17.121' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.23.167' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.16.190' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.28.105' (ECDSA) to the list of known hosts.
Warning: Permanently added '172.31.31.35' (ECDSA) to the list of known hosts.
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,7]<stderr>:	data: None
[1,7]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,6]<stderr>:	data: None
[1,6]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,162]<stderr>:	data: None
[1,162]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,160]<stderr>:	data: None
[1,160]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,163]<stderr>:	data: None
[1,163]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,164]<stderr>:	data: None
[1,164]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,167]<stderr>:	data: None
[1,167]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,5]<stderr>:	data: None
[1,5]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,110]<stderr>:	data: None
[1,110]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,111]<stderr>:	data: None
[1,111]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,108]<stderr>:	data: None
[1,108]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,83]<stderr>:	data: None
[1,83]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,166]<stderr>:	data: None
[1,166]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,61]<stderr>:	data: None
[1,61]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,3]<stderr>:	data: None
[1,3]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,62]<stderr>:	data: None
[1,62]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,2]<stderr>:	data: None
[1,2]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,21]<stderr>:	data: None
[1,21]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,87]<stderr>:	data: None
[1,87]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,84]<stderr>:	data: None
[1,84]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,85]<stderr>:	data: None
[1,85]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,16]<stderr>:	data: None
[1,16]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,86]<stderr>:	data: None
[1,86]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,56]<stderr>:	data: None
[1,56]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,19]<stderr>:	data: None
[1,19]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,18]<stderr>:	data: None
[1,18]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,63]<stderr>:	data: None
[1,63]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,66]<stderr>:	data: None
[1,66]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,106]<stderr>:	data: None
[1,106]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,81]<stderr>:	data: None
[1,81]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,161]<stderr>:	data: None
[1,161]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,109]<stderr>:	data: None
[1,109]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,82]<stderr>:	data: None
[1,82]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,165]<stderr>:	data: None
[1,165]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,107]<stderr>:	data: None
[1,107]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,104]<stderr>:	data: None
[1,104]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,80]<stderr>:	data: None
[1,80]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,57]<stderr>:	data: None
[1,57]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,17]<stderr>:	data: None
[1,17]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,1]<stderr>:	data: None
[1,1]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,60]<stderr>:	data: None
[1,60]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,105]<stderr>:	data: None
[1,105]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,22]<stderr>:	data: None
[1,22]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,59]<stderr>:	data: None
[1,59]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,58]<stderr>:	data: None
[1,58]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,23]<stderr>:	data: None
[1,23]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,20]<stderr>:	data: None
[1,20]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,128]<stderr>:	data: None
[1,128]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,71]<stderr>:	data: None
[1,71]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,70]<stderr>:	data: None
[1,70]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,69]<stderr>:	data: None
[1,69]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,64]<stderr>:	data: None
[1,64]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,135]<stderr>:	data: None
[1,135]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,130]<stderr>:	data: None
[1,130]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,131]<stderr>:	data: None
[1,131]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,133]<stderr>:	data: None
[1,133]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,67]<stderr>:	data: None
[1,67]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,183]<stderr>:	data: None
[1,183]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,178]<stderr>:	data: None
[1,178]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,182]<stderr>:	data: None
[1,182]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,181]<stderr>:	data: None
[1,181]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,65]<stderr>:	data: None
[1,65]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,32]<stderr>:	data: None
[1,32]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,33]<stderr>:	data: None
[1,33]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,129]<stderr>:	data: None
[1,129]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,132]<stderr>:	data: None
[1,132]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,52]<stderr>:	data: None
[1,52]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,68]<stderr>:	data: None
[1,68]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,54]<stderr>:	data: None
[1,54]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,53]<stderr>:	data: None
[1,53]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,134]<stderr>:	data: None
[1,134]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,37]<stderr>:	data: None
[1,37]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,38]<stderr>:	data: None
[1,38]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,35]<stderr>:	data: None
[1,35]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,34]<stderr>:	data: None
[1,34]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,36]<stderr>:	data: None
[1,36]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,50]<stderr>:	data: None
[1,50]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,48]<stderr>:	data: None
[1,48]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,176]<stderr>:	data: None
[1,176]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,51]<stderr>:	data: None
[1,51]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,177]<stderr>:	data: None
[1,177]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,55]<stderr>:	data: None
[1,55]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,138]<stderr>:	data: None
[1,138]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,39]<stderr>:	data: None
[1,39]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,49]<stderr>:	data: None
[1,49]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,137]<stderr>:	data: None
[1,137]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,112]<stderr>:	data: None
[1,112]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,119]<stderr>:	data: None
[1,119]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,189]<stderr>:	data: None
[1,189]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,30]<stderr>:	data: None
[1,30]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,117]<stderr>:	data: None
[1,117]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,142]<stderr>:	data: None
[1,142]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,25]<stderr>:	data: None
[1,25]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,118]<stderr>:	data: None
[1,118]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,143]<stderr>:	data: None
[1,143]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,191]<stderr>:	data: None
[1,191]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,27]<stderr>:	data: None
[1,27]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,115]<stderr>:	data: None
[1,115]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,141]<stderr>:	data: None
[1,141]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,31]<stderr>:	data: None
[1,31]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,114]<stderr>:	data: None
[1,114]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,187]<stderr>:	data: None
[1,187]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,186]<stderr>:	data: None
[1,186]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,136]<stderr>:	data: None
[1,136]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,9]<stderr>:	data: None
[1,9]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,26]<stderr>:	data: None
[1,26]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,29]<stderr>:	data: None
[1,29]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,127]<stderr>:	data: None
[1,127]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,15]<stderr>:	data: None
[1,15]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,184]<stderr>:	data: None
[1,184]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,149]<stderr>:	data: None
[1,149]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,12]<stderr>:	data: None
[1,12]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,13]<stderr>:	data: None
[1,13]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,14]<stderr>:	data: None
[1,14]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,179]<stderr>:	data: None
[1,179]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,120]<stderr>:	data: None
[1,120]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,113]<stderr>:	data: None
[1,113]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,122]<stderr>:	data: None
[1,122]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,123]<stderr>:	data: None
[1,123]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,124]<stderr>:	data: None
[1,124]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,144]<stderr>:	data: None
[1,144]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,125]<stderr>:	data: None
[1,125]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,126]<stderr>:	data: None
[1,126]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,24]<stderr>:	data: None
[1,24]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,146]<stderr>:	data: None
[1,146]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,174]<stderr>:	data: None
[1,174]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,151]<stderr>:	data: None
[1,151]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,41]<stderr>:	data: None
[1,41]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,121]<stderr>:	data: None
[1,121]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,170]<stderr>:	data: None
[1,170]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,145]<stderr>:	data: None
[1,145]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,173]<stderr>:	data: None
[1,173]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,92]<stderr>:	data: None
[1,92]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,11]<stderr>:	data: None
[1,11]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,190]<stderr>:	data: None
[1,190]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,93]<stderr>:	data: None
[1,93]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,8]<stderr>:	data: None
[1,8]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,72]<stderr>:	data: None
[1,72]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,73]<stderr>:	data: None
[1,73]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,75]<stderr>:	data: None
[1,75]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,172]<stderr>:	data: None
[1,172]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,74]<stderr>:	data: None
[1,74]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,94]<stderr>:	data: None
[1,94]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,44]<stderr>:	data: None
[1,44]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,46]<stderr>:	data: None
[1,46]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,154]<stderr>:	data: None
[1,154]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,169]<stderr>:	data: None
[1,169]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,147]<stderr>:	data: None
[1,147]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,157]<stderr>:	data: None
[1,157]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,10]<stderr>:	data: None
[1,10]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,76]<stderr>:	data: None
[1,76]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,156]<stderr>:	data: None
[1,156]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,90]<stderr>:	data: None
[1,90]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,40]<stderr>:	data: None
[1,40]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,79]<stderr>:	data: None
[1,79]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,43]<stderr>:	data: None
[1,43]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,77]<stderr>:	data: None
[1,77]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,45]<stderr>:	data: None
[1,45]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,78]<stderr>:	data: None
[1,78]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,155]<stderr>:	data: None
[1,155]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,139]<stderr>:	data: None
[1,139]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,153]<stderr>:	data: None
[1,153]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,185]<stderr>:	data: None
[1,185]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,171]<stderr>:	data: None
[1,171]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,47]<stderr>:	data: None
[1,47]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,158]<stderr>:	data: None
[1,158]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,89]<stderr>:	data: None
[1,89]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,91]<stderr>:	data: None
[1,91]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,150]<stderr>:	data: None
[1,150]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,140]<stderr>:	data: None
[1,140]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,88]<stderr>:	data: None
[1,88]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,175]<stderr>:	data: None
[1,175]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,95]<stderr>:	data: None
[1,95]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,168]<stderr>:	data: None
[1,168]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,102]<stderr>:	data: None
[1,102]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,103]<stderr>:	data: None
[1,103]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,101]<stderr>:	data: None
[1,101]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,100]<stderr>:	data: None
[1,100]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,159]<stderr>:	data: None
[1,159]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,98]<stderr>:	data: None
[1,98]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,99]<stderr>:	data: None
[1,99]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,97]<stderr>:	data: None
[1,97]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,96]<stderr>:	data: None
[1,96]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,152]<stderr>:	data: None
[1,152]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,42]<stderr>:	data: None
[1,42]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,4]<stderr>:	data: None
[1,4]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,180]<stderr>:	data: None
[1,180]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,28]<stderr>:	data: None
[1,28]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,116]<stderr>:	data: None
[1,116]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,188]<stderr>:	data: None
[1,188]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,148]<stderr>:	data: None
[1,148]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:1328: UserWarning: Cannot decide type for the following arguments. Consider providing them as input:
[1,0]<stderr>:	data: None
[1,0]<stderr>:  input_sym_arg_type = in_param.infer_type()[0]
[1,5]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,24]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,31]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,90]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,7]<stderr>:[19:21:02] src/storage/storage.cc:[1,7]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,88]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,91]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,26]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,93]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,94]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,2]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,0]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,27]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,95]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,6]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,1]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,29]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,92]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,89]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,25]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,3]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,30]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,28]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,130]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,135]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,133]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,82]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,81]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,63]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,131]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,186]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,52]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,132]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,165]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,53]<stderr>:[19:21:02] src/storage/storage.cc:[1,53]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,85]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,57]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,55]<stderr>:[19:21:02] src/storage/storage.cc[1,55]<stderr>::110: Using GPUPooledRoundedStorageManager.
[1,164]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,37]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,146]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,121]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,20]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,80]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,163]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,149]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,84]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,16]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,51]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,67]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,69]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,98]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,128]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,160]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,109]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,56]<stderr>:[19:21:02] src/storage/storage.cc:110: [1,49]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,56]<stderr>:Using GPUPooledRoundedStorageManager.
[1,134]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,190]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,113]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,83]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,74]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,41]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,147]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,54]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,101]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,157]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,191]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,65]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,71]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,58]<stderr>:[19:21:02] src/storage/storage.cc:110[1,58]<stderr>:: Using GPUPooledRoundedStorageManager.
[1,189]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,34]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,70]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,119]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,62]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,77]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,126]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,144]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,13]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,46]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,106]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,103]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,33]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,79]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,35]<stderr>:[19:21:02] src/storage/storage.cc[1,35]<stderr>::110: Using GPUPooledRoundedStorageManager.
[1,48]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,66]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,50]<stderr>:[19:21:02] src/storage/storage.cc:[1,50]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,127]<stderr>:[19:21:02] src/storage/storage.cc:[1,127]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,59]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,159]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,8]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,40]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,32]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,120]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,61]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,187]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,148]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,117]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,114]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,43]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,75]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,100]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,87]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,107]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,9]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,108]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,174]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,73]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,178]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,122]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,162]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,22]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,64]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,36]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,15]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,112]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,151]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,188]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,14]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,60]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,118]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,47]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,184]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,45]<stderr>:[19:21:02] [1,45]<stderr>:src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,104]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,78]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,111]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,125]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,175]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,18]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,140]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,166]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,116]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,152]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,72]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,176]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,124]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,17]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,143]<stderr>:[19:21:02] src/storage/storage.cc[1,143]<stderr>::110: Using GPUPooledRoundedStorageManager.
[1,19]<stderr>:[19:21:02] src/storage/storage.cc:[1,19]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,39]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,170]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,42]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,168]<stderr>:[19:21:02] src/storage/storage.cc:110[1,168]<stderr>:: Using GPUPooledRoundedStorageManager.
[1,10]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,150]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,167]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,161]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,173]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,177]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,96]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,141]<stderr>:[19:21:02] src/storage/storage.cc:[1,141]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,182]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,102]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,185]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,181]<stderr>:[19:21:02] [1,181]<stderr>:src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,153]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,137]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,76]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,38]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,154]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,142]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,156]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,115]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,44]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,179]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,110]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,155]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,180]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,23]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,136]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,171]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,139]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,169]<stderr>:[19:21:02] src/storage/storage.cc:[1,169]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,11]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,99]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,97]<stderr>:[19:21:02] [1,97]<stderr>:src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,138]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,123]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,129]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,183]<stderr>:[19:21:02] src/storage/storage.cc:[1,183]<stderr>:110: Using GPUPooledRoundedStorageManager.
[1,105]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,86]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,21]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,145]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,68]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,158]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,172]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,12]<stderr>:[19:21:02] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,4]<stderr>:[19:21:03] src/storage/storage.cc:110: Using GPUPooledRoundedStorageManager.
[1,5]<stdout>:loading annotations into memory...
[1,178]<stdout>:loading annotations into memory...
[1,186]<stdout>:loading annotations into memory...
[1,24]<stdout>:loading annotations into memory...
[1,7]<stdout>:loading annotations into memory...
[1,31]<stdout>:loading annotations into memory...
[1,26]<stdout>:loading annotations into memory...
[1,174]<stdout>:loading annotations into memory...
[1,37]<stdout>:loading annotations into memory...
[1,25]<stdout>:loading annotations into memory...
[1,28]<stdout>:loading annotations into memory...
[1,27]<stdout>:loading annotations into memory...
[1,109]<stdout>:loading annotations into memory...
[1,29]<stdout>:loading annotations into memory...
[1,30]<stdout>:loading annotations into memory...
[1,90]<stdout>:loading annotations into memory...
[1,2]<stdout>:loading annotations into memory...
[1,63]<stdout>:loading annotations into memory...
[1,121]<stdout>:loading annotations into memory...
[1,0]<stdout>:loading annotations into memory...
[1,6]<stdout>:loading annotations into memory...
[1,3]<stdout>:loading annotations into memory...
[1,1]<stdout>:loading annotations into memory...
[1,165]<stdout>:loading annotations into memory...
[1,140]<stdout>:loading annotations into memory...
[1,52]<stdout>:loading annotations into memory...
[1,16]<stdout>:loading annotations into memory...
[1,143]<stdout>:loading annotations into memory...
[1,74]<stdout>:loading annotations into memory...
[1,41]<stdout>:loading annotations into memory...
[1,157]<stdout>:loading annotations into memory...
[1,176]<stdout>:loading annotations into memory...
[1,175]<stdout>:loading annotations into memory...
[1,20]<stdout>:loading annotations into memory...
[1,113]<stdout>:loading annotations into memory...
[1,170]<stdout>:loading annotations into memory...
[1,88]<stdout>:loading annotations into memory...
[1,130]<stdout>:loading annotations into memory...
[1,4]<stdout>:loading annotations into memory...
[1,126]<stdout>:loading annotations into memory...
[1,13]<stdout>:loading annotations into memory...
[1,173]<stdout>:loading annotations into memory...
[1,18]<stdout>:loading annotations into memory...
[1,159]<stdout>:loading annotations into memory...
[1,137]<stdout>:loading annotations into memory...
[1,164]<stdout>:loading annotations into memory...
[1,168]<stdout>:loading annotations into memory...
[1,146]<stdout>:loading annotations into memory...
[1,171]<stdout>:loading annotations into memory...
[1,142]<stdout>:loading annotations into memory...
[1,177]<stdout>:loading annotations into memory...
[1,169]<stdout>:loading annotations into memory...
[1,22]<stdout>:loading annotations into memory...
[1,136]<stdout>:loading annotations into memory...
[1,23]<stdout>:loading annotations into memory...
[1,172]<stdout>:loading annotations into memory...
[1,93]<stdout>:loading annotations into memory...
[1,138]<stdout>:loading annotations into memory...
[1,92]<stdout>:loading annotations into memory...
[1,91]<stdout>:loading annotations into memory...
[1,17]<stdout>:loading annotations into memory...
[1,21]<stdout>:loading annotations into memory...
[1,19]<stdout>:loading annotations into memory...
[1,89]<stdout>:loading annotations into memory...
[1,95]<stdout>:loading annotations into memory...
[1,181]<stdout>:loading annotations into memory...
[1,183]<stdout>:loading annotations into memory...
[1,57]<stdout>:loading annotations into memory...
[1,163]<stdout>:loading annotations into memory...
[1,82]<stdout>:loading annotations into memory...
[1,139]<stdout>:loading annotations into memory...
[1,179]<stdout>:loading annotations into memory...
[1,94]<stdout>:loading annotations into memory...
[1,141]<stdout>:loading annotations into memory...
[1,98]<stdout>:loading annotations into memory...
[1,182]<stdout>:loading annotations into memory...
[1,180]<stdout>:loading annotations into memory...
[1,152]<stdout>:loading annotations into memory...
[1,106]<stdout>:loading annotations into memory...
[1,162]<stdout>:loading annotations into memory...
[1,160]<stdout>:loading annotations into memory...
[1,34]<stdout>:loading annotations into memory...
[1,167]<stdout>:loading annotations into memory...
[1,161]<stdout>:loading annotations into memory...
[1,67]<stdout>:loading annotations into memory...
[1,127]<stdout>:loading annotations into memory...
[1,166]<stdout>:loading annotations into memory...
[1,119]<stdout>:loading annotations into memory...
[1,190]<stdout>:loading annotations into memory...
[1,81]<stdout>:loading annotations into memory...
[1,154]<stdout>:loading annotations into memory...
[1,120]<stdout>:loading annotations into memory...
[1,122]<stdout>:loading annotations into memory...
[1,107]<stdout>:loading annotations into memory...
[1,123]<stdout>:loading annotations into memory...
[1,149]<stdout>:loading annotations into memory...
[1,101]<stdout>:loading annotations into memory...
[1,133]<stdout>:loading annotations into memory...
[1,124]<stdout>:loading annotations into memory...
[1,125]<stdout>:loading annotations into memory...
[1,155]<stdout>:loading annotations into memory...
[1,158]<stdout>:loading annotations into memory...
[1,8]<stdout>:loading annotations into memory...
[1,77]<stdout>:loading annotations into memory...
[1,46]<stdout>:loading annotations into memory...
[1,153]<stdout>:loading annotations into memory...
[1,135]<stdout>:loading annotations into memory...
[1,108]<stdout>:loading annotations into memory...
[1,111]<stdout>:loading annotations into memory...
[1,104]<stdout>:loading annotations into memory...
[1,105]<stdout>:loading annotations into memory...
[1,156]<stdout>:loading annotations into memory...
[1,110]<stdout>:loading annotations into memory...
[1,191]<stdout>:loading annotations into memory...
[1,69]<stdout>:loading annotations into memory...
[1,189]<stdout>:loading annotations into memory...
[1,103]<stdout>:loading annotations into memory...
[1,85]<stdout>:loading annotations into memory...
[1,56]<stdout>:loading annotations into memory...
[1,187]<stdout>:loading annotations into memory...
[1,185]<stdout>:loading annotations into memory...
[1,100]<stdout>:loading annotations into memory...
[1,35]<stdout>:loading annotations into memory...
[1,184]<stdout>:loading annotations into memory...
[1,61]<stdout>:loading annotations into memory...
[1,62]<stdout>:loading annotations into memory...
[1,132]<stdout>:loading annotations into memory...
[1,70]<stdout>:loading annotations into memory...
[1,188]<stdout>:loading annotations into memory...
[1,131]<stdout>:loading annotations into memory...
[1,128]<stdout>:loading annotations into memory...
[1,147]<stdout>:loading annotations into memory...
[1,129]<stdout>:loading annotations into memory...
[1,83]<stdout>:loading annotations into memory...
[1,134]<stdout>:loading annotations into memory...
[1,58]<stdout>:loading annotations into memory...
[1,59]<stdout>:loading annotations into memory...
[1,87]<stdout>:loading annotations into memory...
[1,65]<stdout>:loading annotations into memory...
[1,144]<stdout>:loading annotations into memory...
[1,86]<stdout>:loading annotations into memory...
[1,14]<stdout>:loading annotations into memory...
[1,39]<stdout>:loading annotations into memory...
[1,10]<stdout>:loading annotations into memory...
[1,9]<stdout>:loading annotations into memory...
[1,32]<stdout>:loading annotations into memory...
[1,38]<stdout>:loading annotations into memory...
[1,60]<stdout>:loading annotations into memory...
[1,79]<stdout>:loading annotations into memory...
[1,36]<stdout>:loading annotations into memory...
[1,55]<stdout>:loading annotations into memory...
[1,117]<stdout>:loading annotations into memory...
[1,84]<stdout>:loading annotations into memory...
[1,11]<stdout>:loading annotations into memory...
[1,15]<stdout>:loading annotations into memory...
[1,71]<stdout>:loading annotations into memory...
[1,96]<stdout>:loading annotations into memory...
[1,148]<stdout>:loading annotations into memory...
[1,64]<stdout>:loading annotations into memory...
[1,66]<stdout>:loading annotations into memory...
[1,68]<stdout>:loading annotations into memory...
[1,80]<stdout>:loading annotations into memory...
[1,150]<stdout>:loading annotations into memory...
[1,151]<stdout>:loading annotations into memory...
[1,33]<stdout>:loading annotations into memory...
[1,12]<stdout>:loading annotations into memory...
[1,40]<stdout>:loading annotations into memory...
[1,53]<stdout>:loading annotations into memory...
[1,99]<stdout>:loading annotations into memory...
[1,102]<stdout>:loading annotations into memory...
[1,145]<stdout>:loading annotations into memory...
[1,73]<stdout>:loading annotations into memory...
[1,75]<stdout>:loading annotations into memory...
[1,97]<stdout>:loading annotations into memory...
[1,49]<stdout>:loading annotations into memory...
[1,114]<stdout>:loading annotations into memory...
[1,72]<stdout>:loading annotations into memory...
[1,112]<stdout>:loading annotations into memory...
[1,116]<stdout>:loading annotations into memory...
[1,118]<stdout>:loading annotations into memory...
[1,42]<stdout>:loading annotations into memory...
[1,76]<stdout>:loading annotations into memory...
[1,78]<stdout>:loading annotations into memory...
[1,50]<stdout>:loading annotations into memory...
[1,48]<stdout>:loading annotations into memory...
[1,115]<stdout>:loading annotations into memory...
[1,51]<stdout>:loading annotations into memory...
[1,44]<stdout>:loading annotations into memory...
[1,45]<stdout>:loading annotations into memory...
[1,47]<stdout>:loading annotations into memory...
[1,43]<stdout>:loading annotations into memory...
[1,54]<stdout>:loading annotations into memory...
[1,178]<stdout>:Done (t=13.52s)
[1,178]<stdout>:creating index...
[1,186]<stdout>:Done (t=13.54s)
[1,186]<stdout>:creating index...
[1,5]<stdout>:Done (t=13.80s)
[1,5]<stdout>:creating index...
[1,31]<stdout>:Done (t=13.66s)
[1,31]<stdout>:creating index...
[1,174]<stdout>:Done (t=13.66s)
[1,174]<stdout>:creating index...
[1,7]<stdout>:Done (t=13.70s)
[1,7]<stdout>:creating index...
[1,37]<stdout>:Done (t=13.70s)
[1,37]<stdout>:creating index...
[1,26]<stdout>:Done (t=13.74s)
[1,26]<stdout>:creating index...
[1,63]<stdout>:Done (t=13.59s)
[1,63]<stdout>:creating index...
[1,109]<stdout>:Done (t=13.69s)
[1,109]<stdout>:creating index...
[1,2]<stdout>:Done (t=13.67s)
[1,2]<stdout>:creating index...
[1,24]<stdout>:Done (t=13.88s)
[1,24]<stdout>:creating index...
[1,6]<stdout>:Done (t=13.66s)
[1,6]<stdout>:creating index...
[1,52]<stdout>:Done (t=13.63s)
[1,52]<stdout>:creating index...
[1,176]<stdout>:Done (t=13.57s)
[1,176]<stdout>:creating index...
[1,74]<stdout>:Done (t=13.63s)
[1,74]<stdout>:creating index...
[1,3]<stdout>:Done (t=13.74s)
[1,3]<stdout>:creating index...
[1,27]<stdout>:Done (t=13.85s)
[1,27]<stdout>:creating index...
[1,157]<stdout>:Done (t=13.64s)
[1,157]<stdout>:creating index...
[1,0]<stdout>:Done (t=13.78s)
[1,0]<stdout>:creating index...
[1,1]<stdout>:Done (t=13.77s)
[1,1]<stdout>:creating index...
[1,127]<stdout>:Done (t=13.48s)
[1,127]<stdout>:creating index...
[1,170]<stdout>:Done (t=13.67s)
[1,170]<stdout>:creating index...
[1,124]<stdout>:Done (t=13.46s)
[1,124]<stdout>:creating index...
[1,67]<stdout>:Done (t=13.52s)
[1,67]<stdout>:creating index...
[1,90]<stdout>:Done (t=13.97s)
[1,90]<stdout>:creating index...
[1,138]<stdout>:Done (t=13.64s)
[1,138]<stdout>:creating index...
[1,125]<stdout>:Done (t=13.50s)
[1,125]<stdout>:creating index...
[1,29]<stdout>:Done (t=14.01s)
[1,29]<stdout>:creating index...
[1,13]<stdout>:Done (t=13.69s)
[1,13]<stdout>:creating index...
[1,95]<stdout>:Done (t=13.65s)
[1,95]<stdout>:creating index...
[1,120]<stdout>:Done (t=13.53s)
[1,120]<stdout>:creating index...
[1,133]<stdout>:Done (t=13.52s)
[1,133]<stdout>:creating index...
[1,135]<stdout>:Done (t=13.51s)
[1,135]<stdout>:creating index...
[1,34]<stdout>:Done (t=13.60s)
[1,34]<stdout>:creating index...
[1,165]<stdout>:Done (t=13.94s)
[1,165]<stdout>:creating index...
[1,175]<stdout>:Done (t=13.81s)
[1,175]<stdout>:creating index...
[1,123]<stdout>:Done (t=13.55s)
[1,123]<stdout>:creating index...
[1,140]<stdout>:Done (t=13.95s)
[1,140]<stdout>:creating index...
[1,89]<stdout>:Done (t=13.70s)
[1,89]<stdout>:creating index...
[1,181]<stdout>:Done (t=13.70s)
[1,181]<stdout>:creating index...
[1,178]<stdout>:index created!
[1,177]<stdout>:Done (t=13.73s)
[1,177]<stdout>:creating index...
[1,143]<stdout>:Done (t=13.91s)
[1,143]<stdout>:creating index...
[1,93]<stdout>:Done (t=13.73s)
[1,93]<stdout>:creating index...
[1,164]<stdout>:Done (t=13.74s)
[1,164]<stdout>:creating index...
[1,134]<stdout>:Done (t=13.48s)
[1,134]<stdout>:creating index...
[1,132]<stdout>:Done (t=13.49s)
[1,132]<stdout>:creating index...
[1,179]<stdout>:Done (t=13.70s)
[1,179]<stdout>:creating index...
[1,159]<stdout>:Done (t=13.76s)
[1,159]<stdout>:creating index...
[1,121]<stdout>:Done (t=14.01s)
[1,121]<stdout>:creating index...
[1,187]<stdout>:Done (t=13.51s)
[1,187]<stdout>:creating index...
[1,186]<stdout>:index created!
[1,183]<stdout>:Done (t=13.73s)
[1,183]<stdout>:creating index...
[1,25]<stdout>:Done (t=14.13s)
[1,25]<stdout>:creating index...
[1,144]<stdout>:Done (t=13.51s)
[1,144]<stdout>:creating index...
[1,16]<stdout>:Done (t=13.96s)
[1,16]<stdout>:creating index...
[1,46]<stdout>:Done (t=13.60s)
[1,46]<stdout>:creating index...
[1,98]<stdout>:Done (t=13.74s)
[1,98]<stdout>:creating index...
[1,137]<stdout>:Done (t=13.80s)
[1,137]<stdout>:creating index...
[1,185]<stdout>:Done (t=13.56s)
[1,185]<stdout>:creating index...
[1,146]<stdout>:Done (t=13.81s)
[1,146]<stdout>:creating index...
[1,126]<stdout>:Done (t=13.83s)
[1,126]<stdout>:creating index...
[1,30]<stdout>:Done (t=14.15s)
[1,30]<stdout>:creating index...
[1,91]<stdout>:Done (t=13.79s)
[1,91]<stdout>:creating index...
[1,106]<stdout>:Done (t=13.76s)
[1,106]<stdout>:creating index...
[1,139]<stdout>:Done (t=13.79s)
[1,139]<stdout>:creating index...
[1,128]<stdout>:Done (t=13.59s)
[1,128]<stdout>:creating index...
[1,167]<stdout>:Done (t=13.75s)
[1,167]<stdout>:creating index...
[1,147]<stdout>:Done (t=13.60s)
[1,147]<stdout>:creating index...
[1,62]<stdout>:Done (t=13.61s)
[1,62]<stdout>:creating index...
[1,66]<stdout>:Done (t=13.58s)
[1,66]<stdout>:creating index...
[1,158]<stdout>:Done (t=13.69s)
[1,158]<stdout>:creating index...
[1,69]<stdout>:Done (t=13.64s)
[1,69]<stdout>:creating index...
[1,108]<stdout>:Done (t=13.68s)
[1,108]<stdout>:creating index...
[1,28]<stdout>:Done (t=14.23s)
[1,28]<stdout>:creating index...
[1,53]<stdout>:Done (t=13.59s)
[1,53]<stdout>:creating index...
[1,162]<stdout>:Done (t=13.79s)
[1,162]<stdout>:creating index...
[1,57]<stdout>:Done (t=13.84s)
[1,57]<stdout>:creating index...
[1,32]<stdout>:Done (t=13.61s)
[1,32]<stdout>:creating index...
[1,75]<stdout>:Done (t=13.60s)
[1,75]<stdout>:creating index...
[1,119]<stdout>:Done (t=13.74s)
[1,119]<stdout>:creating index...
[1,129]<stdout>:Done (t=13.62s)
[1,129]<stdout>:creating index...
[1,130]<stdout>:Done (t=13.93s)
[1,130]<stdout>:creating index...
[1,107]<stdout>:Done (t=13.73s)
[1,107]<stdout>:creating index...
[1,172]<stdout>:Done (t=13.89s)
[1,172]<stdout>:creating index...
[1,21]<stdout>:Done (t=13.88s)
[1,21]<stdout>:creating index...
[1,72]<stdout>:Done (t=13.59s)
[1,72]<stdout>:creating index...
[1,23]<stdout>:Done (t=13.90s)
[1,23]<stdout>:creating index...
[1,55]<stdout>:Done (t=13.64s)
[1,55]<stdout>:creating index...
[1,81]<stdout>:Done (t=13.76s)
[1,81]<stdout>:creating index...
[1,155]<stdout>:Done (t=13.74s)
[1,155]<stdout>:creating index...
[1,122]<stdout>:Done (t=13.76s)
[1,122]<stdout>:creating index...
[1,70]<stdout>:Done (t=13.67s)
[1,70]<stdout>:creating index...
[1,101]<stdout>:Done (t=13.76s)
[1,101]<stdout>:creating index...
[1,136]<stdout>:Done (t=13.92s)
[1,136]<stdout>:creating index...
[1,73]<stdout>:Done (t=13.64s)
[1,73]<stdout>:creating index...
[1,131]<stdout>:Done (t=13.68s)
[1,131]<stdout>:creating index...
[1,180]<stdout>:Done (t=13.88s)
[1,180]<stdout>:creating index...
[1,49]<stdout>:Done (t=13.64s)
[1,49]<stdout>:creating index...
[1,113]<stdout>:Done (t=14.01s)
[1,113]<stdout>:creating index...
[1,35]<stdout>:Done (t=13.69s)
[1,35]<stdout>:creating index...
[1,149]<stdout>:Done (t=13.78s)
[1,149]<stdout>:creating index...
[1,4]<stdout>:Done (t=13.97s)
[1,4]<stdout>:creating index...
[1,111]<stdout>:Done (t=13.75s)
[1,111]<stdout>:creating index...
[1,160]<stdout>:Done (t=13.88s)
[1,160]<stdout>:creating index...
[1,50]<stdout>:Done (t=13.65s)
[1,50]<stdout>:creating index...
[1,92]<stdout>:Done (t=13.95s)
[1,92]<stdout>:creating index...
[1,100]<stdout>:Done (t=13.72s)
[1,100]<stdout>:creating index...
[1,71]<stdout>:Done (t=13.69s)
[1,71]<stdout>:creating index...
[1,182]<stdout>:Done (t=13.91s)
[1,182]<stdout>:creating index...
[1,173]<stdout>:Done (t=13.99s)
[1,173]<stdout>:creating index...
[1,17]<stdout>:Done (t=13.95s)
[1,17]<stdout>:creating index...
[1,184]<stdout>:Done (t=13.73s)
[1,184]<stdout>:creating index...
[1,19]<stdout>:Done (t=13.95s)
[1,19]<stdout>:creating index...
[1,169]<stdout>:Done (t=13.98s)
[1,169]<stdout>:creating index...
[1,142]<stdout>:Done (t=13.99s)
[1,142]<stdout>:creating index...
[1,8]<stdout>:Done (t=13.82s)
[1,8]<stdout>:creating index...
[1,5]<stdout>:index created!
[1,12]<stdout>:Done (t=13.71s)
[1,12]<stdout>:creating index...
[1,48]<stdout>:Done (t=13.68s)
[1,48]<stdout>:creating index...
[1,103]<stdout>:Done (t=13.77s)
[1,103]<stdout>:creating index...
[1,31]<stdout>:index created!
[1,174]<stdout>:index created!
[1,188]<stdout>:Done (t=13.74s)
[1,188]<stdout>:creating index...
[1,38]<stdout>:Done (t=13.73s)
[1,38]<stdout>:creating index...
[1,36]<stdout>:Done (t=13.73s)
[1,36]<stdout>:creating index...
[1,168]<stdout>:Done (t=14.01s)
[1,168]<stdout>:creating index...
[1,85]<stdout>:Done (t=13.78s)
[1,85]<stdout>:creating index...
[1,148]<stdout>:Done (t=13.73s)
[1,148]<stdout>:creating index...
[1,152]<stdout>:Done (t=13.95s)
[1,152]<stdout>:creating index...
[1,117]<stdout>:Done (t=13.75s)
[1,117]<stdout>:creating index...
[1,96]<stdout>:Done (t=13.74s)
[1,96]<stdout>:creating index...
[1,7]<stdout>:index created!
[1,161]<stdout>:Done (t=13.91s)
[1,161]<stdout>:creating index...
[1,68]<stdout>:Done (t=13.75s)
[1,68]<stdout>:creating index...
[1,151]<stdout>:Done (t=13.75s)
[1,151]<stdout>:creating index...
[1,58]<stdout>:Done (t=13.77s)
[1,58]<stdout>:creating index...
[1,97]<stdout>:Done (t=13.75s)
[1,97]<stdout>:creating index...
[1,18]<stdout>:Done (t=14.06s)
[1,18]<stdout>:creating index...
[1,141]<stdout>:Done (t=14.00s)
[1,141]<stdout>:creating index...
[1,44]<stdout>:Done (t=13.73s)
[1,44]<stdout>:creating index...
[1,118]<stdout>:Done (t=13.74s)
[1,118]<stdout>:creating index...
[1,163]<stdout>:Done (t=14.01s)
[1,163]<stdout>:creating index...
[1,51]<stdout>:Done (t=13.73s)
[1,51]<stdout>:creating index...
[1,41]<stdout>:Done (t=14.21s)
[1,41]<stdout>:creating index...
[1,114]<stdout>:Done (t=13.76s)
[1,114]<stdout>:creating index...
[1,37]<stdout>:index created!
[1,45]<stdout>:Done (t=13.74s)
[1,45]<stdout>:creating index...
[1,87]<stdout>:Done (t=13.79s)
[1,87]<stdout>:creating index...
[1,78]<stdout>:Done (t=13.75s)
[1,78]<stdout>:creating index...
[1,86]<stdout>:Done (t=13.80s)
[1,86]<stdout>:creating index...
[1,63]<stdout>:index created!
[1,189]<stdout>:Done (t=13.85s)
[1,189]<stdout>:creating index...
[1,79]<stdout>:Done (t=13.81s)
[1,79]<stdout>:creating index...
[1,26]<stdout>:index created!
[1,190]<stdout>:Done (t=13.95s)
[1,190]<stdout>:creating index...
[1,109]<stdout>:index created!
[1,115]<stdout>:Done (t=13.79s)
[1,115]<stdout>:creating index...
[1,171]<stdout>:Done (t=14.10s)
[1,171]<stdout>:creating index...
[1,15]<stdout>:Done (t=13.83s)
[1,15]<stdout>:creating index...
[1,82]<stdout>:Done (t=14.07s)
[1,82]<stdout>:creating index...
[1,88]<stdout>:Done (t=14.16s)
[1,88]<stdout>:creating index...
[1,11]<stdout>:Done (t=13.85s)
[1,11]<stdout>:creating index...
[1,99]<stdout>:Done (t=13.84s)
[1,99]<stdout>:creating index...
[1,154]<stdout>:Done (t=13.97s)
[1,154]<stdout>:creating index...
[1,145]<stdout>:Done (t=13.85s)
[1,145]<stdout>:creating index...
[1,80]<stdout>:Done (t=13.86s)
[1,80]<stdout>:creating index...
[1,2]<stdout>:index created!
[1,116]<stdout>:Done (t=13.83s)
[1,116]<stdout>:creating index...
[1,22]<stdout>:Done (t=14.14s)
[1,22]<stdout>:creating index...
[1,43]<stdout>:Done (t=13.83s)
[1,43]<stdout>:creating index...
[1,65]<stdout>:Done (t=13.90s)
[1,65]<stdout>:creating index...
[1,84]<stdout>:Done (t=13.90s)
[1,84]<stdout>:creating index...
[1,110]<stdout>:Done (t=13.97s)
[1,110]<stdout>:creating index...
[1,60]<stdout>:Done (t=13.92s)
[1,60]<stdout>:creating index...
[1,6]<stdout>:index created!
[1,24]<stdout>:index created!
[1,52]<stdout>:index created!
[1,74]<stdout>:index created!
[1,76]<stdout>:Done (t=13.91s)
[1,76]<stdout>:creating index...
[1,176]<stdout>:index created!
[1,83]<stdout>:Done (t=13.97s)
[1,83]<stdout>:creating index...
[1,39]<stdout>:Done (t=13.97s)
[1,39]<stdout>:creating index...
[1,102]<stdout>:Done (t=13.96s)
[1,102]<stdout>:creating index...
[1,10]<stdout>:Done (t=13.98s)
[1,10]<stdout>:creating index...
[1,47]<stdout>:Done (t=13.94s)
[1,47]<stdout>:creating index...
[1,77]<stdout>:Done (t=14.08s)
[1,77]<stdout>:creating index...
[1,150]<stdout>:Done (t=13.98s)
[1,150]<stdout>:creating index...
[1,105]<stdout>:Done (t=14.07s)
[1,105]<stdout>:creating index...
[1,3]<stdout>:index created!
[1,157]<stdout>:index created!
[1,27]<stdout>:index created!
[1,61]<stdout>:Done (t=14.04s)
[1,61]<stdout>:creating index...
[1,33]<stdout>:Done (t=14.02s)
[1,33]<stdout>:creating index...
[1,112]<stdout>:Done (t=13.99s)
[1,112]<stdout>:creating index...
[1,0]<stdout>:index created!
[1,64]<stdout>:Done (t=14.03s)
[1,64]<stdout>:creating index...
[1,14]<stdout>:Done (t=14.04s)
[1,14]<stdout>:creating index...
[1,104]<stdout>:Done (t=14.11s)
[1,104]<stdout>:creating index...
[1,1]<stdout>:index created!
[1,9]<stdout>:Done (t=14.05s)
[1,9]<stdout>:creating index...
[1,56]<stdout>:Done (t=14.09s)
[1,56]<stdout>:creating index...
[1,59]<stdout>:Done (t=14.07s)
[1,59]<stdout>:creating index...
[1,153]<stdout>:Done (t=14.15s)
[1,153]<stdout>:creating index...
[1,40]<stdout>:Done (t=14.08s)
[1,40]<stdout>:creating index...
[1,127]<stdout>:index created!
[1,170]<stdout>:index created!
[1,156]<stdout>:Done (t=14.17s)
[1,156]<stdout>:creating index...
[1,166]<stdout>:Done (t=14.26s)
[1,166]<stdout>:creating index...
[1,42]<stdout>:Done (t=14.08s)
[1,42]<stdout>:creating index...
[1,124]<stdout>:index created!
[1,67]<stdout>:index created!
[1,54]<stdout>:Done (t=14.06s)
[1,54]<stdout>:creating index...
[1,20]<stdout>:Done (t=14.49s)
[1,20]<stdout>:creating index...
[1,138]<stdout>:index created!
[1,94]<stdout>:Done (t=14.38s)
[1,94]<stdout>:creating index...
[1,90]<stdout>:index created!
[1,13]<stdout>:index created!
[1,95]<stdout>:index created!
[1,125]<stdout>:index created!
[1,29]<stdout>:index created!
[1,120]<stdout>:index created!
[1,135]<stdout>:index created!
[1,34]<stdout>:index created!
[1,133]<stdout>:index created!
[1,165]<stdout>:index created!
[1,175]<stdout>:index created!
[1,123]<stdout>:index created!
[1,177]<stdout>:index created!
[1,89]<stdout>:index created!
[1,93]<stdout>:index created!
[1,181]<stdout>:index created!
[1,164]<stdout>:index created!
[1,140]<stdout>:index created!
[1,187]<stdout>:index created!
[1,134]<stdout>:index created!
[1,179]<stdout>:index created!
[1,132]<stdout>:index created!
[1,143]<stdout>:index created!
[1,159]<stdout>:index created!
[1,144]<stdout>:index created!
[1,183]<stdout>:index created!
[1,25]<stdout>:index created!
[1,46]<stdout>:index created!
[1,121]<stdout>:index created!
[1,185]<stdout>:index created!
[1,98]<stdout>:index created!
[1,146]<stdout>:index created!
[1,16]<stdout>:index created!
[1,137]<stdout>:index created!
[1,30]<stdout>:index created!
[1,126]<stdout>:index created!
[1,91]<stdout>:index created!
[1,106]<stdout>:index created!
[1,191]<stdout>:Done (t=14.39s)
[1,191]<stdout>:creating index...
[1,108]<stdout>:index created!
[1,139]<stdout>:index created!
[1,158]<stdout>:index created!
[1,62]<stdout>:index created!
[1,128]<stdout>:index created!
[1,147]<stdout>:index created!
[1,66]<stdout>:index created!
[1,167]<stdout>:index created!
[1,53]<stdout>:index created!
[1,28]<stdout>:index created!
[1,69]<stdout>:index created!
[1,32]<stdout>:index created!
[1,57]<stdout>:index created!
[1,72]<stdout>:index created!
[1,107]<stdout>:index created!
[1,75]<stdout>:index created!
[1,119]<stdout>:index created!
[1,162]<stdout>:index created!
[1,129]<stdout>:index created!
[1,130]<stdout>:index created!
[1,122]<stdout>:index created!
[1,172]<stdout>:index created!
[1,55]<stdout>:index created!
[1,21]<stdout>:index created!
[1,81]<stdout>:index created!
[1,23]<stdout>:index created!
[1,155]<stdout>:index created!
[1,70]<stdout>:index created!
[1,101]<stdout>:index created!
[1,73]<stdout>:index created!
[1,4]<stdout>:index created!
[1,136]<stdout>:index created!
[1,49]<stdout>:index created!
[1,113]<stdout>:index created!
[1,131]<stdout>:index created!
[1,149]<stdout>:index created!
[1,35]<stdout>:index created!
[1,111]<stdout>:index created!
[1,184]<stdout>:index created!
[1,173]<stdout>:index created!
[1,92]<stdout>:index created!
[1,180]<stdout>:index created!
[1,50]<stdout>:index created!
[1,100]<stdout>:index created!
[1,71]<stdout>:index created!
[1,160]<stdout>:index created!
[1,182]<stdout>:index created!
[1,12]<stdout>:index created!
[1,17]<stdout>:index created!
[1,188]<stdout>:index created!
[1,142]<stdout>:index created!
[1,38]<stdout>:index created!
[1,48]<stdout>:index created!
[1,8]<stdout>:index created!
[1,36]<stdout>:index created!
[1,103]<stdout>:index created!
[1,148]<stdout>:index created!
[1,85]<stdout>:index created!
[1,169]<stdout>:index created!
[1,96]<stdout>:index created!
[1,19]<stdout>:index created!
[1,117]<stdout>:index created!
[1,168]<stdout>:index created!
[1,68]<stdout>:index created!
[1,58]<stdout>:index created!
[1,152]<stdout>:index created!
[1,151]<stdout>:index created!
[1,18]<stdout>:index created!
[1,51]<stdout>:index created!
[1,118]<stdout>:index created!
[1,44]<stdout>:index created!
[1,97]<stdout>:index created!
[1,87]<stdout>:index created!
[1,161]<stdout>:index created!
[1,45]<stdout>:index created!
[1,78]<stdout>:index created!
[1,114]<stdout>:index created!
[1,189]<stdout>:index created!
[1,86]<stdout>:index created!
[1,79]<stdout>:index created!
[1,163]<stdout>:index created!
[1,141]<stdout>:index created!
[1,41]<stdout>:index created!
[1,190]<stdout>:index created!
[1,15]<stdout>:index created!
[1,115]<stdout>:index created!
[1,171]<stdout>:index created!
[1,82]<stdout>:index created!
[1,88]<stdout>:index created!
[1,154]<stdout>:index created!
[1,11]<stdout>:index created!
[1,99]<stdout>:index created!
[1,145]<stdout>:index created!
[1,116]<stdout>:index created!
[1,80]<stdout>:index created!
[1,65]<stdout>:index created!
[1,43]<stdout>:index created!
[1,22]<stdout>:index created!
[1,60]<stdout>:index created!
[1,110]<stdout>:index created!
[1,84]<stdout>:index created!
[1,83]<stdout>:index created!
[1,76]<stdout>:index created!
[1,39]<stdout>:index created!
[1,102]<stdout>:index created!
[1,10]<stdout>:index created!
[1,150]<stdout>:index created!
[1,77]<stdout>:index created!
[1,61]<stdout>:index created!
[1,47]<stdout>:index created!
[1,105]<stdout>:index created!
[1,14]<stdout>:index created!
[1,112]<stdout>:index created!
[1,64]<stdout>:index created!
[1,33]<stdout>:index created!
[1,104]<stdout>:index created!
[1,56]<stdout>:index created!
[1,9]<stdout>:index created!
[1,59]<stdout>:index created!
[1,153]<stdout>:index created!
[1,156]<stdout>:index created!
[1,40]<stdout>:index created!
[1,166]<stdout>:index created!
[1,42]<stdout>:index created!
[1,54]<stdout>:index created!
[1,20]<stdout>:index created!
[1,94]<stdout>:index created!
[1,191]<stdout>:index created!
[1,186]<stdout>:loading annotations into memory...
[1,178]<stdout>:loading annotations into memory...
[1,174]<stdout>:loading annotations into memory...
[1,186]<stdout>:Done (t=0.38s)
[1,186]<stdout>:creating index...
[1,186]<stdout>:index created!
[1,178]<stdout>:Done (t=0.38s)
[1,178]<stdout>:creating index...
[1,178]<stdout>:index created!
[1,31]<stdout>:loading annotations into memory...
[1,0]<stdout>:loading annotations into memory...
[1,63]<stdout>:loading annotations into memory...
[1,5]<stdout>:loading annotations into memory...
[1,2]<stdout>:loading annotations into memory...
[1,109]<stdout>:loading annotations into memory...
[1,90]<stdout>:loading annotations into memory...
[1,183]<stdout>:loading annotations into memory...
[1,37]<stdout>:loading annotations into memory...
[1,93]<stdout>:loading annotations into memory...
[1,7]<stdout>:loading annotations into memory...
[1,174]<stdout>:Done (t=0.38s)
[1,174]<stdout>:creating index...
[1,125]<stdout>:loading annotations into memory...
[1,174]<stdout>:index created!
[1,170]<stdout>:loading annotations into memory...
[1,132]<stdout>:loading annotations into memory...
[1,133]<stdout>:loading annotations into memory...
[1,13]<stdout>:loading annotations into memory...
[1,66]<stdout>:loading annotations into memory...
[1,31]<stdout>:Done (t=0.38s)
[1,31]<stdout>:creating index...
[1,67]<stdout>:loading annotations into memory...
[1,0]<stdout>:Done (t=0.39s)
[1,0]<stdout>:creating index...
[1,31]<stdout>:index created!
[1,0]<stdout>:index created!
[1,6]<stdout>:loading annotations into memory...
[1,72]<stdout>:loading annotations into memory...
[1,177]<stdout>:loading annotations into memory...
[1,175]<stdout>:loading annotations into memory...
[1,95]<stdout>:loading annotations into memory...
[1,63]<stdout>:Done (t=0.39s)
[1,63]<stdout>:creating index...
[1,1]<stdout>:loading annotations into memory...
[1,3]<stdout>:loading annotations into memory...
[1,5]<stdout>:Done (t=0.39s)
[1,5]<stdout>:creating index...
[1,63]<stdout>:index created!
[1,85]<stdout>:loading annotations into memory...
[1,187]<stdout>:loading annotations into memory...
[1,5]<stdout>:index created!
[1,2]<stdout>:Done (t=0.39s)
[1,2]<stdout>:creating index...
[1,126]<stdout>:loading annotations into memory...
[1,2]<stdout>:index created!
[1,164]<stdout>:loading annotations into memory...
[1,130]<stdout>:loading annotations into memory...
[1,109]<stdout>:Done (t=0.39s)
[1,109]<stdout>:creating index...
[1,157]<stdout>:loading annotations into memory...
[1,185]<stdout>:loading annotations into memory...
[1,131]<stdout>:loading annotations into memory...
[1,165]<stdout>:loading annotations into memory...
[1,184]<stdout>:loading annotations into memory...
[1,124]<stdout>:loading annotations into memory...
[1,109]<stdout>:index created!
[1,137]<stdout>:loading annotations into memory...
[1,89]<stdout>:loading annotations into memory...
[1,98]<stdout>:loading annotations into memory...
[1,23]<stdout>:loading annotations into memory...
[1,101]<stdout>:loading annotations into memory...
[1,90]<stdout>:Done (t=0.40s)
[1,90]<stdout>:creating index...
[1,183]<stdout>:Done (t=0.39s)
[1,183]<stdout>:creating index...
[1,37]<stdout>:Done (t=0.39s)
[1,37]<stdout>:creating index...
[1,107]<stdout>:loading annotations into memory...
[1,129]<stdout>:loading annotations into memory...
[1,93]<stdout>:Done (t=0.39s)
[1,93]<stdout>:creating index...
[1,90]<stdout>:index created!
[1,183]<stdout>:index created!
[1,37]<stdout>:index created!
[1,46]<stdout>:loading annotations into memory...
[1,155]<stdout>:loading annotations into memory...
[1,7]<stdout>:Done (t=0.39s)
[1,7]<stdout>:creating index...
[1,118]<stdout>:loading annotations into memory...
[1,34]<stdout>:loading annotations into memory...
[1,93]<stdout>:index created!
[1,125]<stdout>:Done (t=0.38s)
[1,125]<stdout>:creating index...
[1,7]<stdout>:index created!
[1,125]<stdout>:index created!
[1,132]<stdout>:Done (t=0.38s)
[1,132]<stdout>:creating index...
[1,170]<stdout>:Done (t=0.38s)
[1,170]<stdout>:creating index...
[1,103]<stdout>:loading annotations into memory...
[1,159]<stdout>:loading annotations into memory...
[1,132]<stdout>:index created!
[1,28]<stdout>:loading annotations into memory...
[1,170]<stdout>:index created!
[1,133]<stdout>:Done (t=0.38s)
[1,133]<stdout>:creating index...
[1,39]<stdout>:loading annotations into memory...
[1,96]<stdout>:loading annotations into memory...
[1,13]<stdout>:Done (t=0.39s)
[1,13]<stdout>:creating index...
[1,133]<stdout>:index created!
[1,147]<stdout>:loading annotations into memory...
[1,13]<stdout>:index created!
[1,91]<stdout>:loading annotations into memory...
[1,143]<stdout>:loading annotations into memory...
[1,73]<stdout>:loading annotations into memory...
[1,123]<stdout>:loading annotations into memory...
[1,32]<stdout>:loading annotations into memory...
[1,100]<stdout>:loading annotations into memory...
[1,66]<stdout>:Done (t=0.38s)
[1,66]<stdout>:creating index...
[1,186]<stdout>:creating index...
[1,108]<stdout>:loading annotations into memory...
[1,66]<stdout>:index created!
[1,67]<stdout>:Done (t=0.38s)
[1,67]<stdout>:creating index...
[1,120]<stdout>:loading annotations into memory...
[1,106]<stdout>:loading annotations into memory...
[1,70]<stdout>:loading annotations into memory...
[1,78]<stdout>:loading annotations into memory...
[1,79]<stdout>:loading annotations into memory...
[1,67]<stdout>:index created!
[1,122]<stdout>:loading annotations into memory...
[1,71]<stdout>:loading annotations into memory...
[1,55]<stdout>:loading annotations into memory...
[1,148]<stdout>:loading annotations into memory...
[1,6]<stdout>:Done (t=0.39s)
[1,6]<stdout>:creating index...
[1,72]<stdout>:Done (t=0.39s)
[1,72]<stdout>:creating index...
[1,75]<stdout>:loading annotations into memory...
[1,175]<stdout>:Done (t=0.39s)
[1,175]<stdout>:creating index...
[1,95]<stdout>:Done (t=0.38s)
[1,95]<stdout>:creating index...
[1,149]<stdout>:loading annotations into memory...
[1,177]<stdout>:Done (t=0.39s)
[1,177]<stdout>:creating index...
[1,51]<stdout>:loading annotations into memory...
[1,111]<stdout>:loading annotations into memory...
[1,176]<stdout>:loading annotations into memory...
[1,6]<stdout>:index created!
[1,3]<stdout>:Done (t=0.39s)
[1,3]<stdout>:creating index...
[1,72]<stdout>:index created!
[1,1]<stdout>:Done (t=0.39s)
[1,1]<stdout>:creating index...
[1,138]<stdout>:loading annotations into memory...
[1,95]<stdout>:index created!
[1,175]<stdout>:index created!
[1,48]<stdout>:loading annotations into memory...
[1,177]<stdout>:index created!
[1,128]<stdout>:loading annotations into memory...
[1,50]<stdout>:loading annotations into memory...
[1,69]<stdout>:loading annotations into memory...
[1,82]<stdout>:loading annotations into memory...
[1,187]<stdout>:Done (t=0.38s)
[1,187]<stdout>:creating index...
[1,178]<stdout>:creating index...
[1,85]<stdout>:Done (t=0.39s)
[1,85]<stdout>:creating index...
[1,3]<stdout>:index created!
[1,1]<stdout>:index created!
[1,158]<stdout>:loading annotations into memory...
[1,134]<stdout>:loading annotations into memory...
[1,187]<stdout>:index created!
[1,44]<stdout>:loading annotations into memory...
[1,85]<stdout>:index created!
[1,24]<stdout>:loading annotations into memory...
[1,92]<stdout>:loading annotations into memory...
[1,126]<stdout>:Done (t=0.39s)
[1,126]<stdout>:creating index...
[1,164]<stdout>:Done (t=0.39s)
[1,164]<stdout>:creating index...
[1,83]<stdout>:loading annotations into memory...
[1,157]<stdout>:Done (t=0.38s)
[1,157]<stdout>:creating index...
[1,130]<stdout>:Done (t=0.40s)
[1,130]<stdout>:creating index...
[1,185]<stdout>:Done (t=0.38s)
[1,185]<stdout>:creating index...
[1,126]<stdout>:index created!
[1,151]<stdout>:loading annotations into memory...
[1,131]<stdout>:Done (t=0.38s)
[1,131]<stdout>:creating index...
[1,124]<stdout>:Done (t=0.38s)
[1,124]<stdout>:creating index...
[1,113]<stdout>:loading annotations into memory...
[1,68]<stdout>:loading annotations into memory...
[1,164]<stdout>:index created!
[1,157]<stdout>:index created!
[1,130]<stdout>:index created!
[1,184]<stdout>:Done (t=0.39s)
[1,184]<stdout>:creating index...
[1,185]<stdout>:index created!
[1,165]<stdout>:Done (t=0.40s)
[1,165]<stdout>:creating index...
[1,87]<stdout>:loading annotations into memory...
[1,131]<stdout>:index created!
[1,124]<stdout>:index created!
[1,89]<stdout>:Done (t=0.39s)
[1,89]<stdout>:creating index...
[1,137]<stdout>:Done (t=0.39s)
[1,137]<stdout>:creating index...
[1,99]<stdout>:loading annotations into memory...
[1,77]<stdout>:loading annotations into memory...
[1,98]<stdout>:Done (t=0.39s)
[1,98]<stdout>:creating index...
[1,60]<stdout>:loading annotations into memory...
[1,184]<stdout>:index created!
[1,165]<stdout>:index created!
[1,23]<stdout>:Done (t=0.39s)
[1,23]<stdout>:creating index...
[1,145]<stdout>:loading annotations into memory...
[1,89]<stdout>:index created!
[1,137]<stdout>:index created!
[1,53]<stdout>:loading annotations into memory...
[1,49]<stdout>:loading annotations into memory...
[1,98]<stdout>:index created!
[1,23]<stdout>:index created!
[1,105]<stdout>:loading annotations into memory...
[1,101]<stdout>:Done (t=0.39s)
[1,101]<stdout>:creating index...
[1,62]<stdout>:loading annotations into memory...
[1,84]<stdout>:loading annotations into memory...
[1,129]<stdout>:Done (t=0.38s)
[1,129]<stdout>:creating index...
[1,107]<stdout>:Done (t=0.39s)
[1,107]<stdout>:creating index...
[1,101]<stdout>:index created!
[1,46]<stdout>:Done (t=0.39s)
[1,46]<stdout>:creating index...
[1,155]<stdout>:Done (t=0.38s)
[1,155]<stdout>:creating index...
[1,118]<stdout>:Done (t=0.39s)
[1,118]<stdout>:creating index...
[1,163]<stdout>:loading annotations into memory...
[1,129]<stdout>:index created!
[1,161]<stdout>:loading annotations into memory...
[1,107]<stdout>:index created!
[1,74]<stdout>:loading annotations into memory...
[1,34]<stdout>:Done (t=0.39s)
[1,34]<stdout>:creating index...
[1,43]<stdout>:loading annotations into memory...
[1,117]<stdout>:loading annotations into memory...
[1,46]<stdout>:index created!
[1,155]<stdout>:index created!
[1,146]<stdout>:loading annotations into memory...
[1,118]<stdout>:index created!
[1,34]<stdout>:index created!
[1,97]<stdout>:loading annotations into memory...
[1,160]<stdout>:loading annotations into memory...
[1,19]<stdout>:loading annotations into memory...
[1,114]<stdout>:loading annotations into memory...
[1,35]<stdout>:loading annotations into memory...
[1,103]<stdout>:Done (t=0.39s)
[1,103]<stdout>:creating index...
[1,173]<stdout>:loading annotations into memory...
[1,36]<stdout>:loading annotations into memory...
[1,159]<stdout>:Done (t=0.39s)
[1,159]<stdout>:creating index...
[1,25]<stdout>:loading annotations into memory...
[1,103]<stdout>:index created!
[1,96]<stdout>:Done (t=0.39s)
[1,96]<stdout>:creating index...
[1,167]<stdout>:loading annotations into memory...
[1,159]<stdout>:index created!
[1,115]<stdout>:loading annotations into memory...
[1,39]<stdout>:Done (t=0.40s)
[1,39]<stdout>:creating index...
[1,102]<stdout>:loading annotations into memory...
[1,147]<stdout>:Done (t=0.38s)
[1,147]<stdout>:creating index...
[1,96]<stdout>:index created!
[1,28]<stdout>:Done (t=0.42s)
[1,28]<stdout>:creating index...
[1,39]<stdout>:index created!
[1,91]<stdout>:Done (t=0.39s)
[1,91]<stdout>:creating index...
[1,154]<stdout>:loading annotations into memory...
[1,143]<stdout>:Done (t=0.39s)
[1,143]<stdout>:creating index...
[1,65]<stdout>:loading annotations into memory...
[1,147]<stdout>:index created!
[1,123]<stdout>:Done (t=0.38s)
[1,123]<stdout>:creating index...
[1,73]<stdout>:Done (t=0.39s)
[1,73]<stdout>:creating index...
[1,28]<stdout>:index created!
[1,29]<stdout>:loading annotations into memory...
[1,32]<stdout>:Done (t=0.39s)
[1,32]<stdout>:creating index...
[1,174]<stdout>:creating index...
[1,91]<stdout>:index created!
[1,172]<stdout>:loading annotations into memory...
[1,171]<stdout>:loading annotations into memory...
[1,100]<stdout>:Done (t=0.39s)
[1,100]<stdout>:creating index...
[1,143]<stdout>:index created!
[1,123]<stdout>:index created!
[1,73]<stdout>:index created!
[1,108]<stdout>:Done (t=0.39s)
[1,108]<stdout>:creating index...
[1,32]<stdout>:index created!
[1,100]<stdout>:index created!
[1,104]<stdout>:loading annotations into memory...
[1,120]<stdout>:Done (t=0.38s)
[1,120]<stdout>:creating index...
[1,190]<stdout>:loading annotations into memory...
[1,106]<stdout>:Done (t=0.39s)
[1,106]<stdout>:creating index...
[1,70]<stdout>:Done (t=0.39s)
[1,70]<stdout>:creating index...
[1,108]<stdout>:index created!
[1,78]<stdout>:Done (t=0.39s)
[1,78]<stdout>:creating index...
[1,79]<stdout>:Done (t=0.39s)
[1,79]<stdout>:creating index...
[1,120]<stdout>:index created!
[1,182]<stdout>:loading annotations into memory...
[1,71]<stdout>:Done (t=0.39s)
[1,71]<stdout>:creating index...
[1,122]<stdout>:Done (t=0.39s)
[1,122]<stdout>:creating index...
[1,106]<stdout>:index created!
[1,70]<stdout>:index created!
[1,78]<stdout>:index created!
[1,79]<stdout>:index created!
[1,38]<stdout>:loading annotations into memory...
[1,8]<stdout>:loading annotations into memory...
[1,55]<stdout>:Done (t=0.38s)
[1,55]<stdout>:creating index...
[1,136]<stdout>:loading annotations into memory...
[1,148]<stdout>:Done (t=0.39s)
[1,148]<stdout>:creating index...
[1,142]<stdout>:loading annotations into memory...
[1,71]<stdout>:index created!
[1,122]<stdout>:index created!
[1,75]<stdout>:Done (t=0.39s)
[1,75]<stdout>:creating index...
[1,55]<stdout>:index created!
[1,15]<stdout>:loading annotations into memory...
[1,51]<stdout>:Done (t=0.39s)
[1,51]<stdout>:creating index...
[1,148]<stdout>:index created!
[1,149]<stdout>:Done (t=0.39s)
[1,149]<stdout>:creating index...
[1,59]<stdout>:loading annotations into memory...
[1,176]<stdout>:Done (t=0.38s)
[1,176]<stdout>:creating index...
[1,111]<stdout>:Done (t=0.39s)
[1,111]<stdout>:creating index...
[1,128]<stdout>:Done (t=0.38s)
[1,128]<stdout>:creating index...
[1,50]<stdout>:Done (t=0.38s)
[1,50]<stdout>:creating index...
[1,138]<stdout>:Done (t=0.39s)
[1,138]<stdout>:creating index...
[1,75]<stdout>:index created!
[1,48]<stdout>:Done (t=0.38s)
[1,48]<stdout>:creating index...
[1,69]<stdout>:Done (t=0.39s)
[1,69]<stdout>:creating index...
[1,51]<stdout>:index created!
[1,149]<stdout>:index created!
[1,176]<stdout>:index created!
[1,111]<stdout>:index created!
[1,128]<stdout>:index created!
[1,50]<stdout>:index created!
[1,138]<stdout>:index created!
[1,48]<stdout>:index created!
[1,82]<stdout>:Done (t=0.40s)
[1,82]<stdout>:creating index...
[1,134]<stdout>:Done (t=0.38s)
[1,134]<stdout>:creating index...
[1,61]<stdout>:loading annotations into memory...
[1,69]<stdout>:index created!
[1,158]<stdout>:Done (t=0.39s)
[1,158]<stdout>:creating index...
[1,44]<stdout>:Done (t=0.39s)
[1,44]<stdout>:creating index...
[1,12]<stdout>:loading annotations into memory...
[1,24]<stdout>:Done (t=0.39s)
[1,24]<stdout>:creating index...
[1,82]<stdout>:index created!
[1,134]<stdout>:index created!
[1,92]<stdout>:Done (t=0.40s)
[1,92]<stdout>:creating index...
[1,158]<stdout>:index created!
[1,0]<stdout>:creating index...
[1,31]<stdout>:creating index...
[1,44]<stdout>:index created!
[1,24]<stdout>:index created!
[1,47]<stdout>:loading annotations into memory...
[1,92]<stdout>:index created!
[1,127]<stdout>:loading annotations into memory...
[1,151]<stdout>:Done (t=0.39s)
[1,151]<stdout>:creating index...
[1,162]<stdout>:loading annotations into memory...
[1,83]<stdout>:Done (t=0.40s)
[1,83]<stdout>:creating index...
[1,139]<stdout>:loading annotations into memory...
[1,27]<stdout>:loading annotations into memory...
[1,68]<stdout>:Done (t=0.39s)
[1,68]<stdout>:creating index...
[1,113]<stdout>:Done (t=0.40s)
[1,113]<stdout>:creating index...
[1,121]<stdout>:loading annotations into memory...
[1,87]<stdout>:Done (t=0.39s)
[1,87]<stdout>:creating index...
[1,151]<stdout>:index created!
[1,83]<stdout>:index created!
[1,68]<stdout>:index created!
[1,99]<stdout>:Done (t=0.39s)
[1,99]<stdout>:creating index...
[1,113]<stdout>:index created!
[1,87]<stdout>:index created!
[1,63]<stdout>:creating index...
[1,53]<stdout>:Done (t=0.38s)
[1,53]<stdout>:creating index...
[1,77]<stdout>:Done (t=0.40s)
[1,77]<stdout>:creating index...
[1,60]<stdout>:Done (t=0.40s)
[1,60]<stdout>:creating index...
[1,49]<stdout>:Done (t=0.38s)
[1,49]<stdout>:creating index...
[1,99]<stdout>:index created!
[1,145]<stdout>:Done (t=0.40s)
[1,145]<stdout>:creating index...
[1,53]<stdout>:index created!
[1,5]<stdout>:creating index...
[1,77]<stdout>:index created!
[1,60]<stdout>:index created!
[1,49]<stdout>:index created!
[1,145]<stdout>:index created!
[1,62]<stdout>:Done (t=0.39s)
[1,62]<stdout>:creating index...
[1,17]<stdout>:loading annotations into memory...
[1,105]<stdout>:Done (t=0.40s)
[1,105]<stdout>:creating index...
[1,2]<stdout>:creating index...
[1,84]<stdout>:Done (t=0.39s)
[1,84]<stdout>:creating index...
[1,62]<stdout>:index created!
[1,22]<stdout>:loading annotations into memory...
[1,105]<stdout>:index created!
[1,84]<stdout>:index created!
[1,161]<stdout>:Done (t=0.39s)
[1,161]<stdout>:creating index...
[1,74]<stdout>:Done (t=0.39s)
[1,74]<stdout>:creating index...
[1,163]<stdout>:Done (t=0.40s)
[1,163]<stdout>:creating index...
[1,117]<stdout>:Done (t=0.39s)
[1,117]<stdout>:creating index...
[1,43]<stdout>:Done (t=0.39s)
[1,43]<stdout>:creating index...
[1,45]<stdout>:loading annotations into memory...
[1,109]<stdout>:creating index...
[1,74]<stdout>:index created!
[1,161]<stdout>:index created!
[1,97]<stdout>:Done (t=0.39s)
[1,97]<stdout>:creating index...
[1,146]<stdout>:Done (t=0.40s)
[1,146]<stdout>:creating index...
[1,160]<stdout>:Done (t=0.39s)
[1,160]<stdout>:creating index...
[1,163]<stdout>:index created!
[1,117]<stdout>:index created!
[1,114]<stdout>:Done (t=0.39s)
[1,114]<stdout>:creating index...
[1,43]<stdout>:index created!
[1,35]<stdout>:Done (t=0.38s)
[1,35]<stdout>:creating index...
[1,19]<stdout>:Done (t=0.39s)
[1,19]<stdout>:creating index...
[1,97]<stdout>:index created!
[1,146]<stdout>:index created!
[1,189]<stdout>:loading annotations into memory...
[1,80]<stdout>:loading annotations into memory...
[1,160]<stdout>:index created!
[1,114]<stdout>:index created!
[1,35]<stdout>:index created!
[1,36]<stdout>:Done (t=0.39s)
[1,36]<stdout>:creating index...
[1,19]<stdout>:index created!
[1,173]<stdout>:Done (t=0.40s)
[1,173]<stdout>:creating index...
[1,36]<stdout>:index created!
[1,42]<stdout>:loading annotations into memory...
[1,183]<stdout>:creating index...
[1,25]<stdout>:Done (t=0.40s)
[1,25]<stdout>:creating index...
[1,90]<stdout>:creating index...
[1,167]<stdout>:Done (t=0.39s)
[1,167]<stdout>:creating index...
[1,86]<stdout>:loading annotations into memory...
[1,115]<stdout>:Done (t=0.39s)
[1,115]<stdout>:creating index...
[1,173]<stdout>:index created!
[1,141]<stdout>:loading annotations into memory...
[1,102]<stdout>:Done (t=0.40s)
[1,102]<stdout>:creating index...
[1,25]<stdout>:index created!
[1,93]<stdout>:creating index...
[1,167]<stdout>:index created!
[1,115]<stdout>:index created!
[1,37]<stdout>:creating index...
[1,110]<stdout>:loading annotations into memory...
[1,154]<stdout>:Done (t=0.40s)
[1,154]<stdout>:creating index...
[1,102]<stdout>:index created!
[1,65]<stdout>:Done (t=0.40s)
[1,65]<stdout>:creating index...
[1,29]<stdout>:Done (t=0.40s)
[1,29]<stdout>:creating index...
[1,172]<stdout>:Done (t=0.39s)
[1,172]<stdout>:creating index...
[1,7]<stdout>:creating index...
[1,154]<stdout>:index created!
[1,18]<stdout>:loading annotations into memory...
[1,171]<stdout>:Done (t=0.40s)
[1,171]<stdout>:creating index...
[1,125]<stdout>:creating index...
[1,81]<stdout>:loading annotations into memory...
[1,65]<stdout>:index created!
[1,29]<stdout>:index created!
[1,172]<stdout>:index created!
[1,171]<stdout>:index created!
[1,104]<stdout>:Done (t=0.40s)
[1,104]<stdout>:creating index...
[1,190]<stdout>:Done (t=0.39s)
[1,190]<stdout>:creating index...
[1,132]<stdout>:creating index...
[1,88]<stdout>:loading annotations into memory...
[1,170]<stdout>:creating index...
[1,182]<stdout>:Done (t=0.39s)
[1,182]<stdout>:creating index...
[1,26]<stdout>:loading annotations into memory...
[1,104]<stdout>:index created!
[1,190]<stdout>:index created!
[1,38]<stdout>:Done (t=0.39s)
[1,38]<stdout>:creating index...
[1,8]<stdout>:Done (t=0.39s)
[1,8]<stdout>:creating index...
[1,181]<stdout>:loading annotations into memory...
[1,133]<stdout>:creating index...
[1,182]<stdout>:index created!
[1,136]<stdout>:Done (t=0.40s)
[1,136]<stdout>:creating index...
[1,142]<stdout>:Done (t=0.40s)
[1,142]<stdout>:creating index...
[1,57]<stdout>:loading annotations into memory...
[1,38]<stdout>:index created!
[1,13]<stdout>:creating index...
[1,8]<stdout>:index created!
[1,15]<stdout>:Done (t=0.39s)
[1,15]<stdout>:creating index...
[1,179]<stdout>:loading annotations into memory...
[1,140]<stdout>:loading annotations into memory...
[1,136]<stdout>:index created!
[1,59]<stdout>:Done (t=0.40s)
[1,59]<stdout>:creating index...
[1,142]<stdout>:index created!
[1,15]<stdout>:index created!
[1,59]<stdout>:index created!
[1,66]<stdout>:creating index...
[1,12]<stdout>:Done (t=0.39s)
[1,12]<stdout>:creating index...
[1,61]<stdout>:Done (t=0.41s)
[1,61]<stdout>:creating index...
[1,64]<stdout>:loading annotations into memory...
[1,135]<stdout>:loading annotations into memory...
[1,67]<stdout>:creating index...
[1,11]<stdout>:loading annotations into memory...
[1,12]<stdout>:index created!
[1,127]<stdout>:Done (t=0.38s)
[1,127]<stdout>:creating index...
[1,61]<stdout>:index created!
[1,47]<stdout>:Done (t=0.40s)
[1,47]<stdout>:creating index...
[1,152]<stdout>:loading annotations into memory...
[1,162]<stdout>:Done (t=0.39s)
[1,162]<stdout>:creating index...
[1,139]<stdout>:Done (t=0.39s)
[1,139]<stdout>:creating index...
[1,127]<stdout>:index created!
[1,27]<stdout>:Done (t=0.39s)
[1,27]<stdout>:creating index...
[1,47]<stdout>:index created!
[1,162]<stdout>:index created!
[1,139]<stdout>:index created!
[1,27]<stdout>:index created!
[1,121]<stdout>:Done (t=0.40s)
[1,121]<stdout>:creating index...
[1,72]<stdout>:creating index...
[1,6]<stdout>:creating index...
[1,9]<stdout>:loading annotations into memory...
[1,175]<stdout>:creating index...
[1,169]<stdout>:loading annotations into memory...
[1,95]<stdout>:creating index...
[1,177]<stdout>:creating index...
[1,121]<stdout>:index created!
[1,168]<stdout>:loading annotations into memory...
[1,1]<stdout>:creating index...
[1,3]<stdout>:creating index...
[1,85]<stdout>:creating index...
[1,187]<stdout>:creating index...
[1,144]<stdout>:loading annotations into memory...
[1,17]<stdout>:Done (t=0.39s)
[1,17]<stdout>:creating index...
[1,126]<stdout>:creating index...
[1,17]<stdout>:index created!
[1,22]<stdout>:Done (t=0.40s)
[1,22]<stdout>:creating index...
[1,164]<stdout>:creating index...
[1,185]<stdout>:creating index...
[1,131]<stdout>:creating index...
[1,45]<stdout>:Done (t=0.39s)
[1,45]<stdout>:creating index...
[1,130]<stdout>:creating index...
[1,184]<stdout>:creating index...
[1,157]<stdout>:creating index...
[1,124]<stdout>:creating index...
[1,22]<stdout>:index created!
[1,45]<stdout>:index created!
[1,165]<stdout>:creating index...
[1,137]<stdout>:creating index...
[1,89]<stdout>:creating index...
[1,189]<stdout>:Done (t=0.39s)
[1,189]<stdout>:creating index...
[1,80]<stdout>:Done (t=0.39s)
[1,80]<stdout>:creating index...
[1,119]<stdout>:loading annotations into memory...
[1,23]<stdout>:creating index...
[1,98]<stdout>:creating index...
[1,10]<stdout>:loading annotations into memory...
[1,189]<stdout>:index created!
[1,80]<stdout>:index created!
[1,86]<stdout>:Done (t=0.39s)
[1,86]<stdout>:creating index...
[1,42]<stdout>:Done (t=0.40s)
[1,42]<stdout>:creating index...
[1,101]<stdout>:creating index...
[1,150]<stdout>:loading annotations into memory...
[1,141]<stdout>:Done (t=0.39s)
[1,141]<stdout>:creating index...
[1,40]<stdout>:loading annotations into memory...
[1,86]<stdout>:index created!
[1,129]<stdout>:creating index...
[1,107]<stdout>:creating index...
[1,42]<stdout>:index created!
[1,141]<stdout>:index created!
[1,118]<stdout>:creating index...
[1,155]<stdout>:creating index...
[1,110]<stdout>:Done (t=0.40s)
[1,110]<stdout>:creating index...
[1,46]<stdout>:creating index...
[1,34]<stdout>:creating index...
[1,81]<stdout>:Done (t=0.39s)
[1,81]<stdout>:creating index...
[1,110]<stdout>:index created!
[1,18]<stdout>:Done (t=0.40s)
[1,18]<stdout>:creating index...
[1,58]<stdout>:loading annotations into memory...
[1,81]<stdout>:index created!
[1,14]<stdout>:loading annotations into memory...
[1,156]<stdout>:loading annotations into memory...
[1,18]<stdout>:index created!
[1,26]<stdout>:Done (t=0.39s)
[1,26]<stdout>:creating index...
[1,103]<stdout>:creating index...
[1,112]<stdout>:loading annotations into memory...
[1,88]<stdout>:Done (t=0.40s)
[1,88]<stdout>:creating index...
[1,191]<stdout>:loading annotations into memory...
[1,181]<stdout>:Done (t=0.39s)
[1,181]<stdout>:creating index...
[1,26]<stdout>:index created!
[1,166]<stdout>:loading annotations into memory...
[1,159]<stdout>:creating index...
[1,88]<stdout>:index created!
[1,39]<stdout>:creating index...
[1,57]<stdout>:Done (t=0.39s)
[1,57]<stdout>:creating index...
[1,96]<stdout>:creating index...
[1,179]<stdout>:Done (t=0.39s)
[1,179]<stdout>:creating index...
[1,181]<stdout>:index created!
[1,16]<stdout>:loading annotations into memory...
[1,140]<stdout>:Done (t=0.39s)
[1,140]<stdout>:creating index...
[1,57]<stdout>:index created!
[1,147]<stdout>:creating index...
[1,179]<stdout>:index created!
[1,28]<stdout>:creating index...
[1,91]<stdout>:creating index...
[1,21]<stdout>:loading annotations into memory...
[1,140]<stdout>:index created!
[1,73]<stdout>:creating index...
[1,143]<stdout>:creating index...
[1,100]<stdout>:creating index...
[1,123]<stdout>:creating index...
[1,32]<stdout>:creating index...
[1,135]<stdout>:Done (t=0.38s)
[1,135]<stdout>:creating index...
[1,108]<stdout>:creating index...
[1,11]<stdout>:Done (t=0.39s)
[1,11]<stdout>:creating index...
[1,135]<stdout>:index created!
[1,64]<stdout>:Done (t=0.40s)
[1,64]<stdout>:creating index...
[1,79]<stdout>:creating index...
[1,78]<stdout>:creating index...
[1,120]<stdout>:creating index...
[1,70]<stdout>:creating index...
[1,11]<stdout>:index created!
[1,106]<stdout>:creating index...
[1,152]<stdout>:Done (t=0.39s)
[1,152]<stdout>:creating index...
[1,64]<stdout>:index created!
[1,71]<stdout>:creating index...
[1,55]<stdout>:creating index...
[1,122]<stdout>:creating index...
[1,148]<stdout>:creating index...
[1,152]<stdout>:index created!
[1,51]<stdout>:creating index...
[1,75]<stdout>:creating index...
[1,169]<stdout>:Done (t=0.39s)
[1,169]<stdout>:creating index...
[1,9]<stdout>:Done (t=0.40s)
[1,9]<stdout>:creating index...
[1,149]<stdout>:creating index...
[1,111]<stdout>:creating index...
[1,128]<stdout>:creating index...
[1,50]<stdout>:creating index...
[1,48]<stdout>:creating index...
[1,144]<stdout>:Done (t=0.38s)
[1,144]<stdout>:creating index...
[1,168]<stdout>:Done (t=0.40s)
[1,168]<stdout>:creating index...
[1,169]<stdout>:index created!
[1,9]<stdout>:index created!
[1,176]<stdout>:creating index...
[1,69]<stdout>:creating index...
[1,138]<stdout>:creating index...
[1,82]<stdout>:creating index...
[1,144]<stdout>:index created!
[1,168]<stdout>:index created!
[1,158]<stdout>:creating index...
[1,153]<stdout>:loading annotations into memory...
[1,44]<stdout>:creating index...
[1,92]<stdout>:creating index...
[1,134]<stdout>:creating index...
[1,83]<stdout>:creating index...
[1,151]<stdout>:creating index...
[1,24]<stdout>:creating index...
[1,68]<stdout>:creating index...
[1,113]<stdout>:creating index...
[1,87]<stdout>:creating index...
[1,99]<stdout>:creating index...
[1,119]<stdout>:Done (t=0.39s)
[1,119]<stdout>:creating index...
[1,77]<stdout>:creating index...
[1,41]<stdout>:loading annotations into memory...
[1,60]<stdout>:creating index...
[1,119]<stdout>:index created!
[1,53]<stdout>:creating index...
[1,49]<stdout>:creating index...
[1,10]<stdout>:Done (t=0.40s)
[1,10]<stdout>:creating index...
[1,145]<stdout>:creating index...
[1,105]<stdout>:creating index...
[1,10]<stdout>:index created!
[1,84]<stdout>:creating index...
[1,150]<stdout>:Done (t=0.40s)
[1,150]<stdout>:creating index...
[1,62]<stdout>:creating index...
[1,40]<stdout>:Done (t=0.40s)
[1,40]<stdout>:creating index...
[1,150]<stdout>:index created!
[1,40]<stdout>:index created!
[1,33]<stdout>:loading annotations into memory...
[1,161]<stdout>:creating index...
[1,163]<stdout>:creating index...
[1,43]<stdout>:creating index...
[1,117]<stdout>:creating index...
[1,97]<stdout>:creating index...
[1,58]<stdout>:Done (t=0.39s)
[1,58]<stdout>:creating index...
[1,74]<stdout>:creating index...
[1,35]<stdout>:creating index...
[1,114]<stdout>:creating index...
[1,146]<stdout>:creating index...
[1,58]<stdout>:index created!
[1,160]<stdout>:creating index...
[1,14]<stdout>:Done (t=0.40s)
[1,14]<stdout>:creating index...
[1,156]<stdout>:Done (t=0.40s)
[1,156]<stdout>:creating index...
[1,19]<stdout>:creating index...
[1,112]<stdout>:Done (t=0.40s)
[1,112]<stdout>:creating index...
[1,36]<stdout>:creating index...
[1,14]<stdout>:index created!
[1,156]<stdout>:index created!
[1,173]<stdout>:creating index...
[1,112]<stdout>:index created!
[1,166]<stdout>:Done (t=0.41s)
[1,166]<stdout>:creating index...
[1,115]<stdout>:creating index...
[1,191]<stdout>:Done (t=0.42s)
[1,191]<stdout>:creating index...
[1,16]<stdout>:Done (t=0.39s)
[1,16]<stdout>:creating index...
[1,102]<stdout>:creating index...
[1,167]<stdout>:creating index...
[1,25]<stdout>:creating index...
[1,166]<stdout>:index created!
[1,191]<stdout>:index created!
[1,16]<stdout>:index created!
[1,21]<stdout>:Done (t=0.39s)
[1,21]<stdout>:creating index...
[1,65]<stdout>:creating index...
[1,154]<stdout>:creating index...
[1,21]<stdout>:index created!
[1,172]<stdout>:creating index...
[1,171]<stdout>:creating index...
[1,104]<stdout>:creating index...
[1,29]<stdout>:creating index...
[1,190]<stdout>:creating index...
[1,182]<stdout>:creating index...
[1,38]<stdout>:creating index...
[1,8]<stdout>:creating index...
[1,136]<stdout>:creating index...
[1,15]<stdout>:creating index...
[1,142]<stdout>:creating index...
[1,59]<stdout>:creating index...
[1,153]<stdout>:Done (t=0.39s)
[1,153]<stdout>:creating index...
[1,61]<stdout>:creating index...
[1,12]<stdout>:creating index...
[1,153]<stdout>:index created!
[1,47]<stdout>:creating index...
[1,127]<stdout>:creating index...
[1,162]<stdout>:creating index...
[1,139]<stdout>:creating index...
[1,20]<stdout>:loading annotations into memory...
[1,27]<stdout>:creating index...
[1,41]<stdout>:Done (t=0.39s)
[1,41]<stdout>:creating index...
[1,121]<stdout>:creating index...
[1,41]<stdout>:index created!
[1,17]<stdout>:creating index...
[1,33]<stdout>:Done (t=0.39s)
[1,33]<stdout>:creating index...
[1,56]<stdout>:loading annotations into memory...
[1,22]<stdout>:creating index...
[1,45]<stdout>:creating index...
[1,33]<stdout>:index created!
[1,54]<stdout>:loading annotations into memory...
[1,80]<stdout>:creating index...
[1,189]<stdout>:creating index...
[1,86]<stdout>:creating index...
[1,42]<stdout>:creating index...
[1,141]<stdout>:creating index...
[1,110]<stdout>:creating index...
[1,81]<stdout>:creating index...
[1,18]<stdout>:creating index...
[1,88]<stdout>:creating index...
[1,26]<stdout>:creating index...
[1,181]<stdout>:creating index...
[1,57]<stdout>:creating index...
[1,179]<stdout>:creating index...
[1,140]<stdout>:creating index...
[1,64]<stdout>:creating index...
[1,11]<stdout>:creating index...
[1,135]<stdout>:creating index...
[1,152]<stdout>:creating index...
[1,20]<stdout>:Done (t=0.40s)
[1,20]<stdout>:creating index...
[1,169]<stdout>:creating index...
[1,9]<stdout>:creating index...
[1,20]<stdout>:index created!
[1,168]<stdout>:creating index...
[1,144]<stdout>:creating index...
[1,56]<stdout>:Done (t=0.40s)
[1,56]<stdout>:creating index...
[1,54]<stdout>:Done (t=0.38s)
[1,54]<stdout>:creating index...
[1,56]<stdout>:index created!
[1,54]<stdout>:index created!
[1,119]<stdout>:creating index...
[1,10]<stdout>:creating index...
[1,150]<stdout>:creating index...
[1,30]<stdout>:loading annotations into memory...
[1,40]<stdout>:creating index...
[1,156]<stdout>:creating index...
[1,58]<stdout>:creating index...
[1,166]<stdout>:creating index...
[1,94]<stdout>:loading annotations into memory...
[1,14]<stdout>:creating index...
[1,112]<stdout>:creating index...
[1,191]<stdout>:creating index...
[1,16]<stdout>:creating index...
[1,21]<stdout>:creating index...
[1,153]<stdout>:creating index...
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,186]<stderr>:  'is ignored.'.format(self.name, req))
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,186]<stderr>:  'is ignored.'.format(self.name, req))
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,186]<stderr>:  'is ignored.'.format(self.name, req))
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,186]<stderr>:  'is ignored.'.format(self.name, req))
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,186]<stderr>:  'is ignored.'.format(self.name, req))
[1,41]<stdout>:creating index...
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,178]<stderr>:  'is ignored.'.format(self.name, req))
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,178]<stderr>:  'is ignored.'.format(self.name, req))
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,178]<stderr>:  'is ignored.'.format(self.name, req))
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,178]<stderr>:  'is ignored.'.format(self.name, req))
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,178]<stderr>:  'is ignored.'.format(self.name, req))
[1,33]<stdout>:creating index...
[1,30]<stdout>:Done (t=0.40s)
[1,30]<stdout>:creating index...
[1,30]<stdout>:index created!
[1,94]<stdout>:Done (t=0.40s)
[1,94]<stdout>:creating index...
[1,94]<stdout>:index created!
[1,52]<stdout>:loading annotations into memory...
[1,116]<stdout>:loading annotations into memory...
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,174]<stderr>:  'is ignored.'.format(self.name, req))
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,174]<stderr>:  'is ignored.'.format(self.name, req))
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,174]<stderr>:  'is ignored.'.format(self.name, req))
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,174]<stderr>:  'is ignored.'.format(self.name, req))
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,174]<stderr>:  'is ignored.'.format(self.name, req))
[1,20]<stdout>:creating index...
[1,54]<stdout>:creating index...
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,31]<stderr>:  'is ignored.'.format(self.name, req))
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,31]<stderr>:  'is ignored.'.format(self.name, req))
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,31]<stderr>:  'is ignored.'.format(self.name, req))
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,31]<stderr>:  'is ignored.'.format(self.name, req))
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,31]<stderr>:  'is ignored.'.format(self.name, req))
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,63]<stderr>:  'is ignored.'.format(self.name, req))
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,63]<stderr>:  'is ignored.'.format(self.name, req))
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,63]<stderr>:  'is ignored.'.format(self.name, req))
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,63]<stderr>:  'is ignored.'.format(self.name, req))
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,63]<stderr>:  'is ignored.'.format(self.name, req))
[1,56]<stdout>:creating index...
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,5]<stderr>:  'is ignored.'.format(self.name, req))
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,5]<stderr>:  'is ignored.'.format(self.name, req))
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,5]<stderr>:  'is ignored.'.format(self.name, req))
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,5]<stderr>:  'is ignored.'.format(self.name, req))
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,5]<stderr>:  'is ignored.'.format(self.name, req))
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,109]<stderr>:  'is ignored.'.format(self.name, req))
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,109]<stderr>:  'is ignored.'.format(self.name, req))
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,109]<stderr>:  'is ignored.'.format(self.name, req))
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,109]<stderr>:  'is ignored.'.format(self.name, req))
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,109]<stderr>:  'is ignored.'.format(self.name, req))
[1,52]<stdout>:Done (t=0.38s)
[1,52]<stdout>:creating index...
[1,52]<stdout>:index created!
[1,116]<stdout>:Done (t=0.39s)
[1,116]<stdout>:creating index...
[1,116]<stdout>:index created!
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,183]<stderr>:  'is ignored.'.format(self.name, req))
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,183]<stderr>:  'is ignored.'.format(self.name, req))
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,183]<stderr>:  'is ignored.'.format(self.name, req))
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,183]<stderr>:  'is ignored.'.format(self.name, req))
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,183]<stderr>:  'is ignored.'.format(self.name, req))
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,37]<stderr>:  'is ignored.'.format(self.name, req))
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,37]<stderr>:  'is ignored.'.format(self.name, req))
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,37]<stderr>:  'is ignored.'.format(self.name, req))
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,37]<stderr>:  'is ignored.'.format(self.name, req))
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,37]<stderr>:  'is ignored.'.format(self.name, req))
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,90]<stderr>:  'is ignored.'.format(self.name, req))
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,90]<stderr>:  'is ignored.'.format(self.name, req))
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,90]<stderr>:  'is ignored.'.format(self.name, req))
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,90]<stderr>:  'is ignored.'.format(self.name, req))
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,90]<stderr>:  'is ignored.'.format(self.name, req))
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,93]<stderr>:  'is ignored.'.format(self.name, req))
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,93]<stderr>:  'is ignored.'.format(self.name, req))
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,93]<stderr>:  'is ignored.'.format(self.name, req))
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,93]<stderr>:  'is ignored.'.format(self.name, req))
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,93]<stderr>:  'is ignored.'.format(self.name, req))
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,125]<stderr>:  'is ignored.'.format(self.name, req))
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,125]<stderr>:  'is ignored.'.format(self.name, req))
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,125]<stderr>:  'is ignored.'.format(self.name, req))
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,125]<stderr>:  'is ignored.'.format(self.name, req))
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,125]<stderr>:  'is ignored.'.format(self.name, req))
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,170]<stderr>:  'is ignored.'.format(self.name, req))
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,170]<stderr>:  'is ignored.'.format(self.name, req))
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,170]<stderr>:  'is ignored.'.format(self.name, req))
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,170]<stderr>:  'is ignored.'.format(self.name, req))
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,170]<stderr>:  'is ignored.'.format(self.name, req))
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,7]<stderr>:  'is ignored.'.format(self.name, req))
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,7]<stderr>:  'is ignored.'.format(self.name, req))
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,7]<stderr>:  'is ignored.'.format(self.name, req))
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,7]<stderr>:  'is ignored.'.format(self.name, req))
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,7]<stderr>:  'is ignored.'.format(self.name, req))
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,0]<stderr>:  'is ignored.'.format(self.name, req))
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,0]<stderr>:  'is ignored.'.format(self.name, req))
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,0]<stderr>:  'is ignored.'.format(self.name, req))
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,0]<stderr>:  'is ignored.'.format(self.name, req))
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,0]<stderr>:  'is ignored.'.format(self.name, req))
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,132]<stderr>:  'is ignored.'.format(self.name, req))
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,132]<stderr>:  'is ignored.'.format(self.name, req))
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,132]<stderr>:  'is ignored.'.format(self.name, req))
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,132]<stderr>:  'is ignored.'.format(self.name, req))
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,132]<stderr>:  'is ignored.'.format(self.name, req))
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,13]<stderr>:  'is ignored.'.format(self.name, req))
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,13]<stderr>:  'is ignored.'.format(self.name, req))
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,13]<stderr>:  'is ignored.'.format(self.name, req))
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,13]<stderr>:  'is ignored.'.format(self.name, req))
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,13]<stderr>:  'is ignored.'.format(self.name, req))
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,133]<stderr>:  'is ignored.'.format(self.name, req))
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,133]<stderr>:  'is ignored.'.format(self.name, req))
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,133]<stderr>:  'is ignored.'.format(self.name, req))
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,133]<stderr>:  'is ignored.'.format(self.name, req))
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,133]<stderr>:  'is ignored.'.format(self.name, req))
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,2]<stderr>:  'is ignored.'.format(self.name, req))
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,2]<stderr>:  'is ignored.'.format(self.name, req))
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,2]<stderr>:  'is ignored.'.format(self.name, req))
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,2]<stderr>:  'is ignored.'.format(self.name, req))
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,2]<stderr>:  'is ignored.'.format(self.name, req))
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,66]<stderr>:  'is ignored.'.format(self.name, req))
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,66]<stderr>:  'is ignored.'.format(self.name, req))
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,66]<stderr>:  'is ignored.'.format(self.name, req))
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,66]<stderr>:  'is ignored.'.format(self.name, req))
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,66]<stderr>:  'is ignored.'.format(self.name, req))
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,67]<stderr>:  'is ignored.'.format(self.name, req))
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,67]<stderr>:  'is ignored.'.format(self.name, req))
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,67]<stderr>:  'is ignored.'.format(self.name, req))
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,67]<stderr>:  'is ignored.'.format(self.name, req))
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,67]<stderr>:  'is ignored.'.format(self.name, req))
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,72]<stderr>:  'is ignored.'.format(self.name, req))
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,72]<stderr>:  'is ignored.'.format(self.name, req))
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,72]<stderr>:  'is ignored.'.format(self.name, req))
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,72]<stderr>:  'is ignored.'.format(self.name, req))
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,72]<stderr>:  'is ignored.'.format(self.name, req))
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,95]<stderr>:  'is ignored.'.format(self.name, req))
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,95]<stderr>:  'is ignored.'.format(self.name, req))
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,95]<stderr>:  'is ignored.'.format(self.name, req))
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,95]<stderr>:  'is ignored.'.format(self.name, req))
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,95]<stderr>:  'is ignored.'.format(self.name, req))
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,85]<stderr>:  'is ignored.'.format(self.name, req))
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,85]<stderr>:  'is ignored.'.format(self.name, req))
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,85]<stderr>:  'is ignored.'.format(self.name, req))
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,85]<stderr>:  'is ignored.'.format(self.name, req))
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,85]<stderr>:  'is ignored.'.format(self.name, req))
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,6]<stderr>:  'is ignored.'.format(self.name, req))
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,6]<stderr>:  'is ignored.'.format(self.name, req))
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,6]<stderr>:  'is ignored.'.format(self.name, req))
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,6]<stderr>:  'is ignored.'.format(self.name, req))
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,6]<stderr>:  'is ignored.'.format(self.name, req))
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,175]<stderr>:  'is ignored.'.format(self.name, req))
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,175]<stderr>:  'is ignored.'.format(self.name, req))
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,175]<stderr>:  'is ignored.'.format(self.name, req))
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,175]<stderr>:  'is ignored.'.format(self.name, req))
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,175]<stderr>:  'is ignored.'.format(self.name, req))
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,177]<stderr>:  'is ignored.'.format(self.name, req))
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,177]<stderr>:  'is ignored.'.format(self.name, req))
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,177]<stderr>:  'is ignored.'.format(self.name, req))
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,177]<stderr>:  'is ignored.'.format(self.name, req))
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,177]<stderr>:  'is ignored.'.format(self.name, req))
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,187]<stderr>:  'is ignored.'.format(self.name, req))
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,187]<stderr>:  'is ignored.'.format(self.name, req))
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,187]<stderr>:  'is ignored.'.format(self.name, req))
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,187]<stderr>:  'is ignored.'.format(self.name, req))
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,187]<stderr>:  'is ignored.'.format(self.name, req))
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,126]<stderr>:  'is ignored.'.format(self.name, req))
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,126]<stderr>:  'is ignored.'.format(self.name, req))
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,126]<stderr>:  'is ignored.'.format(self.name, req))
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,126]<stderr>:  'is ignored.'.format(self.name, req))
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,126]<stderr>:  'is ignored.'.format(self.name, req))
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,185]<stderr>:  'is ignored.'.format(self.name, req))
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,185]<stderr>:  'is ignored.'.format(self.name, req))
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,185]<stderr>:  'is ignored.'.format(self.name, req))
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,185]<stderr>:  'is ignored.'.format(self.name, req))
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,185]<stderr>:  'is ignored.'.format(self.name, req))
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,184]<stderr>:  'is ignored.'.format(self.name, req))
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,184]<stderr>:  'is ignored.'.format(self.name, req))
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,184]<stderr>:  'is ignored.'.format(self.name, req))
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,184]<stderr>:  'is ignored.'.format(self.name, req))
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,184]<stderr>:  'is ignored.'.format(self.name, req))
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,131]<stderr>:  'is ignored.'.format(self.name, req))
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,131]<stderr>:  'is ignored.'.format(self.name, req))
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,131]<stderr>:  'is ignored.'.format(self.name, req))
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,131]<stderr>:  'is ignored.'.format(self.name, req))
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,131]<stderr>:  'is ignored.'.format(self.name, req))
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,157]<stderr>:  'is ignored.'.format(self.name, req))
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,157]<stderr>:  'is ignored.'.format(self.name, req))
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,157]<stderr>:  'is ignored.'.format(self.name, req))
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,157]<stderr>:  'is ignored.'.format(self.name, req))
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,157]<stderr>:  'is ignored.'.format(self.name, req))
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,130]<stderr>:  'is ignored.'.format(self.name, req))
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,130]<stderr>:  'is ignored.'.format(self.name, req))
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,130]<stderr>:  'is ignored.'.format(self.name, req))
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,130]<stderr>:  'is ignored.'.format(self.name, req))
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,130]<stderr>:  'is ignored.'.format(self.name, req))
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,124]<stderr>:  'is ignored.'.format(self.name, req))
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,124]<stderr>:  'is ignored.'.format(self.name, req))
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,124]<stderr>:  'is ignored.'.format(self.name, req))
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,124]<stderr>:  'is ignored.'.format(self.name, req))
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,124]<stderr>:  'is ignored.'.format(self.name, req))
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,164]<stderr>:  'is ignored.'.format(self.name, req))
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,164]<stderr>:  'is ignored.'.format(self.name, req))
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,164]<stderr>:  'is ignored.'.format(self.name, req))
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,164]<stderr>:  'is ignored.'.format(self.name, req))
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,164]<stderr>:  'is ignored.'.format(self.name, req))
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,23]<stderr>:  'is ignored.'.format(self.name, req))
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,23]<stderr>:  'is ignored.'.format(self.name, req))
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,23]<stderr>:  'is ignored.'.format(self.name, req))
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,23]<stderr>:  'is ignored.'.format(self.name, req))
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,23]<stderr>:  'is ignored.'.format(self.name, req))
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,165]<stderr>:  'is ignored.'.format(self.name, req))
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,165]<stderr>:  'is ignored.'.format(self.name, req))
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,165]<stderr>:  'is ignored.'.format(self.name, req))
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,165]<stderr>:  'is ignored.'.format(self.name, req))
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,165]<stderr>:  'is ignored.'.format(self.name, req))
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,98]<stderr>:  'is ignored.'.format(self.name, req))
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,98]<stderr>:  'is ignored.'.format(self.name, req))
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,98]<stderr>:  'is ignored.'.format(self.name, req))
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,98]<stderr>:  'is ignored.'.format(self.name, req))
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,98]<stderr>:  'is ignored.'.format(self.name, req))
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,89]<stderr>:  'is ignored.'.format(self.name, req))
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,89]<stderr>:  'is ignored.'.format(self.name, req))
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,89]<stderr>:  'is ignored.'.format(self.name, req))
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,89]<stderr>:  'is ignored.'.format(self.name, req))
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,89]<stderr>:  'is ignored.'.format(self.name, req))
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,137]<stderr>:  'is ignored.'.format(self.name, req))
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,137]<stderr>:  'is ignored.'.format(self.name, req))
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,137]<stderr>:  'is ignored.'.format(self.name, req))
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,137]<stderr>:  'is ignored.'.format(self.name, req))
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,137]<stderr>:  'is ignored.'.format(self.name, req))
[1,30]<stdout>:creating index...
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,129]<stderr>:  'is ignored.'.format(self.name, req))
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,129]<stderr>:  'is ignored.'.format(self.name, req))
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,129]<stderr>:  'is ignored.'.format(self.name, req))
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,129]<stderr>:  'is ignored.'.format(self.name, req))
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,129]<stderr>:  'is ignored.'.format(self.name, req))
[1,94]<stdout>:creating index...
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,118]<stderr>:  'is ignored.'.format(self.name, req))
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,118]<stderr>:  'is ignored.'.format(self.name, req))
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,118]<stderr>:  'is ignored.'.format(self.name, req))
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,118]<stderr>:  'is ignored.'.format(self.name, req))
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,118]<stderr>:  'is ignored.'.format(self.name, req))
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,107]<stderr>:  'is ignored.'.format(self.name, req))
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,107]<stderr>:  'is ignored.'.format(self.name, req))
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,107]<stderr>:  'is ignored.'.format(self.name, req))
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,107]<stderr>:  'is ignored.'.format(self.name, req))
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,107]<stderr>:  'is ignored.'.format(self.name, req))
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,46]<stderr>:  'is ignored.'.format(self.name, req))
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,46]<stderr>:  'is ignored.'.format(self.name, req))
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,46]<stderr>:  'is ignored.'.format(self.name, req))
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,46]<stderr>:  'is ignored.'.format(self.name, req))
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,46]<stderr>:  'is ignored.'.format(self.name, req))
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,155]<stderr>:  'is ignored.'.format(self.name, req))
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,155]<stderr>:  'is ignored.'.format(self.name, req))
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,155]<stderr>:  'is ignored.'.format(self.name, req))
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,155]<stderr>:  'is ignored.'.format(self.name, req))
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,155]<stderr>:  'is ignored.'.format(self.name, req))
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,101]<stderr>:  'is ignored.'.format(self.name, req))
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,101]<stderr>:  'is ignored.'.format(self.name, req))
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,101]<stderr>:  'is ignored.'.format(self.name, req))
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,101]<stderr>:  'is ignored.'.format(self.name, req))
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,101]<stderr>:  'is ignored.'.format(self.name, req))
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,34]<stderr>:  'is ignored.'.format(self.name, req))
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,34]<stderr>:  'is ignored.'.format(self.name, req))
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,34]<stderr>:  'is ignored.'.format(self.name, req))
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,34]<stderr>:  'is ignored.'.format(self.name, req))
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,34]<stderr>:  'is ignored.'.format(self.name, req))
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,3]<stderr>:  'is ignored.'.format(self.name, req))
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,3]<stderr>:  'is ignored.'.format(self.name, req))
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,3]<stderr>:  'is ignored.'.format(self.name, req))
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,3]<stderr>:  'is ignored.'.format(self.name, req))
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,3]<stderr>:  'is ignored.'.format(self.name, req))
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,1]<stderr>:  'is ignored.'.format(self.name, req))
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,1]<stderr>:  'is ignored.'.format(self.name, req))
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,1]<stderr>:  'is ignored.'.format(self.name, req))
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,1]<stderr>:  'is ignored.'.format(self.name, req))
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,1]<stderr>:  'is ignored.'.format(self.name, req))
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,39]<stderr>:  'is ignored.'.format(self.name, req))
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,39]<stderr>:  'is ignored.'.format(self.name, req))
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,39]<stderr>:  'is ignored.'.format(self.name, req))
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,39]<stderr>:  'is ignored.'.format(self.name, req))
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,39]<stderr>:  'is ignored.'.format(self.name, req))
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,103]<stderr>:  'is ignored.'.format(self.name, req))
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,103]<stderr>:  'is ignored.'.format(self.name, req))
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,103]<stderr>:  'is ignored.'.format(self.name, req))
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,103]<stderr>:  'is ignored.'.format(self.name, req))
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,103]<stderr>:  'is ignored.'.format(self.name, req))
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,28]<stderr>:  'is ignored.'.format(self.name, req))
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,28]<stderr>:  'is ignored.'.format(self.name, req))
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,28]<stderr>:  'is ignored.'.format(self.name, req))
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,28]<stderr>:  'is ignored.'.format(self.name, req))
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,28]<stderr>:  'is ignored.'.format(self.name, req))
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,159]<stderr>:  'is ignored.'.format(self.name, req))
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,159]<stderr>:  'is ignored.'.format(self.name, req))
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,159]<stderr>:  'is ignored.'.format(self.name, req))
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,159]<stderr>:  'is ignored.'.format(self.name, req))
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,159]<stderr>:  'is ignored.'.format(self.name, req))
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,96]<stderr>:  'is ignored.'.format(self.name, req))
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,96]<stderr>:  'is ignored.'.format(self.name, req))
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,96]<stderr>:  'is ignored.'.format(self.name, req))
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,96]<stderr>:  'is ignored.'.format(self.name, req))
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,96]<stderr>:  'is ignored.'.format(self.name, req))
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,147]<stderr>:  'is ignored.'.format(self.name, req))
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,147]<stderr>:  'is ignored.'.format(self.name, req))
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,147]<stderr>:  'is ignored.'.format(self.name, req))
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,147]<stderr>:  'is ignored.'.format(self.name, req))
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,147]<stderr>:  'is ignored.'.format(self.name, req))
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,73]<stderr>:  'is ignored.'.format(self.name, req))
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,73]<stderr>:  'is ignored.'.format(self.name, req))
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,73]<stderr>:  'is ignored.'.format(self.name, req))
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,73]<stderr>:  'is ignored.'.format(self.name, req))
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,73]<stderr>:  'is ignored.'.format(self.name, req))
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,143]<stderr>:  'is ignored.'.format(self.name, req))
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,143]<stderr>:  'is ignored.'.format(self.name, req))
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,143]<stderr>:  'is ignored.'.format(self.name, req))
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,143]<stderr>:  'is ignored.'.format(self.name, req))
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,143]<stderr>:  'is ignored.'.format(self.name, req))
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,32]<stderr>:  'is ignored.'.format(self.name, req))
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,32]<stderr>:  'is ignored.'.format(self.name, req))
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,32]<stderr>:  'is ignored.'.format(self.name, req))
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,32]<stderr>:  'is ignored.'.format(self.name, req))
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,32]<stderr>:  'is ignored.'.format(self.name, req))
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,91]<stderr>:  'is ignored.'.format(self.name, req))
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,91]<stderr>:  'is ignored.'.format(self.name, req))
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,91]<stderr>:  'is ignored.'.format(self.name, req))
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,91]<stderr>:  'is ignored.'.format(self.name, req))
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,91]<stderr>:  'is ignored.'.format(self.name, req))
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,100]<stderr>:  'is ignored.'.format(self.name, req))
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,100]<stderr>:  'is ignored.'.format(self.name, req))
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,100]<stderr>:  'is ignored.'.format(self.name, req))
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,100]<stderr>:  'is ignored.'.format(self.name, req))
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,100]<stderr>:  'is ignored.'.format(self.name, req))
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,108]<stderr>:  'is ignored.'.format(self.name, req))
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,108]<stderr>:  'is ignored.'.format(self.name, req))
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,108]<stderr>:  'is ignored.'.format(self.name, req))
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,108]<stderr>:  'is ignored.'.format(self.name, req))
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,108]<stderr>:  'is ignored.'.format(self.name, req))
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,123]<stderr>:  'is ignored.'.format(self.name, req))
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,123]<stderr>:  'is ignored.'.format(self.name, req))
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,123]<stderr>:  'is ignored.'.format(self.name, req))
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,123]<stderr>:  'is ignored.'.format(self.name, req))
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,123]<stderr>:  'is ignored.'.format(self.name, req))
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,78]<stderr>:  'is ignored.'.format(self.name, req))
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,78]<stderr>:  'is ignored.'.format(self.name, req))
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,78]<stderr>:  'is ignored.'.format(self.name, req))
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,78]<stderr>:  'is ignored.'.format(self.name, req))
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,78]<stderr>:  'is ignored.'.format(self.name, req))
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,120]<stderr>:  'is ignored.'.format(self.name, req))
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,120]<stderr>:  'is ignored.'.format(self.name, req))
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,120]<stderr>:  'is ignored.'.format(self.name, req))
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,120]<stderr>:  'is ignored.'.format(self.name, req))
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,120]<stderr>:  'is ignored.'.format(self.name, req))
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,79]<stderr>:  'is ignored.'.format(self.name, req))
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,79]<stderr>:  'is ignored.'.format(self.name, req))
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,79]<stderr>:  'is ignored.'.format(self.name, req))
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,79]<stderr>:  'is ignored.'.format(self.name, req))
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,79]<stderr>:  'is ignored.'.format(self.name, req))
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,55]<stderr>:  'is ignored.'.format(self.name, req))
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,55]<stderr>:  'is ignored.'.format(self.name, req))
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,55]<stderr>:  'is ignored.'.format(self.name, req))
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,55]<stderr>:  'is ignored.'.format(self.name, req))
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,55]<stderr>:  'is ignored.'.format(self.name, req))
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,106]<stderr>:  'is ignored.'.format(self.name, req))
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,106]<stderr>:  'is ignored.'.format(self.name, req))
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,106]<stderr>:  'is ignored.'.format(self.name, req))
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,106]<stderr>:  'is ignored.'.format(self.name, req))
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,106]<stderr>:  'is ignored.'.format(self.name, req))
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,122]<stderr>:  'is ignored.'.format(self.name, req))
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,122]<stderr>:  'is ignored.'.format(self.name, req))
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,122]<stderr>:  'is ignored.'.format(self.name, req))
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,122]<stderr>:  'is ignored.'.format(self.name, req))
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,122]<stderr>:  'is ignored.'.format(self.name, req))
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,71]<stderr>:  'is ignored.'.format(self.name, req))
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,71]<stderr>:  'is ignored.'.format(self.name, req))
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,71]<stderr>:  'is ignored.'.format(self.name, req))
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,71]<stderr>:  'is ignored.'.format(self.name, req))
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,71]<stderr>:  'is ignored.'.format(self.name, req))
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,70]<stderr>:  'is ignored.'.format(self.name, req))
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,70]<stderr>:  'is ignored.'.format(self.name, req))
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,70]<stderr>:  'is ignored.'.format(self.name, req))
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,70]<stderr>:  'is ignored.'.format(self.name, req))
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,70]<stderr>:  'is ignored.'.format(self.name, req))
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,148]<stderr>:  'is ignored.'.format(self.name, req))
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,148]<stderr>:  'is ignored.'.format(self.name, req))
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,148]<stderr>:  'is ignored.'.format(self.name, req))
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,148]<stderr>:  'is ignored.'.format(self.name, req))
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,148]<stderr>:  'is ignored.'.format(self.name, req))
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,75]<stderr>:  'is ignored.'.format(self.name, req))
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,75]<stderr>:  'is ignored.'.format(self.name, req))
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,75]<stderr>:  'is ignored.'.format(self.name, req))
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,75]<stderr>:  'is ignored.'.format(self.name, req))
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,75]<stderr>:  'is ignored.'.format(self.name, req))
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,128]<stderr>:  'is ignored.'.format(self.name, req))
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,128]<stderr>:  'is ignored.'.format(self.name, req))
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,128]<stderr>:  'is ignored.'.format(self.name, req))
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,128]<stderr>:  'is ignored.'.format(self.name, req))
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,128]<stderr>:  'is ignored.'.format(self.name, req))
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,111]<stderr>:  'is ignored.'.format(self.name, req))
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,111]<stderr>:  'is ignored.'.format(self.name, req))
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,111]<stderr>:  'is ignored.'.format(self.name, req))
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,111]<stderr>:  'is ignored.'.format(self.name, req))
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,111]<stderr>:  'is ignored.'.format(self.name, req))
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,176]<stderr>:  'is ignored.'.format(self.name, req))
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,176]<stderr>:  'is ignored.'.format(self.name, req))
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,176]<stderr>:  'is ignored.'.format(self.name, req))
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,176]<stderr>:  'is ignored.'.format(self.name, req))
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,176]<stderr>:  'is ignored.'.format(self.name, req))
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,51]<stderr>:  'is ignored.'.format(self.name, req))
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,51]<stderr>:  'is ignored.'.format(self.name, req))
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,51]<stderr>:  'is ignored.'.format(self.name, req))
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,51]<stderr>:  'is ignored.'.format(self.name, req))
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,51]<stderr>:  'is ignored.'.format(self.name, req))
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,50]<stderr>:  'is ignored.'.format(self.name, req))
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,50]<stderr>:  'is ignored.'.format(self.name, req))
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,50]<stderr>:  'is ignored.'.format(self.name, req))
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,50]<stderr>:  'is ignored.'.format(self.name, req))
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,50]<stderr>:  'is ignored.'.format(self.name, req))
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,138]<stderr>:  'is ignored.'.format(self.name, req))
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,138]<stderr>:  'is ignored.'.format(self.name, req))
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,138]<stderr>:  'is ignored.'.format(self.name, req))
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,138]<stderr>:  'is ignored.'.format(self.name, req))
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,138]<stderr>:  'is ignored.'.format(self.name, req))
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,149]<stderr>:  'is ignored.'.format(self.name, req))
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,149]<stderr>:  'is ignored.'.format(self.name, req))
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,149]<stderr>:  'is ignored.'.format(self.name, req))
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,149]<stderr>:  'is ignored.'.format(self.name, req))
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,149]<stderr>:  'is ignored.'.format(self.name, req))
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,48]<stderr>:  'is ignored.'.format(self.name, req))
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,48]<stderr>:  'is ignored.'.format(self.name, req))
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,48]<stderr>:  'is ignored.'.format(self.name, req))
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,48]<stderr>:  'is ignored.'.format(self.name, req))
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,48]<stderr>:  'is ignored.'.format(self.name, req))
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,92]<stderr>:  'is ignored.'.format(self.name, req))
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,92]<stderr>:  'is ignored.'.format(self.name, req))
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,92]<stderr>:  'is ignored.'.format(self.name, req))
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,92]<stderr>:  'is ignored.'.format(self.name, req))
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,92]<stderr>:  'is ignored.'.format(self.name, req))
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,44]<stderr>:  'is ignored.'.format(self.name, req))
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,44]<stderr>:  'is ignored.'.format(self.name, req))
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,44]<stderr>:  'is ignored.'.format(self.name, req))
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,44]<stderr>:  'is ignored.'.format(self.name, req))
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,44]<stderr>:  'is ignored.'.format(self.name, req))
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,69]<stderr>:  'is ignored.'.format(self.name, req))
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,69]<stderr>:  'is ignored.'.format(self.name, req))
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,69]<stderr>:  'is ignored.'.format(self.name, req))
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,69]<stderr>:  'is ignored.'.format(self.name, req))
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,69]<stderr>:  'is ignored.'.format(self.name, req))
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,158]<stderr>:  'is ignored.'.format(self.name, req))
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,158]<stderr>:  'is ignored.'.format(self.name, req))
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,158]<stderr>:  'is ignored.'.format(self.name, req))
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,158]<stderr>:  'is ignored.'.format(self.name, req))
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,158]<stderr>:  'is ignored.'.format(self.name, req))
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,82]<stderr>:  'is ignored.'.format(self.name, req))
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,82]<stderr>:  'is ignored.'.format(self.name, req))
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,82]<stderr>:  'is ignored.'.format(self.name, req))
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,82]<stderr>:  'is ignored.'.format(self.name, req))
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,82]<stderr>:  'is ignored.'.format(self.name, req))
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,134]<stderr>:  'is ignored.'.format(self.name, req))
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,134]<stderr>:  'is ignored.'.format(self.name, req))
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,134]<stderr>:  'is ignored.'.format(self.name, req))
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,134]<stderr>:  'is ignored.'.format(self.name, req))
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,134]<stderr>:  'is ignored.'.format(self.name, req))
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,151]<stderr>:  'is ignored.'.format(self.name, req))
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,151]<stderr>:  'is ignored.'.format(self.name, req))
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,151]<stderr>:  'is ignored.'.format(self.name, req))
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,151]<stderr>:  'is ignored.'.format(self.name, req))
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,151]<stderr>:  'is ignored.'.format(self.name, req))
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,113]<stderr>:  'is ignored.'.format(self.name, req))
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,113]<stderr>:  'is ignored.'.format(self.name, req))
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,113]<stderr>:  'is ignored.'.format(self.name, req))
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,113]<stderr>:  'is ignored.'.format(self.name, req))
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,113]<stderr>:  'is ignored.'.format(self.name, req))
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,83]<stderr>:  'is ignored.'.format(self.name, req))
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,83]<stderr>:  'is ignored.'.format(self.name, req))
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,83]<stderr>:  'is ignored.'.format(self.name, req))
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,83]<stderr>:  'is ignored.'.format(self.name, req))
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,83]<stderr>:  'is ignored.'.format(self.name, req))
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,24]<stderr>:  'is ignored.'.format(self.name, req))
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,24]<stderr>:  'is ignored.'.format(self.name, req))
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,24]<stderr>:  'is ignored.'.format(self.name, req))
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,24]<stderr>:  'is ignored.'.format(self.name, req))
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,24]<stderr>:  'is ignored.'.format(self.name, req))
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,68]<stderr>:  'is ignored.'.format(self.name, req))
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,68]<stderr>:  'is ignored.'.format(self.name, req))
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,68]<stderr>:  'is ignored.'.format(self.name, req))
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,68]<stderr>:  'is ignored.'.format(self.name, req))
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,68]<stderr>:  'is ignored.'.format(self.name, req))
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,87]<stderr>:  'is ignored.'.format(self.name, req))
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,87]<stderr>:  'is ignored.'.format(self.name, req))
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,87]<stderr>:  'is ignored.'.format(self.name, req))
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,87]<stderr>:  'is ignored.'.format(self.name, req))
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,87]<stderr>:  'is ignored.'.format(self.name, req))
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,53]<stderr>:  'is ignored.'.format(self.name, req))
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,53]<stderr>:  'is ignored.'.format(self.name, req))
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,53]<stderr>:  'is ignored.'.format(self.name, req))
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,53]<stderr>:  'is ignored.'.format(self.name, req))
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,53]<stderr>:  'is ignored.'.format(self.name, req))
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,77]<stderr>:  'is ignored.'.format(self.name, req))
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,77]<stderr>:  'is ignored.'.format(self.name, req))
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,77]<stderr>:  'is ignored.'.format(self.name, req))
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,77]<stderr>:  'is ignored.'.format(self.name, req))
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,77]<stderr>:  'is ignored.'.format(self.name, req))
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,145]<stderr>:  'is ignored.'.format(self.name, req))
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,145]<stderr>:  'is ignored.'.format(self.name, req))
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,145]<stderr>:  'is ignored.'.format(self.name, req))
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,145]<stderr>:  'is ignored.'.format(self.name, req))
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,145]<stderr>:  'is ignored.'.format(self.name, req))
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,60]<stderr>:  'is ignored.'.format(self.name, req))
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,60]<stderr>:  'is ignored.'.format(self.name, req))
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,60]<stderr>:  'is ignored.'.format(self.name, req))
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,60]<stderr>:  'is ignored.'.format(self.name, req))
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,60]<stderr>:  'is ignored.'.format(self.name, req))
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,49]<stderr>:  'is ignored.'.format(self.name, req))
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,49]<stderr>:  'is ignored.'.format(self.name, req))
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,49]<stderr>:  'is ignored.'.format(self.name, req))
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,49]<stderr>:  'is ignored.'.format(self.name, req))
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,49]<stderr>:  'is ignored.'.format(self.name, req))
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,62]<stderr>:  'is ignored.'.format(self.name, req))
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,62]<stderr>:  'is ignored.'.format(self.name, req))
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,62]<stderr>:  'is ignored.'.format(self.name, req))
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,62]<stderr>:  'is ignored.'.format(self.name, req))
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,62]<stderr>:  'is ignored.'.format(self.name, req))
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,105]<stderr>:  'is ignored.'.format(self.name, req))
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,105]<stderr>:  'is ignored.'.format(self.name, req))
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,105]<stderr>:  'is ignored.'.format(self.name, req))
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,105]<stderr>:  'is ignored.'.format(self.name, req))
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,105]<stderr>:  'is ignored.'.format(self.name, req))
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,84]<stderr>:  'is ignored.'.format(self.name, req))
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,84]<stderr>:  'is ignored.'.format(self.name, req))
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,84]<stderr>:  'is ignored.'.format(self.name, req))
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,84]<stderr>:  'is ignored.'.format(self.name, req))
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,84]<stderr>:  'is ignored.'.format(self.name, req))
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,99]<stderr>:  'is ignored.'.format(self.name, req))
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,99]<stderr>:  'is ignored.'.format(self.name, req))
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,99]<stderr>:  'is ignored.'.format(self.name, req))
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,99]<stderr>:  'is ignored.'.format(self.name, req))
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,99]<stderr>:  'is ignored.'.format(self.name, req))
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,43]<stderr>:  'is ignored.'.format(self.name, req))
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,43]<stderr>:  'is ignored.'.format(self.name, req))
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,43]<stderr>:  'is ignored.'.format(self.name, req))
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,43]<stderr>:  'is ignored.'.format(self.name, req))
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,43]<stderr>:  'is ignored.'.format(self.name, req))
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,117]<stderr>:  'is ignored.'.format(self.name, req))
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,117]<stderr>:  'is ignored.'.format(self.name, req))
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,117]<stderr>:  'is ignored.'.format(self.name, req))
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,117]<stderr>:  'is ignored.'.format(self.name, req))
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,117]<stderr>:  'is ignored.'.format(self.name, req))
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,74]<stderr>:  'is ignored.'.format(self.name, req))
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,74]<stderr>:  'is ignored.'.format(self.name, req))
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,74]<stderr>:  'is ignored.'.format(self.name, req))
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,74]<stderr>:  'is ignored.'.format(self.name, req))
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,74]<stderr>:  'is ignored.'.format(self.name, req))
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,97]<stderr>:  'is ignored.'.format(self.name, req))
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,97]<stderr>:  'is ignored.'.format(self.name, req))
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,97]<stderr>:  'is ignored.'.format(self.name, req))
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,97]<stderr>:  'is ignored.'.format(self.name, req))
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,97]<stderr>:  'is ignored.'.format(self.name, req))
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,161]<stderr>:  'is ignored.'.format(self.name, req))
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,161]<stderr>:  'is ignored.'.format(self.name, req))
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,161]<stderr>:  'is ignored.'.format(self.name, req))
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,161]<stderr>:  'is ignored.'.format(self.name, req))
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,161]<stderr>:  'is ignored.'.format(self.name, req))
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,146]<stderr>:  'is ignored.'.format(self.name, req))
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,146]<stderr>:  'is ignored.'.format(self.name, req))
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,146]<stderr>:  'is ignored.'.format(self.name, req))
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,146]<stderr>:  'is ignored.'.format(self.name, req))
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,146]<stderr>:  'is ignored.'.format(self.name, req))
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,163]<stderr>:  'is ignored.'.format(self.name, req))
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,163]<stderr>:  'is ignored.'.format(self.name, req))
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,163]<stderr>:  'is ignored.'.format(self.name, req))
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,163]<stderr>:  'is ignored.'.format(self.name, req))
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,163]<stderr>:  'is ignored.'.format(self.name, req))
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,114]<stderr>:  'is ignored.'.format(self.name, req))
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,114]<stderr>:  'is ignored.'.format(self.name, req))
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,114]<stderr>:  'is ignored.'.format(self.name, req))
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,114]<stderr>:  'is ignored.'.format(self.name, req))
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,114]<stderr>:  'is ignored.'.format(self.name, req))
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,19]<stderr>:  'is ignored.'.format(self.name, req))
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,19]<stderr>:  'is ignored.'.format(self.name, req))
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,19]<stderr>:  'is ignored.'.format(self.name, req))
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,19]<stderr>:  'is ignored.'.format(self.name, req))
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,19]<stderr>:  'is ignored.'.format(self.name, req))
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,35]<stderr>:  'is ignored.'.format(self.name, req))
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,35]<stderr>:  'is ignored.'.format(self.name, req))
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,35]<stderr>:  'is ignored.'.format(self.name, req))
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,35]<stderr>:  'is ignored.'.format(self.name, req))
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,35]<stderr>:  'is ignored.'.format(self.name, req))
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,36]<stderr>:  'is ignored.'.format(self.name, req))
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,36]<stderr>:  'is ignored.'.format(self.name, req))
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,36]<stderr>:  'is ignored.'.format(self.name, req))
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,36]<stderr>:  'is ignored.'.format(self.name, req))
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,36]<stderr>:  'is ignored.'.format(self.name, req))
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,173]<stderr>:  'is ignored.'.format(self.name, req))
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,173]<stderr>:  'is ignored.'.format(self.name, req))
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,173]<stderr>:  'is ignored.'.format(self.name, req))
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,173]<stderr>:  'is ignored.'.format(self.name, req))
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,173]<stderr>:  'is ignored.'.format(self.name, req))
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,160]<stderr>:  'is ignored.'.format(self.name, req))
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,160]<stderr>:  'is ignored.'.format(self.name, req))
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,160]<stderr>:  'is ignored.'.format(self.name, req))
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,160]<stderr>:  'is ignored.'.format(self.name, req))
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,160]<stderr>:  'is ignored.'.format(self.name, req))
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,167]<stderr>:  'is ignored.'.format(self.name, req))
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,167]<stderr>:  'is ignored.'.format(self.name, req))
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,167]<stderr>:  'is ignored.'.format(self.name, req))
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,167]<stderr>:  'is ignored.'.format(self.name, req))
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,167]<stderr>:  'is ignored.'.format(self.name, req))
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,115]<stderr>:  'is ignored.'.format(self.name, req))
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,115]<stderr>:  'is ignored.'.format(self.name, req))
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,115]<stderr>:  'is ignored.'.format(self.name, req))
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,115]<stderr>:  'is ignored.'.format(self.name, req))
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,115]<stderr>:  'is ignored.'.format(self.name, req))
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,102]<stderr>:  'is ignored.'.format(self.name, req))
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,102]<stderr>:  'is ignored.'.format(self.name, req))
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,102]<stderr>:  'is ignored.'.format(self.name, req))
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,102]<stderr>:  'is ignored.'.format(self.name, req))
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,102]<stderr>:  'is ignored.'.format(self.name, req))
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,65]<stderr>:  'is ignored.'.format(self.name, req))
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,65]<stderr>:  'is ignored.'.format(self.name, req))
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,65]<stderr>:  'is ignored.'.format(self.name, req))
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,65]<stderr>:  'is ignored.'.format(self.name, req))
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,65]<stderr>:  'is ignored.'.format(self.name, req))
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,25]<stderr>:  'is ignored.'.format(self.name, req))
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,25]<stderr>:  'is ignored.'.format(self.name, req))
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,25]<stderr>:  'is ignored.'.format(self.name, req))
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,25]<stderr>:  'is ignored.'.format(self.name, req))
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,25]<stderr>:  'is ignored.'.format(self.name, req))
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,154]<stderr>:  'is ignored.'.format(self.name, req))
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,154]<stderr>:  'is ignored.'.format(self.name, req))
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,154]<stderr>:  'is ignored.'.format(self.name, req))
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,154]<stderr>:  'is ignored.'.format(self.name, req))
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,154]<stderr>:  'is ignored.'.format(self.name, req))
[1,52]<stdout>:creating index...
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,171]<stderr>:  'is ignored.'.format(self.name, req))
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,171]<stderr>:  'is ignored.'.format(self.name, req))
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,171]<stderr>:  'is ignored.'.format(self.name, req))
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,171]<stderr>:  'is ignored.'.format(self.name, req))
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,171]<stderr>:  'is ignored.'.format(self.name, req))
[1,116]<stdout>:creating index...
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,172]<stderr>:  'is ignored.'.format(self.name, req))
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,172]<stderr>:  'is ignored.'.format(self.name, req))
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,172]<stderr>:  'is ignored.'.format(self.name, req))
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,172]<stderr>:  'is ignored.'.format(self.name, req))
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,172]<stderr>:  'is ignored.'.format(self.name, req))
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,29]<stderr>:  'is ignored.'.format(self.name, req))
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,29]<stderr>:  'is ignored.'.format(self.name, req))
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,29]<stderr>:  'is ignored.'.format(self.name, req))
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,29]<stderr>:  'is ignored.'.format(self.name, req))
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,29]<stderr>:  'is ignored.'.format(self.name, req))
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,190]<stderr>:  'is ignored.'.format(self.name, req))
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,190]<stderr>:  'is ignored.'.format(self.name, req))
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,190]<stderr>:  'is ignored.'.format(self.name, req))
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,190]<stderr>:  'is ignored.'.format(self.name, req))
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,190]<stderr>:  'is ignored.'.format(self.name, req))
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,104]<stderr>:  'is ignored.'.format(self.name, req))
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,104]<stderr>:  'is ignored.'.format(self.name, req))
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,104]<stderr>:  'is ignored.'.format(self.name, req))
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,104]<stderr>:  'is ignored.'.format(self.name, req))
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,104]<stderr>:  'is ignored.'.format(self.name, req))
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,38]<stderr>:  'is ignored.'.format(self.name, req))
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,38]<stderr>:  'is ignored.'.format(self.name, req))
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,38]<stderr>:  'is ignored.'.format(self.name, req))
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,38]<stderr>:  'is ignored.'.format(self.name, req))
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,38]<stderr>:  'is ignored.'.format(self.name, req))
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,182]<stderr>:  'is ignored.'.format(self.name, req))
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,182]<stderr>:  'is ignored.'.format(self.name, req))
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,182]<stderr>:  'is ignored.'.format(self.name, req))
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,182]<stderr>:  'is ignored.'.format(self.name, req))
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,182]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stdout>:loading annotations into memory...
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,8]<stderr>:  'is ignored.'.format(self.name, req))
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,8]<stderr>:  'is ignored.'.format(self.name, req))
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,8]<stderr>:  'is ignored.'.format(self.name, req))
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,8]<stderr>:  'is ignored.'.format(self.name, req))
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,8]<stderr>:  'is ignored.'.format(self.name, req))
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,15]<stderr>:  'is ignored.'.format(self.name, req))
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,15]<stderr>:  'is ignored.'.format(self.name, req))
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,15]<stderr>:  'is ignored.'.format(self.name, req))
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,15]<stderr>:  'is ignored.'.format(self.name, req))
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,15]<stderr>:  'is ignored.'.format(self.name, req))
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,59]<stderr>:  'is ignored.'.format(self.name, req))
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,59]<stderr>:  'is ignored.'.format(self.name, req))
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,59]<stderr>:  'is ignored.'.format(self.name, req))
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,59]<stderr>:  'is ignored.'.format(self.name, req))
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,59]<stderr>:  'is ignored.'.format(self.name, req))
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,136]<stderr>:  'is ignored.'.format(self.name, req))
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,136]<stderr>:  'is ignored.'.format(self.name, req))
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,136]<stderr>:  'is ignored.'.format(self.name, req))
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,136]<stderr>:  'is ignored.'.format(self.name, req))
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,136]<stderr>:  'is ignored.'.format(self.name, req))
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,142]<stderr>:  'is ignored.'.format(self.name, req))
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,142]<stderr>:  'is ignored.'.format(self.name, req))
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,142]<stderr>:  'is ignored.'.format(self.name, req))
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,142]<stderr>:  'is ignored.'.format(self.name, req))
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,142]<stderr>:  'is ignored.'.format(self.name, req))
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,61]<stderr>:  'is ignored.'.format(self.name, req))
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,61]<stderr>:  'is ignored.'.format(self.name, req))
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,61]<stderr>:  'is ignored.'.format(self.name, req))
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,61]<stderr>:  'is ignored.'.format(self.name, req))
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,61]<stderr>:  'is ignored.'.format(self.name, req))
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,12]<stderr>:  'is ignored.'.format(self.name, req))
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,12]<stderr>:  'is ignored.'.format(self.name, req))
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,12]<stderr>:  'is ignored.'.format(self.name, req))
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,12]<stderr>:  'is ignored.'.format(self.name, req))
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,12]<stderr>:  'is ignored.'.format(self.name, req))
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,127]<stderr>:  'is ignored.'.format(self.name, req))
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,127]<stderr>:  'is ignored.'.format(self.name, req))
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,127]<stderr>:  'is ignored.'.format(self.name, req))
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,127]<stderr>:  'is ignored.'.format(self.name, req))
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,127]<stderr>:  'is ignored.'.format(self.name, req))
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,47]<stderr>:  'is ignored.'.format(self.name, req))
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,47]<stderr>:  'is ignored.'.format(self.name, req))
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,47]<stderr>:  'is ignored.'.format(self.name, req))
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,47]<stderr>:  'is ignored.'.format(self.name, req))
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,47]<stderr>:  'is ignored.'.format(self.name, req))
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,139]<stderr>:  'is ignored.'.format(self.name, req))
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,139]<stderr>:  'is ignored.'.format(self.name, req))
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,139]<stderr>:  'is ignored.'.format(self.name, req))
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,139]<stderr>:  'is ignored.'.format(self.name, req))
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,139]<stderr>:  'is ignored.'.format(self.name, req))
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,121]<stderr>:  'is ignored.'.format(self.name, req))
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,121]<stderr>:  'is ignored.'.format(self.name, req))
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,121]<stderr>:  'is ignored.'.format(self.name, req))
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,121]<stderr>:  'is ignored.'.format(self.name, req))
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,121]<stderr>:  'is ignored.'.format(self.name, req))
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,162]<stderr>:  'is ignored.'.format(self.name, req))
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,162]<stderr>:  'is ignored.'.format(self.name, req))
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,162]<stderr>:  'is ignored.'.format(self.name, req))
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,162]<stderr>:  'is ignored.'.format(self.name, req))
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,162]<stderr>:  'is ignored.'.format(self.name, req))
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,27]<stderr>:  'is ignored.'.format(self.name, req))
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,27]<stderr>:  'is ignored.'.format(self.name, req))
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,27]<stderr>:  'is ignored.'.format(self.name, req))
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,27]<stderr>:  'is ignored.'.format(self.name, req))
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,27]<stderr>:  'is ignored.'.format(self.name, req))
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,22]<stderr>:  'is ignored.'.format(self.name, req))
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,22]<stderr>:  'is ignored.'.format(self.name, req))
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,22]<stderr>:  'is ignored.'.format(self.name, req))
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,22]<stderr>:  'is ignored.'.format(self.name, req))
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,22]<stderr>:  'is ignored.'.format(self.name, req))
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,17]<stderr>:  'is ignored.'.format(self.name, req))
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,17]<stderr>:  'is ignored.'.format(self.name, req))
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,17]<stderr>:  'is ignored.'.format(self.name, req))
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,17]<stderr>:  'is ignored.'.format(self.name, req))
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,17]<stderr>:  'is ignored.'.format(self.name, req))
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,45]<stderr>:  'is ignored.'.format(self.name, req))
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,45]<stderr>:  'is ignored.'.format(self.name, req))
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,45]<stderr>:  'is ignored.'.format(self.name, req))
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,45]<stderr>:  'is ignored.'.format(self.name, req))
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,45]<stderr>:  'is ignored.'.format(self.name, req))
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,189]<stderr>:  'is ignored.'.format(self.name, req))
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,189]<stderr>:  'is ignored.'.format(self.name, req))
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,189]<stderr>:  'is ignored.'.format(self.name, req))
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,189]<stderr>:  'is ignored.'.format(self.name, req))
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,189]<stderr>:  'is ignored.'.format(self.name, req))
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,42]<stderr>:  'is ignored.'.format(self.name, req))
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,42]<stderr>:  'is ignored.'.format(self.name, req))
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,42]<stderr>:  'is ignored.'.format(self.name, req))
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,42]<stderr>:  'is ignored.'.format(self.name, req))
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,42]<stderr>:  'is ignored.'.format(self.name, req))
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,86]<stderr>:  'is ignored.'.format(self.name, req))
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,86]<stderr>:  'is ignored.'.format(self.name, req))
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,86]<stderr>:  'is ignored.'.format(self.name, req))
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,86]<stderr>:  'is ignored.'.format(self.name, req))
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,86]<stderr>:  'is ignored.'.format(self.name, req))
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,110]<stderr>:  'is ignored.'.format(self.name, req))
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,110]<stderr>:  'is ignored.'.format(self.name, req))
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,110]<stderr>:  'is ignored.'.format(self.name, req))
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,110]<stderr>:  'is ignored.'.format(self.name, req))
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,110]<stderr>:  'is ignored.'.format(self.name, req))
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,80]<stderr>:  'is ignored.'.format(self.name, req))
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,80]<stderr>:  'is ignored.'.format(self.name, req))
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,80]<stderr>:  'is ignored.'.format(self.name, req))
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,80]<stderr>:  'is ignored.'.format(self.name, req))
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,80]<stderr>:  'is ignored.'.format(self.name, req))
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,141]<stderr>:  'is ignored.'.format(self.name, req))
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,141]<stderr>:  'is ignored.'.format(self.name, req))
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,141]<stderr>:  'is ignored.'.format(self.name, req))
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,141]<stderr>:  'is ignored.'.format(self.name, req))
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,141]<stderr>:  'is ignored.'.format(self.name, req))
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,81]<stderr>:  'is ignored.'.format(self.name, req))
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,81]<stderr>:  'is ignored.'.format(self.name, req))
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,81]<stderr>:  'is ignored.'.format(self.name, req))
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,81]<stderr>:  'is ignored.'.format(self.name, req))
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,81]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stdout>:Done (t=0.39s)
[1,76]<stdout>:creating index...
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,88]<stderr>:  'is ignored.'.format(self.name, req))
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,88]<stderr>:  'is ignored.'.format(self.name, req))
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,88]<stderr>:  'is ignored.'.format(self.name, req))
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,88]<stderr>:  'is ignored.'.format(self.name, req))
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,88]<stderr>:  'is ignored.'.format(self.name, req))
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,18]<stderr>:  'is ignored.'.format(self.name, req))
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,18]<stderr>:  'is ignored.'.format(self.name, req))
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,18]<stderr>:  'is ignored.'.format(self.name, req))
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,18]<stderr>:  'is ignored.'.format(self.name, req))
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,18]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stdout>:loading annotations into memory...
[1,76]<stdout>:index created!
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,181]<stderr>:  'is ignored.'.format(self.name, req))
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,181]<stderr>:  'is ignored.'.format(self.name, req))
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,181]<stderr>:  'is ignored.'.format(self.name, req))
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,181]<stderr>:  'is ignored.'.format(self.name, req))
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,181]<stderr>:  'is ignored.'.format(self.name, req))
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,179]<stderr>:  'is ignored.'.format(self.name, req))
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,179]<stderr>:  'is ignored.'.format(self.name, req))
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,179]<stderr>:  'is ignored.'.format(self.name, req))
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,179]<stderr>:  'is ignored.'.format(self.name, req))
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,179]<stderr>:  'is ignored.'.format(self.name, req))
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,57]<stderr>:  'is ignored.'.format(self.name, req))
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,57]<stderr>:  'is ignored.'.format(self.name, req))
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,57]<stderr>:  'is ignored.'.format(self.name, req))
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,57]<stderr>:  'is ignored.'.format(self.name, req))
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,57]<stderr>:  'is ignored.'.format(self.name, req))
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,26]<stderr>:  'is ignored.'.format(self.name, req))
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,26]<stderr>:  'is ignored.'.format(self.name, req))
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,26]<stderr>:  'is ignored.'.format(self.name, req))
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,26]<stderr>:  'is ignored.'.format(self.name, req))
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,26]<stderr>:  'is ignored.'.format(self.name, req))
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,140]<stderr>:  'is ignored.'.format(self.name, req))
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,140]<stderr>:  'is ignored.'.format(self.name, req))
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,140]<stderr>:  'is ignored.'.format(self.name, req))
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,140]<stderr>:  'is ignored.'.format(self.name, req))
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,140]<stderr>:  'is ignored.'.format(self.name, req))
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,135]<stderr>:  'is ignored.'.format(self.name, req))
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,135]<stderr>:  'is ignored.'.format(self.name, req))
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,135]<stderr>:  'is ignored.'.format(self.name, req))
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,135]<stderr>:  'is ignored.'.format(self.name, req))
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,135]<stderr>:  'is ignored.'.format(self.name, req))
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,64]<stderr>:  'is ignored.'.format(self.name, req))
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,64]<stderr>:  'is ignored.'.format(self.name, req))
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,64]<stderr>:  'is ignored.'.format(self.name, req))
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,64]<stderr>:  'is ignored.'.format(self.name, req))
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,64]<stderr>:  'is ignored.'.format(self.name, req))
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,11]<stderr>:  'is ignored.'.format(self.name, req))
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,11]<stderr>:  'is ignored.'.format(self.name, req))
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,11]<stderr>:  'is ignored.'.format(self.name, req))
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,11]<stderr>:  'is ignored.'.format(self.name, req))
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,11]<stderr>:  'is ignored.'.format(self.name, req))
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,152]<stderr>:  'is ignored.'.format(self.name, req))
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,152]<stderr>:  'is ignored.'.format(self.name, req))
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,152]<stderr>:  'is ignored.'.format(self.name, req))
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,152]<stderr>:  'is ignored.'.format(self.name, req))
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,152]<stderr>:  'is ignored.'.format(self.name, req))
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,169]<stderr>:  'is ignored.'.format(self.name, req))
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,169]<stderr>:  'is ignored.'.format(self.name, req))
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,169]<stderr>:  'is ignored.'.format(self.name, req))
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,169]<stderr>:  'is ignored.'.format(self.name, req))
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,169]<stderr>:  'is ignored.'.format(self.name, req))
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,144]<stderr>:  'is ignored.'.format(self.name, req))
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,144]<stderr>:  'is ignored.'.format(self.name, req))
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,144]<stderr>:  'is ignored.'.format(self.name, req))
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,144]<stderr>:  'is ignored.'.format(self.name, req))
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,144]<stderr>:  'is ignored.'.format(self.name, req))
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,9]<stderr>:  'is ignored.'.format(self.name, req))
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,9]<stderr>:  'is ignored.'.format(self.name, req))
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,9]<stderr>:  'is ignored.'.format(self.name, req))
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,9]<stderr>:  'is ignored.'.format(self.name, req))
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,9]<stderr>:  'is ignored.'.format(self.name, req))
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,168]<stderr>:  'is ignored.'.format(self.name, req))
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,168]<stderr>:  'is ignored.'.format(self.name, req))
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,168]<stderr>:  'is ignored.'.format(self.name, req))
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,168]<stderr>:  'is ignored.'.format(self.name, req))
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,168]<stderr>:  'is ignored.'.format(self.name, req))
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,119]<stderr>:  'is ignored.'.format(self.name, req))
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,119]<stderr>:  'is ignored.'.format(self.name, req))
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,119]<stderr>:  'is ignored.'.format(self.name, req))
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,119]<stderr>:  'is ignored.'.format(self.name, req))
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,119]<stderr>:  'is ignored.'.format(self.name, req))
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,150]<stderr>:  'is ignored.'.format(self.name, req))
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,150]<stderr>:  'is ignored.'.format(self.name, req))
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,150]<stderr>:  'is ignored.'.format(self.name, req))
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,150]<stderr>:  'is ignored.'.format(self.name, req))
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,150]<stderr>:  'is ignored.'.format(self.name, req))
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,10]<stderr>:  'is ignored.'.format(self.name, req))
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,10]<stderr>:  'is ignored.'.format(self.name, req))
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,10]<stderr>:  'is ignored.'.format(self.name, req))
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,10]<stderr>:  'is ignored.'.format(self.name, req))
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,10]<stderr>:  'is ignored.'.format(self.name, req))
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,156]<stderr>:  'is ignored.'.format(self.name, req))
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,156]<stderr>:  'is ignored.'.format(self.name, req))
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,156]<stderr>:  'is ignored.'.format(self.name, req))
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,156]<stderr>:  'is ignored.'.format(self.name, req))
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,156]<stderr>:  'is ignored.'.format(self.name, req))
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,40]<stderr>:  'is ignored.'.format(self.name, req))
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,40]<stderr>:  'is ignored.'.format(self.name, req))
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,40]<stderr>:  'is ignored.'.format(self.name, req))
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,40]<stderr>:  'is ignored.'.format(self.name, req))
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,40]<stderr>:  'is ignored.'.format(self.name, req))
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,58]<stderr>:  'is ignored.'.format(self.name, req))
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,58]<stderr>:  'is ignored.'.format(self.name, req))
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,58]<stderr>:  'is ignored.'.format(self.name, req))
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,58]<stderr>:  'is ignored.'.format(self.name, req))
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,58]<stderr>:  'is ignored.'.format(self.name, req))
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,14]<stderr>:  'is ignored.'.format(self.name, req))
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,14]<stderr>:  'is ignored.'.format(self.name, req))
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,14]<stderr>:  'is ignored.'.format(self.name, req))
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,14]<stderr>:  'is ignored.'.format(self.name, req))
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,14]<stderr>:  'is ignored.'.format(self.name, req))
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,166]<stderr>:  'is ignored.'.format(self.name, req))
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,166]<stderr>:  'is ignored.'.format(self.name, req))
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,166]<stderr>:  'is ignored.'.format(self.name, req))
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,166]<stderr>:  'is ignored.'.format(self.name, req))
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,166]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stdout>:Done (t=0.39s)
[1,188]<stdout>:creating index...
[1,4]<stdout>:loading annotations into memory...
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,112]<stderr>:  'is ignored.'.format(self.name, req))
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,112]<stderr>:  'is ignored.'.format(self.name, req))
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,112]<stderr>:  'is ignored.'.format(self.name, req))
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,112]<stderr>:  'is ignored.'.format(self.name, req))
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,112]<stderr>:  'is ignored.'.format(self.name, req))
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,16]<stderr>:  'is ignored.'.format(self.name, req))
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,16]<stderr>:  'is ignored.'.format(self.name, req))
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,16]<stderr>:  'is ignored.'.format(self.name, req))
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,16]<stderr>:  'is ignored.'.format(self.name, req))
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,16]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stdout>:index created!
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,191]<stderr>:  'is ignored.'.format(self.name, req))
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,191]<stderr>:  'is ignored.'.format(self.name, req))
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,191]<stderr>:  'is ignored.'.format(self.name, req))
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,191]<stderr>:  'is ignored.'.format(self.name, req))
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,191]<stderr>:  'is ignored.'.format(self.name, req))
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,21]<stderr>:  'is ignored.'.format(self.name, req))
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,21]<stderr>:  'is ignored.'.format(self.name, req))
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,21]<stderr>:  'is ignored.'.format(self.name, req))
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,21]<stderr>:  'is ignored.'.format(self.name, req))
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,21]<stderr>:  'is ignored.'.format(self.name, req))
[1,180]<stdout>:loading annotations into memory...
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,153]<stderr>:  'is ignored.'.format(self.name, req))
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,153]<stderr>:  'is ignored.'.format(self.name, req))
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,153]<stderr>:  'is ignored.'.format(self.name, req))
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,153]<stderr>:  'is ignored.'.format(self.name, req))
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,153]<stderr>:  'is ignored.'.format(self.name, req))
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,41]<stderr>:  'is ignored.'.format(self.name, req))
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,41]<stderr>:  'is ignored.'.format(self.name, req))
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,41]<stderr>:  'is ignored.'.format(self.name, req))
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,41]<stderr>:  'is ignored.'.format(self.name, req))
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,41]<stderr>:  'is ignored.'.format(self.name, req))
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,33]<stderr>:  'is ignored.'.format(self.name, req))
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,33]<stderr>:  'is ignored.'.format(self.name, req))
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,33]<stderr>:  'is ignored.'.format(self.name, req))
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,33]<stderr>:  'is ignored.'.format(self.name, req))
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,33]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stdout>:Done (t=0.40s)
[1,4]<stdout>:creating index...
[1,4]<stdout>:index created!
[1,180]<stdout>:Done (t=0.39s)
[1,180]<stdout>:creating index...
[1,180]<stdout>:index created!
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,20]<stderr>:  'is ignored.'.format(self.name, req))
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,20]<stderr>:  'is ignored.'.format(self.name, req))
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,20]<stderr>:  'is ignored.'.format(self.name, req))
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,20]<stderr>:  'is ignored.'.format(self.name, req))
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,20]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stdout>:creating index...
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,54]<stderr>:  'is ignored.'.format(self.name, req))
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,54]<stderr>:  'is ignored.'.format(self.name, req))
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,54]<stderr>:  'is ignored.'.format(self.name, req))
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,54]<stderr>:  'is ignored.'.format(self.name, req))
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,54]<stderr>:  'is ignored.'.format(self.name, req))
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,56]<stderr>:  'is ignored.'.format(self.name, req))
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,56]<stderr>:  'is ignored.'.format(self.name, req))
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,56]<stderr>:  'is ignored.'.format(self.name, req))
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,56]<stderr>:  'is ignored.'.format(self.name, req))
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,56]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stdout>:creating index...
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,30]<stderr>:  'is ignored.'.format(self.name, req))
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,30]<stderr>:  'is ignored.'.format(self.name, req))
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,30]<stderr>:  'is ignored.'.format(self.name, req))
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,30]<stderr>:  'is ignored.'.format(self.name, req))
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,30]<stderr>:  'is ignored.'.format(self.name, req))
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,94]<stderr>:  'is ignored.'.format(self.name, req))
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,94]<stderr>:  'is ignored.'.format(self.name, req))
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,94]<stderr>:  'is ignored.'.format(self.name, req))
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,94]<stderr>:  'is ignored.'.format(self.name, req))
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,94]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stdout>:creating index...
[1,180]<stdout>:creating index...
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,52]<stderr>:  'is ignored.'.format(self.name, req))
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,52]<stderr>:  'is ignored.'.format(self.name, req))
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,52]<stderr>:  'is ignored.'.format(self.name, req))
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,52]<stderr>:  'is ignored.'.format(self.name, req))
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,52]<stderr>:  'is ignored.'.format(self.name, req))
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,116]<stderr>:  'is ignored.'.format(self.name, req))
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,116]<stderr>:  'is ignored.'.format(self.name, req))
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,116]<stderr>:  'is ignored.'.format(self.name, req))
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,116]<stderr>:  'is ignored.'.format(self.name, req))
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,116]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,76]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,76]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,76]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,76]<stderr>:  'is ignored.'.format(self.name, req))
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,76]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,188]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,188]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,188]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,188]<stderr>:  'is ignored.'.format(self.name, req))
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,188]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,4]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,4]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,4]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,4]<stderr>:  'is ignored.'.format(self.name, req))
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,4]<stderr>:  'is ignored.'.format(self.name, req))
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator0_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,180]<stderr>:  'is ignored.'.format(self.name, req))
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator1_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,180]<stderr>:  'is ignored.'.format(self.name, req))
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator2_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,180]<stderr>:  'is ignored.'.format(self.name, req))
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator3_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,180]<stderr>:  'is ignored.'.format(self.name, req))
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/parameter.py:703: UserWarning: Constant parameter "maskrcnn0_rpn0_rpnanchorgenerator4_anchor_" does not support grad_req other than "null", and new value "write" is ignored.
[1,180]<stderr>:  'is ignored.'.format(self.name, req))
[1,2]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,5]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,7]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,1]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,6]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,5]<stderr>:INFO:root:Start training from [Epoch 0]
[1,1]<stderr>:INFO:root:Start training from [Epoch 0]
[1,4]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,2]<stderr>:INFO:root:Start training from [Epoch 0]
[1,6]<stderr>:INFO:root:Start training from [Epoch 0]
[1,7]<stderr>:INFO:root:Start training from [Epoch 0]
[1,13]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,3]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,4]<stderr>:INFO:root:Start training from [Epoch 0]
[1,0]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,51]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,0]<stderr>:INFO:root:Start training from [Epoch 0]
[1,57]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,21]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,40]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,3]<stderr>:INFO:root:Start training from [Epoch 0]
[1,25]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,73]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,100]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,107]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,170]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,12]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,39]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,95]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,53]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,56]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,19]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,145]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,46]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,26]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,76]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,114]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,97]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,84]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,142]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,160]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,66]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,157]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,110]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,172]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,10]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,191]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,176]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,134]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,32]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,125]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,90]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,52]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,58]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,22]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,144]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,47]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,27]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,78]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,112]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,101]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,87]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,138]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,166]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,65]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,159]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,109]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,173]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,14]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,187]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,177]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,130]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,34]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,122]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,89]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,50]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,59]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,23]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,149]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,42]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,29]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,74]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,115]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,96]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,82]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,136]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,163]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,69]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,154]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,104]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,169]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,9]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,184]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,181]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,131]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,36]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,123]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,92]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,48]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,61]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,18]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,146]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,45]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,24]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,72]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,117]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,98]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,98]<stderr>:INFO:root:Start training from [Epoch 0]
[1,86]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,143]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,167]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,70]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,152]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,105]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,168]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,15]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,185]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,180]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,129]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,37]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,126]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,88]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,54]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,62]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,17]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,148]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,43]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,28]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,75]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,116]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,103]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,80]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,141]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,164]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,67]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,153]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,111]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,171]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,12]<stderr>:INFO:root:Start training from [Epoch 0]
[1,189]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,178]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,128]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,35]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,120]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,94]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,53]<stderr>:INFO:root:Start training from [Epoch 0]
[1,60]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,16]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,150]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,40]<stderr>:INFO:root:Start training from [Epoch 0]
[1,30]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,77]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,113]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,102]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,102]<stderr>:INFO:root:Start training from [Epoch 0]
[1,83]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,139]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,161]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,68]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,158]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,106]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,174]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,10]<stderr>:INFO:root:Start training from [Epoch 0]
[1,186]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,183]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,132]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,33]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,121]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,91]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,49]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,63]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,21]<stderr>:INFO:root:Start training from [Epoch 0]
[1,147]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,43]<stderr>:INFO:root:Start training from [Epoch 0]
[1,25]<stderr>:INFO:root:Start training from [Epoch 0]
[1,73]<stderr>:INFO:root:Start training from [Epoch 0]
[1,119]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,100]<stderr>:INFO:root:Start training from [Epoch 0]
[1,81]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,138]<stderr>:INFO:root:Start training from [Epoch 0]
[1,162]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,64]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,155]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,108]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,170]<stderr>:INFO:root:Start training from [Epoch 0]
[1,14]<stderr>:INFO:root:Start training from [Epoch 0]
[1,190]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,179]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,133]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,38]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,120]<stderr>:INFO:root:Start training from [Epoch 0]
[1,93]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,51]<stderr>:INFO:root:Start training from [Epoch 0]
[1,59]<stderr>:INFO:root:Start training from [Epoch 0]
[1,22]<stderr>:INFO:root:Start training from [Epoch 0]
[1,151]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,45]<stderr>:INFO:root:Start training from [Epoch 0]
[1,31]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,77]<stderr>:INFO:root:Start training from [Epoch 0]
[1,114]<stderr>:INFO:root:Start training from [Epoch 0]
[1,99]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,85]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,137]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,165]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,71]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,156]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,107]<stderr>:INFO:root:Start training from [Epoch 0]
[1,171]<stderr>:INFO:root:Start training from [Epoch 0]
[1,8]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,188]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,182]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,135]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,32]<stderr>:INFO:root:Start training from [Epoch 0]
[1,124]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,95]<stderr>:INFO:root:Start training from [Epoch 0]
[1,55]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,57]<stderr>:INFO:root:Start training from [Epoch 0]
[1,23]<stderr>:INFO:root:Start training from [Epoch 0]
[1,144]<stderr>:INFO:root:Start training from [Epoch 0]
[1,46]<stderr>:INFO:root:Start training from [Epoch 0]
[1,26]<stderr>:INFO:root:Start training from [Epoch 0]
[1,76]<stderr>:INFO:root:Start training from [Epoch 0]
[1,112]<stderr>:INFO:root:Start training from [Epoch 0]
[1,97]<stderr>:INFO:root:Start training from [Epoch 0]
[1,84]<stderr>:INFO:root:Start training from [Epoch 0]
[1,140]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,166]<stderr>:INFO:root:Start training from [Epoch 0]
[1,69]<stderr>:INFO:root:Start training from [Epoch 0]
[1,157]<stderr>:INFO:root:Start training from [Epoch 0]
[1,104]<stderr>:INFO:root:Start training from [Epoch 0]
[1,172]<stderr>:INFO:root:Start training from [Epoch 0]
[1,11]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,191]<stderr>:INFO:root:Start training from [Epoch 0]
[1,176]<stderr>:INFO:root:Start training from [Epoch 0]
[1,130]<stderr>:INFO:root:Start training from [Epoch 0]
[1,35]<stderr>:INFO:root:Start training from [Epoch 0]
[1,127]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,89]<stderr>:INFO:root:Start training from [Epoch 0]
[1,52]<stderr>:INFO:root:Start training from [Epoch 0]
[1,58]<stderr>:INFO:root:Start training from [Epoch 0]
[1,17]<stderr>:INFO:root:Start training from [Epoch 0]
[1,149]<stderr>:INFO:root:Start training from [Epoch 0]
[1,47]<stderr>:INFO:root:Start training from [Epoch 0]
[1,27]<stderr>:INFO:root:Start training from [Epoch 0]
[1,78]<stderr>:INFO:root:Start training from [Epoch 0]
[1,118]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,101]<stderr>:INFO:root:Start training from [Epoch 0]
[1,82]<stderr>:INFO:root:Start training from [Epoch 0]
[1,142]<stderr>:INFO:root:Start training from [Epoch 0]
[1,165]<stderr>:INFO:root:Start training from [Epoch 0]
[1,70]<stderr>:INFO:root:Start training from [Epoch 0]
[1,159]<stderr>:INFO:root:Start training from [Epoch 0]
[1,105]<stderr>:INFO:root:Start training from [Epoch 0]
[1,173]<stderr>:INFO:root:Start training from [Epoch 0]
[1,9]<stderr>:INFO:root:Start training from [Epoch 0]
[1,189]<stderr>:INFO:root:Start training from [Epoch 0]
[1,177]<stderr>:INFO:root:Start training from [Epoch 0]
[1,129]<stderr>:INFO:root:Start training from [Epoch 0]
[1,34]<stderr>:INFO:root:Start training from [Epoch 0]
[1,121]<stderr>:INFO:root:Start training from [Epoch 0]
[1,90]<stderr>:INFO:root:Start training from [Epoch 0]
[1,55]<stderr>:INFO:root:Start training from [Epoch 0]
[1,61]<stderr>:INFO:root:Start training from [Epoch 0]
[1,20]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,146]<stderr>:INFO:root:Start training from [Epoch 0]
[1,42]<stderr>:INFO:root:Start training from [Epoch 0]
[1,28]<stderr>:INFO:root:Start training from [Epoch 0]
[1,79]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,115]<stderr>:INFO:root:Start training from [Epoch 0]
[1,96]<stderr>:INFO:root:Start training from [Epoch 0]
[1,80]<stderr>:INFO:root:Start training from [Epoch 0]
[1,139]<stderr>:INFO:root:Start training from [Epoch 0]
[1,163]<stderr>:INFO:root:Start training from [Epoch 0]
[1,66]<stderr>:INFO:root:Start training from [Epoch 0]
[1,154]<stderr>:INFO:root:Start training from [Epoch 0]
[1,110]<stderr>:INFO:root:Start training from [Epoch 0]
[1,168]<stderr>:INFO:root:Start training from [Epoch 0]
[1,13]<stderr>:INFO:root:Start training from [Epoch 0]
[1,186]<stderr>:INFO:root:Start training from [Epoch 0]
[1,181]<stderr>:INFO:root:Start training from [Epoch 0]
[1,135]<stderr>:INFO:root:Start training from [Epoch 0]
[1,36]<stderr>:INFO:root:Start training from [Epoch 0]
[1,123]<stderr>:INFO:root:Start training from [Epoch 0]
[1,88]<stderr>:INFO:root:Start training from [Epoch 0]
[1,48]<stderr>:INFO:root:Start training from [Epoch 0]
[1,56]<stderr>:INFO:root:Start training from [Epoch 0]
[1,16]<stderr>:INFO:root:Start training from [Epoch 0]
[1,148]<stderr>:INFO:root:Start training from [Epoch 0]
[1,41]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,31]<stderr>:INFO:root:Start training from [Epoch 0]
[1,74]<stderr>:INFO:root:Start training from [Epoch 0]
[1,113]<stderr>:INFO:root:Start training from [Epoch 0]
[1,103]<stderr>:INFO:root:Start training from [Epoch 0]
[1,87]<stderr>:INFO:root:Start training from [Epoch 0]
[1,136]<stderr>:INFO:root:Start training from [Epoch 0]
[1,167]<stderr>:INFO:root:Start training from [Epoch 0]
[1,65]<stderr>:INFO:root:Start training from [Epoch 0]
[1,152]<stderr>:INFO:root:Start training from [Epoch 0]
[1,109]<stderr>:INFO:root:Start training from [Epoch 0]
[1,174]<stderr>:INFO:root:Start training from [Epoch 0]
[1,15]<stderr>:INFO:root:Start training from [Epoch 0]
[1,187]<stderr>:INFO:root:Start training from [Epoch 0]
[1,180]<stderr>:INFO:root:Start training from [Epoch 0]
[1,128]<stderr>:INFO:root:Start training from [Epoch 0]
[1,37]<stderr>:INFO:root:Start training from [Epoch 0]
[1,126]<stderr>:INFO:root:Start training from [Epoch 0]
[1,92]<stderr>:INFO:root:Start training from [Epoch 0]
[1,49]<stderr>:INFO:root:Start training from [Epoch 0]
[1,62]<stderr>:INFO:root:Start training from [Epoch 0]
[1,19]<stderr>:INFO:root:Start training from [Epoch 0]
[1,150]<stderr>:INFO:root:Start training from [Epoch 0]
[1,44]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,29]<stderr>:INFO:root:Start training from [Epoch 0]
[1,72]<stderr>:INFO:root:Start training from [Epoch 0]
[1,119]<stderr>:INFO:root:Start training from [Epoch 0]
[1,99]<stderr>:INFO:root:Start training from [Epoch 0]
[1,86]<stderr>:INFO:root:Start training from [Epoch 0]
[1,143]<stderr>:INFO:root:Start training from [Epoch 0]
[1,164]<stderr>:INFO:root:Start training from [Epoch 0]
[1,68]<stderr>:INFO:root:Start training from [Epoch 0]
[1,158]<stderr>:INFO:root:Start training from [Epoch 0]
[1,111]<stderr>:INFO:root:Start training from [Epoch 0]
[1,169]<stderr>:INFO:root:Start training from [Epoch 0]
[1,8]<stderr>:INFO:root:Start training from [Epoch 0]
[1,184]<stderr>:INFO:root:Start training from [Epoch 0]
[1,179]<stderr>:INFO:root:Start training from [Epoch 0]
[1,134]<stderr>:INFO:root:Start training from [Epoch 0]
[1,38]<stderr>:INFO:root:Start training from [Epoch 0]
[1,125]<stderr>:INFO:root:Start training from [Epoch 0]
[1,93]<stderr>:INFO:root:Start training from [Epoch 0]
[1,50]<stderr>:INFO:root:Start training from [Epoch 0]
[1,60]<stderr>:INFO:root:Start training from [Epoch 0]
[1,18]<stderr>:INFO:root:Start training from [Epoch 0]
[1,145]<stderr>:INFO:root:Start training from [Epoch 0]
[1,44]<stderr>:INFO:root:Start training from [Epoch 0]
[1,24]<stderr>:INFO:root:Start training from [Epoch 0]
[1,75]<stderr>:INFO:root:Start training from [Epoch 0]
[1,118]<stderr>:INFO:root:Start training from [Epoch 0]
[1,83]<stderr>:INFO:root:Start training from [Epoch 0]
[1,141]<stderr>:INFO:root:Start training from [Epoch 0]
[1,162]<stderr>:INFO:root:Start training from [Epoch 0]
[1,64]<stderr>:INFO:root:Start training from [Epoch 0]
[1,156]<stderr>:INFO:root:Start training from [Epoch 0]
[1,106]<stderr>:INFO:root:Start training from [Epoch 0]
[1,175]<stderr>:INFO:root:Namespace(amp=True, batch_size=192, clip_gradient=1.5, dataset='coco', disable_hybridization=False, dtype='float16', epochs=12, executor_threads=1, gpus='0', horovod=True, kv_store='device', log_interval=100, lr=0.16, lr_decay=0.1, lr_decay_epoch='10,14', lr_warmup='1600', lr_warmup_factor=0.001, momentum=0.9, network='resnet50_v1b', norm_layer=None, num_workers=8, resume='', save_interval=1, save_prefix='mask_rcnn_fpn_resnet50_v1b_coco', seed=233, start_epoch=0, static_alloc=True, use_ext=True, use_fpn=True, val_interval=1, verbose=False, wd=0.0001)
[1,11]<stderr>:INFO:root:Start training from [Epoch 0]
[1,190]<stderr>:INFO:root:Start training from [Epoch 0]
[1,178]<stderr>:INFO:root:Start training from [Epoch 0]
[1,133]<stderr>:INFO:root:Start training from [Epoch 0]
[1,33]<stderr>:INFO:root:Start training from [Epoch 0]
[1,122]<stderr>:INFO:root:Start training from [Epoch 0]
[1,94]<stderr>:INFO:root:Start training from [Epoch 0]
[1,54]<stderr>:INFO:root:Start training from [Epoch 0]
[1,63]<stderr>:INFO:root:Start training from [Epoch 0]
[1,20]<stderr>:INFO:root:Start training from [Epoch 0]
[1,151]<stderr>:INFO:root:Start training from [Epoch 0]
[1,41]<stderr>:INFO:root:Start training from [Epoch 0]
[1,30]<stderr>:INFO:root:Start training from [Epoch 0]
[1,79]<stderr>:INFO:root:Start training from [Epoch 0]
[1,117]<stderr>:INFO:root:Start training from [Epoch 0]
[1,81]<stderr>:INFO:root:Start training from [Epoch 0]
[1,137]<stderr>:INFO:root:Start training from [Epoch 0]
[1,160]<stderr>:INFO:root:Start training from [Epoch 0]
[1,71]<stderr>:INFO:root:Start training from [Epoch 0]
[1,155]<stderr>:INFO:root:Start training from [Epoch 0]
[1,108]<stderr>:INFO:root:Start training from [Epoch 0]
[1,175]<stderr>:INFO:root:Start training from [Epoch 0]
[1,185]<stderr>:INFO:root:Start training from [Epoch 0]
[1,183]<stderr>:INFO:root:Start training from [Epoch 0]
[1,132]<stderr>:INFO:root:Start training from [Epoch 0]
[1,39]<stderr>:INFO:root:Start training from [Epoch 0]
[1,127]<stderr>:INFO:root:Start training from [Epoch 0]
[1,91]<stderr>:INFO:root:Start training from [Epoch 0]
[1,147]<stderr>:INFO:root:Start training from [Epoch 0]
[1,116]<stderr>:INFO:root:Start training from [Epoch 0]
[1,85]<stderr>:INFO:root:Start training from [Epoch 0]
[1,140]<stderr>:INFO:root:Start training from [Epoch 0]
[1,161]<stderr>:INFO:root:Start training from [Epoch 0]
[1,67]<stderr>:INFO:root:Start training from [Epoch 0]
[1,153]<stderr>:INFO:root:Start training from [Epoch 0]
[1,188]<stderr>:INFO:root:Start training from [Epoch 0]
[1,182]<stderr>:INFO:root:Start training from [Epoch 0]
[1,131]<stderr>:INFO:root:Start training from [Epoch 0]
[1,124]<stderr>:INFO:root:Start training from [Epoch 0]
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 0] Set learning rate to 0.00016
[1,0]<stdout>:NCCL version 2.4.7ms0+cuda10.0
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 32768.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 16384.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 8192.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 4096.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 2048.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 1024.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 512.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 256.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 128.000000
[1,141]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,140]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,9]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,137]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,169]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,11]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,143]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,172]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,8]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,138]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,175]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,12]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,142]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,174]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,3]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,14]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,139]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,0]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,153]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,7]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,1]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,2]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,4]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,173]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,15]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,5]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,6]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,144]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,45]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,136]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,161]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,155]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,170]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,10]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,191]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,57]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,150]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,46]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,29]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,162]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,65]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,157]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,168]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,13]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,190]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,180]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,128]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,49]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,56]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,16]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,148]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,43]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,30]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,113]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,164]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,66]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,158]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,171]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,185]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,182]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,132]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,36]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,121]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,54]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,58]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,17]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,146]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,40]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,24]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,114]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,167]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,64]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,152]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,107]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,188]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,178]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,129]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,34]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,120]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,50]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,61]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,18]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,145]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,41]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,28]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,115]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,166]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,67]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,154]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,105]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,187]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,177]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,134]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,38]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,122]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,55]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,62]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,22]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,151]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,47]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,25]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,119]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,97]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,160]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,70]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,156]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,111]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,186]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,183]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,131]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,32]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,123]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,51]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,59]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,21]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,149]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,42]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,27]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,112]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,99]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,165]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,69]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,159]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,106]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,184]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,176]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,133]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,33]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,126]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,53]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,60]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,20]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,147]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,44]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,26]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,73]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,118]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,96]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,85]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,163]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,68]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,108]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,189]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,179]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,135]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,39]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,125]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,48]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,63]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,23]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,31]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,75]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,116]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,98]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,84]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,71]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,110]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,181]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,130]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,37]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,124]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,90]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,52]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,19]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,74]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,117]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,101]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,80]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,109]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,35]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,127]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,94]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,79]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,103]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,81]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,104]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,93]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,77]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,102]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,86]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,95]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,72]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,100]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,87]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,91]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,76]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,83]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,88]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,78]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,82]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,89]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,92]<stderr>:INFO:root:AMP: decreasing loss scale to 64.000000
[1,0]<stderr>:INFO:root:[Epoch 0][Batch 99], Speed: 658.447 samples/sec, RPN_Conf=0.280,RPN_SmoothL1=0.067,RCNN_CrossEntropy=1.034,RCNN_SmoothL1=0.132,RCNN_Mask=0.925,RPNL1Loss=0.599,RCNNL1Loss=2.232
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 100] Set learning rate to 0.01015
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,0]<stderr>:INFO:root:[Epoch 0][Batch 199], Speed: 1167.821 samples/sec, RPN_Conf=0.182,RPN_SmoothL1=0.059,RCNN_CrossEntropy=0.794,RCNN_SmoothL1=0.176,RCNN_Mask=0.768,RPNL1Loss=0.542,RCNNL1Loss=2.321
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 200] Set learning rate to 0.020139999999999998
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,0]<stderr>:INFO:root:[Epoch 0][Batch 299], Speed: 1174.012 samples/sec, RPN_Conf=0.148,RPN_SmoothL1=0.056,RCNN_CrossEntropy=0.741,RCNN_SmoothL1=0.208,RCNN_Mask=0.671,RPNL1Loss=0.501,RCNNL1Loss=2.278
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 300] Set learning rate to 0.03013
[1,0]<stderr>:INFO:root:[Epoch 0][Batch 399], Speed: 1168.100 samples/sec, RPN_Conf=0.132,RPN_SmoothL1=0.055,RCNN_CrossEntropy=0.684,RCNN_SmoothL1=0.212,RCNN_Mask=0.610,RPNL1Loss=0.491,RCNNL1Loss=2.190
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 400] Set learning rate to 0.040119999999999996
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,0]<stderr>:INFO:root:[Epoch 0][Batch 499], Speed: 1175.256 samples/sec, RPN_Conf=0.120,RPN_SmoothL1=0.053,RCNN_CrossEntropy=0.638,RCNN_SmoothL1=0.210,RCNN_Mask=0.566,RPNL1Loss=0.482,RCNNL1Loss=2.088
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 500] Set learning rate to 0.05011
[1,172]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,168]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,136]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,173]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,0]<stderr>:INFO:root:[Epoch 0][Batch 599], Speed: 1176.035 samples/sec, RPN_Conf=0.111,RPN_SmoothL1=0.054,RCNN_CrossEntropy=0.608,RCNN_SmoothL1=0.208,RCNN_Mask=0.537,RPNL1Loss=0.474,RCNNL1Loss=1.967
[1,75]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,141]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,174]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,7]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,2]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,140]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,161]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,175]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,0]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,72]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,142]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,162]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,169]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,4]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,139]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,158]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,171]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,146]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,138]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,152]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,170]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,187]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,176]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,3]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,144]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,41]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,6]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,28]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,73]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,143]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,5]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,167]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,154]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,111]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,8]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,186]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,177]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,122]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,52]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,57]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,19]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,145]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,42]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,24]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,74]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,114]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,97]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,83]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,137]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,165]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,64]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,156]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,107]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,12]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,191]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,183]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,130]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,36]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,124]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,89]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,50]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,59]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,16]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,147]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,43]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,29]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,76]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,112]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,96]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,86]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,166]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,66]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,1]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,153]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,105]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,15]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,188]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,179]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,131]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,38]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,123]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,88]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,49]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,56]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,20]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,151]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,46]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,31]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,78]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,118]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,102]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,81]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,164]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,67]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,159]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,109]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,13]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,190]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,178]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,129]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,34]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,126]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,90]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,55]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,58]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,21]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,149]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,40]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,30]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,79]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,113]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,100]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,82]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,160]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,65]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,155]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,110]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,10]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,185]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,182]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,128]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,37]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,127]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,94]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,54]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,60]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,17]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,150]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,44]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,26]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,77]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,115]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,101]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,80]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,163]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,69]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,157]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,104]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,14]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,184]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,181]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,134]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,39]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,125]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,91]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,51]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,63]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,22]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,148]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,47]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,27]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,117]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,98]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,87]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,71]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,108]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,9]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,189]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,180]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,133]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,35]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,121]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,95]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,53]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,61]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,18]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,45]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,25]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,116]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,103]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,84]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,68]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,106]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,11]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,132]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,33]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,120]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,93]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,48]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,62]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,23]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,119]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,99]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,85]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,70]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,135]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,32]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,92]<stderr>:INFO:root:[Epoch 0 Iteration 600] Set learning rate to 0.0601
[1,0]<stderr>:INFO:root:[Epoch 0] Training cost: 112.714, RPN_Conf=0.110,RPN_SmoothL1=0.054,RCNN_CrossEntropy=0.606,RCNN_SmoothL1=0.208,RCNN_Mask=0.534
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,25]<stderr>:  out = self.forward(*args)
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,19]<stderr>:  out = self.forward(*args)
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,22]<stderr>:  out = self.forward(*args)
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,37]<stderr>:  out = self.forward(*args)
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,80]<stderr>:  out = self.forward(*args)
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,155]<stderr>:  out = self.forward(*args)
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,71]<stderr>:  out = self.forward(*args)
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,49]<stderr>:  out = self.forward(*args)
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,82]<stderr>:  out = self.forward(*args)
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,132]<stderr>:  out = self.forward(*args)
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,35]<stderr>:  out = self.forward(*args)
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,115]<stderr>:  out = self.forward(*args)
[1,2]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,2]<stderr>:  out = self.forward(*args)
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,74]<stderr>:  out = self.forward(*args)
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,68]<stderr>:  out = self.forward(*args)
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,54]<stderr>:  out = self.forward(*args)
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,187]<stderr>:  out = self.forward(*args)
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,169]<stderr>:  out = self.forward(*args)
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,90]<stderr>:  out = self.forward(*args)
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,134]<stderr>:  out = self.forward(*args)
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,51]<stderr>:  out = self.forward(*args)
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,106]<stderr>:  out = self.forward(*args)
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,170]<stderr>:  out = self.forward(*args)
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,8]<stderr>:  out = self.forward(*args)
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,151]<stderr>:  out = self.forward(*args)
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,154]<stderr>:  out = self.forward(*args)
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,44]<stderr>:  out = self.forward(*args)
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,72]<stderr>:  out = self.forward(*args)
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,168]<stderr>:  out = self.forward(*args)
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,180]<stderr>:  out = self.forward(*args)
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,117]<stderr>:  out = self.forward(*args)
[1,1]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,1]<stderr>:  out = self.forward(*args)
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,31]<stderr>:  out = self.forward(*args)
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,175]<stderr>:  out = self.forward(*args)
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,23]<stderr>:  out = self.forward(*args)
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,46]<stderr>:  out = self.forward(*args)
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,21]<stderr>:  out = self.forward(*args)
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,78]<stderr>:  out = self.forward(*args)
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,163]<stderr>:  out = self.forward(*args)
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,13]<stderr>:  out = self.forward(*args)
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,83]<stderr>:  out = self.forward(*args)
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,110]<stderr>:  out = self.forward(*args)
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,174]<stderr>:  out = self.forward(*args)
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,107]<stderr>:  out = self.forward(*args)
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,129]<stderr>:  out = self.forward(*args)
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,91]<stderr>:  out = self.forward(*args)
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,88]<stderr>:  out = self.forward(*args)
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,11]<stderr>:  out = self.forward(*args)
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,60]<stderr>:  out = self.forward(*args)
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,152]<stderr>:  out = self.forward(*args)
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,29]<stderr>:  out = self.forward(*args)
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,172]<stderr>:  out = self.forward(*args)
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,130]<stderr>:  out = self.forward(*args)
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,39]<stderr>:  out = self.forward(*args)
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,55]<stderr>:  out = self.forward(*args)
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,167]<stderr>:  out = self.forward(*args)
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,100]<stderr>:  out = self.forward(*args)
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,121]<stderr>:  out = self.forward(*args)
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,184]<stderr>:  out = self.forward(*args)
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,176]<stderr>:  out = self.forward(*args)
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,146]<stderr>:  out = self.forward(*args)
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,162]<stderr>:  out = self.forward(*args)
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,14]<stderr>:  out = self.forward(*args)
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,150]<stderr>:  out = self.forward(*args)
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,26]<stderr>:  out = self.forward(*args)
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,131]<stderr>:  out = self.forward(*args)
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,161]<stderr>:  out = self.forward(*args)
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,173]<stderr>:  out = self.forward(*args)
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,166]<stderr>:  out = self.forward(*args)
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,67]<stderr>:  out = self.forward(*args)
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,50]<stderr>:  out = self.forward(*args)
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,17]<stderr>:  out = self.forward(*args)
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,125]<stderr>:  out = self.forward(*args)
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,16]<stderr>:  out = self.forward(*args)
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,124]<stderr>:  out = self.forward(*args)
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,64]<stderr>:  out = self.forward(*args)
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,15]<stderr>:  out = self.forward(*args)
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,66]<stderr>:  out = self.forward(*args)
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,32]<stderr>:  out = self.forward(*args)
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,57]<stderr>:  out = self.forward(*args)
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,58]<stderr>:  out = self.forward(*args)
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,171]<stderr>:  out = self.forward(*args)
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,75]<stderr>:  out = self.forward(*args)
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,141]<stderr>:  out = self.forward(*args)
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,102]<stderr>:  out = self.forward(*args)
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,87]<stderr>:  out = self.forward(*args)
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,28]<stderr>:  out = self.forward(*args)
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,189]<stderr>:  out = self.forward(*args)
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,135]<stderr>:  out = self.forward(*args)
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,97]<stderr>:  out = self.forward(*args)
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,119]<stderr>:  out = self.forward(*args)
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,186]<stderr>:  out = self.forward(*args)
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,89]<stderr>:  out = self.forward(*args)
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,156]<stderr>:  out = self.forward(*args)
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,30]<stderr>:  out = self.forward(*args)
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,47]<stderr>:  out = self.forward(*args)
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,95]<stderr>:  out = self.forward(*args)
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,9]<stderr>:  out = self.forward(*args)
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,48]<stderr>:  out = self.forward(*args)
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,159]<stderr>:  out = self.forward(*args)
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,109]<stderr>:  out = self.forward(*args)
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,61]<stderr>:  out = self.forward(*args)
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,56]<stderr>:  out = self.forward(*args)
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,108]<stderr>:  out = self.forward(*args)
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,177]<stderr>:  out = self.forward(*args)
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,52]<stderr>:  out = self.forward(*args)
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,139]<stderr>:  out = self.forward(*args)
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,158]<stderr>:  out = self.forward(*args)
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,103]<stderr>:  out = self.forward(*args)
[1,4]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,4]<stderr>:  out = self.forward(*args)
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,114]<stderr>:  out = self.forward(*args)
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,59]<stderr>:  out = self.forward(*args)
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,42]<stderr>:  out = self.forward(*args)
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,84]<stderr>:  out = self.forward(*args)
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,143]<stderr>:  out = self.forward(*args)
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,101]<stderr>:  out = self.forward(*args)
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,62]<stderr>:  out = self.forward(*args)
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,153]<stderr>:  out = self.forward(*args)
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,123]<stderr>:  out = self.forward(*args)
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,113]<stderr>:  out = self.forward(*args)
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,148]<stderr>:  out = self.forward(*args)
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,92]<stderr>:  out = self.forward(*args)
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,133]<stderr>:  out = self.forward(*args)
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,18]<stderr>:  out = self.forward(*args)
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,70]<stderr>:  out = self.forward(*args)
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,38]<stderr>:  out = self.forward(*args)
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,94]<stderr>:  out = self.forward(*args)
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,165]<stderr>:  out = self.forward(*args)
[1,5]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,5]<stderr>:  out = self.forward(*args)
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,12]<stderr>:  out = self.forward(*args)
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,34]<stderr>:  out = self.forward(*args)
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,190]<stderr>:  out = self.forward(*args)
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,86]<stderr>:  out = self.forward(*args)
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,120]<stderr>:  out = self.forward(*args)
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,142]<stderr>:  out = self.forward(*args)
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,76]<stderr>:  out = self.forward(*args)
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,160]<stderr>:  out = self.forward(*args)
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,140]<stderr>:  out = self.forward(*args)
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,104]<stderr>:  out = self.forward(*args)
[1,7]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,7]<stderr>:  out = self.forward(*args)
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,185]<stderr>:  out = self.forward(*args)
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,183]<stderr>:  out = self.forward(*args)
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,105]<stderr>:  out = self.forward(*args)
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,98]<stderr>:  out = self.forward(*args)
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,116]<stderr>:  out = self.forward(*args)
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,65]<stderr>:  out = self.forward(*args)
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,96]<stderr>:  out = self.forward(*args)
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,63]<stderr>:  out = self.forward(*args)
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,178]<stderr>:  out = self.forward(*args)
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,79]<stderr>:  out = self.forward(*args)
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,128]<stderr>:  out = self.forward(*args)
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,149]<stderr>:  out = self.forward(*args)
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,20]<stderr>:  out = self.forward(*args)
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,40]<stderr>:  out = self.forward(*args)
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,24]<stderr>:  out = self.forward(*args)
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,138]<stderr>:  out = self.forward(*args)
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,181]<stderr>:  out = self.forward(*args)
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,188]<stderr>:  out = self.forward(*args)
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,182]<stderr>:  out = self.forward(*args)
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,81]<stderr>:  out = self.forward(*args)
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,99]<stderr>:  out = self.forward(*args)
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,179]<stderr>:  out = self.forward(*args)
[1,3]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,3]<stderr>:  out = self.forward(*args)
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,41]<stderr>:  out = self.forward(*args)
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,93]<stderr>:  out = self.forward(*args)
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,126]<stderr>:  out = self.forward(*args)
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,144]<stderr>:  out = self.forward(*args)
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,53]<stderr>:  out = self.forward(*args)
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,137]<stderr>:  out = self.forward(*args)
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,69]<stderr>:  out = self.forward(*args)
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,27]<stderr>:  out = self.forward(*args)
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,164]<stderr>:  out = self.forward(*args)
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,145]<stderr>:  out = self.forward(*args)
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,127]<stderr>:  out = self.forward(*args)
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,147]<stderr>:  out = self.forward(*args)
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,136]<stderr>:  out = self.forward(*args)
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,111]<stderr>:  out = self.forward(*args)
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,43]<stderr>:  out = self.forward(*args)
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,45]<stderr>:  out = self.forward(*args)
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,157]<stderr>:  out = self.forward(*args)
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,191]<stderr>:  out = self.forward(*args)
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,73]<stderr>:  out = self.forward(*args)
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,10]<stderr>:  out = self.forward(*args)
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,77]<stderr>:  out = self.forward(*args)
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,85]<stderr>:  out = self.forward(*args)
[1,0]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,0]<stderr>:  out = self.forward(*args)
[1,6]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,6]<stderr>:  out = self.forward(*args)
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,36]<stderr>:  out = self.forward(*args)
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,33]<stderr>:  out = self.forward(*args)
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,112]<stderr>:  out = self.forward(*args)
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,118]<stderr>:  out = self.forward(*args)
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,122]<stderr>:  out = self.forward(*args)
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,0]<stderr>:INFO:root:[Epoch 0] Validation Inference cost: 37.938
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 0] Set learning rate to 0.06119890000000001
[1,0]<stdout>:DONE (t=4.13s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stderr>:INFO:root:[Epoch 1][Batch 99], Speed: 1071.593 samples/sec, RPN_Conf=0.059,RPN_SmoothL1=0.044,RCNN_CrossEntropy=0.387,RCNN_SmoothL1=0.179,RCNN_Mask=0.380,RPNL1Loss=0.461,RCNNL1Loss=1.880
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 100] Set learning rate to 0.0711889
[1,0]<stdout>:DONE (t=16.14s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,0]<stderr>:INFO:root:[Epoch 1][Batch 199], Speed: 1178.371 samples/sec, RPN_Conf=0.062,RPN_SmoothL1=0.043,RCNN_CrossEntropy=0.369,RCNN_SmoothL1=0.177,RCNN_Mask=0.365,RPNL1Loss=0.451,RCNNL1Loss=1.804
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 200] Set learning rate to 0.0811789
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,0]<stderr>:INFO:root:[Epoch 1][Batch 299], Speed: 1151.093 samples/sec, RPN_Conf=0.062,RPN_SmoothL1=0.046,RCNN_CrossEntropy=0.369,RCNN_SmoothL1=0.178,RCNN_Mask=0.364,RPNL1Loss=0.444,RCNNL1Loss=1.744
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 300] Set learning rate to 0.0911689
[1,0]<stdout>:DONE (t=32.11s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,0]<stderr>:INFO:root:[Epoch 1][Batch 399], Speed: 1171.837 samples/sec, RPN_Conf=0.062,RPN_SmoothL1=0.046,RCNN_CrossEntropy=0.361,RCNN_SmoothL1=0.174,RCNN_Mask=0.358,RPNL1Loss=0.438,RCNNL1Loss=1.684
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 400] Set learning rate to 0.10115890000000001
[1,0]<stdout>:DONE (t=28.26s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 0] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.05848
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.14070
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.03815
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.04142
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.08069
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.06061
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.11573
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24796
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29044
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.16151
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31947
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35055
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=5.8
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.06158
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.13329
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.05026
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.02848
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.07902
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.08305
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.12518
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.24746
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28297
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.14267
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.32212
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35900
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=6.2
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,0]<stderr>:INFO:root:[Epoch 1][Batch 499], Speed: 1165.659 samples/sec, RPN_Conf=0.060,RPN_SmoothL1=0.046,RCNN_CrossEntropy=0.360,RCNN_SmoothL1=0.173,RCNN_Mask=0.352,RPNL1Loss=0.434,RCNNL1Loss=1.639
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 500] Set learning rate to 0.1111489
[1,0]<stderr>:INFO:root:[Epoch 1][Batch 599], Speed: 1166.453 samples/sec, RPN_Conf=0.063,RPN_SmoothL1=0.048,RCNN_CrossEntropy=0.358,RCNN_SmoothL1=0.172,RCNN_Mask=0.351,RPNL1Loss=0.432,RCNNL1Loss=1.599
[1,0]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,1]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,169]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,168]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,6]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,171]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,174]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,141]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,5]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,175]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,138]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,170]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,137]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,2]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,172]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,7]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,139]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,173]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,140]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,143]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,136]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,142]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,4]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,73]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,152]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,189]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,75]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,154]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,9]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,187]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,181]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,42]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,72]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,159]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,12]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,188]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,180]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,133]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,41]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,31]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,113]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,97]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,161]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,158]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,11]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,185]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,176]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,128]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,121]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,49]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,57]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,3]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,22]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,149]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,40]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,27]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,74]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,115]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,98]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,81]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,163]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,69]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,153]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,106]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,8]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,184]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,178]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,134]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,33]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,122]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,90]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,51]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,58]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,17]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,146]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,43]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,25]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,78]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,114]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,101]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,80]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,160]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,70]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,156]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,104]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,10]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,186]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,182]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,132]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,34]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,120]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,89]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,50]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,63]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,16]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,150]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,45]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,26]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,79]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,112]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,99]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,83]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,164]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,65]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,157]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,105]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,15]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,191]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,177]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,131]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,35]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,123]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,91]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,53]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,61]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,23]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,151]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,46]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,28]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,77]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,118]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,96]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,82]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,167]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,67]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,155]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,110]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,14]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,190]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,183]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,129]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,37]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,127]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,88]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,55]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,59]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,21]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,147]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,44]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,24]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,76]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,117]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,103]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,84]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,166]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,64]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,111]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,13]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,179]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,135]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,39]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,125]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,92]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,52]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,60]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,19]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,144]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,47]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,30]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,119]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,100]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,86]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,162]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,66]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,108]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,130]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,36]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,124]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,94]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,48]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,56]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,20]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,148]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,29]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,116]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,102]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,85]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,165]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,71]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,109]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,38]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,126]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,95]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,54]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,62]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,18]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,145]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,87]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,68]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,107]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,32]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,93]<stderr>:INFO:root:[Epoch 1 Iteration 600] Set learning rate to 0.1211389
[1,0]<stderr>:INFO:root:[Epoch 1] Training cost: 101.828, RPN_Conf=0.063,RPN_SmoothL1=0.048,RCNN_CrossEntropy=0.358,RCNN_SmoothL1=0.172,RCNN_Mask=0.352
[1,33]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,33]<stderr>:  out = self.forward(*args)
[1,63]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,63]<stderr>:  out = self.forward(*args)
[1,127]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,127]<stderr>:  out = self.forward(*args)
[1,44]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,44]<stderr>:  out = self.forward(*args)
[1,191]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,191]<stderr>:  out = self.forward(*args)
[1,104]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,104]<stderr>:  out = self.forward(*args)
[1,101]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,101]<stderr>:  out = self.forward(*args)
[1,138]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,138]<stderr>:  out = self.forward(*args)
[1,62]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,62]<stderr>:  out = self.forward(*args)
[1,123]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,123]<stderr>:  out = self.forward(*args)
[1,61]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,61]<stderr>:  out = self.forward(*args)
[1,105]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,105]<stderr>:  out = self.forward(*args)
[1,85]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,85]<stderr>:  out = self.forward(*args)
[1,15]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,15]<stderr>:  out = self.forward(*args)
[1,56]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,56]<stderr>:  out = self.forward(*args)
[1,173]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,173]<stderr>:  out = self.forward(*args)
[1,120]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,120]<stderr>:  out = self.forward(*args)
[1,151]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,151]<stderr>:  out = self.forward(*args)
[1,22]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,22]<stderr>:  out = self.forward(*args)
[1,134]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,134]<stderr>:  out = self.forward(*args)
[1,143]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,143]<stderr>:  out = self.forward(*args)
[1,31]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,31]<stderr>:  out = self.forward(*args)
[1,114]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,114]<stderr>:  out = self.forward(*args)
[1,162]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,162]<stderr>:  out = self.forward(*args)
[1,75]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,75]<stderr>:  out = self.forward(*args)
[1,116]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,116]<stderr>:  out = self.forward(*args)
[1,171]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,171]<stderr>:  out = self.forward(*args)
[1,19]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,19]<stderr>:  out = self.forward(*args)
[1,72]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,72]<stderr>:  out = self.forward(*args)
[1,79]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,79]<stderr>:  out = self.forward(*args)
[1,112]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,112]<stderr>:  out = self.forward(*args)
[1,59]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,59]<stderr>:  out = self.forward(*args)
[1,130]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,130]<stderr>:  out = self.forward(*args)
[1,188]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,188]<stderr>:  out = self.forward(*args)
[1,69]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,69]<stderr>:  out = self.forward(*args)
[1,137]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,137]<stderr>:  out = self.forward(*args)
[1,97]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,97]<stderr>:  out = self.forward(*args)
[1,29]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,29]<stderr>:  out = self.forward(*args)
[1,52]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,52]<stderr>:  out = self.forward(*args)
[1,23]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,23]<stderr>:  out = self.forward(*args)
[1,78]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,78]<stderr>:  out = self.forward(*args)
[1,24]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,24]<stderr>:  out = self.forward(*args)
[1,64]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,64]<stderr>:  out = self.forward(*args)
[1,51]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,51]<stderr>:  out = self.forward(*args)
[1,91]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,91]<stderr>:  out = self.forward(*args)
[1,67]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,67]<stderr>:  out = self.forward(*args)
[1,83]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,83]<stderr>:  out = self.forward(*args)
[1,11]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,11]<stderr>:  out = self.forward(*args)
[1,21]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,21]<stderr>:  out = self.forward(*args)
[1,14]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,14]<stderr>:  out = self.forward(*args)
[1,185]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,185]<stderr>:  out = self.forward(*args)
[1,141]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,141]<stderr>:  out = self.forward(*args)
[1,30]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,30]<stderr>:  out = self.forward(*args)
[1,175]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,175]<stderr>:  out = self.forward(*args)
[1,32]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,32]<stderr>:  out = self.forward(*args)
[1,93]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,93]<stderr>:  out = self.forward(*args)
[1,38]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,38]<stderr>:  out = self.forward(*args)
[1,90]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,90]<stderr>:  out = self.forward(*args)
[1,135]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,135]<stderr>:  out = self.forward(*args)
[1,115]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,115]<stderr>:  out = self.forward(*args)
[1,107]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,107]<stderr>:  out = self.forward(*args)
[1,66]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,66]<stderr>:  out = self.forward(*args)
[1,82]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,82]<stderr>:  out = self.forward(*args)
[1,53]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,53]<stderr>:  out = self.forward(*args)
[1,187]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,187]<stderr>:  out = self.forward(*args)
[1,176]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,176]<stderr>:  out = self.forward(*args)
[1,140]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,140]<stderr>:  out = self.forward(*args)
[1,152]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,152]<stderr>:  out = self.forward(*args)
[1,10]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,10]<stderr>:  out = self.forward(*args)
[1,36]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,36]<stderr>:  out = self.forward(*args)
[1,86]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,86]<stderr>:  out = self.forward(*args)
[1,47]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,47]<stderr>:  out = self.forward(*args)
[1,182]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,182]<stderr>:  out = self.forward(*args)
[1,60]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,60]<stderr>:  out = self.forward(*args)
[1,178]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,178]<stderr>:  out = self.forward(*args)
[1,87]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,87]<stderr>:  out = self.forward(*args)
[1,88]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,88]<stderr>:  out = self.forward(*args)
[1,65]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,65]<stderr>:  out = self.forward(*args)
[1,95]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,95]<stderr>:  out = self.forward(*args)
[1,147]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,147]<stderr>:  out = self.forward(*args)
[1,100]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,100]<stderr>:  out = self.forward(*args)
[1,12]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,12]<stderr>:  out = self.forward(*args)
[1,166]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,166]<stderr>:  out = self.forward(*args)
[1,18]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,18]<stderr>:  out = self.forward(*args)
[1,149]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,149]<stderr>:  out = self.forward(*args)
[1,50]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,50]<stderr>:  out = self.forward(*args)
[1,96]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,96]<stderr>:  out = self.forward(*args)
[1,99]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,99]<stderr>:  out = self.forward(*args)
[1,125]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,125]<stderr>:  out = self.forward(*args)
[1,142]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,142]<stderr>:  out = self.forward(*args)
[1,167]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,167]<stderr>:  out = self.forward(*args)
[1,168]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,168]<stderr>:  out = self.forward(*args)
[1,128]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,128]<stderr>:  out = self.forward(*args)
[1,58]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,58]<stderr>:  out = self.forward(*args)
[1,179]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,179]<stderr>:  out = self.forward(*args)
[1,113]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,113]<stderr>:  out = self.forward(*args)
[1,150]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,150]<stderr>:  out = self.forward(*args)
[1,17]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,17]<stderr>:  out = self.forward(*args)
[1,49]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,49]<stderr>:  out = self.forward(*args)
[1,146]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,146]<stderr>:  out = self.forward(*args)
[1,169]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,169]<stderr>:  out = self.forward(*args)
[1,80]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,80]<stderr>:  out = self.forward(*args)
[1,118]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,118]<stderr>:  out = self.forward(*args)
[1,184]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,184]<stderr>:  out = self.forward(*args)
[1,157]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,157]<stderr>:  out = self.forward(*args)
[1,172]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,172]<stderr>:  out = self.forward(*args)
[1,148]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,148]<stderr>:  out = self.forward(*args)
[1,124]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,124]<stderr>:  out = self.forward(*args)
[1,16]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,16]<stderr>:  out = self.forward(*args)
[1,181]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,181]<stderr>:  out = self.forward(*args)
[1,145]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,145]<stderr>:  out = self.forward(*args)
[1,43]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,43]<stderr>:  out = self.forward(*args)
[1,132]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,132]<stderr>:  out = self.forward(*args)
[1,40]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,40]<stderr>:  out = self.forward(*args)
[1,153]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,153]<stderr>:  out = self.forward(*args)
[1,111]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,111]<stderr>:  out = self.forward(*args)
[1,129]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,129]<stderr>:  out = self.forward(*args)
[1,133]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,133]<stderr>:  out = self.forward(*args)
[1,37]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,37]<stderr>:  out = self.forward(*args)
[1,81]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,81]<stderr>:  out = self.forward(*args)
[1,39]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,39]<stderr>:  out = self.forward(*args)
[1,48]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,48]<stderr>:  out = self.forward(*args)
[1,46]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,46]<stderr>:  out = self.forward(*args)
[1,98]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,98]<stderr>:  out = self.forward(*args)
[1,70]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,70]<stderr>:  out = self.forward(*args)
[1,34]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,34]<stderr>:  out = self.forward(*args)
[1,68]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,68]<stderr>:  out = self.forward(*args)
[1,109]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,109]<stderr>:  out = self.forward(*args)
[1,180]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,180]<stderr>:  out = self.forward(*args)
[1,189]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,189]<stderr>:  out = self.forward(*args)
[1,27]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,27]<stderr>:  out = self.forward(*args)
[1,136]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,136]<stderr>:  out = self.forward(*args)
[1,163]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,163]<stderr>:  out = self.forward(*args)
[1,73]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,73]<stderr>:  out = self.forward(*args)
[1,117]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,117]<stderr>:  out = self.forward(*args)
[1,106]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,106]<stderr>:  out = self.forward(*args)
[1,54]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,54]<stderr>:  out = self.forward(*args)
[1,103]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,103]<stderr>:  out = self.forward(*args)
[1,160]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,160]<stderr>:  out = self.forward(*args)
[1,158]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,158]<stderr>:  out = self.forward(*args)
[1,41]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,41]<stderr>:  out = self.forward(*args)
[1,45]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,45]<stderr>:  out = self.forward(*args)
[1,25]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,25]<stderr>:  out = self.forward(*args)
[1,165]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,165]<stderr>:  out = self.forward(*args)
[1,156]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,156]<stderr>:  out = self.forward(*args)
[1,9]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,9]<stderr>:  out = self.forward(*args)
[1,71]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,71]<stderr>:  out = self.forward(*args)
[1,102]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,102]<stderr>:  out = self.forward(*args)
[1,154]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,154]<stderr>:  out = self.forward(*args)
[1,122]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,122]<stderr>:  out = self.forward(*args)
[1,35]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,35]<stderr>:  out = self.forward(*args)
[1,13]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,13]<stderr>:  out = self.forward(*args)
[1,121]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,121]<stderr>:  out = self.forward(*args)
[1,119]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,119]<stderr>:  out = self.forward(*args)
[1,77]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,77]<stderr>:  out = self.forward(*args)
[1,108]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,108]<stderr>:  out = self.forward(*args)
[1,74]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,74]<stderr>:  out = self.forward(*args)
[1,20]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,20]<stderr>:  out = self.forward(*args)
[1,161]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,161]<stderr>:  out = self.forward(*args)
[1,8]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,8]<stderr>:  out = self.forward(*args)
[1,139]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,139]<stderr>:  out = self.forward(*args)
[1,89]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,89]<stderr>:  out = self.forward(*args)
[1,92]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,92]<stderr>:  out = self.forward(*args)
[1,190]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,190]<stderr>:  out = self.forward(*args)
[1,55]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,55]<stderr>:  out = self.forward(*args)
[1,126]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,126]<stderr>:  out = self.forward(*args)
[1,110]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,110]<stderr>:  out = self.forward(*args)
[1,84]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,84]<stderr>:  out = self.forward(*args)
[1,170]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,170]<stderr>:  out = self.forward(*args)
[1,42]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,42]<stderr>:  out = self.forward(*args)
[1,94]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,94]<stderr>:  out = self.forward(*args)
[1,159]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,159]<stderr>:  out = self.forward(*args)
[1,57]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,57]<stderr>:  out = self.forward(*args)
[1,26]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,26]<stderr>:  out = self.forward(*args)
[1,174]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,174]<stderr>:  out = self.forward(*args)
[1,131]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,131]<stderr>:  out = self.forward(*args)
[1,28]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,28]<stderr>:  out = self.forward(*args)
[1,155]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,155]<stderr>:  out = self.forward(*args)
[1,183]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,183]<stderr>:  out = self.forward(*args)
[1,76]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_stds, normalizedperclassboxcenterencoder0_means is not used by any computation. Is this intended?
[1,76]<stderr>:  out = self.forward(*args)
[1,186]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,186]<stderr>:  out = self.forward(*args)
[1,144]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,144]<stderr>:  out = self.forward(*args)
[1,177]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,177]<stderr>:  out = self.forward(*args)
[1,164]<stderr>:/home/ec2-user/anaconda3/lib/python3.7/site-packages/mxnet/gluon/block.py:620: UserWarning: Parameter normalizedperclassboxcenterencoder0_means, normalizedperclassboxcenterencoder0_stds is not used by any computation. Is this intended?
[1,164]<stderr>:  out = self.forward(*args)
[1,5]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,10]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,15]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,11]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,14]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,19]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,3]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,12]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,24]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,9]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,21]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,29]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,8]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,22]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,23]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,20]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,32]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,33]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,6]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,1]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,44]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,38]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,37]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,52]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,55]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,43]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,51]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,18]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,54]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,58]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,2]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,31]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,30]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,69]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,25]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,36]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,27]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,41]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,48]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,40]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,73]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,70]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,67]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,79]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,16]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,77]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,56]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,34]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,64]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,17]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,35]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,60]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,62]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,47]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,88]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,53]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,72]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,93]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,90]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,85]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,74]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,86]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,65]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,94]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,99]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,28]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,76]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,66]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,103]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,59]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,80]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,13]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,115]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,26]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,68]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,98]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,4]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,102]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,116]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,95]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,82]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,100]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,84]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,61]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,63]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,91]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,135]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,71]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,105]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,78]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,130]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,104]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,96]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,109]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,125]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,57]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,124]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,45]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,120]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,119]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,138]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,122]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,129]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,128]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,83]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,139]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,123]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,75]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,118]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,101]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,150]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,126]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,49]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,92]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,107]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,108]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,140]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,127]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,97]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,106]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,158]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,147]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,133]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,136]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,137]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,141]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,110]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,151]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,111]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,142]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,50]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,89]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,153]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,168]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,165]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,117]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,167]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,132]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,166]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,160]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,162]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,184]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,146]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,154]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,163]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,159]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,81]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,131]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,170]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,189]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,173]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,143]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,190]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,182]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,171]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,188]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,144]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,148]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,172]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,145]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,152]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,180]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,169]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,179]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,187]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,186]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,175]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,155]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,178]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,185]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,121]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,177]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,7]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,46]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,174]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,157]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,156]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,183]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,191]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,181]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,164]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,112]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,149]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,113]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,134]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,176]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,114]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,161]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,39]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,42]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,87]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,0]<stderr>:INFO:root:[Epoch 1] Validation Inference cost: 18.703
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 2 Iteration 0] Set learning rate to 0.12223780000000002
[1,0]<stdout>:DONE (t=2.63s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=8.09s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=14.75s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stderr>:INFO:root:[Epoch 2][Batch 99], Speed: 577.316 samples/sec, RPN_Conf=0.051,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.322,RCNN_SmoothL1=0.161,RCNN_Mask=0.336,RPNL1Loss=0.425,RCNNL1Loss=1.564
[1,0]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,139]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,138]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,171]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,136]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,172]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,137]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,175]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,169]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,170]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,174]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,6]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,190]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,143]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,191]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,7]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,5]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,141]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,186]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,142]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,4]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,173]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,189]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,3]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,150]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,140]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,185]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,2]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,149]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,163]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,168]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,184]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,177]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,1]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,18]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,148]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,25]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,78]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,162]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,104]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,187]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,176]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,17]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,147]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,46]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,27]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,77]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,98]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,164]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,156]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,106]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,178]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,34]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,120]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,93]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,53]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,63]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,19]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,145]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,42]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,28]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,75]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,97]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,82]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,160]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,68]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,152]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,110]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,9]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,188]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,180]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,128]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,33]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,121]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,92]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,51]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,58]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,20]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,151]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,41]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,31]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,79]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,118]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,99]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,84]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,165]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,64]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,159]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,107]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,14]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,179]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,129]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,35]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,123]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,94]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,52]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,59]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,22]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,144]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,47]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,26]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,72]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,115]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,96]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,83]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,166]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,65]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,155]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,109]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,12]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,181]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,133]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,32]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,126]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,91]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,55]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,56]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,16]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,146]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,43]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,24]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,73]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,112]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,100]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,80]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,167]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,71]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,153]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,105]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,11]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,183]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,131]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,39]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,122]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,89]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,49]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,61]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,21]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,44]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,29]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,74]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,113]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,102]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,86]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,161]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,66]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,158]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,108]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,8]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,182]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,132]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,37]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,124]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,95]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,48]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,62]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,23]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,40]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,30]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,76]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,117]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,101]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,87]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,67]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,157]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,111]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,10]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,130]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,36]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,125]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,90]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,50]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,60]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,45]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,116]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,103]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,85]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,70]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,154]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,15]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,134]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,38]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,127]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,88]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,54]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,57]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,114]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,81]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,69]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,13]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,135]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,119]<stderr>:INFO:root:[Epoch 2 Iteration 100] Set learning rate to 0.1322278
[1,0]<stdout>:DONE (t=14.41s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 1] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17759
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.35373
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.16163
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10727
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.21217
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.20659
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.19636
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.36208
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.40268
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.25371
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.44350
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.49392
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=17.8
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.17839
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.33150
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.17600
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.07450
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.20518
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.24533
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.20031
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.34742
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.38135
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.22256
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.42403
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.49290
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=17.8
[1,140]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,138]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,10]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,136]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,15]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,137]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,13]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,40]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,142]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,173]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,8]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,41]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,25]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,143]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,174]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,11]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,45]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,175]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,90]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,44]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,172]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,171]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,7]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,1]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,57]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,29]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,79]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,162]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,2]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,104]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,191]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,0]<stderr>:INFO:root:[Epoch 2][Batch 199], Speed: 901.526 samples/sec, RPN_Conf=0.049,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.320,RCNN_SmoothL1=0.162,RCNN_Mask=0.328,RPNL1Loss=0.421,RCNNL1Loss=1.535
[1,59]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,5]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,20]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,150]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,46]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,0]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,26]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,72]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,101]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,139]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,165]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,153]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,170]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,14]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,190]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,182]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,129]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,123]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,93]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,54]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,63]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,21]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,146]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,4]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,47]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,28]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,74]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,114]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,97]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,6]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,81]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,3]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,141]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,163]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,70]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,152]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,111]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,168]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,9]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,184]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,178]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,128]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,35]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,125]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,89]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,53]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,61]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,23]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,148]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,42]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,31]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,75]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,117]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,98]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,87]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,164]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,68]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,155]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,109]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,169]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,12]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,187]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,176]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,130]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,33]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,121]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,91]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,49]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,60]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,22]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,151]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,43]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,30]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,77]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,119]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,99]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,85]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,167]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,65]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,154]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,106]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,188]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,181]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,132]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,38]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,126]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,92]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,55]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,62]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,19]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,149]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,27]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,73]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,116]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,102]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,80]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,161]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,66]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,159]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,110]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,186]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,179]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,135]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,36]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,120]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,95]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,48]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,56]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,16]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,147]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,24]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,78]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,112]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,103]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,84]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,160]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,71]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,158]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,105]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,189]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,180]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,133]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,34]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,127]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,94]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,51]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,58]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,17]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,145]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,76]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,113]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,96]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,86]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,166]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,67]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,157]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,108]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,185]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,177]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,134]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,37]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,122]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,88]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,50]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,18]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,144]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,115]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,100]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,83]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,64]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,156]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,107]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,183]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,131]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,39]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,124]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,52]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,118]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,82]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,69]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,32]<stderr>:INFO:root:[Epoch 2 Iteration 200] Set learning rate to 0.1422178
[1,141]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,170]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,139]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,1]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,136]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,189]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,5]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,143]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,140]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,9]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,7]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,172]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,174]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,159]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,173]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,152]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,8]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,178]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,4]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,11]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,188]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,3]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,157]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,6]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,156]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,190]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,12]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,167]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,2]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,0]<stderr>:INFO:root:[Epoch 2][Batch 299], Speed: 1070.316 samples/sec, RPN_Conf=0.048,RPN_SmoothL1=0.042,RCNN_CrossEntropy=0.309,RCNN_SmoothL1=0.155,RCNN_Mask=0.318,RPNL1Loss=0.419,RCNNL1Loss=1.504
[1,184]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,165]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,185]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,186]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,137]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,0]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,149]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,43]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,166]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,154]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,148]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,45]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,153]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,180]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,144]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,40]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,138]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,70]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,187]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,177]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,151]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,31]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,64]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,176]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,57]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,161]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,179]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,39]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,62]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,150]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,162]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,155]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,37]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,58]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,147]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,130]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,35]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,63]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,23]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,26]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,113]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,134]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,38]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,60]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,20]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,29]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,118]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,160]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,32]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,61]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,18]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,44]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,28]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,115]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,131]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,34]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,53]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,21]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,27]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,67]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,109]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,169]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,10]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,33]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,112]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,97]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,163]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,69]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,105]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,14]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,191]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,133]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,36]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,120]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,48]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,41]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,99]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,164]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,66]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,111]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,175]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,13]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,182]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,135]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,127]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,59]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,103]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,158]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,106]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,168]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,181]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,22]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,24]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,96]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,85]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,107]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,171]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,183]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,132]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,124]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,56]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,117]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,84]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,126]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,46]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,122]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,55]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,15]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,121]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,145]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,142]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,30]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,146]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,102]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,47]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,98]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,25]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,101]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,17]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,16]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,54]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,77]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,129]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,74]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,116]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,83]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,128]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,78]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,73]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,72]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,50]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,76]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,91]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,49]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,68]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,92]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,51]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,42]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,71]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,123]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,90]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,52]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,19]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,87]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,108]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,95]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,114]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,110]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,93]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,119]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,65]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,125]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,89]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,100]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,104]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,82]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,94]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,79]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,86]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,88]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,81]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,80]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,75]<stderr>:INFO:root:[Epoch 2 Iteration 300] Set learning rate to 0.1522078
[1,0]<stderr>:INFO:root:[Epoch 2][Batch 399], Speed: 1165.543 samples/sec, RPN_Conf=0.051,RPN_SmoothL1=0.042,RCNN_CrossEntropy=0.313,RCNN_SmoothL1=0.154,RCNN_Mask=0.320,RPNL1Loss=0.415,RCNNL1Loss=1.480
[1,0]<stderr>:INFO:root:[Epoch 2][Batch 499], Speed: 1161.504 samples/sec, RPN_Conf=0.052,RPN_SmoothL1=0.042,RCNN_CrossEntropy=0.315,RCNN_SmoothL1=0.154,RCNN_Mask=0.318,RPNL1Loss=0.412,RCNNL1Loss=1.455
[1,0]<stderr>:INFO:root:[Epoch 2][Batch 599], Speed: 1168.416 samples/sec, RPN_Conf=0.053,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.310,RCNN_SmoothL1=0.151,RCNN_Mask=0.313,RPNL1Loss=0.408,RCNNL1Loss=1.430
[1,0]<stderr>:INFO:root:[Epoch 2] Training cost: 123.500, RPN_Conf=0.053,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.310,RCNN_SmoothL1=0.151,RCNN_Mask=0.313
[1,0]<stderr>:INFO:root:[Epoch 2] Validation Inference cost: 14.418
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist![1,0]<stdout>:
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.62s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=7.57s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 3][Batch 99], Speed: 1076.834 samples/sec, RPN_Conf=0.051,RPN_SmoothL1=0.043,RCNN_CrossEntropy=0.323,RCNN_SmoothL1=0.157,RCNN_Mask=0.296,RPNL1Loss=0.402,RCNNL1Loss=1.399
[1,0]<stdout>:DONE (t=10.47s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,3]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,1]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,6]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,4]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,2]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,7]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,5]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,0]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,163]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,145]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,136]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,162]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,152]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,147]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,138]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,161]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,155]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,146]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,142]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,160]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,157]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,144]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,141]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,164]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,159]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,168]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,150]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,140]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,167]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,156]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,148]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,137]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,165]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,158]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,149]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,139]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,166]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,153]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,172]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,151]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,143]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,154]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,174]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,186]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,97]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,170]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,187]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,99]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,169]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,185]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,177]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,129]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,98]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,175]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,184]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,176]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,130]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,100]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,171]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,191]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,182]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,128]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,40]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,77]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,117]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,103]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,105]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,173]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,190]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,178]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,131]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,123]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,60]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,41]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,76]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,119]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,102]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,82]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,104]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,189]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,179]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,134]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,35]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,120]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,89]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,56]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,18]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,47]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,24]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,75]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,118]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,96]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,85]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,67]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,110]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,14]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,188]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,181]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,133]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,33]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,121]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,91]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,49]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,58]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,16]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,42]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,30]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,78]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,115]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,101]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,84]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,64]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,106]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,13]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,180]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,135]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,38]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,126]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,94]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,54]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,63]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,20]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,43]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,26]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,79]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,116]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,87]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,71]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,107]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,10]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,183]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,132]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,39]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,125]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,88]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,53]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,62]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,19]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,46]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,29]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,72]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,114]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,81]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,69]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,109]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,8]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,32]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,122]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,90]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,51]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,57]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,22]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,44]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,28]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,74]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,113]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,80]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,65]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,108]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,9]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,37]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,124]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,93]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,48]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,59]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,17]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,45]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,25]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,73]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,112]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,86]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,68]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,111]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,12]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,36]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,127]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,95]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,55]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,61]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,21]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,27]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,83]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,66]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,11]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,34]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,92]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,52]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,23]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,31]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,70]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,15]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,50]<stderr>:INFO:root:AMP: increasing loss scale to 128.000000
[1,0]<stdout>:DONE (t=12.25s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 2] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.22259
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.41722
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.21833
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.13659
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.25069
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.27084
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22719
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.39413
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.43104
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.28329
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.46049
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52828
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=22.3
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.21879
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.39295
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.21887
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.09918
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.24184
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31819
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.22675
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.37659
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.40744
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.24172
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.44417
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.52426
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=21.9
[1,0]<stderr>:INFO:root:[Epoch 3][Batch 199], Speed: 1166.492 samples/sec, RPN_Conf=0.047,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.299,RCNN_SmoothL1=0.147,RCNN_Mask=0.290,RPNL1Loss=0.399,RCNNL1Loss=1.378
[1,0]<stderr>:INFO:root:[Epoch 3][Batch 299], Speed: 1150.161 samples/sec, RPN_Conf=0.048,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.297,RCNN_SmoothL1=0.147,RCNN_Mask=0.295,RPNL1Loss=0.397,RCNNL1Loss=1.361
[1,0]<stderr>:INFO:root:[Epoch 3][Batch 399], Speed: 1157.545 samples/sec, RPN_Conf=0.045,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.286,RCNN_SmoothL1=0.141,RCNN_Mask=0.290,RPNL1Loss=0.393,RCNNL1Loss=1.341
[1,0]<stderr>:INFO:root:[Epoch 3][Batch 499], Speed: 1155.654 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.278,RCNN_SmoothL1=0.136,RCNN_Mask=0.283,RPNL1Loss=0.391,RCNNL1Loss=1.323
[1,0]<stderr>:INFO:root:[Epoch 3][Batch 599], Speed: 1157.015 samples/sec, RPN_Conf=0.044,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.276,RCNN_SmoothL1=0.135,RCNN_Mask=0.280,RPNL1Loss=0.389,RCNNL1Loss=1.306
[1,0]<stderr>:INFO:root:[Epoch 3] Training cost: 102.392, RPN_Conf=0.045,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.279,RCNN_SmoothL1=0.136,RCNN_Mask=0.281
[1,0]<stderr>:INFO:root:[Epoch 3] Validation Inference cost: 15.082
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.78s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=8.12s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 4][Batch 99], Speed: 1089.350 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.239,RCNN_SmoothL1=0.121,RCNN_Mask=0.271,RPNL1Loss=0.387,RCNNL1Loss=1.291
[1,0]<stdout>:DONE (t=11.55s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stderr>:INFO:root:[Epoch 4][Batch 199], Speed: 1158.528 samples/sec, RPN_Conf=0.036,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.251,RCNN_SmoothL1=0.128,RCNN_Mask=0.279,RPNL1Loss=0.385,RCNNL1Loss=1.279
[1,0]<stdout>:DONE (t=14.05s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 3] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.25051
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.45442
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.25079
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.15600
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.28292
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.31712
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.24620
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.42321
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.46284
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30645
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.50009
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.56947
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=25.1
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.24432
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.42767
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.24975
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.10971
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.26623
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35958
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.24502
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.40343
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.43714
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.27001
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.48084
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.55993
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=24.4
[1,0]<stderr>:INFO:root:[Epoch 4][Batch 299], Speed: 1151.862 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.255,RCNN_SmoothL1=0.132,RCNN_Mask=0.282,RPNL1Loss=0.382,RCNNL1Loss=1.265
[1,0]<stderr>:INFO:root:[Epoch 4][Batch 399], Speed: 1164.921 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.035,RCNN_CrossEntropy=0.249,RCNN_SmoothL1=0.130,RCNN_Mask=0.278,RPNL1Loss=0.380,RCNNL1Loss=1.255
[1,0]<stderr>:INFO:root:[Epoch 4][Batch 499], Speed: 1154.891 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.255,RCNN_SmoothL1=0.132,RCNN_Mask=0.280,RPNL1Loss=0.378,RCNNL1Loss=1.242
[1,0]<stderr>:INFO:root:[Epoch 4][Batch 599], Speed: 1166.508 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.253,RCNN_SmoothL1=0.130,RCNN_Mask=0.277,RPNL1Loss=0.376,RCNNL1Loss=1.232
[1,0]<stderr>:INFO:root:[Epoch 4] Training cost: 102.071, RPN_Conf=0.041,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.253,RCNN_SmoothL1=0.130,RCNN_Mask=0.277
[1,0]<stderr>:INFO:root:[Epoch 4] Validation Inference cost: 14.743
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.67s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=7.75s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 5][Batch 99], Speed: 1088.750 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.259,RCNN_SmoothL1=0.131,RCNN_Mask=0.259,RPNL1Loss=0.374,RCNNL1Loss=1.218
[1,0]<stdout>:DONE (t=10.43s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stdout>:DONE (t=12.63s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 4] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27383
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49101
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.28160
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.16466
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31176
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.33955
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.25793
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.44344
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.48334
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.34373
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.51797
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.57732
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=27.4
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26067
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.45645
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.26764
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.11848
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.28899
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37449
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.25335
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.41827
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.45255
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.29540
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.49414
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.56801
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=26.1
[1,0]<stderr>:INFO:root:[Epoch 5][Batch 199], Speed: 1163.963 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.262,RCNN_SmoothL1=0.133,RCNN_Mask=0.274,RPNL1Loss=0.371,RCNNL1Loss=1.207
[1,0]<stderr>:INFO:root:[Epoch 5][Batch 299], Speed: 1163.075 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.254,RCNN_SmoothL1=0.127,RCNN_Mask=0.270,RPNL1Loss=0.370,RCNNL1Loss=1.197
[1,0]<stderr>:INFO:root:[Epoch 5][Batch 399], Speed: 1160.511 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.258,RCNN_SmoothL1=0.128,RCNN_Mask=0.271,RPNL1Loss=0.369,RCNNL1Loss=1.188
[1,0]<stderr>:INFO:root:[Epoch 5][Batch 499], Speed: 1146.811 samples/sec, RPN_Conf=0.043,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.256,RCNN_SmoothL1=0.130,RCNN_Mask=0.272,RPNL1Loss=0.367,RCNNL1Loss=1.179
[1,0]<stderr>:INFO:root:[Epoch 5][Batch 599], Speed: 1172.012 samples/sec, RPN_Conf=0.042,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.253,RCNN_SmoothL1=0.129,RCNN_Mask=0.271,RPNL1Loss=0.365,RCNNL1Loss=1.171
[1,0]<stderr>:INFO:root:[Epoch 5] Training cost: 101.950, RPN_Conf=0.042,RPN_SmoothL1=0.039,RCNN_CrossEntropy=0.253,RCNN_SmoothL1=0.129,RCNN_Mask=0.271
[1,0]<stderr>:INFO:root:[Epoch 5] Validation Inference cost: 15.760
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.77s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=8.32s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 6][Batch 99], Speed: 1044.309 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.041,RCNN_CrossEntropy=0.243,RCNN_SmoothL1=0.130,RCNN_Mask=0.256,RPNL1Loss=0.363,RCNNL1Loss=1.159
[1,0]<stdout>:DONE (t=11.71s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stdout>:DONE (t=12.80s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 5] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27942
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.48893
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.28653
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.18038
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31461
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.34227
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.26017
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.44598
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.48866
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.33750
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.53082
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.58037
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=27.9
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.26721
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.45756
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.27763
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.12623
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.29481
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38272
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.25515
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.42150
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.45787
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.29338
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.50683
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.57027
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=26.7
[1,0]<stderr>:INFO:root:[Epoch 6][Batch 199], Speed: 1063.458 samples/sec, RPN_Conf=0.038,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.227,RCNN_SmoothL1=0.121,RCNN_Mask=0.259,RPNL1Loss=0.361,RCNNL1Loss=1.151
[1,0]<stderr>:INFO:root:[Epoch 6][Batch 299], Speed: 1163.629 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.231,RCNN_SmoothL1=0.119,RCNN_Mask=0.257,RPNL1Loss=0.359,RCNNL1Loss=1.142
[1,7]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,6]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,2]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,3]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,5]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,0]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,4]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,1]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,177]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,171]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,184]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,176]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,174]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,186]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,180]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,169]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,185]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,182]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,103]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,167]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,168]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,187]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,181]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,99]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,161]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,175]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,188]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,178]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,101]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,166]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,170]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,190]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,179]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,97]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,164]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,173]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,191]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,183]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,98]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,82]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,165]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,172]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,189]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,96]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,86]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,160]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,67]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,102]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,87]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,163]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,64]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,74]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,100]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,81]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,162]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,66]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,105]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,95]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,147]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,72]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,114]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,80]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,65]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,104]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,130]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,120]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,94]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,150]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,79]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,118]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,83]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,139]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,69]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,159]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,111]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,132]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,122]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,89]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,54]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,19]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,148]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,40]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,26]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,78]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,112]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,85]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,138]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,71]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,155]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,106]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,11]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,128]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,32]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,123]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,91]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,53]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,57]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,16]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,146]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,43]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,27]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,73]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,115]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,84]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,136]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,68]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,158]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,107]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,9]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,131]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,33]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,126]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,93]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,50]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,62]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,21]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,144]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,41]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,30]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,76]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,116]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,137]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,70]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,152]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,110]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,10]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,135]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,38]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,125]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,90]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,49]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,58]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,23]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,145]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,42]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,25]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,75]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,119]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,142]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,156]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,109]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,8]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,129]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,39]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,127]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,92]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,48]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,61]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,20]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,149]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,45]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,29]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,77]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,117]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,141]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,157]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,108]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,14]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,134]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,36]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,121]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,88]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,55]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,59]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,18]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,151]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,44]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,28]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,113]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,143]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,154]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,15]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,133]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,35]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,124]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,52]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,56]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,22]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,47]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,31]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,140]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,153]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,12]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,34]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,51]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,63]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,17]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,46]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,24]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,13]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,37]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,60]<stderr>:INFO:root:AMP: increasing loss scale to 256.000000
[1,0]<stderr>:INFO:root:[Epoch 6][Batch 399], Speed: 1167.908 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.037,RCNN_CrossEntropy=0.235,RCNN_SmoothL1=0.124,RCNN_Mask=0.263,RPNL1Loss=0.358,RCNNL1Loss=1.136
[1,0]<stderr>:INFO:root:[Epoch 6][Batch 499], Speed: 1167.850 samples/sec, RPN_Conf=0.039,RPN_SmoothL1=0.036,RCNN_CrossEntropy=0.232,RCNN_SmoothL1=0.123,RCNN_Mask=0.265,RPNL1Loss=0.356,RCNNL1Loss=1.129
[1,0]<stderr>:INFO:root:[Epoch 6][Batch 599], Speed: 1174.954 samples/sec, RPN_Conf=0.040,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.237,RCNN_SmoothL1=0.123,RCNN_Mask=0.265,RPNL1Loss=0.355,RCNNL1Loss=1.121
[1,0]<stderr>:INFO:root:[Epoch 6] Training cost: 103.842, RPN_Conf=0.039,RPN_SmoothL1=0.038,RCNN_CrossEntropy=0.236,RCNN_SmoothL1=0.123,RCNN_Mask=0.265
[1,0]<stderr>:INFO:root:[Epoch 6] Validation Inference cost: 14.676
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.86s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=7.97s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=9.52s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stderr>:INFO:root:[Epoch 7][Batch 99], Speed: 994.474 samples/sec, RPN_Conf=0.029,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.200,RCNN_SmoothL1=0.106,RCNN_Mask=0.269,RPNL1Loss=0.354,RCNNL1Loss=1.114
[1,0]<stdout>:DONE (t=12.68s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 6] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28963
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.50141
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30088
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.18114
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.32151
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.35372
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.27009
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.46054
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50423
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.35835
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.53614
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.60737
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=29.0
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27345
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.46790
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.28214
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.12660
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.29937
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.38834
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.26223
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.42924
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.46544
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30874
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.50370
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.59102
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=27.3
[1,0]<stderr>:INFO:root:[Epoch 7][Batch 199], Speed: 1155.983 samples/sec, RPN_Conf=0.028,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.197,RCNN_SmoothL1=0.102,RCNN_Mask=0.263,RPNL1Loss=0.353,RCNNL1Loss=1.107
[1,0]<stderr>:INFO:root:[Epoch 7][Batch 299], Speed: 1068.625 samples/sec, RPN_Conf=0.030,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.205,RCNN_SmoothL1=0.105,RCNN_Mask=0.266,RPNL1Loss=0.352,RCNNL1Loss=1.102
[1,0]<stderr>:INFO:root:[Epoch 7][Batch 399], Speed: 1161.243 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.215,RCNN_SmoothL1=0.112,RCNN_Mask=0.267,RPNL1Loss=0.351,RCNNL1Loss=1.098
[1,0]<stderr>:INFO:root:[Epoch 7][Batch 499], Speed: 1154.355 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.213,RCNN_SmoothL1=0.110,RCNN_Mask=0.264,RPNL1Loss=0.349,RCNNL1Loss=1.091
[1,0]<stderr>:INFO:root:[Epoch 7][Batch 599], Speed: 1174.022 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.218,RCNN_SmoothL1=0.111,RCNN_Mask=0.264,RPNL1Loss=0.348,RCNNL1Loss=1.085
[1,0]<stderr>:INFO:root:[Epoch 7] Training cost: 104.990, RPN_Conf=0.034,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.218,RCNN_SmoothL1=0.110,RCNN_Mask=0.263
[1,0]<stderr>:INFO:root:[Epoch 7] Validation Inference cost: 14.306
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.68s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=7.13s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=8.68s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stderr>:INFO:root:[Epoch 8][Batch 99], Speed: 1088.194 samples/sec, RPN_Conf=0.029,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.222,RCNN_SmoothL1=0.127,RCNN_Mask=0.270,RPNL1Loss=0.346,RCNNL1Loss=1.080
[1,0]<stdout>:DONE (t=11.80s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 7] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29676
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.50966
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30983
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.17262
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.33889
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37204
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.27459
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.46223
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50126
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.34799
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.54237
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.60819
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=29.7
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.27998
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.47858
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.28938
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.12677
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.30912
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.40395
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.26588
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.43080
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.46410
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30169
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.50963
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.59138
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=28.0
[1,0]<stderr>:INFO:root:[Epoch 8][Batch 199], Speed: 1157.611 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.228,RCNN_SmoothL1=0.120,RCNN_Mask=0.268,RPNL1Loss=0.345,RCNNL1Loss=1.074
[1,0]<stderr>:INFO:root:[Epoch 8][Batch 299], Speed: 1142.587 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.221,RCNN_SmoothL1=0.116,RCNN_Mask=0.262,RPNL1Loss=0.345,RCNNL1Loss=1.068
[1,0]<stderr>:INFO:root:[Epoch 8][Batch 399], Speed: 1160.375 samples/sec, RPN_Conf=0.035,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.225,RCNN_SmoothL1=0.118,RCNN_Mask=0.261,RPNL1Loss=0.343,RCNNL1Loss=1.064
[1,0]<stderr>:INFO:root:[Epoch 8][Batch 499], Speed: 1172.541 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.221,RCNN_SmoothL1=0.117,RCNN_Mask=0.263,RPNL1Loss=0.343,RCNNL1Loss=1.060
[1,0]<stderr>:INFO:root:[Epoch 8][Batch 599], Speed: 1162.964 samples/sec, RPN_Conf=0.034,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.222,RCNN_SmoothL1=0.117,RCNN_Mask=0.265,RPNL1Loss=0.342,RCNNL1Loss=1.056
[1,0]<stderr>:INFO:root:[Epoch 8] Training cost: 102.149, RPN_Conf=0.034,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.222,RCNN_SmoothL1=0.116,RCNN_Mask=0.265
[1,0]<stderr>:INFO:root:[Epoch 8] Validation Inference cost: 12.216
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=1.41s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=7.16s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=8.55s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stderr>:INFO:root:[Epoch 9][Batch 99], Speed: 1084.299 samples/sec, RPN_Conf=0.030,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.226,RCNN_SmoothL1=0.115,RCNN_Mask=0.248,RPNL1Loss=0.340,RCNNL1Loss=1.050
[1,0]<stdout>:DONE (t=11.10s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 8] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.30488
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.51861
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.32005
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.18935
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.34250
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.37766
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.27672
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.47101
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.51067
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.36655
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.54589
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.61194
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=30.5
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.29075
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49234
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30372
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.14223
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31841
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.41392
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.26986
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.44059
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.47406
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.31954
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.51605
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.59264
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=29.1
[1,0]<stderr>:INFO:root:[Epoch 9][Batch 199], Speed: 1156.441 samples/sec, RPN_Conf=0.029,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.228,RCNN_SmoothL1=0.115,RCNN_Mask=0.249,RPNL1Loss=0.339,RCNNL1Loss=1.045
[1,0]<stderr>:INFO:root:[Epoch 9][Batch 299], Speed: 1163.273 samples/sec, RPN_Conf=0.030,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.226,RCNN_SmoothL1=0.114,RCNN_Mask=0.246,RPNL1Loss=0.337,RCNNL1Loss=1.039
[1,0]<stderr>:INFO:root:[Epoch 9][Batch 399], Speed: 1161.833 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.225,RCNN_SmoothL1=0.116,RCNN_Mask=0.249,RPNL1Loss=0.337,RCNNL1Loss=1.036
[1,0]<stderr>:INFO:root:[Epoch 9][Batch 499], Speed: 1149.060 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.228,RCNN_SmoothL1=0.116,RCNN_Mask=0.251,RPNL1Loss=0.336,RCNNL1Loss=1.031
[1,2]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,1]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,6]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,5]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,7]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,0]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,3]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,4]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,160]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,161]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,165]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,163]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,162]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,166]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,164]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,167]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,146]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,182]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,128]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,144]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,98]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,66]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,158]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,172]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,186]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,176]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,129]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,151]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,118]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,99]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,81]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,136]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,68]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,153]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,170]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,187]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,180]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,131]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,36]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,145]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,75]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,119]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,97]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,80]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,137]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,67]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,159]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,171]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,184]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,183]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,130]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,35]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,123]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,94]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,50]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,57]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,22]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,148]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,43]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,29]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,79]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,112]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,102]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,82]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,139]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,70]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,157]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,104]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,175]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,185]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,179]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,132]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,32]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,121]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,91]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,51]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,62]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,16]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,150]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,44]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,28]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,73]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,117]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,101]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,83]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,138]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,71]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,156]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,105]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,174]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,8]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,190]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,178]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,133]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,34]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,120]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,88]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,52]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,58]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,23]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,147]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,42]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,25]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,72]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,116]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,100]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,86]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,142]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,64]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,152]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,106]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,169]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,13]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,188]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,177]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,134]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,33]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,122]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,90]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,49]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,63]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,21]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,149]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,46]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,27]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,77]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,115]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,103]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,87]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,140]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,65]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,155]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,107]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,168]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,14]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,189]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,181]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,135]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,38]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,126]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,92]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,48]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,59]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,20]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,47]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,24]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,78]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,113]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,96]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,84]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,141]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,69]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,154]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,108]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,173]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,15]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,191]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,37]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,124]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,89]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,54]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,61]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,17]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,41]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,30]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,76]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,114]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,85]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,143]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,111]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,12]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,39]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,125]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,95]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,55]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,60]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,19]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,40]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,31]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,74]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,110]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,10]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,127]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,93]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,53]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,56]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,18]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,45]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,26]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,109]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,11]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,9]<stderr>:INFO:root:AMP: increasing loss scale to 512.000000
[1,0]<stderr>:INFO:root:[Epoch 9][Batch 599], Speed: 1166.817 samples/sec, RPN_Conf=0.033,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.225,RCNN_SmoothL1=0.115,RCNN_Mask=0.250,RPNL1Loss=0.335,RCNNL1Loss=1.027
[1,0]<stderr>:INFO:root:[Epoch 9] Training cost: 102.170, RPN_Conf=0.033,RPN_SmoothL1=0.033,RCNN_CrossEntropy=0.224,RCNN_SmoothL1=0.114,RCNN_Mask=0.252
[1,2]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,3]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,4]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,5]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,1]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,6]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,8]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,7]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,10]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,9]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,11]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,12]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,13]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,14]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,16]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,17]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,15]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,18]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,19]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,20]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,21]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,22]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,23]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,24]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,25]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,27]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,28]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,26]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,29]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,32]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,30]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,31]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,35]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,33]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,34]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,36]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,38]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,37]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,39]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,40]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,43]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,41]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,42]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,45]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,46]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,44]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,47]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,48]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,49]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,50]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,51]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,52]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,53]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,55]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,54]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,56]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,57]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,58]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,59]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,60]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,61]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,63]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,62]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,64]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,66]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,65]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,67]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,68]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,69]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,70]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,71]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,73]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,72]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,74]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,75]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,76]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,77]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,78]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,79]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,80]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,81]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,82]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,83]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,84]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,85]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,86]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,87]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,88]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,89]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,90]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,91]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,92]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,93]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,94]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,95]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,96]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,97]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,98]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,100]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,101]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,99]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,102]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,103]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,104]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,106]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,107]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,105]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,109]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,108]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,111]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,110]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,112]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,114]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,115]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,113]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,117]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,116]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,118]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,119]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,120]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,121]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,122]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,124]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,125]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,123]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,126]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,127]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,128]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,129]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,130]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,131]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,133]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,132]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,134]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,135]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,136]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,137]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,139]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,138]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,140]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,142]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,143]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,141]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,144]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,145]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,146]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,147]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,148]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,149]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,150]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,152]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,151]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,153]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,154]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,155]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,156]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,157]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,159]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,160]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,158]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,161]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,162]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,163]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,165]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,166]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,164]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,168]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,167]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,170]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,169]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,171]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,172]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,173]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,175]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,174]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,177]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,176]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,178]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,179]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,181]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,182]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,180]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,183]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,185]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,184]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,186]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,189]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,187]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,188]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,190]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,191]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,0]<stderr>:INFO:root:[Epoch 9] Validation Inference cost: 15.311
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist![1,0]<stdout>:
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 10] Set learning rate to 0.016
[1,0]<stdout>:DONE (t=1.58s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=7.78s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 10][Batch 99], Speed: 1077.788 samples/sec, RPN_Conf=0.031,RPN_SmoothL1=0.034,RCNN_CrossEntropy=0.239,RCNN_SmoothL1=0.124,RCNN_Mask=0.258,RPNL1Loss=0.334,RCNNL1Loss=1.023
[1,0]<stdout>:DONE (t=9.99s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stdout>:DONE (t=12.38s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 9] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.31004
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.52147
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.32914
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.18361
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.34828
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.39119
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.28386
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.47635
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.51779
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.36012
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.55467
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.63217
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=31.0
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.28990
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.49023
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.30440
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.13280
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.31963
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.41792
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.27309
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.44392
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.47896
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.30769
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.52238
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.61443
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=29.0
[1,0]<stderr>:INFO:root:[Epoch 10][Batch 199], Speed: 1173.910 samples/sec, RPN_Conf=0.029,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.215,RCNN_SmoothL1=0.117,RCNN_Mask=0.249,RPNL1Loss=0.333,RCNNL1Loss=1.019
[1,0]<stderr>:INFO:root:[Epoch 10][Batch 299], Speed: 1166.659 samples/sec, RPN_Conf=0.027,RPN_SmoothL1=0.032,RCNN_CrossEntropy=0.200,RCNN_SmoothL1=0.111,RCNN_Mask=0.246,RPNL1Loss=0.332,RCNNL1Loss=1.014
[1,0]<stderr>:INFO:root:[Epoch 10][Batch 399], Speed: 1166.623 samples/sec, RPN_Conf=0.026,RPN_SmoothL1=0.031,RCNN_CrossEntropy=0.192,RCNN_SmoothL1=0.108,RCNN_Mask=0.244,RPNL1Loss=0.331,RCNNL1Loss=1.009
[1,0]<stderr>:INFO:root:[Epoch 10][Batch 499], Speed: 1156.451 samples/sec, RPN_Conf=0.024,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.187,RCNN_SmoothL1=0.106,RCNN_Mask=0.244,RPNL1Loss=0.330,RCNNL1Loss=1.005
[1,0]<stderr>:INFO:root:[Epoch 10][Batch 599], Speed: 1167.877 samples/sec, RPN_Conf=0.024,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.181,RCNN_SmoothL1=0.104,RCNN_Mask=0.240,RPNL1Loss=0.329,RCNNL1Loss=0.999
[1,0]<stderr>:INFO:root:[Epoch 10] Training cost: 101.769, RPN_Conf=0.024,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.179,RCNN_SmoothL1=0.103,RCNN_Mask=0.239
[1,0]<stderr>:INFO:root:[Epoch 10] Validation Inference cost: 8.315
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=0.90s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=5.43s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=6.24s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stderr>:INFO:root:[Epoch 11][Batch 99], Speed: 1091.903 samples/sec, RPN_Conf=0.028,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.165,RCNN_SmoothL1=0.094,RCNN_Mask=0.249,RPNL1Loss=0.327,RCNNL1Loss=0.994
[1,0]<stdout>:DONE (t=8.84s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 10] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.37051
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.59290
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.40224
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.22302
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.40694
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.47156
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.31335
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.51283
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.55073
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.38721
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.58404
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.67690
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=37.1
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.33791
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.55917
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.35365
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.16103
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.36704
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.49122
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.29590
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.47259
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50426
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.32910
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.54296
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.65360
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=33.8
[1,0]<stderr>:INFO:root:[Epoch 11][Batch 199], Speed: 1152.270 samples/sec, RPN_Conf=0.025,RPN_SmoothL1=0.030,RCNN_CrossEntropy=0.170,RCNN_SmoothL1=0.094,RCNN_Mask=0.241,RPNL1Loss=0.326,RCNNL1Loss=0.989
[1,0]<stderr>:INFO:root:[Epoch 11][Batch 299], Speed: 1155.566 samples/sec, RPN_Conf=0.024,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.172,RCNN_SmoothL1=0.095,RCNN_Mask=0.240,RPNL1Loss=0.325,RCNNL1Loss=0.984
[1,0]<stderr>:INFO:root:[Epoch 11][Batch 399], Speed: 1159.236 samples/sec, RPN_Conf=0.024,RPN_SmoothL1=0.029,RCNN_CrossEntropy=0.180,RCNN_SmoothL1=0.099,RCNN_Mask=0.241,RPNL1Loss=0.323,RCNNL1Loss=0.979
[1,0]<stderr>:INFO:root:[Epoch 11][Batch 499], Speed: 1166.538 samples/sec, RPN_Conf=0.024,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.175,RCNN_SmoothL1=0.097,RCNN_Mask=0.235,RPNL1Loss=0.322,RCNNL1Loss=0.973
[1,0]<stderr>:INFO:root:[Epoch 11][Batch 599], Speed: 1151.549 samples/sec, RPN_Conf=0.023,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.176,RCNN_SmoothL1=0.098,RCNN_Mask=0.236,RPNL1Loss=0.321,RCNNL1Loss=0.968
[1,0]<stderr>:INFO:root:[Epoch 11] Training cost: 102.193, RPN_Conf=0.023,RPN_SmoothL1=0.028,RCNN_CrossEntropy=0.176,RCNN_SmoothL1=0.099,RCNN_Mask=0.236
[1,2]<stderr>:INFO:root:Total Training with validation: 1525.9646999835968 secs
[1,3]<stderr>:INFO:root:Total Training with validation: 1525.9654777050018 secs
[1,1]<stderr>:INFO:root:Total Training with validation: 1525.9660518169403 secs
[1,4]<stderr>:INFO:root:Total Training with validation: 1525.9664027690887 secs
[1,6]<stderr>:INFO:root:Total Training with validation: 1525.9677498340607 secs
[1,7]<stderr>:INFO:root:Total Training with validation: 1525.9684329032898 secs
[1,9]<stderr>:INFO:root:Total Training with validation: 1525.9706063270569 secs
[1,9]<stdout>:[1,5]<stderr>:INFO:root:Total Training with validation: 1525.9726898670197 secs
[1,10]<stderr>:INFO:root:Total Training with validation: 1525.973492860794 secs
[1,10]<stdout>:[1,11]<stderr>:INFO:root:Total Training with validation: 1525.9746642112732 secs
[1,8]<stderr>:INFO:root:Total Training with validation: 1525.9748902320862 secs
[1,11]<stdout>:[1,8]<stdout>:[1,12]<stderr>:INFO:root:Total Training with validation: 1525.9753971099854 secs
[1,12]<stdout>:[1,13]<stderr>:INFO:root:Total Training with validation: 1525.9772160053253 secs
[1,13]<stdout>:[1,14]<stderr>:INFO:root:Total Training with validation: 1525.9782750606537 secs
[1,14]<stdout>:[1,17]<stderr>:INFO:root:Total Training with validation: 1525.9809954166412 secs
[1,17]<stdout>:[1,19]<stderr>:INFO:root:Total Training with validation: 1525.9836883544922 secs
[1,15]<stderr>:INFO:root:Total Training with validation: 1525.983674287796 secs
[1,19]<stdout>:[1,15]<stdout>:[1,20]<stderr>:INFO:root:Total Training with validation: 1525.9853730201721 secs
[1,20]<stdout>:[1,18]<stderr>:INFO:root:Total Training with validation: 1525.9864308834076 secs
[1,18]<stdout>:[1,21]<stderr>:INFO:root:Total Training with validation: 1525.9868609905243 secs
[1,16]<stderr>:INFO:root:Total Training with validation: 1525.9870419502258 secs
[1,21]<stdout>:[1,16]<stdout>:[1,22]<stderr>:INFO:root:Total Training with validation: 1525.987646818161 secs
[1,22]<stdout>:[1,24]<stderr>:INFO:root:Total Training with validation: 1525.990095615387 secs
[1,24]<stdout>:[1,23]<stderr>:INFO:root:Total Training with validation: 1525.9919881820679 secs
[1,23]<stdout>:[1,26]<stderr>:INFO:root:Total Training with validation: 1525.9924111366272 secs
[1,26]<stdout>:[1,27]<stderr>:INFO:root:Total Training with validation: 1525.9935657978058 secs
[1,27]<stdout>:[1,28]<stderr>:INFO:root:Total Training with validation: 1525.9947018623352 secs
[1,28]<stdout>:[1,25]<stderr>:INFO:root:Total Training with validation: 1525.9960687160492 secs
[1,25]<stdout>:[1,29]<stderr>:INFO:root:Total Training with validation: 1525.9963867664337 secs
[1,30]<stderr>:INFO:root:Total Training with validation: 1525.9963808059692 secs
[1,29]<stdout>:[1,30]<stdout>:[1,31]<stderr>:INFO:root:Total Training with validation: 1525.9973487854004 secs
[1,31]<stdout>:[1,32]<stderr>:INFO:root:Total Training with validation: 1525.998527288437 secs
[1,32]<stdout>:[1,33]<stderr>:INFO:root:Total Training with validation: 1526.0000188350677 secs
[1,33]<stdout>:[1,34]<stderr>:INFO:root:Total Training with validation: 1526.0004017353058 secs
[1,34]<stdout>:[1,35]<stderr>:INFO:root:Total Training with validation: 1526.0015306472778 secs
[1,35]<stdout>:[1,36]<stderr>:INFO:root:Total Training with validation: 1526.00253033638 secs
[1,36]<stdout>:[1,37]<stderr>:INFO:root:Total Training with validation: 1526.003576040268 secs
[1,37]<stdout>:[1,38]<stderr>:INFO:root:Total Training with validation: 1526.0047433376312 secs
[1,38]<stdout>:[1,42]<stderr>:INFO:root:Total Training with validation: 1526.008275270462 secs
[1,42]<stdout>:[1,43]<stderr>:INFO:root:Total Training with validation: 1526.0091230869293 secs
[1,43]<stdout>:[1,39]<stderr>:INFO:root:Total Training with validation: 1526.0105862617493 secs
[1,44]<stderr>:INFO:root:Total Training with validation: 1526.0102672576904 secs
[1,39]<stdout>:[1,44]<stdout>:[1,45]<stderr>:INFO:root:Total Training with validation: 1526.011088848114 secs
[1,45]<stdout>:[1,40]<stderr>:INFO:root:Total Training with validation: 1526.0112414360046 secs
[1,40]<stdout>:[1,41]<stderr>:INFO:root:Total Training with validation: 1526.0116612911224 secs
[1,41]<stdout>:[1,46]<stderr>:INFO:root:Total Training with validation: 1526.0118973255157 secs
[1,46]<stdout>:[1,48]<stderr>:INFO:root:Total Training with validation: 1526.014675617218 secs
[1,48]<stdout>:[1,49]<stderr>:INFO:root:Total Training with validation: 1526.0155911445618 secs
[1,49]<stdout>:[1,50]<stderr>:INFO:root:Total Training with validation: 1526.0178484916687 secs
[1,50]<stdout>:[1,47]<stderr>:INFO:root:Total Training with validation: 1526.0183882713318 secs
[1,47]<stdout>:[1,52]<stderr>:INFO:root:Total Training with validation: 1526.0203974246979 secs
[1,53]<stderr>:INFO:root:Total Training with validation: 1526.0207450389862 secs
[1,52]<stdout>:[1,53]<stdout>:[1,54]<stderr>:INFO:root:Total Training with validation: 1526.0215311050415 secs
[1,54]<stdout>:[1,55]<stderr>:INFO:root:Total Training with validation: 1526.0228688716888 secs
[1,51]<stderr>:INFO:root:Total Training with validation: 1526.0229334831238 secs
[1,55]<stdout>:[1,51]<stdout>:[1,56]<stderr>:INFO:root:Total Training with validation: 1526.0246105194092 secs
[1,56]<stdout>:[1,57]<stderr>:INFO:root:Total Training with validation: 1526.0261270999908 secs
[1,57]<stdout>:[1,58]<stderr>:INFO:root:Total Training with validation: 1526.0275781154633 secs
[1,58]<stdout>:[1,59]<stderr>:INFO:root:Total Training with validation: 1526.029034614563 secs
[1,59]<stdout>:[1,62]<stderr>:INFO:root:Total Training with validation: 1526.0316236019135 secs
[1,62]<stdout>:[1,60]<stderr>:INFO:root:Total Training with validation: 1526.0344412326813 secs
[1,65]<stderr>:INFO:root:Total Training with validation: 1526.0341007709503 secs
[1,65]<stdout>:[1,60]<stdout>:[1,66]<stderr>:INFO:root:Total Training with validation: 1526.0352985858917 secs
[1,66]<stdout>:[1,61]<stderr>:INFO:root:Total Training with validation: 1526.0368392467499 secs
[1,61]<stdout>:[1,63]<stderr>:INFO:root:Total Training with validation: 1526.038167476654 secs
[1,63]<stdout>:[1,69]<stderr>:INFO:root:Total Training with validation: 1526.0386056900024 secs
[1,64]<stderr>:INFO:root:Total Training with validation: 1526.0387754440308 secs
[1,69]<stdout>:[1,64]<stdout>:[1,70]<stderr>:INFO:root:Total Training with validation: 1526.0394217967987 secs
[1,70]<stdout>:[1,67]<stderr>:INFO:root:Total Training with validation: 1526.0409090518951 secs
[1,67]<stdout>:[1,72]<stderr>:INFO:root:Total Training with validation: 1526.0412459373474 secs
[1,72]<stdout>:[1,75]<stderr>:INFO:root:Total Training with validation: 1526.0445375442505 secs
[1,75]<stdout>:[1,71]<stderr>:INFO:root:Total Training with validation: 1526.0447626113892 secs
[1,71]<stdout>:[1,76]<stderr>:INFO:root:Total Training with validation: 1526.0454316139221 secs
[1,68]<stderr>:INFO:root:Total Training with validation: 1526.0453624725342 secs
[1,76]<stdout>:[1,68]<stdout>:[1,73]<stderr>:INFO:root:Total Training with validation: 1526.0479445457458 secs
[1,73]<stdout>:[1,74]<stderr>:INFO:root:Total Training with validation: 1526.0488686561584 secs
[1,74]<stdout>:[1,77]<stderr>:INFO:root:Total Training with validation: 1526.0500056743622 secs
[1,77]<stdout>:[1,81]<stderr>:INFO:root:Total Training with validation: 1526.051662683487 secs
[1,81]<stdout>:[1,78]<stderr>:INFO:root:Total Training with validation: 1526.0528545379639 secs
[1,78]<stdout>:[1,82]<stderr>:INFO:root:Total Training with validation: 1526.053659439087 secs
[1,82]<stdout>:[1,83]<stderr>:INFO:root:Total Training with validation: 1526.0543043613434 secs
[1,79]<stderr>:INFO:root:Total Training with validation: 1526.054547548294 secs
[1,83]<stdout>:[1,79]<stdout>:[1,84]<stderr>:INFO:root:Total Training with validation: 1526.055468082428 secs
[1,80]<stderr>:INFO:root:Total Training with validation: 1526.0558576583862 secs
[1,84]<stdout>:[1,80]<stdout>:[1,85]<stderr>:INFO:root:Total Training with validation: 1526.0563960075378 secs
[1,85]<stdout>:[1,87]<stderr>:INFO:root:Total Training with validation: 1526.0588898658752 secs
[1,87]<stdout>:[1,88]<stderr>:INFO:root:Total Training with validation: 1526.059419631958 secs
[1,88]<stdout>:[1,89]<stderr>:INFO:root:Total Training with validation: 1526.060911655426 secs
[1,89]<stdout>:[1,86]<stderr>:INFO:root:Total Training with validation: 1526.0621175765991 secs
[1,86]<stdout>:[1,91]<stderr>:INFO:root:Total Training with validation: 1526.063466310501 secs
[1,91]<stdout>:[1,93]<stderr>:INFO:root:Total Training with validation: 1526.0651030540466 secs
[1,93]<stdout>:[1,94]<stderr>:INFO:root:Total Training with validation: 1526.06605219841 secs
[1,90]<stderr>:INFO:root:Total Training with validation: 1526.0661437511444 secs
[1,90]<stdout>:[1,94]<stdout>:[1,95]<stderr>:INFO:root:Total Training with validation: 1526.067899465561 secs
[1,95]<stdout>:[1,96]<stderr>:INFO:root:Total Training with validation: 1526.0679042339325 secs
[1,96]<stdout>:[1,92]<stderr>:INFO:root:Total Training with validation: 1526.0691063404083 secs
[1,97]<stderr>:INFO:root:Total Training with validation: 1526.069350719452 secs
[1,92]<stdout>:[1,97]<stdout>:[1,99]<stderr>:INFO:root:Total Training with validation: 1526.0709648132324 secs
[1,99]<stdout>:[1,101]<stderr>:INFO:root:Total Training with validation: 1526.0729055404663 secs
[1,101]<stdout>:[1,102]<stderr>:INFO:root:Total Training with validation: 1526.0739986896515 secs
[1,98]<stderr>:INFO:root:Total Training with validation: 1526.0751581192017 secs
[1,102]<stdout>:[1,98]<stdout>:[1,104]<stderr>:INFO:root:Total Training with validation: 1526.0764927864075 secs
[1,104]<stdout>:[1,100]<stderr>:INFO:root:Total Training with validation: 1526.0778696537018 secs
[1,100]<stdout>:[1,106]<stderr>:INFO:root:Total Training with validation: 1526.079426765442 secs
[1,107]<stderr>:INFO:root:Total Training with validation: 1526.079440355301 secs
[1,107]<stdout>:[1,106]<stdout>:[1,105]<stderr>:INFO:root:Total Training with validation: 1526.0813083648682 secs
[1,105]<stdout>:[1,103]<stderr>:INFO:root:Total Training with validation: 1526.0817122459412 secs
[1,103]<stdout>:[1,110]<stderr>:INFO:root:Total Training with validation: 1526.0829775333405 secs
[1,110]<stdout>:[1,111]<stderr>:INFO:root:Total Training with validation: 1526.0847074985504 secs
[1,111]<stdout>:[1,108]<stderr>:INFO:root:Total Training with validation: 1526.0856812000275 secs
[1,112]<stderr>:INFO:root:Total Training with validation: 1526.0856149196625 secs
[1,108]<stdout>:[1,112]<stdout>:[1,109]<stderr>:INFO:root:Total Training with validation: 1526.0868141651154 secs
[1,109]<stdout>:[1,113]<stderr>:INFO:root:Total Training with validation: 1526.0873019695282 secs
[1,113]<stdout>:[1,115]<stderr>:INFO:root:Total Training with validation: 1526.0898311138153 secs
[1,115]<stdout>:[1,114]<stderr>:INFO:root:Total Training with validation: 1526.0919954776764 secs
[1,118]<stderr>:INFO:root:Total Training with validation: 1526.092069864273 secs
[1,117]<stderr>:INFO:root:Total Training with validation: 1526.0922303199768 secs
[1,118]<stdout>:[1,114]<stdout>:[1,117]<stdout>:[1,119]<stderr>:INFO:root:Total Training with validation: 1526.0939707756042 secs
[1,119]<stdout>:[1,120]<stderr>:INFO:root:Total Training with validation: 1526.0951120853424 secs
[1,116]<stderr>:INFO:root:Total Training with validation: 1526.0957758426666 secs
[1,120]<stdout>:[1,116]<stdout>:[1,123]<stderr>:INFO:root:Total Training with validation: 1526.0977292060852 secs
[1,122]<stderr>:INFO:root:Total Training with validation: 1526.0977792739868 secs
[1,123]<stdout>:[1,122]<stdout>:[1,121]<stderr>:INFO:root:Total Training with validation: 1526.0998075008392 secs
[1,121]<stdout>:[1,125]<stderr>:INFO:root:Total Training with validation: 1526.1001098155975 secs
[1,124]<stderr>:INFO:root:Total Training with validation: 1526.1002924442291 secs
[1,125]<stdout>:[1,124]<stdout>:[1,126]<stderr>:INFO:root:Total Training with validation: 1526.1007902622223 secs
[1,126]<stdout>:[1,128]<stderr>:INFO:root:Total Training with validation: 1526.104041814804 secs
[1,128]<stdout>:[1,129]<stderr>:INFO:root:Total Training with validation: 1526.1045758724213 secs
[1,129]<stdout>:[1,130]<stderr>:INFO:root:Total Training with validation: 1526.1054227352142 secs
[1,130]<stdout>:[1,131]<stderr>:INFO:root:Total Training with validation: 1526.1061754226685 secs
[1,127]<stderr>:INFO:root:Total Training with validation: 1526.1058456897736 secs
[1,127]<stdout>:[1,131]<stdout>:[1,132]<stderr>:INFO:root:Total Training with validation: 1526.107436656952 secs
[1,132]<stdout>:[1,133]<stderr>:INFO:root:Total Training with validation: 1526.108694076538 secs
[1,133]<stdout>:[1,134]<stderr>:INFO:root:Total Training with validation: 1526.1102502346039 secs
[1,134]<stdout>:[1,136]<stderr>:INFO:root:Total Training with validation: 1526.1117985248566 secs
[1,136]<stdout>:[1,137]<stderr>:INFO:root:Total Training with validation: 1526.1131381988525 secs
[1,137]<stdout>:[1,138]<stderr>:INFO:root:Total Training with validation: 1526.1138045787811 secs
[1,138]<stdout>:[1,139]<stderr>:INFO:root:Total Training with validation: 1526.1152794361115 secs
[1,139]<stdout>:[1,135]<stderr>:INFO:root:Total Training with validation: 1526.1159818172455 secs
[1,135]<stdout>:[1,143]<stderr>:INFO:root:Total Training with validation: 1526.1203734874725 secs
[1,144]<stderr>:INFO:root:Total Training with validation: 1526.1200709342957 secs
[1,143]<stdout>:[1,144]<stdout>:[1,145]<stderr>:INFO:root:Total Training with validation: 1526.120943069458 secs
[1,145]<stdout>:[1,140]<stderr>:INFO:root:Total Training with validation: 1526.1217002868652 secs
[1,140]<stdout>:[1,141]<stderr>:INFO:root:Total Training with validation: 1526.122174501419 secs
[1,141]<stdout>:[1,147]<stderr>:INFO:root:Total Training with validation: 1526.1227660179138 secs
[1,147]<stdout>:[1,148]<stderr>:INFO:root:Total Training with validation: 1526.1240005493164 secs
[1,142]<stderr>:INFO:root:Total Training with validation: 1526.1245188713074 secs
[1,148]<stdout>:[1,142]<stdout>:[1,150]<stderr>:INFO:root:Total Training with validation: 1526.1259880065918 secs
[1,150]<stdout>:[1,146]<stderr>:INFO:root:Total Training with validation: 1526.1268224716187 secs
[1,146]<stdout>:[1,151]<stderr>:INFO:root:Total Training with validation: 1526.1274111270905 secs
[1,151]<stdout>:[1,149]<stderr>:INFO:root:Total Training with validation: 1526.128146648407 secs
[1,152]<stderr>:INFO:root:Total Training with validation: 1526.128249168396 secs
[1,149]<stdout>:[1,152]<stdout>:[1,153]<stderr>:INFO:root:Total Training with validation: 1526.130027770996 secs
[1,153]<stdout>:[1,156]<stderr>:INFO:root:Total Training with validation: 1526.1326565742493 secs
[1,156]<stdout>:[1,157]<stderr>:INFO:root:Total Training with validation: 1526.1336483955383 secs
[1,157]<stdout>:[1,154]<stderr>:INFO:root:Total Training with validation: 1526.1344599723816 secs
[1,154]<stdout>:[1,159]<stderr>:INFO:root:Total Training with validation: 1526.1365506649017 secs
[1,159]<stdout>:[1,160]<stderr>:INFO:root:Total Training with validation: 1526.1366465091705 secs
[1,160]<stdout>:[1,155]<stderr>:INFO:root:Total Training with validation: 1526.1372804641724 secs
[1,155]<stdout>:[1,158]<stderr>:INFO:root:Total Training with validation: 1526.139034986496 secs
[1,158]<stdout>:[1,163]<stderr>:INFO:root:Total Training with validation: 1526.1403567790985 secs
[1,163]<stdout>:[1,165]<stderr>:INFO:root:Total Training with validation: 1526.1422581672668 secs
[1,165]<stdout>:[1,161]<stderr>:INFO:root:Total Training with validation: 1526.1429600715637 secs
[1,161]<stdout>:[1,167]<stderr>:INFO:root:Total Training with validation: 1526.1436924934387 secs
[1,167]<stdout>:[1,162]<stderr>:INFO:root:Total Training with validation: 1526.1443965435028 secs
[1,162]<stdout>:[1,164]<stderr>:INFO:root:Total Training with validation: 1526.145173549652 secs
[1,164]<stdout>:[1,168]<stderr>:INFO:root:Total Training with validation: 1526.1452350616455 secs
[1,168]<stdout>:[1,170]<stderr>:INFO:root:Total Training with validation: 1526.1470096111298 secs
[1,170]<stdout>:[1,169]<stderr>:INFO:root:Total Training with validation: 1526.1473503112793 secs
[1,169]<stdout>:[1,171]<stderr>:INFO:root:Total Training with validation: 1526.1477272510529 secs
[1,171]<stdout>:[1,166]<stderr>:INFO:root:Total Training with validation: 1526.1484570503235 secs
[1,166]<stdout>:[1,172]<stderr>:INFO:root:Total Training with validation: 1526.1497478485107 secs
[1,172]<stdout>:[1,173]<stderr>:INFO:root:Total Training with validation: 1526.1503784656525 secs
[1,173]<stdout>:[1,174]<stderr>:INFO:root:Total Training with validation: 1526.1512763500214 secs
[1,174]<stdout>:[1,175]<stderr>:INFO:root:Total Training with validation: 1526.1527717113495 secs
[1,175]<stdout>:[1,177]<stderr>:INFO:root:Total Training with validation: 1526.1552362442017 secs
[1,177]<stdout>:[1,178]<stderr>:INFO:root:Total Training with validation: 1526.1564655303955 secs
[1,178]<stdout>:[1,179]<stderr>:INFO:root:Total Training with validation: 1526.157345533371 secs
[1,179]<stdout>:[1,180]<stderr>:INFO:root:Total Training with validation: 1526.1583585739136 secs
[1,180]<stdout>:[1,176]<stderr>:INFO:root:Total Training with validation: 1526.1588377952576 secs
[1,176]<stdout>:[1,181]<stderr>:INFO:root:Total Training with validation: 1526.1595158576965 secs
[1,181]<stdout>:[1,182]<stderr>:INFO:root:Total Training with validation: 1526.1606690883636 secs
[1,182]<stdout>:[1,183]<stderr>:INFO:root:Total Training with validation: 1526.1618270874023 secs
[1,183]<stdout>:[1,184]<stderr>:INFO:root:Total Training with validation: 1526.1625354290009 secs
[1,184]<stdout>:[1,185]<stderr>:INFO:root:Total Training with validation: 1526.1641931533813 secs
[1,185]<stdout>:[1,186]<stderr>:INFO:root:Total Training with validation: 1526.1652381420135 secs
[1,186]<stdout>:[1,187]<stderr>:INFO:root:Total Training with validation: 1526.1664023399353 secs
[1,187]<stdout>:[1,188]<stderr>:INFO:root:Total Training with validation: 1526.1679396629333 secs
[1,188]<stdout>:[1,189]<stderr>:INFO:root:Total Training with validation: 1526.168489933014 secs
[1,189]<stdout>:[1,190]<stderr>:INFO:root:Total Training with validation: 1526.1702077388763 secs
[1,190]<stdout>:[1,191]<stderr>:INFO:root:Total Training with validation: 1526.1716237068176 secs
[1,191]<stdout>:[1,0]<stderr>:INFO:root:[Epoch 11] Validation Inference cost: 8.104
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stderr>:INFO:root:[Epoch 11] Saving parameters to mask_rcnn_fpn_resnet50_v1b_coco_0011_0.0000.params
[1,0]<stdout>:DONE (t=0.73s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *bbox*
[1,0]<stdout>:DONE (t=3.49s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stdout>:creating index...
[1,0]<stdout>:GT annotations already exist!
[1,0]<stdout>:Loading and preparing results...
[1,0]<stdout>:DONE (t=4.06s)
[1,0]<stdout>:Running per image evaluation...
[1,0]<stdout>:Evaluate annotation type *segm*
[1,0]<stdout>:DONE (t=5.57s).
[1,0]<stdout>:Accumulating evaluation results...
[1,0]<stdout>:DONE (t=0.00s).
[1,0]<stderr>:INFO:root:[Epoch 11] Validation:
[1,0]<stderr>:~~~~ Summary bbox metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.37689
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.59955
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.40910
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.23123
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.41465
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.47745
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.31573
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.51629
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.55376
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.39634
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.58749
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.66899
[1,0]<stderr>:~~~~ Mean AP for bbox ~~~~
[1,0]<stderr>:=37.7
[1,0]<stderr>:~~~~ Summary segm metrics ~~~~
[1,0]<stderr>:=Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.34187
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.56146
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.36022
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.16545
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.37213
[1,0]<stderr>: Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.49643
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.29727
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.47336
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.50435
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.33288
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.54123
[1,0]<stderr>: Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.64552
[1,0]<stderr>:~~~~ Mean AP for segm ~~~~
[1,0]<stderr>:=34.2
[1,0]<stderr>:INFO:root:Total Training with validation: 1543.1355950832367 secs
