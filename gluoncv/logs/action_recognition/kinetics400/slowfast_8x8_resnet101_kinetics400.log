Namespace(accumulate=1, batch_norm=False, batch_size=7, clip_grad=0, crop_ratio=0.875, data_dir='/home/ubuntu/yizhu/data/kinetics400/kinetics400/train_256', dataset='kinetics400', dtype='float32', eval=False, fast_temporal_stride=2, freeze_bn=False, hard_weight=0.5, hashtag='', input_5d=False, input_size=224, kvstore='dist_sync_device', label_smoothing=False, last_gamma=False, log_interval=50, logging_file='slowfast_8x8_res101_seg1_k400_b7_g8_f64s1_cosine_dist_warm34_warmlr01_lr6_epoch196_v3.txt', lr=0.6, lr_decay=0.1, lr_decay_epoch='40,60', lr_decay_period=0, lr_mode='cosine', mixup=False, mixup_alpha=0.2, mixup_off_epoch=0, mode='hybrid', model='slowfast_8x8_resnet101_kinetics400', momentum=0.9, new_height=256, new_length=64, new_step=1, new_width=340, no_wd=False, num_classes=400, num_crop=1, num_epochs=196, num_gpus=8, num_segments=1, num_workers=16, partial_bn=False, prefetch_ratio=1.0, resume_epoch=0, resume_params='', resume_states='', save_dir='/home/ubuntu/yizhu/logs/mxnet/kinetics400/slowfast/slowfast_8x8_res101_seg1_k400_b7_g8_f64s1_cosine_dist_warm34_warmlr01_lr6_epoch196_v3', save_frequency=20, scale_ratios='1.0,0.8', slow_temporal_stride=8, slowfast=True, teacher=None, temperature=20, train_list='/home/ubuntu/yizhu/data/kinetics400/kinetics400/k400_train_240618.txt', use_amp=False, use_decord=True, use_gn=False, use_pretrained=False, use_se=False, use_tsn=False, val_data_dir='/home/ubuntu/yizhu/data/kinetics400/kinetics400/val_256', val_list='/home/ubuntu/yizhu/code/gluon-cv/extra/kinetics400/k400_val_19761_cleanv3.txt', video_loader=True, warmup_epochs=34, warmup_lr=0.01, wd=0.0001)
Namespace(accumulate=1, batch_norm=False, batch_size=7, clip_grad=0, crop_ratio=0.875, data_dir='/home/ubuntu/yizhu/data/kinetics400/kinetics400/train_256', dataset='kinetics400', dtype='float32', eval=False, fast_temporal_stride=2, freeze_bn=False, hard_weight=0.5, hashtag='', input_5d=False, input_size=224, kvstore='dist_sync_device', label_smoothing=False, last_gamma=False, log_interval=50, logging_file='slowfast_8x8_res101_seg1_k400_b7_g8_f64s1_cosine_dist_warm34_warmlr01_lr6_epoch196_v3.txt', lr=0.6, lr_decay=0.1, lr_decay_epoch='40,60', lr_decay_period=0, lr_mode='cosine', mixup=False, mixup_alpha=0.2, mixup_off_epoch=0, mode='hybrid', model='slowfast_8x8_resnet101_kinetics400', momentum=0.9, new_height=256, new_length=64, new_step=1, new_width=340, no_wd=False, num_classes=400, num_crop=1, num_epochs=196, num_gpus=8, num_segments=1, num_workers=16, partial_bn=False, prefetch_ratio=1.0, resume_epoch=0, resume_params='', resume_states='', save_dir='/home/ubuntu/yizhu/logs/mxnet/kinetics400/slowfast/slowfast_8x8_res101_seg1_k400_b7_g8_f64s1_cosine_dist_warm34_warmlr01_lr6_epoch196_v3', save_frequency=20, scale_ratios='1.0,0.8', slow_temporal_stride=8, slowfast=True, teacher=None, temperature=20, train_list='/home/ubuntu/yizhu/data/kinetics400/kinetics400/k400_train_240618.txt', use_amp=False, use_decord=True, use_gn=False, use_pretrained=False, use_se=False, use_tsn=False, val_data_dir='/home/ubuntu/yizhu/data/kinetics400/kinetics400/val_256', val_list='/home/ubuntu/yizhu/code/gluon-cv/extra/kinetics400/k400_val_19761_cleanv3.txt', video_loader=True, warmup_epochs=34, warmup_lr=0.01, wd=0.0001)
Distributed training with 6 workers and current rank is 2
Total batch size is set to 56 on 8 GPUs
SlowFast(
  (fast_conv1): Conv3D(3 -> 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)
  (fast_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
  (fast_relu): Activation(relu)
  (fast_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)
  (fast_res2): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(8 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(32 -> 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
      (conv2): Conv3D(8 -> 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=8)
      (conv3): Conv3D(8 -> 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (relu): Activation(relu)
    )
  )
  (fast_res3): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(32 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(32 -> 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (relu): Activation(relu)
    )
    (3): Bottleneck(
      (conv1): Conv3D(64 -> 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv2): Conv3D(16 -> 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
      (conv3): Conv3D(16 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (relu): Activation(relu)
    )
  )
  (fast_res4): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(64 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(64 -> 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (3): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (4): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (5): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (6): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (7): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (8): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (9): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (10): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (11): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (12): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (13): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (14): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (15): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (16): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (17): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (18): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (19): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (20): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (21): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
    (22): Bottleneck(
      (conv1): Conv3D(128 -> 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv2): Conv3D(32 -> 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=32)
      (conv3): Conv3D(32 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (relu): Activation(relu)
    )
  )
  (fast_res5): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(128 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(128 -> 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(256 -> 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (relu): Activation(relu)
    )
  )
  (lateral_p1): HybridSequential(
    (0): Conv3D(8 -> 16, kernel_size=(5, 1, 1), stride=(4, 1, 1), padding=(2, 0, 0), bias=False)
    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=16)
    (2): Activation(relu)
  )
  (lateral_res2): HybridSequential(
    (0): Conv3D(32 -> 64, kernel_size=(5, 1, 1), stride=(4, 1, 1), padding=(2, 0, 0), bias=False)
    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
    (2): Activation(relu)
  )
  (lateral_res3): HybridSequential(
    (0): Conv3D(64 -> 128, kernel_size=(5, 1, 1), stride=(4, 1, 1), padding=(2, 0, 0), bias=False)
    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
    (2): Activation(relu)
  )
  (lateral_res4): HybridSequential(
    (0): Conv3D(128 -> 256, kernel_size=(5, 1, 1), stride=(4, 1, 1), padding=(2, 0, 0), bias=False)
    (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
    (2): Activation(relu)
  )
  (slow_conv1): Conv3D(3 -> 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)
  (slow_bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
  (slow_relu): Activation(relu)
  (slow_maxpool): MaxPool3D(size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), ceil_mode=False, global_pool=False, pool_type=max, layout=NCDHW)
  (slow_res2): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(80 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(80 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(256 -> 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv2): Conv3D(64 -> 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)
      (conv3): Conv3D(64 -> 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (relu): Activation(relu)
    )
  )
  (slow_res3): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(320 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(320 -> 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (relu): Activation(relu)
    )
    (3): Bottleneck(
      (conv1): Conv3D(512 -> 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv2): Conv3D(128 -> 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)
      (conv3): Conv3D(128 -> 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (relu): Activation(relu)
    )
  )
  (slow_res4): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(640 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(640 -> 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (3): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (4): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (5): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (6): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (7): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (8): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (9): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (10): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (11): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (12): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (13): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (14): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (15): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (16): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (17): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (18): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (19): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (20): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (21): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
    (22): Bottleneck(
      (conv1): Conv3D(1024 -> 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv2): Conv3D(256 -> 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)
      (conv3): Conv3D(256 -> 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)
      (relu): Activation(relu)
    )
  )
  (slow_res5): HybridSequential(
    (0): Bottleneck(
      (conv1): Conv3D(1280 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)
      (relu): Activation(relu)
      (downsample): HybridSequential(
        (0): Conv3D(1280 -> 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)
        (1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)
      )
    )
    (1): Bottleneck(
      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)
      (relu): Activation(relu)
    )
    (2): Bottleneck(
      (conv1): Conv3D(2048 -> 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)
      (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (conv2): Conv3D(512 -> 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)
      (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)
      (conv3): Conv3D(512 -> 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
      (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)
      (relu): Activation(relu)
    )
  )
  (avg): GlobalAvgPool3D(size=(1, 1, 1), stride=(1, 1, 1), padding=(0, 0, 0), ceil_mode=True, global_pool=True, pool_type=avg, layout=NCDHW)
  (dp): Dropout(p = 0.5, axes=())
  (fc): Dense(2304 -> 400, linear)
)
Load 240618 training samples and 19404 validation samples.
Epoch[000] Batch [0049]/[0716]	Speed: 18.192996 samples/sec	 accuracy=1.000000	 loss=5.929306	 lr=0.011212
Epoch[000] Batch [0099]/[0716]	Speed: 25.178082 samples/sec	 accuracy=1.000000	 loss=5.874285	 lr=0.012424
Epoch[000] Batch [0149]/[0716]	Speed: 25.388983 samples/sec	 accuracy=1.250000	 loss=5.815254	 lr=0.013636
Epoch[000] Batch [0199]/[0716]	Speed: 25.609997 samples/sec	 accuracy=1.437500	 loss=5.774211	 lr=0.014847
Epoch[000] Batch [0249]/[0716]	Speed: 25.463264 samples/sec	 accuracy=1.735714	 loss=5.737050	 lr=0.016059
Epoch[000] Batch [0299]/[0716]	Speed: 25.314117 samples/sec	 accuracy=1.821429	 loss=5.705742	 lr=0.017271
Epoch[000] Batch [0349]/[0716]	Speed: 25.075982 samples/sec	 accuracy=2.000000	 loss=5.679431	 lr=0.018483
Epoch[000] Batch [0399]/[0716]	Speed: 25.199615 samples/sec	 accuracy=2.120536	 loss=5.661259	 lr=0.019695
Epoch[000] Batch [0449]/[0716]	Speed: 25.130675 samples/sec	 accuracy=2.230159	 loss=5.643740	 lr=0.020907
Epoch[000] Batch [0499]/[0716]	Speed: 25.422425 samples/sec	 accuracy=2.400000	 loss=5.621626	 lr=0.022118
Epoch[000] Batch [0549]/[0716]	Speed: 25.387999 samples/sec	 accuracy=2.444805	 loss=5.603249	 lr=0.023330
Epoch[000] Batch [0599]/[0716]	Speed: 25.718594 samples/sec	 accuracy=2.535714	 loss=5.586903	 lr=0.024542
Epoch[000] Batch [0649]/[0716]	Speed: 25.386988 samples/sec	 accuracy=2.593407	 loss=5.570416	 lr=0.025754
Epoch[000] Batch [0699]/[0716]	Speed: 25.095606 samples/sec	 accuracy=2.619898	 loss=5.557475	 lr=0.026966
Batch [0049]/[0057]: acc-top1=3.571429 acc-top5=12.178571
[Epoch 000] training: accuracy=2.631185	 loss=5.553529
[Epoch 000] speed: 24 samples/sec	time cost: 1681.432719
[Epoch 000] validation: acc-top1=3.743735 acc-top5=11.936090 loss=5.410374
Epoch[001] Batch [0049]/[0716]	Speed: 21.590801 samples/sec	 accuracy=4.071429	 loss=5.336989	 lr=0.028566
Epoch[001] Batch [0099]/[0716]	Speed: 25.463224 samples/sec	 accuracy=4.375000	 loss=5.314481	 lr=0.029777
Epoch[001] Batch [0149]/[0716]	Speed: 25.342243 samples/sec	 accuracy=4.321429	 loss=5.312248	 lr=0.030989
Epoch[001] Batch [0199]/[0716]	Speed: 25.188949 samples/sec	 accuracy=4.250000	 loss=5.304545	 lr=0.032201
Epoch[001] Batch [0249]/[0716]	Speed: 25.366987 samples/sec	 accuracy=4.321429	 loss=5.295242	 lr=0.033413
Epoch[001] Batch [0299]/[0716]	Speed: 25.352023 samples/sec	 accuracy=4.315476	 loss=5.289049	 lr=0.034625
Epoch[001] Batch [0349]/[0716]	Speed: 25.496108 samples/sec	 accuracy=4.357143	 loss=5.282410	 lr=0.035837
Epoch[001] Batch [0399]/[0716]	Speed: 25.238318 samples/sec	 accuracy=4.464286	 loss=5.269750	 lr=0.037048
Epoch[001] Batch [0449]/[0716]	Speed: 25.596349 samples/sec	 accuracy=4.575397	 loss=5.254392	 lr=0.038260
Epoch[001] Batch [0499]/[0716]	Speed: 25.677754 samples/sec	 accuracy=4.621429	 loss=5.247899	 lr=0.039472
Epoch[001] Batch [0549]/[0716]	Speed: 25.326430 samples/sec	 accuracy=4.685065	 loss=5.238433	 lr=0.040684
Epoch[001] Batch [0599]/[0716]	Speed: 25.558235 samples/sec	 accuracy=4.723214	 loss=5.230003	 lr=0.041896
Epoch[001] Batch [0649]/[0716]	Speed: 25.509938 samples/sec	 accuracy=4.747253	 loss=5.220930	 lr=0.043108
Epoch[001] Batch [0699]/[0716]	Speed: 25.381683 samples/sec	 accuracy=4.790816	 loss=5.213997	 lr=0.044320
Batch [0049]/[0057]: acc-top1=5.892857 acc-top5=15.678571
[Epoch 001] training: accuracy=4.813448	 loss=5.212441
[Epoch 001] speed: 25 samples/sec	time cost: 1653.468039
[Epoch 001] validation: acc-top1=5.482456 acc-top5=15.935673 loss=5.214703
Epoch[002] Batch [0049]/[0716]	Speed: 22.083799 samples/sec	 accuracy=6.464286	 loss=5.062379	 lr=0.045919
Epoch[002] Batch [0099]/[0716]	Speed: 25.466727 samples/sec	 accuracy=6.446429	 loss=5.046374	 lr=0.047131
Epoch[002] Batch [0149]/[0716]	Speed: 25.797811 samples/sec	 accuracy=6.345238	 loss=5.043450	 lr=0.048343
Epoch[002] Batch [0199]/[0716]	Speed: 25.406439 samples/sec	 accuracy=6.410714	 loss=5.037961	 lr=0.049555
Epoch[002] Batch [0249]/[0716]	Speed: 25.533665 samples/sec	 accuracy=6.507143	 loss=5.023712	 lr=0.050767
Epoch[002] Batch [0299]/[0716]	Speed: 25.364354 samples/sec	 accuracy=6.339286	 loss=5.027617	 lr=0.051978
Epoch[002] Batch [0349]/[0716]	Speed: 25.069410 samples/sec	 accuracy=6.357143	 loss=5.029702	 lr=0.053190
Epoch[002] Batch [0399]/[0716]	Speed: 25.763593 samples/sec	 accuracy=6.312500	 loss=5.025115	 lr=0.054402
Epoch[002] Batch [0449]/[0716]	Speed: 25.586605 samples/sec	 accuracy=6.257937	 loss=5.019495	 lr=0.055614
Epoch[002] Batch [0499]/[0716]	Speed: 25.400574 samples/sec	 accuracy=6.257143	 loss=5.014404	 lr=0.056826
Epoch[002] Batch [0549]/[0716]	Speed: 25.292527 samples/sec	 accuracy=6.340909	 loss=5.004546	 lr=0.058038
Epoch[002] Batch [0599]/[0716]	Speed: 25.202369 samples/sec	 accuracy=6.464286	 loss=4.996751	 lr=0.059249
Epoch[002] Batch [0649]/[0716]	Speed: 25.385984 samples/sec	 accuracy=6.497253	 loss=4.992732	 lr=0.060461
Epoch[002] Batch [0699]/[0716]	Speed: 25.602688 samples/sec	 accuracy=6.471939	 loss=4.987129	 lr=0.061673
Batch [0049]/[0057]: acc-top1=7.464286 acc-top5=19.928571
[Epoch 002] training: accuracy=6.457003	 loss=4.987529
[Epoch 002] speed: 25 samples/sec	time cost: 1647.380952
[Epoch 002] validation: acc-top1=7.309941 acc-top5=20.499165 loss=4.995237
Epoch[003] Batch [0049]/[0716]	Speed: 22.814360 samples/sec	 accuracy=6.928571	 loss=4.876801	 lr=0.063273
Epoch[003] Batch [0099]/[0716]	Speed: 25.033905 samples/sec	 accuracy=7.392857	 loss=4.860469	 lr=0.064485
Epoch[003] Batch [0149]/[0716]	Speed: 25.260896 samples/sec	 accuracy=7.440476	 loss=4.847786	 lr=0.065697
Epoch[003] Batch [0199]/[0716]	Speed: 25.519389 samples/sec	 accuracy=7.517857	 loss=4.838858	 lr=0.066908
Epoch[003] Batch [0249]/[0716]	Speed: 25.600728 samples/sec	 accuracy=7.442857	 loss=4.839186	 lr=0.068120
Epoch[003] Batch [0299]/[0716]	Speed: 25.408798 samples/sec	 accuracy=7.559524	 loss=4.828016	 lr=0.069332
Epoch[003] Batch [0349]/[0716]	Speed: 25.103674 samples/sec	 accuracy=7.734694	 loss=4.813301	 lr=0.070544
Epoch[003] Batch [0399]/[0716]	Speed: 25.594130 samples/sec	 accuracy=7.892857	 loss=4.806425	 lr=0.071756
Epoch[003] Batch [0449]/[0716]	Speed: 25.339359 samples/sec	 accuracy=8.083333	 loss=4.797949	 lr=0.072968
Epoch[003] Batch [0499]/[0716]	Speed: 25.079236 samples/sec	 accuracy=8.032143	 loss=4.794490	 lr=0.074179
Epoch[003] Batch [0549]/[0716]	Speed: 25.548007 samples/sec	 accuracy=8.042208	 loss=4.785177	 lr=0.075391
Epoch[003] Batch [0599]/[0716]	Speed: 25.231202 samples/sec	 accuracy=8.136905	 loss=4.780279	 lr=0.076603
Epoch[003] Batch [0649]/[0716]	Speed: 25.652970 samples/sec	 accuracy=8.225275	 loss=4.774279	 lr=0.077815
Epoch[003] Batch [0699]/[0716]	Speed: 25.971702 samples/sec	 accuracy=8.303571	 loss=4.767600	 lr=0.079027
Batch [0049]/[0057]: acc-top1=9.750000 acc-top5=25.214286
[Epoch 003] training: accuracy=8.364924	 loss=4.762592
[Epoch 003] speed: 25 samples/sec	time cost: 1645.178684
[Epoch 003] validation: acc-top1=9.497702 acc-top5=25.736216 loss=4.693472
Epoch[004] Batch [0049]/[0716]	Speed: 22.644721 samples/sec	 accuracy=9.464286	 loss=4.666607	 lr=0.080626
Epoch[004] Batch [0099]/[0716]	Speed: 25.467345 samples/sec	 accuracy=9.232143	 loss=4.615948	 lr=0.081838
Epoch[004] Batch [0149]/[0716]	Speed: 25.772744 samples/sec	 accuracy=9.702381	 loss=4.600458	 lr=0.083050
Epoch[004] Batch [0199]/[0716]	Speed: 25.741605 samples/sec	 accuracy=9.758929	 loss=4.591451	 lr=0.084262
Epoch[004] Batch [0249]/[0716]	Speed: 24.841980 samples/sec	 accuracy=9.964286	 loss=4.587002	 lr=0.085474
Epoch[004] Batch [0299]/[0716]	Speed: 25.757268 samples/sec	 accuracy=10.053571	 loss=4.575102	 lr=0.086686
Epoch[004] Batch [0349]/[0716]	Speed: 25.812683 samples/sec	 accuracy=10.153061	 loss=4.567427	 lr=0.087898
Epoch[004] Batch [0399]/[0716]	Speed: 25.642714 samples/sec	 accuracy=10.294643	 loss=4.557764	 lr=0.089109
Epoch[004] Batch [0449]/[0716]	Speed: 25.962219 samples/sec	 accuracy=10.325397	 loss=4.552191	 lr=0.090321
Epoch[004] Batch [0499]/[0716]	Speed: 25.200060 samples/sec	 accuracy=10.385714	 loss=4.545839	 lr=0.091533
Epoch[004] Batch [0549]/[0716]	Speed: 25.756303 samples/sec	 accuracy=10.431818	 loss=4.539605	 lr=0.092745
Epoch[004] Batch [0599]/[0716]	Speed: 25.673883 samples/sec	 accuracy=10.470238	 loss=4.533823	 lr=0.093957
Epoch[004] Batch [0649]/[0716]	Speed: 25.145778 samples/sec	 accuracy=10.563187	 loss=4.530247	 lr=0.095169
Epoch[004] Batch [0699]/[0716]	Speed: 25.694078 samples/sec	 accuracy=10.647959	 loss=4.520550	 lr=0.096380
Batch [0049]/[0057]: acc-top1=11.607143 acc-top5=28.464286
[Epoch 004] training: accuracy=10.651935	 loss=4.519814
[Epoch 004] speed: 25 samples/sec	time cost: 1638.815001
[Epoch 004] validation: acc-top1=10.886592 acc-top5=27.809105 loss=4.741601
Epoch[005] Batch [0049]/[0716]	Speed: 22.665623 samples/sec	 accuracy=12.500000	 loss=4.359538	 lr=0.097980
Epoch[005] Batch [0099]/[0716]	Speed: 25.533533 samples/sec	 accuracy=12.178571	 loss=4.355087	 lr=0.099192
Epoch[005] Batch [0149]/[0716]	Speed: 25.450372 samples/sec	 accuracy=12.166667	 loss=4.363197	 lr=0.100404
Epoch[005] Batch [0199]/[0716]	Speed: 25.653606 samples/sec	 accuracy=12.696429	 loss=4.354520	 lr=0.101616
Epoch[005] Batch [0249]/[0716]	Speed: 25.337340 samples/sec	 accuracy=12.835714	 loss=4.346925	 lr=0.102828
Epoch[005] Batch [0299]/[0716]	Speed: 25.867535 samples/sec	 accuracy=13.000000	 loss=4.337735	 lr=0.104039
Epoch[005] Batch [0349]/[0716]	Speed: 25.649217 samples/sec	 accuracy=13.153061	 loss=4.327144	 lr=0.105251
Epoch[005] Batch [0399]/[0716]	Speed: 25.820197 samples/sec	 accuracy=13.200893	 loss=4.316008	 lr=0.106463
Epoch[005] Batch [0449]/[0716]	Speed: 25.725525 samples/sec	 accuracy=13.246032	 loss=4.313438	 lr=0.107675
Epoch[005] Batch [0499]/[0716]	Speed: 25.423716 samples/sec	 accuracy=13.378571	 loss=4.299820	 lr=0.108887
Epoch[005] Batch [0549]/[0716]	Speed: 25.436515 samples/sec	 accuracy=13.435065	 loss=4.296023	 lr=0.110099
Epoch[005] Batch [0599]/[0716]	Speed: 26.070883 samples/sec	 accuracy=13.538690	 loss=4.287271	 lr=0.111310
Epoch[005] Batch [0649]/[0716]	Speed: 25.379508 samples/sec	 accuracy=13.640110	 loss=4.281563	 lr=0.112522
Epoch[005] Batch [0699]/[0716]	Speed: 25.253299 samples/sec	 accuracy=13.701531	 loss=4.275940	 lr=0.113734
Batch [0049]/[0057]: acc-top1=15.071429 acc-top5=37.357143
[Epoch 005] training: accuracy=13.756983	 loss=4.272214
[Epoch 005] speed: 25 samples/sec	time cost: 1635.104015
[Epoch 005] validation: acc-top1=15.685045 acc-top5=37.155388 loss=4.159998
Epoch[006] Batch [0049]/[0716]	Speed: 22.930299 samples/sec	 accuracy=14.464286	 loss=4.131870	 lr=0.115334
Epoch[006] Batch [0099]/[0716]	Speed: 25.867811 samples/sec	 accuracy=15.892857	 loss=4.105852	 lr=0.116546
Epoch[006] Batch [0149]/[0716]	Speed: 25.546946 samples/sec	 accuracy=16.488095	 loss=4.084017	 lr=0.117757
Epoch[006] Batch [0199]/[0716]	Speed: 25.645367 samples/sec	 accuracy=16.544643	 loss=4.076903	 lr=0.118969
Epoch[006] Batch [0249]/[0716]	Speed: 25.219949 samples/sec	 accuracy=16.371429	 loss=4.072378	 lr=0.120181
Epoch[006] Batch [0299]/[0716]	Speed: 25.958692 samples/sec	 accuracy=16.339286	 loss=4.071821	 lr=0.121393
Epoch[006] Batch [0349]/[0716]	Speed: 25.998028 samples/sec	 accuracy=16.352041	 loss=4.056379	 lr=0.122605
Epoch[006] Batch [0399]/[0716]	Speed: 25.466014 samples/sec	 accuracy=16.450893	 loss=4.045336	 lr=0.123817
Epoch[006] Batch [0449]/[0716]	Speed: 25.835770 samples/sec	 accuracy=16.722222	 loss=4.028040	 lr=0.125029
Epoch[006] Batch [0499]/[0716]	Speed: 25.643171 samples/sec	 accuracy=16.846429	 loss=4.014716	 lr=0.126240
Epoch[006] Batch [0549]/[0716]	Speed: 25.378341 samples/sec	 accuracy=16.866883	 loss=4.008955	 lr=0.127452
Epoch[006] Batch [0599]/[0716]	Speed: 25.737246 samples/sec	 accuracy=16.830357	 loss=4.011319	 lr=0.128664
Epoch[006] Batch [0649]/[0716]	Speed: 25.544914 samples/sec	 accuracy=16.862637	 loss=4.004394	 lr=0.129876
Epoch[006] Batch [0699]/[0716]	Speed: 25.710954 samples/sec	 accuracy=16.956633	 loss=3.993469	 lr=0.131088
Batch [0049]/[0057]: acc-top1=16.642857 acc-top5=38.785714
[Epoch 006] training: accuracy=17.011672	 loss=3.989640
[Epoch 006] speed: 25 samples/sec	time cost: 1630.263729
[Epoch 006] validation: acc-top1=17.611738 acc-top5=40.215122 loss=4.109827
Epoch[007] Batch [0049]/[0717]	Speed: 23.104746 samples/sec	 accuracy=19.071429	 loss=3.794854	 lr=0.132687
Epoch[007] Batch [0099]/[0717]	Speed: 25.845055 samples/sec	 accuracy=19.285714	 loss=3.830461	 lr=0.133899
Epoch[007] Batch [0149]/[0717]	Speed: 26.223313 samples/sec	 accuracy=19.297619	 loss=3.838269	 lr=0.135111
Epoch[007] Batch [0199]/[0717]	Speed: 25.644288 samples/sec	 accuracy=19.660714	 loss=3.820174	 lr=0.136323
Epoch[007] Batch [0249]/[0717]	Speed: 25.780115 samples/sec	 accuracy=19.721429	 loss=3.808677	 lr=0.137535
Epoch[007] Batch [0299]/[0717]	Speed: 25.914816 samples/sec	 accuracy=19.779762	 loss=3.806704	 lr=0.138747
Epoch[007] Batch [0349]/[0717]	Speed: 26.143475 samples/sec	 accuracy=19.780612	 loss=3.806047	 lr=0.139959
Epoch[007] Batch [0399]/[0717]	Speed: 26.120758 samples/sec	 accuracy=19.790179	 loss=3.800826	 lr=0.141170
Epoch[007] Batch [0449]/[0717]	Speed: 25.375127 samples/sec	 accuracy=20.000000	 loss=3.789954	 lr=0.142382
Epoch[007] Batch [0499]/[0717]	Speed: 26.094781 samples/sec	 accuracy=20.146429	 loss=3.780148	 lr=0.143594
Epoch[007] Batch [0549]/[0717]	Speed: 25.586328 samples/sec	 accuracy=20.240260	 loss=3.777773	 lr=0.144806
Epoch[007] Batch [0599]/[0717]	Speed: 25.865310 samples/sec	 accuracy=20.336310	 loss=3.769682	 lr=0.146018
Epoch[007] Batch [0649]/[0717]	Speed: 26.007867 samples/sec	 accuracy=20.486264	 loss=3.756251	 lr=0.147230
Epoch[007] Batch [0699]/[0717]	Speed: 25.518344 samples/sec	 accuracy=20.579082	 loss=3.746876	 lr=0.148441
Batch [0049]/[0057]: acc-top1=20.678571 acc-top5=44.250000
[Epoch 007] training: accuracy=20.673939	 loss=3.743884
[Epoch 007] speed: 25 samples/sec	time cost: 1620.543428
[Epoch 007] validation: acc-top1=20.405180 acc-top5=44.559311 loss=3.904016
Epoch[008] Batch [0049]/[0716]	Speed: 22.546691 samples/sec	 accuracy=23.678571	 loss=3.541227	 lr=0.150065
Epoch[008] Batch [0099]/[0716]	Speed: 26.111669 samples/sec	 accuracy=22.571429	 loss=3.582392	 lr=0.151277
Epoch[008] Batch [0149]/[0716]	Speed: 26.505503 samples/sec	 accuracy=22.380952	 loss=3.588626	 lr=0.152489
Epoch[008] Batch [0199]/[0716]	Speed: 25.921865 samples/sec	 accuracy=22.642857	 loss=3.582453	 lr=0.153701
Epoch[008] Batch [0249]/[0716]	Speed: 25.801679 samples/sec	 accuracy=22.571429	 loss=3.580248	 lr=0.154913
Epoch[008] Batch [0299]/[0716]	Speed: 26.037938 samples/sec	 accuracy=22.648810	 loss=3.582434	 lr=0.156125
Epoch[008] Batch [0349]/[0716]	Speed: 25.620420 samples/sec	 accuracy=22.765306	 loss=3.581939	 lr=0.157336
Epoch[008] Batch [0399]/[0716]	Speed: 25.518241 samples/sec	 accuracy=22.915179	 loss=3.576055	 lr=0.158548
Epoch[008] Batch [0449]/[0716]	Speed: 26.599327 samples/sec	 accuracy=23.007937	 loss=3.567090	 lr=0.159760
Epoch[008] Batch [0499]/[0716]	Speed: 25.815841 samples/sec	 accuracy=23.028571	 loss=3.561654	 lr=0.160972
Epoch[008] Batch [0549]/[0716]	Speed: 26.032883 samples/sec	 accuracy=23.162338	 loss=3.550441	 lr=0.162184
Epoch[008] Batch [0599]/[0716]	Speed: 25.690817 samples/sec	 accuracy=23.342262	 loss=3.537949	 lr=0.163396
Epoch[008] Batch [0649]/[0716]	Speed: 25.954016 samples/sec	 accuracy=23.557692	 loss=3.526943	 lr=0.164607
Epoch[008] Batch [0699]/[0716]	Speed: 26.054936 samples/sec	 accuracy=23.734694	 loss=3.521510	 lr=0.165819
Batch [0049]/[0057]: acc-top1=24.928571 acc-top5=51.107143
[Epoch 008] training: accuracy=23.710595	 loss=3.519880
[Epoch 008] speed: 25 samples/sec	time cost: 1616.022071
[Epoch 008] validation: acc-top1=25.172306 acc-top5=51.065166 loss=3.512607
Epoch[009] Batch [0049]/[0716]	Speed: 22.989572 samples/sec	 accuracy=26.250000	 loss=3.341592	 lr=0.167419
Epoch[009] Batch [0099]/[0716]	Speed: 25.583295 samples/sec	 accuracy=26.125000	 loss=3.342931	 lr=0.168631
Epoch[009] Batch [0149]/[0716]	Speed: 25.973764 samples/sec	 accuracy=26.797619	 loss=3.338073	 lr=0.169843
Epoch[009] Batch [0199]/[0716]	Speed: 25.843957 samples/sec	 accuracy=26.571429	 loss=3.348247	 lr=0.171055
Epoch[009] Batch [0249]/[0716]	Speed: 25.973540 samples/sec	 accuracy=26.757143	 loss=3.340693	 lr=0.172266
Epoch[009] Batch [0299]/[0716]	Speed: 25.556315 samples/sec	 accuracy=26.791667	 loss=3.336280	 lr=0.173478
Epoch[009] Batch [0349]/[0716]	Speed: 25.455369 samples/sec	 accuracy=26.948980	 loss=3.325521	 lr=0.174690
Epoch[009] Batch [0399]/[0716]	Speed: 25.943463 samples/sec	 accuracy=26.924107	 loss=3.324605	 lr=0.175902
Epoch[009] Batch [0449]/[0716]	Speed: 26.127114 samples/sec	 accuracy=26.900794	 loss=3.325845	 lr=0.177114
Epoch[009] Batch [0499]/[0716]	Speed: 25.966428 samples/sec	 accuracy=27.007143	 loss=3.322550	 lr=0.178326
Epoch[009] Batch [0549]/[0716]	Speed: 25.847366 samples/sec	 accuracy=27.139610	 loss=3.317367	 lr=0.179537
Epoch[009] Batch [0599]/[0716]	Speed: 25.966846 samples/sec	 accuracy=27.241071	 loss=3.313196	 lr=0.180749
Epoch[009] Batch [0649]/[0716]	Speed: 26.158875 samples/sec	 accuracy=27.260989	 loss=3.313821	 lr=0.181961
Epoch[009] Batch [0699]/[0716]	Speed: 26.001974 samples/sec	 accuracy=27.377551	 loss=3.310409	 lr=0.183173
Batch [0049]/[0057]: acc-top1=28.178571 acc-top5=56.321429
[Epoch 009] training: accuracy=27.359338	 loss=3.311731
[Epoch 009] speed: 25 samples/sec	time cost: 1616.044853
[Epoch 009] validation: acc-top1=28.101507 acc-top5=54.443401 loss=3.308661
Epoch[010] Batch [0049]/[0716]	Speed: 22.641655 samples/sec	 accuracy=29.000000	 loss=3.157684	 lr=0.184773
Epoch[010] Batch [0099]/[0716]	Speed: 25.605029 samples/sec	 accuracy=29.142857	 loss=3.172390	 lr=0.185984
Epoch[010] Batch [0149]/[0716]	Speed: 25.889659 samples/sec	 accuracy=29.166667	 loss=3.181023	 lr=0.187196
Epoch[010] Batch [0199]/[0716]	Speed: 25.466201 samples/sec	 accuracy=29.107143	 loss=3.185118	 lr=0.188408
Epoch[010] Batch [0249]/[0716]	Speed: 26.178610 samples/sec	 accuracy=29.214286	 loss=3.182553	 lr=0.189620
Epoch[010] Batch [0299]/[0716]	Speed: 25.865928 samples/sec	 accuracy=29.309524	 loss=3.185605	 lr=0.190832
Epoch[010] Batch [0349]/[0716]	Speed: 25.667377 samples/sec	 accuracy=29.525510	 loss=3.179349	 lr=0.192044
Epoch[010] Batch [0399]/[0716]	Speed: 25.623730 samples/sec	 accuracy=29.473214	 loss=3.175901	 lr=0.193256
Epoch[010] Batch [0449]/[0716]	Speed: 26.085215 samples/sec	 accuracy=29.496032	 loss=3.177365	 lr=0.194467
Epoch[010] Batch [0499]/[0716]	Speed: 25.698968 samples/sec	 accuracy=29.542857	 loss=3.175249	 lr=0.195679
Epoch[010] Batch [0549]/[0716]	Speed: 26.357221 samples/sec	 accuracy=29.665584	 loss=3.170391	 lr=0.196891
Epoch[010] Batch [0599]/[0716]	Speed: 25.585349 samples/sec	 accuracy=29.809524	 loss=3.162180	 lr=0.198103
Epoch[010] Batch [0649]/[0716]	Speed: 25.769858 samples/sec	 accuracy=29.909341	 loss=3.155986	 lr=0.199315
Epoch[010] Batch [0699]/[0716]	Speed: 25.631963 samples/sec	 accuracy=29.948980	 loss=3.153407	 lr=0.200527
Batch [0049]/[0057]: acc-top1=29.464286 acc-top5=56.964286
[Epoch 010] training: accuracy=29.983041	 loss=3.149679
[Epoch 010] speed: 25 samples/sec	time cost: 1624.010321
[Epoch 010] validation: acc-top1=29.756685 acc-top5=57.027988 loss=3.207619
Epoch[011] Batch [0049]/[0716]	Speed: 22.827323 samples/sec	 accuracy=32.035714	 loss=3.027982	 lr=0.202126
Epoch[011] Batch [0099]/[0716]	Speed: 26.227752 samples/sec	 accuracy=31.607143	 loss=3.057357	 lr=0.203338
Epoch[011] Batch [0149]/[0716]	Speed: 25.548159 samples/sec	 accuracy=31.511905	 loss=3.076382	 lr=0.204550
Epoch[011] Batch [0199]/[0716]	Speed: 25.978780 samples/sec	 accuracy=32.196429	 loss=3.054918	 lr=0.205762
Epoch[011] Batch [0249]/[0716]	Speed: 25.735469 samples/sec	 accuracy=32.107143	 loss=3.053983	 lr=0.206974
Epoch[011] Batch [0299]/[0716]	Speed: 25.532196 samples/sec	 accuracy=32.220238	 loss=3.040875	 lr=0.208186
Epoch[011] Batch [0349]/[0716]	Speed: 25.963253 samples/sec	 accuracy=32.367347	 loss=3.036750	 lr=0.209397
Epoch[011] Batch [0399]/[0716]	Speed: 25.488739 samples/sec	 accuracy=32.263393	 loss=3.038742	 lr=0.210609
Epoch[011] Batch [0449]/[0716]	Speed: 25.796424 samples/sec	 accuracy=32.285714	 loss=3.032468	 lr=0.211821
Epoch[011] Batch [0499]/[0716]	Speed: 25.657915 samples/sec	 accuracy=32.217857	 loss=3.032517	 lr=0.213033
Epoch[011] Batch [0549]/[0716]	Speed: 26.081287 samples/sec	 accuracy=32.165584	 loss=3.033595	 lr=0.214245
Epoch[011] Batch [0599]/[0716]	Speed: 25.786436 samples/sec	 accuracy=32.220238	 loss=3.029941	 lr=0.215457
Epoch[011] Batch [0649]/[0716]	Speed: 26.235454 samples/sec	 accuracy=32.217033	 loss=3.031281	 lr=0.216668
Epoch[011] Batch [0699]/[0716]	Speed: 25.683753 samples/sec	 accuracy=32.242347	 loss=3.031902	 lr=0.217880
Batch [0049]/[0057]: acc-top1=31.000000 acc-top5=58.928571
[Epoch 011] training: accuracy=32.260076	 loss=3.031922
[Epoch 011] speed: 25 samples/sec	time cost: 1621.386681
[Epoch 011] validation: acc-top1=31.840015 acc-top5=59.737892 loss=3.059306
Epoch[012] Batch [0049]/[0716]	Speed: 23.165385 samples/sec	 accuracy=32.928571	 loss=2.980686	 lr=0.219480
Epoch[012] Batch [0099]/[0716]	Speed: 25.931080 samples/sec	 accuracy=33.732143	 loss=2.926039	 lr=0.220692
Epoch[012] Batch [0149]/[0716]	Speed: 26.142520 samples/sec	 accuracy=33.500000	 loss=2.948137	 lr=0.221904
Epoch[012] Batch [0199]/[0716]	Speed: 26.186278 samples/sec	 accuracy=33.803571	 loss=2.945405	 lr=0.223115
Epoch[012] Batch [0249]/[0716]	Speed: 25.896769 samples/sec	 accuracy=33.678571	 loss=2.952576	 lr=0.224327
Epoch[012] Batch [0299]/[0716]	Speed: 25.853005 samples/sec	 accuracy=33.565476	 loss=2.967585	 lr=0.225539
Epoch[012] Batch [0349]/[0716]	Speed: 25.696588 samples/sec	 accuracy=33.739796	 loss=2.958520	 lr=0.226751
Epoch[012] Batch [0399]/[0716]	Speed: 25.622507 samples/sec	 accuracy=33.803571	 loss=2.951987	 lr=0.227963
Epoch[012] Batch [0449]/[0716]	Speed: 25.319127 samples/sec	 accuracy=33.996032	 loss=2.948697	 lr=0.229175
Epoch[012] Batch [0499]/[0716]	Speed: 26.243025 samples/sec	 accuracy=34.050000	 loss=2.945448	 lr=0.230387
Epoch[012] Batch [0549]/[0716]	Speed: 26.118530 samples/sec	 accuracy=34.038961	 loss=2.942728	 lr=0.231598
Epoch[012] Batch [0599]/[0716]	Speed: 25.470260 samples/sec	 accuracy=34.017857	 loss=2.945848	 lr=0.232810
Epoch[012] Batch [0649]/[0716]	Speed: 26.112899 samples/sec	 accuracy=34.049451	 loss=2.941932	 lr=0.234022
Epoch[012] Batch [0699]/[0716]	Speed: 26.087650 samples/sec	 accuracy=34.109694	 loss=2.937034	 lr=0.235234
Batch [0049]/[0057]: acc-top1=34.357143 acc-top5=62.178571
[Epoch 012] training: accuracy=34.123105	 loss=2.938695
[Epoch 012] speed: 25 samples/sec	time cost: 1616.265556
[Epoch 012] validation: acc-top1=34.361946 acc-top5=62.014412 loss=2.990321
Epoch[013] Batch [0049]/[0716]	Speed: 22.746728 samples/sec	 accuracy=37.107143	 loss=2.796895	 lr=0.236834
Epoch[013] Batch [0099]/[0716]	Speed: 25.725571 samples/sec	 accuracy=36.053571	 loss=2.823422	 lr=0.238045
Epoch[013] Batch [0149]/[0716]	Speed: 26.056074 samples/sec	 accuracy=36.142857	 loss=2.821485	 lr=0.239257
Epoch[013] Batch [0199]/[0716]	Speed: 26.056432 samples/sec	 accuracy=36.491071	 loss=2.808615	 lr=0.240469
Epoch[013] Batch [0249]/[0716]	Speed: 26.080899 samples/sec	 accuracy=36.392857	 loss=2.812332	 lr=0.241681
Epoch[013] Batch [0299]/[0716]	Speed: 25.653862 samples/sec	 accuracy=36.380952	 loss=2.811121	 lr=0.242893
Epoch[013] Batch [0349]/[0716]	Speed: 25.972359 samples/sec	 accuracy=36.372449	 loss=2.808009	 lr=0.244105
Epoch[013] Batch [0399]/[0716]	Speed: 25.800900 samples/sec	 accuracy=36.553571	 loss=2.805935	 lr=0.245317
Epoch[013] Batch [0449]/[0716]	Speed: 26.002847 samples/sec	 accuracy=36.373016	 loss=2.817200	 lr=0.246528
Epoch[013] Batch [0499]/[0716]	Speed: 26.311904 samples/sec	 accuracy=36.475000	 loss=2.814907	 lr=0.247740
Epoch[013] Batch [0549]/[0716]	Speed: 25.939084 samples/sec	 accuracy=36.616883	 loss=2.808403	 lr=0.248952
Epoch[013] Batch [0599]/[0716]	Speed: 26.040261 samples/sec	 accuracy=36.586310	 loss=2.807548	 lr=0.250164
Epoch[013] Batch [0649]/[0716]	Speed: 25.668444 samples/sec	 accuracy=36.623626	 loss=2.803772	 lr=0.251376
Epoch[013] Batch [0699]/[0716]	Speed: 26.043144 samples/sec	 accuracy=36.530612	 loss=2.807199	 lr=0.252588
Batch [0049]/[0057]: acc-top1=33.000000 acc-top5=60.714286
[Epoch 013] training: accuracy=36.524840	 loss=2.807615
[Epoch 013] speed: 25 samples/sec	time cost: 1615.321282
[Epoch 013] validation: acc-top1=33.630951 acc-top5=60.980576 loss=3.033915
Epoch[014] Batch [0049]/[0716]	Speed: 22.672870 samples/sec	 accuracy=37.178571	 loss=2.749894	 lr=0.254187
Epoch[014] Batch [0099]/[0716]	Speed: 25.887154 samples/sec	 accuracy=37.446429	 loss=2.755969	 lr=0.255399
Epoch[014] Batch [0149]/[0716]	Speed: 25.966700 samples/sec	 accuracy=37.404762	 loss=2.747136	 lr=0.256611
Epoch[014] Batch [0199]/[0716]	Speed: 25.950371 samples/sec	 accuracy=37.741071	 loss=2.741358	 lr=0.257823
Epoch[014] Batch [0249]/[0716]	Speed: 25.966895 samples/sec	 accuracy=37.550000	 loss=2.750535	 lr=0.259035
Epoch[014] Batch [0299]/[0716]	Speed: 26.084658 samples/sec	 accuracy=37.339286	 loss=2.755560	 lr=0.260246
Epoch[014] Batch [0349]/[0716]	Speed: 25.669033 samples/sec	 accuracy=37.306122	 loss=2.755781	 lr=0.261458
Epoch[014] Batch [0399]/[0716]	Speed: 26.146936 samples/sec	 accuracy=37.339286	 loss=2.758836	 lr=0.262670
Epoch[014] Batch [0449]/[0716]	Speed: 26.101229 samples/sec	 accuracy=37.313492	 loss=2.758162	 lr=0.263882
Epoch[014] Batch [0499]/[0716]	Speed: 26.149491 samples/sec	 accuracy=37.403571	 loss=2.753884	 lr=0.265094
Epoch[014] Batch [0549]/[0716]	Speed: 25.959794 samples/sec	 accuracy=37.311688	 loss=2.757335	 lr=0.266306
Epoch[014] Batch [0599]/[0716]	Speed: 26.234829 samples/sec	 accuracy=37.148810	 loss=2.763342	 lr=0.267518
Epoch[014] Batch [0649]/[0716]	Speed: 26.163026 samples/sec	 accuracy=37.123626	 loss=2.764187	 lr=0.268729
Epoch[014] Batch [0699]/[0716]	Speed: 25.821545 samples/sec	 accuracy=37.137755	 loss=2.764096	 lr=0.269941
Batch [0049]/[0057]: acc-top1=36.678571 acc-top5=64.964286
[Epoch 014] training: accuracy=37.148344	 loss=2.765044
[Epoch 014] speed: 25 samples/sec	time cost: 1612.424561
[Epoch 014] validation: acc-top1=35.907478 acc-top5=64.494568 loss=2.891857
Epoch[015] Batch [0049]/[0717]	Speed: 23.269177 samples/sec	 accuracy=36.428571	 loss=2.758409	 lr=0.271541
Epoch[015] Batch [0099]/[0717]	Speed: 25.836935 samples/sec	 accuracy=37.107143	 loss=2.732810	 lr=0.272753
Epoch[015] Batch [0149]/[0717]	Speed: 26.188883 samples/sec	 accuracy=37.833333	 loss=2.716231	 lr=0.273965
Epoch[015] Batch [0199]/[0717]	Speed: 25.706383 samples/sec	 accuracy=38.098214	 loss=2.709237	 lr=0.275176
Epoch[015] Batch [0249]/[0717]	Speed: 26.117325 samples/sec	 accuracy=37.814286	 loss=2.720950	 lr=0.276388
Epoch[015] Batch [0299]/[0717]	Speed: 25.598838 samples/sec	 accuracy=37.565476	 loss=2.737347	 lr=0.277600
Epoch[015] Batch [0349]/[0717]	Speed: 25.713443 samples/sec	 accuracy=37.816327	 loss=2.729606	 lr=0.278812
Epoch[015] Batch [0399]/[0717]	Speed: 26.111475 samples/sec	 accuracy=37.633929	 loss=2.741434	 lr=0.280024
Epoch[015] Batch [0449]/[0717]	Speed: 26.101590 samples/sec	 accuracy=37.579365	 loss=2.744206	 lr=0.281236
Epoch[015] Batch [0499]/[0717]	Speed: 26.159243 samples/sec	 accuracy=37.914286	 loss=2.731502	 lr=0.282448
Epoch[015] Batch [0549]/[0717]	Speed: 25.179270 samples/sec	 accuracy=37.967532	 loss=2.729252	 lr=0.283659
Epoch[015] Batch [0599]/[0717]	Speed: 26.242756 samples/sec	 accuracy=38.119048	 loss=2.723378	 lr=0.284871
Epoch[015] Batch [0649]/[0717]	Speed: 25.878548 samples/sec	 accuracy=38.148352	 loss=2.715353	 lr=0.286083
Epoch[015] Batch [0699]/[0717]	Speed: 26.040020 samples/sec	 accuracy=38.198980	 loss=2.714758	 lr=0.287295
Batch [0049]/[0057]: acc-top1=38.964286 acc-top5=65.214286
[Epoch 015] training: accuracy=38.127615	 loss=2.714962
[Epoch 015] speed: 25 samples/sec	time cost: 1616.114405
[Epoch 015] validation: acc-top1=36.419178 acc-top5=63.627815 loss=2.933332
Epoch[016] Batch [0049]/[0716]	Speed: 22.985748 samples/sec	 accuracy=39.214286	 loss=2.614592	 lr=0.288919
Epoch[016] Batch [0099]/[0716]	Speed: 26.065485 samples/sec	 accuracy=39.125000	 loss=2.648656	 lr=0.290131
Epoch[016] Batch [0149]/[0716]	Speed: 26.083951 samples/sec	 accuracy=39.178571	 loss=2.648291	 lr=0.291342
Epoch[016] Batch [0199]/[0716]	Speed: 25.783032 samples/sec	 accuracy=39.214286	 loss=2.638409	 lr=0.292554
Epoch[016] Batch [0249]/[0716]	Speed: 25.905707 samples/sec	 accuracy=39.357143	 loss=2.642198	 lr=0.293766
Epoch[016] Batch [0299]/[0716]	Speed: 25.891302 samples/sec	 accuracy=39.363095	 loss=2.647286	 lr=0.294978
Epoch[016] Batch [0349]/[0716]	Speed: 26.182837 samples/sec	 accuracy=39.260204	 loss=2.650750	 lr=0.296190
Epoch[016] Batch [0399]/[0716]	Speed: 25.893791 samples/sec	 accuracy=39.446429	 loss=2.643233	 lr=0.297402
Epoch[016] Batch [0449]/[0716]	Speed: 25.858384 samples/sec	 accuracy=39.349206	 loss=2.648457	 lr=0.298614
Epoch[016] Batch [0499]/[0716]	Speed: 25.959100 samples/sec	 accuracy=39.375000	 loss=2.650183	 lr=0.299825
Epoch[016] Batch [0549]/[0716]	Speed: 26.046862 samples/sec	 accuracy=39.243506	 loss=2.656011	 lr=0.301037
Epoch[016] Batch [0599]/[0716]	Speed: 25.892927 samples/sec	 accuracy=39.178571	 loss=2.656269	 lr=0.302249
Epoch[016] Batch [0649]/[0716]	Speed: 26.246207 samples/sec	 accuracy=39.173077	 loss=2.663229	 lr=0.303461
Epoch[016] Batch [0699]/[0716]	Speed: 25.921539 samples/sec	 accuracy=39.127551	 loss=2.664171	 lr=0.304673
Batch [0049]/[0057]: acc-top1=33.142857 acc-top5=62.785714
[Epoch 016] training: accuracy=39.113627	 loss=2.663951
[Epoch 016] speed: 25 samples/sec	time cost: 1610.808545
[Epoch 016] validation: acc-top1=34.570801 acc-top5=63.215328 loss=3.065785
Epoch[017] Batch [0049]/[0716]	Speed: 22.919052 samples/sec	 accuracy=40.178571	 loss=2.614928	 lr=0.306272
Epoch[017] Batch [0099]/[0716]	Speed: 25.935154 samples/sec	 accuracy=40.089286	 loss=2.624251	 lr=0.307484
Epoch[017] Batch [0149]/[0716]	Speed: 25.948258 samples/sec	 accuracy=39.511905	 loss=2.641491	 lr=0.308696
Epoch[017] Batch [0199]/[0716]	Speed: 25.757126 samples/sec	 accuracy=39.205357	 loss=2.658441	 lr=0.309908
Epoch[017] Batch [0249]/[0716]	Speed: 26.539874 samples/sec	 accuracy=39.357143	 loss=2.648994	 lr=0.311120
Epoch[017] Batch [0299]/[0716]	Speed: 25.705181 samples/sec	 accuracy=39.220238	 loss=2.647977	 lr=0.312332
Epoch[017] Batch [0349]/[0716]	Speed: 25.971700 samples/sec	 accuracy=39.520408	 loss=2.643189	 lr=0.313544
Epoch[017] Batch [0399]/[0716]	Speed: 25.826155 samples/sec	 accuracy=39.477679	 loss=2.646720	 lr=0.314755
Epoch[017] Batch [0449]/[0716]	Speed: 26.130458 samples/sec	 accuracy=39.404762	 loss=2.651251	 lr=0.315967
Epoch[017] Batch [0499]/[0716]	Speed: 26.284249 samples/sec	 accuracy=39.317857	 loss=2.655409	 lr=0.317179
Epoch[017] Batch [0549]/[0716]	Speed: 25.938265 samples/sec	 accuracy=39.275974	 loss=2.660277	 lr=0.318391
Epoch[017] Batch [0599]/[0716]	Speed: 25.670231 samples/sec	 accuracy=39.312500	 loss=2.660692	 lr=0.319603
Epoch[017] Batch [0649]/[0716]	Speed: 26.066979 samples/sec	 accuracy=39.208791	 loss=2.664160	 lr=0.320815
Epoch[017] Batch [0699]/[0716]	Speed: 25.932914 samples/sec	 accuracy=39.224490	 loss=2.664551	 lr=0.322026
Batch [0049]/[0057]: acc-top1=40.892857 acc-top5=67.178571
[Epoch 017] training: accuracy=39.273244	 loss=2.664437
[Epoch 017] speed: 25 samples/sec	time cost: 1612.825350
[Epoch 017] validation: acc-top1=38.721809 acc-top5=65.737259 loss=2.857474
Epoch[018] Batch [0049]/[0716]	Speed: 23.125665 samples/sec	 accuracy=42.750000	 loss=2.533028	 lr=0.323626
Epoch[018] Batch [0099]/[0716]	Speed: 26.257575 samples/sec	 accuracy=41.500000	 loss=2.581108	 lr=0.324838
Epoch[018] Batch [0149]/[0716]	Speed: 26.214706 samples/sec	 accuracy=40.750000	 loss=2.621069	 lr=0.326050
Epoch[018] Batch [0199]/[0716]	Speed: 25.853944 samples/sec	 accuracy=40.410714	 loss=2.623527	 lr=0.327262
Epoch[018] Batch [0249]/[0716]	Speed: 25.662004 samples/sec	 accuracy=40.335714	 loss=2.617034	 lr=0.328473
Epoch[018] Batch [0299]/[0716]	Speed: 26.346698 samples/sec	 accuracy=40.261905	 loss=2.624659	 lr=0.329685
Epoch[018] Batch [0349]/[0716]	Speed: 26.273038 samples/sec	 accuracy=40.137755	 loss=2.623235	 lr=0.330897
Epoch[018] Batch [0399]/[0716]	Speed: 25.756403 samples/sec	 accuracy=40.267857	 loss=2.618555	 lr=0.332109
Epoch[018] Batch [0449]/[0716]	Speed: 26.069039 samples/sec	 accuracy=40.333333	 loss=2.612598	 lr=0.333321
Epoch[018] Batch [0499]/[0716]	Speed: 25.767034 samples/sec	 accuracy=40.114286	 loss=2.623533	 lr=0.334533
Epoch[018] Batch [0549]/[0716]	Speed: 25.955318 samples/sec	 accuracy=40.035714	 loss=2.633270	 lr=0.335745
Epoch[018] Batch [0599]/[0716]	Speed: 26.170939 samples/sec	 accuracy=39.934524	 loss=2.632765	 lr=0.336956
Epoch[018] Batch [0649]/[0716]	Speed: 26.005326 samples/sec	 accuracy=39.953297	 loss=2.635069	 lr=0.338168
Epoch[018] Batch [0699]/[0716]	Speed: 25.767614 samples/sec	 accuracy=39.936224	 loss=2.635777	 lr=0.339380
Batch [0049]/[0057]: acc-top1=39.250000 acc-top5=67.000000
[Epoch 018] training: accuracy=39.969074	 loss=2.634193
[Epoch 018] speed: 25 samples/sec	time cost: 1609.745983
[Epoch 018] validation: acc-top1=39.165619 acc-top5=66.912071 loss=2.788454
Epoch[019] Batch [0049]/[0716]	Speed: 22.681219 samples/sec	 accuracy=40.928571	 loss=2.597105	 lr=0.340980
Epoch[019] Batch [0099]/[0716]	Speed: 26.018808 samples/sec	 accuracy=40.089286	 loss=2.607927	 lr=0.342192
Epoch[019] Batch [0149]/[0716]	Speed: 25.904097 samples/sec	 accuracy=40.452381	 loss=2.586815	 lr=0.343403
Epoch[019] Batch [0199]/[0716]	Speed: 26.024258 samples/sec	 accuracy=40.642857	 loss=2.586346	 lr=0.344615
Epoch[019] Batch [0249]/[0716]	Speed: 25.960459 samples/sec	 accuracy=40.407143	 loss=2.594760	 lr=0.345827
Epoch[019] Batch [0299]/[0716]	Speed: 25.999940 samples/sec	 accuracy=40.625000	 loss=2.593785	 lr=0.347039
Epoch[019] Batch [0349]/[0716]	Speed: 26.221538 samples/sec	 accuracy=40.602041	 loss=2.592028	 lr=0.348251
Epoch[019] Batch [0399]/[0716]	Speed: 25.637235 samples/sec	 accuracy=40.584821	 loss=2.588067	 lr=0.349463
Epoch[019] Batch [0449]/[0716]	Speed: 25.827528 samples/sec	 accuracy=40.603175	 loss=2.589620	 lr=0.350675
Epoch[019] Batch [0499]/[0716]	Speed: 26.221019 samples/sec	 accuracy=40.464286	 loss=2.592307	 lr=0.351886
Epoch[019] Batch [0549]/[0716]	Speed: 26.072221 samples/sec	 accuracy=40.376623	 loss=2.597952	 lr=0.353098
Epoch[019] Batch [0599]/[0716]	Speed: 26.145147 samples/sec	 accuracy=40.407738	 loss=2.600726	 lr=0.354310
Epoch[019] Batch [0649]/[0716]	Speed: 26.057829 samples/sec	 accuracy=40.335165	 loss=2.604721	 lr=0.355522
Epoch[019] Batch [0699]/[0716]	Speed: 26.281108 samples/sec	 accuracy=40.288265	 loss=2.608861	 lr=0.356734
Batch [0049]/[0057]: acc-top1=39.535714 acc-top5=67.535714
[Epoch 019] training: accuracy=40.258380	 loss=2.608517
[Epoch 019] speed: 25 samples/sec	time cost: 1608.485318
[Epoch 019] validation: acc-top1=40.058479 acc-top5=67.533417 loss=2.833037
Epoch[020] Batch [0049]/[0716]	Speed: 23.202073 samples/sec	 accuracy=40.357143	 loss=2.558593	 lr=0.358333
Epoch[020] Batch [0099]/[0716]	Speed: 25.920471 samples/sec	 accuracy=40.910714	 loss=2.531718	 lr=0.359545
Epoch[020] Batch [0149]/[0716]	Speed: 26.026331 samples/sec	 accuracy=41.107143	 loss=2.545303	 lr=0.360757
Epoch[020] Batch [0199]/[0716]	Speed: 25.928089 samples/sec	 accuracy=41.169643	 loss=2.552257	 lr=0.361969
Epoch[020] Batch [0249]/[0716]	Speed: 25.732461 samples/sec	 accuracy=41.378571	 loss=2.548296	 lr=0.363181
Epoch[020] Batch [0299]/[0716]	Speed: 25.838730 samples/sec	 accuracy=41.750000	 loss=2.533214	 lr=0.364393
Epoch[020] Batch [0349]/[0716]	Speed: 26.158412 samples/sec	 accuracy=41.642857	 loss=2.539173	 lr=0.365604
Epoch[020] Batch [0399]/[0716]	Speed: 25.956834 samples/sec	 accuracy=41.616071	 loss=2.540419	 lr=0.366816
Epoch[020] Batch [0449]/[0716]	Speed: 26.168949 samples/sec	 accuracy=41.591270	 loss=2.538083	 lr=0.368028
Epoch[020] Batch [0499]/[0716]	Speed: 26.276255 samples/sec	 accuracy=41.492857	 loss=2.540816	 lr=0.369240
Epoch[020] Batch [0549]/[0716]	Speed: 26.194361 samples/sec	 accuracy=41.344156	 loss=2.547614	 lr=0.370452
Epoch[020] Batch [0599]/[0716]	Speed: 25.909532 samples/sec	 accuracy=41.193452	 loss=2.554492	 lr=0.371664
Epoch[020] Batch [0649]/[0716]	Speed: 26.158416 samples/sec	 accuracy=41.214286	 loss=2.557909	 lr=0.372876
Epoch[020] Batch [0699]/[0716]	Speed: 25.859525 samples/sec	 accuracy=41.188776	 loss=2.560825	 lr=0.374087
Batch [0049]/[0057]: acc-top1=35.428571 acc-top5=61.892857
[Epoch 020] training: accuracy=41.106345	 loss=2.564522
[Epoch 020] speed: 25 samples/sec	time cost: 1607.726321
[Epoch 020] validation: acc-top1=34.805763 acc-top5=61.581032 loss=3.209657
Epoch[021] Batch [0049]/[0716]	Speed: 23.062705 samples/sec	 accuracy=40.642857	 loss=2.610355	 lr=0.375687
Epoch[021] Batch [0099]/[0716]	Speed: 25.412787 samples/sec	 accuracy=41.178571	 loss=2.593687	 lr=0.376899
Epoch[021] Batch [0149]/[0716]	Speed: 25.634181 samples/sec	 accuracy=41.071429	 loss=2.583988	 lr=0.378111
Epoch[021] Batch [0199]/[0716]	Speed: 26.135859 samples/sec	 accuracy=40.964286	 loss=2.579980	 lr=0.379323
Epoch[021] Batch [0249]/[0716]	Speed: 25.624851 samples/sec	 accuracy=40.635714	 loss=2.591812	 lr=0.380534
Epoch[021] Batch [0299]/[0716]	Speed: 26.096623 samples/sec	 accuracy=40.428571	 loss=2.607893	 lr=0.381746
Epoch[021] Batch [0349]/[0716]	Speed: 25.849168 samples/sec	 accuracy=40.204082	 loss=2.615017	 lr=0.382958
Epoch[021] Batch [0399]/[0716]	Speed: 25.992138 samples/sec	 accuracy=40.258929	 loss=2.613706	 lr=0.384170
Epoch[021] Batch [0449]/[0716]	Speed: 25.795890 samples/sec	 accuracy=40.400794	 loss=2.606598	 lr=0.385382
Epoch[021] Batch [0499]/[0716]	Speed: 26.116120 samples/sec	 accuracy=40.460714	 loss=2.604356	 lr=0.386594
Epoch[021] Batch [0549]/[0716]	Speed: 26.452949 samples/sec	 accuracy=40.487013	 loss=2.602786	 lr=0.387806
Epoch[021] Batch [0599]/[0716]	Speed: 25.790986 samples/sec	 accuracy=40.494048	 loss=2.604291	 lr=0.389017
Epoch[021] Batch [0649]/[0716]	Speed: 26.072099 samples/sec	 accuracy=40.461538	 loss=2.598314	 lr=0.390229
Epoch[021] Batch [0699]/[0716]	Speed: 25.995331 samples/sec	 accuracy=40.556122	 loss=2.594861	 lr=0.391441
Batch [0049]/[0057]: acc-top1=39.928571 acc-top5=66.464286
[Epoch 021] training: accuracy=40.557662	 loss=2.594189
[Epoch 021] speed: 25 samples/sec	time cost: 1612.967458
[Epoch 021] validation: acc-top1=38.324974 acc-top5=65.919998 loss=2.869830
Epoch[022] Batch [0049]/[0716]	Speed: 22.926734 samples/sec	 accuracy=42.000000	 loss=2.552694	 lr=0.393041
Epoch[022] Batch [0099]/[0716]	Speed: 25.755290 samples/sec	 accuracy=42.303571	 loss=2.541841	 lr=0.394253
Epoch[022] Batch [0149]/[0716]	Speed: 25.664881 samples/sec	 accuracy=41.523810	 loss=2.569493	 lr=0.395464
Epoch[022] Batch [0199]/[0716]	Speed: 26.214477 samples/sec	 accuracy=41.000000	 loss=2.581001	 lr=0.396676
Epoch[022] Batch [0249]/[0716]	Speed: 26.175656 samples/sec	 accuracy=40.928571	 loss=2.581867	 lr=0.397888
Epoch[022] Batch [0299]/[0716]	Speed: 25.922115 samples/sec	 accuracy=40.809524	 loss=2.579767	 lr=0.399100
Epoch[022] Batch [0349]/[0716]	Speed: 25.992670 samples/sec	 accuracy=40.719388	 loss=2.575787	 lr=0.400312
Epoch[022] Batch [0399]/[0716]	Speed: 25.861883 samples/sec	 accuracy=40.741071	 loss=2.574890	 lr=0.401524
Epoch[022] Batch [0449]/[0716]	Speed: 26.272728 samples/sec	 accuracy=40.801587	 loss=2.577173	 lr=0.402735
Epoch[022] Batch [0499]/[0716]	Speed: 25.991252 samples/sec	 accuracy=40.760714	 loss=2.579836	 lr=0.403947
Epoch[022] Batch [0549]/[0716]	Speed: 26.119727 samples/sec	 accuracy=40.762987	 loss=2.577269	 lr=0.405159
Epoch[022] Batch [0599]/[0716]	Speed: 26.241096 samples/sec	 accuracy=40.925595	 loss=2.577813	 lr=0.406371
Epoch[022] Batch [0649]/[0716]	Speed: 26.296051 samples/sec	 accuracy=40.851648	 loss=2.578543	 lr=0.407583
Epoch[022] Batch [0699]/[0716]	Speed: 26.243289 samples/sec	 accuracy=40.831633	 loss=2.578489	 lr=0.408795
Batch [0049]/[0057]: acc-top1=37.500000 acc-top5=64.750000
[Epoch 022] training: accuracy=40.904330	 loss=2.576285
[Epoch 022] speed: 25 samples/sec	time cost: 1605.855174
[Epoch 022] validation: acc-top1=37.416458 acc-top5=63.784462 loss=3.061044
Epoch[023] Batch [0049]/[0717]	Speed: 23.024508 samples/sec	 accuracy=41.964286	 loss=2.543791	 lr=0.410394
Epoch[023] Batch [0099]/[0717]	Speed: 26.299312 samples/sec	 accuracy=41.535714	 loss=2.569070	 lr=0.411606
Epoch[023] Batch [0149]/[0717]	Speed: 25.488430 samples/sec	 accuracy=40.809524	 loss=2.581623	 lr=0.412818
Epoch[023] Batch [0199]/[0717]	Speed: 26.258535 samples/sec	 accuracy=40.750000	 loss=2.578146	 lr=0.414030
Epoch[023] Batch [0249]/[0717]	Speed: 25.869330 samples/sec	 accuracy=40.750000	 loss=2.578118	 lr=0.415242
Epoch[023] Batch [0299]/[0717]	Speed: 26.529979 samples/sec	 accuracy=40.559524	 loss=2.588165	 lr=0.416454
Epoch[023] Batch [0349]/[0717]	Speed: 25.896615 samples/sec	 accuracy=40.423469	 loss=2.589589	 lr=0.417665
Epoch[023] Batch [0399]/[0717]	Speed: 26.344734 samples/sec	 accuracy=40.495536	 loss=2.584084	 lr=0.418877
Epoch[023] Batch [0449]/[0717]	Speed: 26.284417 samples/sec	 accuracy=40.563492	 loss=2.587510	 lr=0.420089
Epoch[023] Batch [0499]/[0717]	Speed: 25.834989 samples/sec	 accuracy=40.785714	 loss=2.581042	 lr=0.421301
Epoch[023] Batch [0549]/[0717]	Speed: 25.916196 samples/sec	 accuracy=40.827922	 loss=2.580801	 lr=0.422513
Epoch[023] Batch [0599]/[0717]	Speed: 25.730730 samples/sec	 accuracy=40.687500	 loss=2.584436	 lr=0.423725
Epoch[023] Batch [0649]/[0717]	Speed: 26.136027 samples/sec	 accuracy=40.604396	 loss=2.588942	 lr=0.424937
Epoch[023] Batch [0699]/[0717]	Speed: 25.970959 samples/sec	 accuracy=40.581633	 loss=2.588318	 lr=0.426148
Batch [0049]/[0057]: acc-top1=35.714286 acc-top5=63.357143
[Epoch 023] training: accuracy=40.578302	 loss=2.587750
[Epoch 023] speed: 25 samples/sec	time cost: 1608.891719
[Epoch 023] validation: acc-top1=37.933372 acc-top5=65.256897 loss=2.963645
Epoch[024] Batch [0049]/[0716]	Speed: 23.022653 samples/sec	 accuracy=41.678571	 loss=2.551572	 lr=0.427772
Epoch[024] Batch [0099]/[0716]	Speed: 25.612521 samples/sec	 accuracy=41.285714	 loss=2.571177	 lr=0.428984
Epoch[024] Batch [0149]/[0716]	Speed: 26.330938 samples/sec	 accuracy=41.595238	 loss=2.554931	 lr=0.430196
Epoch[024] Batch [0199]/[0716]	Speed: 25.864867 samples/sec	 accuracy=41.571429	 loss=2.554065	 lr=0.431408
Epoch[024] Batch [0249]/[0716]	Speed: 26.068852 samples/sec	 accuracy=41.485714	 loss=2.563290	 lr=0.432620
Epoch[024] Batch [0299]/[0716]	Speed: 25.837979 samples/sec	 accuracy=41.553571	 loss=2.559117	 lr=0.433831
Epoch[024] Batch [0349]/[0716]	Speed: 25.911256 samples/sec	 accuracy=41.505102	 loss=2.560365	 lr=0.435043
Epoch[024] Batch [0399]/[0716]	Speed: 25.824348 samples/sec	 accuracy=41.535714	 loss=2.562933	 lr=0.436255
Epoch[024] Batch [0449]/[0716]	Speed: 26.214218 samples/sec	 accuracy=41.563492	 loss=2.563888	 lr=0.437467
Epoch[024] Batch [0499]/[0716]	Speed: 26.137212 samples/sec	 accuracy=41.460714	 loss=2.570553	 lr=0.438679
Epoch[024] Batch [0549]/[0716]	Speed: 25.824032 samples/sec	 accuracy=41.386364	 loss=2.574747	 lr=0.439891
Epoch[024] Batch [0599]/[0716]	Speed: 25.899899 samples/sec	 accuracy=41.258929	 loss=2.578586	 lr=0.441103
Epoch[024] Batch [0649]/[0716]	Speed: 25.824155 samples/sec	 accuracy=41.186813	 loss=2.581477	 lr=0.442314
Epoch[024] Batch [0699]/[0716]	Speed: 26.404991 samples/sec	 accuracy=41.114796	 loss=2.583419	 lr=0.443526
Batch [0049]/[0057]: acc-top1=39.107143 acc-top5=67.964286
[Epoch 024] training: accuracy=41.051476	 loss=2.586492
[Epoch 024] speed: 25 samples/sec	time cost: 1609.829117
[Epoch 024] validation: acc-top1=38.935879 acc-top5=66.697998 loss=2.977228
Epoch[025] Batch [0049]/[0716]	Speed: 22.892979 samples/sec	 accuracy=42.214286	 loss=2.490125	 lr=0.445126
Epoch[025] Batch [0099]/[0716]	Speed: 26.171697 samples/sec	 accuracy=41.589286	 loss=2.531091	 lr=0.446338
Epoch[025] Batch [0149]/[0716]	Speed: 25.961572 samples/sec	 accuracy=41.154762	 loss=2.556318	 lr=0.447550
Epoch[025] Batch [0199]/[0716]	Speed: 26.440646 samples/sec	 accuracy=41.241071	 loss=2.563322	 lr=0.448761
Epoch[025] Batch [0249]/[0716]	Speed: 26.094151 samples/sec	 accuracy=41.100000	 loss=2.575005	 lr=0.449973
Epoch[025] Batch [0299]/[0716]	Speed: 26.144685 samples/sec	 accuracy=41.172619	 loss=2.571110	 lr=0.451185
Epoch[025] Batch [0349]/[0716]	Speed: 25.724361 samples/sec	 accuracy=41.030612	 loss=2.571805	 lr=0.452397
Epoch[025] Batch [0399]/[0716]	Speed: 26.581093 samples/sec	 accuracy=41.196429	 loss=2.564513	 lr=0.453609
Epoch[025] Batch [0449]/[0716]	Speed: 25.935606 samples/sec	 accuracy=41.234127	 loss=2.564347	 lr=0.454821
Epoch[025] Batch [0499]/[0716]	Speed: 26.179660 samples/sec	 accuracy=41.182143	 loss=2.567163	 lr=0.456033
Epoch[025] Batch [0549]/[0716]	Speed: 25.822337 samples/sec	 accuracy=41.191558	 loss=2.565105	 lr=0.457244
Epoch[025] Batch [0599]/[0716]	Speed: 25.945661 samples/sec	 accuracy=41.014881	 loss=2.570577	 lr=0.458456
Epoch[025] Batch [0649]/[0716]	Speed: 25.947145 samples/sec	 accuracy=40.945055	 loss=2.568626	 lr=0.459668
Epoch[025] Batch [0699]/[0716]	Speed: 25.534124 samples/sec	 accuracy=40.954082	 loss=2.575773	 lr=0.460880
Batch [0049]/[0057]: acc-top1=40.857143 acc-top5=67.964286
[Epoch 025] training: accuracy=40.974162	 loss=2.576351
[Epoch 025] speed: 25 samples/sec	time cost: 1606.992499
[Epoch 025] validation: acc-top1=40.178570 acc-top5=67.554306 loss=2.889069
Epoch[026] Batch [0049]/[0716]	Speed: 23.369134 samples/sec	 accuracy=40.607143	 loss=2.552284	 lr=0.462480
Epoch[026] Batch [0099]/[0716]	Speed: 26.157679 samples/sec	 accuracy=41.000000	 loss=2.541589	 lr=0.463691
Epoch[026] Batch [0149]/[0716]	Speed: 25.956031 samples/sec	 accuracy=42.071429	 loss=2.514476	 lr=0.464903
Epoch[026] Batch [0199]/[0716]	Speed: 25.801485 samples/sec	 accuracy=41.723214	 loss=2.534143	 lr=0.466115
Epoch[026] Batch [0249]/[0716]	Speed: 25.646348 samples/sec	 accuracy=41.385714	 loss=2.548708	 lr=0.467327
Epoch[026] Batch [0299]/[0716]	Speed: 26.261992 samples/sec	 accuracy=41.375000	 loss=2.549920	 lr=0.468539
Epoch[026] Batch [0349]/[0716]	Speed: 25.695720 samples/sec	 accuracy=41.301020	 loss=2.548323	 lr=0.469751
Epoch[026] Batch [0399]/[0716]	Speed: 26.172429 samples/sec	 accuracy=41.330357	 loss=2.554832	 lr=0.470962
Epoch[026] Batch [0449]/[0716]	Speed: 25.819291 samples/sec	 accuracy=41.353175	 loss=2.555397	 lr=0.472174
Epoch[026] Batch [0499]/[0716]	Speed: 26.198630 samples/sec	 accuracy=41.203571	 loss=2.560544	 lr=0.473386
Epoch[026] Batch [0549]/[0716]	Speed: 25.821586 samples/sec	 accuracy=41.139610	 loss=2.566601	 lr=0.474598
Epoch[026] Batch [0599]/[0716]	Speed: 26.035745 samples/sec	 accuracy=40.985119	 loss=2.571839	 lr=0.475810
Epoch[026] Batch [0649]/[0716]	Speed: 26.300125 samples/sec	 accuracy=40.912088	 loss=2.575802	 lr=0.477022
Epoch[026] Batch [0699]/[0716]	Speed: 26.113972 samples/sec	 accuracy=40.803571	 loss=2.577699	 lr=0.478234
Batch [0049]/[0057]: acc-top1=37.821429 acc-top5=66.107143
[Epoch 026] training: accuracy=40.879389	 loss=2.574453
[Epoch 026] speed: 25 samples/sec	time cost: 1606.358813
[Epoch 026] validation: acc-top1=38.497284 acc-top5=65.810356 loss=2.951190
Epoch[027] Batch [0049]/[0716]	Speed: 23.356272 samples/sec	 accuracy=42.857143	 loss=2.473217	 lr=0.479833
Epoch[027] Batch [0099]/[0716]	Speed: 26.347878 samples/sec	 accuracy=41.767857	 loss=2.511840	 lr=0.481045
Epoch[027] Batch [0149]/[0716]	Speed: 25.952784 samples/sec	 accuracy=41.500000	 loss=2.520419	 lr=0.482257
Epoch[027] Batch [0199]/[0716]	Speed: 26.143370 samples/sec	 accuracy=41.455357	 loss=2.533912	 lr=0.483469
Epoch[027] Batch [0249]/[0716]	Speed: 26.181999 samples/sec	 accuracy=41.328571	 loss=2.544769	 lr=0.484681
Epoch[027] Batch [0299]/[0716]	Speed: 25.989785 samples/sec	 accuracy=41.363095	 loss=2.546220	 lr=0.485892
Epoch[027] Batch [0349]/[0716]	Speed: 25.871602 samples/sec	 accuracy=41.433673	 loss=2.543742	 lr=0.487104
Epoch[027] Batch [0399]/[0716]	Speed: 25.822246 samples/sec	 accuracy=41.415179	 loss=2.550945	 lr=0.488316
Epoch[027] Batch [0449]/[0716]	Speed: 26.223895 samples/sec	 accuracy=41.277778	 loss=2.560273	 lr=0.489528
Epoch[027] Batch [0499]/[0716]	Speed: 26.141990 samples/sec	 accuracy=41.242857	 loss=2.562044	 lr=0.490740
Epoch[027] Batch [0549]/[0716]	Speed: 25.843862 samples/sec	 accuracy=41.198052	 loss=2.568151	 lr=0.491952
Epoch[027] Batch [0599]/[0716]	Speed: 25.632605 samples/sec	 accuracy=41.080357	 loss=2.571909	 lr=0.493164
Epoch[027] Batch [0649]/[0716]	Speed: 25.904739 samples/sec	 accuracy=41.170330	 loss=2.570462	 lr=0.494375
Epoch[027] Batch [0699]/[0716]	Speed: 26.217692 samples/sec	 accuracy=41.051020	 loss=2.577128	 lr=0.495587
Batch [0049]/[0057]: acc-top1=39.071429 acc-top5=66.892857
[Epoch 027] training: accuracy=40.976656	 loss=2.579942
[Epoch 027] speed: 26 samples/sec	time cost: 1605.858647
[Epoch 027] validation: acc-top1=41.118423 acc-top5=68.311401 loss=2.805282
Epoch[028] Batch [0049]/[0716]	Speed: 22.902654 samples/sec	 accuracy=40.714286	 loss=2.584143	 lr=0.497187
Epoch[028] Batch [0099]/[0716]	Speed: 25.956446 samples/sec	 accuracy=41.250000	 loss=2.568696	 lr=0.498399
Epoch[028] Batch [0149]/[0716]	Speed: 25.661095 samples/sec	 accuracy=41.523810	 loss=2.561738	 lr=0.499611
Epoch[028] Batch [0199]/[0716]	Speed: 26.368618 samples/sec	 accuracy=41.178571	 loss=2.571079	 lr=0.500822
Epoch[028] Batch [0249]/[0716]	Speed: 25.978770 samples/sec	 accuracy=40.957143	 loss=2.587529	 lr=0.502034
Epoch[028] Batch [0299]/[0716]	Speed: 25.957676 samples/sec	 accuracy=41.154762	 loss=2.577866	 lr=0.503246
Epoch[028] Batch [0349]/[0716]	Speed: 26.252766 samples/sec	 accuracy=41.224490	 loss=2.571220	 lr=0.504458
Epoch[028] Batch [0399]/[0716]	Speed: 25.779539 samples/sec	 accuracy=41.245536	 loss=2.576210	 lr=0.505670
Epoch[028] Batch [0449]/[0716]	Speed: 25.784622 samples/sec	 accuracy=41.071429	 loss=2.581382	 lr=0.506882
Epoch[028] Batch [0499]/[0716]	Speed: 25.543934 samples/sec	 accuracy=41.117857	 loss=2.585951	 lr=0.508093
Epoch[028] Batch [0549]/[0716]	Speed: 25.595061 samples/sec	 accuracy=41.035714	 loss=2.586995	 lr=0.509305
Epoch[028] Batch [0599]/[0716]	Speed: 26.296389 samples/sec	 accuracy=40.982143	 loss=2.584125	 lr=0.510517
Epoch[028] Batch [0649]/[0716]	Speed: 26.183841 samples/sec	 accuracy=40.964286	 loss=2.581060	 lr=0.511729
Epoch[028] Batch [0699]/[0716]	Speed: 25.619271 samples/sec	 accuracy=41.038265	 loss=2.576139	 lr=0.512941
Batch [0049]/[0057]: acc-top1=38.928571 acc-top5=67.357143
[Epoch 028] training: accuracy=41.021548	 loss=2.575449
[Epoch 028] speed: 25 samples/sec	time cost: 1613.584027
[Epoch 028] validation: acc-top1=40.021931 acc-top5=67.549080 loss=2.905342
Epoch[029] Batch [0049]/[0716]	Speed: 22.878368 samples/sec	 accuracy=40.250000	 loss=2.562811	 lr=0.514541
Epoch[029] Batch [0099]/[0716]	Speed: 25.603586 samples/sec	 accuracy=40.607143	 loss=2.563671	 lr=0.515752
Epoch[029] Batch [0149]/[0716]	Speed: 25.920274 samples/sec	 accuracy=41.392857	 loss=2.535495	 lr=0.516964
Epoch[029] Batch [0199]/[0716]	Speed: 25.777247 samples/sec	 accuracy=41.392857	 loss=2.550131	 lr=0.518176
Epoch[029] Batch [0249]/[0716]	Speed: 25.824894 samples/sec	 accuracy=41.278571	 loss=2.558082	 lr=0.519388
Epoch[029] Batch [0299]/[0716]	Speed: 26.260975 samples/sec	 accuracy=41.220238	 loss=2.565706	 lr=0.520600
Epoch[029] Batch [0349]/[0716]	Speed: 25.985932 samples/sec	 accuracy=41.464286	 loss=2.558296	 lr=0.521812
Epoch[029] Batch [0399]/[0716]	Speed: 26.131891 samples/sec	 accuracy=41.633929	 loss=2.551627	 lr=0.523023
Epoch[029] Batch [0449]/[0716]	Speed: 26.543105 samples/sec	 accuracy=41.599206	 loss=2.549738	 lr=0.524235
Epoch[029] Batch [0499]/[0716]	Speed: 26.140275 samples/sec	 accuracy=41.635714	 loss=2.546368	 lr=0.525447
Epoch[029] Batch [0549]/[0716]	Speed: 26.503307 samples/sec	 accuracy=41.558442	 loss=2.548966	 lr=0.526659
Epoch[029] Batch [0599]/[0716]	Speed: 25.977308 samples/sec	 accuracy=41.491071	 loss=2.551761	 lr=0.527871
Epoch[029] Batch [0649]/[0716]	Speed: 25.632002 samples/sec	 accuracy=41.420330	 loss=2.558770	 lr=0.529083
Epoch[029] Batch [0699]/[0716]	Speed: 25.963448 samples/sec	 accuracy=41.443878	 loss=2.557782	 lr=0.530295
Batch [0049]/[0057]: acc-top1=39.321429 acc-top5=66.642857
[Epoch 029] training: accuracy=41.458001	 loss=2.557621
[Epoch 029] speed: 25 samples/sec	time cost: 1606.712840
[Epoch 029] validation: acc-top1=38.685253 acc-top5=65.899124 loss=2.935471
Epoch[030] Batch [0049]/[0716]	Speed: 22.948431 samples/sec	 accuracy=41.214286	 loss=2.515949	 lr=0.531894
Epoch[030] Batch [0099]/[0716]	Speed: 25.985403 samples/sec	 accuracy=41.410714	 loss=2.543011	 lr=0.533106
Epoch[030] Batch [0149]/[0716]	Speed: 26.058109 samples/sec	 accuracy=41.630952	 loss=2.536302	 lr=0.534318
Epoch[030] Batch [0199]/[0716]	Speed: 25.930287 samples/sec	 accuracy=41.642857	 loss=2.546969	 lr=0.535530
Epoch[030] Batch [0249]/[0716]	Speed: 25.960543 samples/sec	 accuracy=41.464286	 loss=2.547976	 lr=0.536742
Epoch[030] Batch [0299]/[0716]	Speed: 26.473932 samples/sec	 accuracy=41.315476	 loss=2.547630	 lr=0.537953
Epoch[030] Batch [0349]/[0716]	Speed: 25.982144 samples/sec	 accuracy=41.061224	 loss=2.564230	 lr=0.539165
Epoch[030] Batch [0399]/[0716]	Speed: 25.946438 samples/sec	 accuracy=41.004464	 loss=2.563832	 lr=0.540377
Epoch[030] Batch [0449]/[0716]	Speed: 25.885044 samples/sec	 accuracy=40.837302	 loss=2.577415	 lr=0.541589
Epoch[030] Batch [0499]/[0716]	Speed: 25.820815 samples/sec	 accuracy=41.007143	 loss=2.574781	 lr=0.542801
Epoch[030] Batch [0549]/[0716]	Speed: 26.037254 samples/sec	 accuracy=40.961039	 loss=2.579370	 lr=0.544013
Epoch[030] Batch [0599]/[0716]	Speed: 25.728220 samples/sec	 accuracy=40.830357	 loss=2.580890	 lr=0.545224
Epoch[030] Batch [0649]/[0716]	Speed: 25.782368 samples/sec	 accuracy=40.706044	 loss=2.586308	 lr=0.546436
Epoch[030] Batch [0699]/[0716]	Speed: 26.216929 samples/sec	 accuracy=40.688776	 loss=2.589570	 lr=0.547648
Batch [0049]/[0057]: acc-top1=38.071429 acc-top5=65.392857
[Epoch 030] training: accuracy=40.627494	 loss=2.593238
[Epoch 030] speed: 25 samples/sec	time cost: 1610.354341
[Epoch 030] validation: acc-top1=38.230995 acc-top5=65.272552 loss=3.008538
Epoch[031] Batch [0049]/[0717]	Speed: 22.688318 samples/sec	 accuracy=42.500000	 loss=2.525447	 lr=0.549248
Epoch[031] Batch [0099]/[0717]	Speed: 26.532049 samples/sec	 accuracy=41.750000	 loss=2.558705	 lr=0.550460
Epoch[031] Batch [0149]/[0717]	Speed: 25.663878 samples/sec	 accuracy=41.642857	 loss=2.565697	 lr=0.551672
Epoch[031] Batch [0199]/[0717]	Speed: 25.730221 samples/sec	 accuracy=41.526786	 loss=2.566015	 lr=0.552883
Epoch[031] Batch [0249]/[0717]	Speed: 25.672836 samples/sec	 accuracy=41.400000	 loss=2.569871	 lr=0.554095
Epoch[031] Batch [0299]/[0717]	Speed: 26.100956 samples/sec	 accuracy=41.202381	 loss=2.591258	 lr=0.555307
Epoch[031] Batch [0349]/[0717]	Speed: 26.294332 samples/sec	 accuracy=41.071429	 loss=2.592264	 lr=0.556519
Epoch[031] Batch [0399]/[0717]	Speed: 26.049725 samples/sec	 accuracy=40.950893	 loss=2.595970	 lr=0.557731
Epoch[031] Batch [0449]/[0717]	Speed: 26.083867 samples/sec	 accuracy=40.738095	 loss=2.606393	 lr=0.558943
Epoch[031] Batch [0499]/[0717]	Speed: 26.056670 samples/sec	 accuracy=40.646429	 loss=2.608924	 lr=0.560154
Epoch[031] Batch [0549]/[0717]	Speed: 26.101861 samples/sec	 accuracy=40.633117	 loss=2.609351	 lr=0.561366
Epoch[031] Batch [0599]/[0717]	Speed: 25.814288 samples/sec	 accuracy=40.678571	 loss=2.607783	 lr=0.562578
Epoch[031] Batch [0649]/[0717]	Speed: 25.927223 samples/sec	 accuracy=40.730769	 loss=2.605169	 lr=0.563790
Epoch[031] Batch [0699]/[0717]	Speed: 26.216382 samples/sec	 accuracy=40.714286	 loss=2.598167	 lr=0.565002
Batch [0049]/[0057]: acc-top1=38.714286 acc-top5=67.535714
[Epoch 031] training: accuracy=40.757621	 loss=2.597210
[Epoch 031] speed: 25 samples/sec	time cost: 1612.385644
[Epoch 031] validation: acc-top1=39.666878 acc-top5=66.765877 loss=2.868554
Epoch[032] Batch [0049]/[0716]	Speed: 23.031116 samples/sec	 accuracy=40.964286	 loss=2.592106	 lr=0.566626
Epoch[032] Batch [0099]/[0716]	Speed: 26.030094 samples/sec	 accuracy=40.928571	 loss=2.587585	 lr=0.567838
Epoch[032] Batch [0149]/[0716]	Speed: 26.107505 samples/sec	 accuracy=40.928571	 loss=2.588986	 lr=0.569049
Epoch[032] Batch [0199]/[0716]	Speed: 25.766752 samples/sec	 accuracy=40.830357	 loss=2.590933	 lr=0.570261
Epoch[032] Batch [0249]/[0716]	Speed: 26.044487 samples/sec	 accuracy=40.700000	 loss=2.585881	 lr=0.571473
Epoch[032] Batch [0299]/[0716]	Speed: 26.493556 samples/sec	 accuracy=40.940476	 loss=2.584977	 lr=0.572685
Epoch[032] Batch [0349]/[0716]	Speed: 26.192757 samples/sec	 accuracy=40.785714	 loss=2.593202	 lr=0.573897
Epoch[032] Batch [0399]/[0716]	Speed: 25.762178 samples/sec	 accuracy=40.790179	 loss=2.599039	 lr=0.575109
Epoch[032] Batch [0449]/[0716]	Speed: 26.403380 samples/sec	 accuracy=40.698413	 loss=2.601070	 lr=0.576321
Epoch[032] Batch [0499]/[0716]	Speed: 26.044463 samples/sec	 accuracy=40.539286	 loss=2.602608	 lr=0.577532
Epoch[032] Batch [0549]/[0716]	Speed: 25.839466 samples/sec	 accuracy=40.457792	 loss=2.607609	 lr=0.578744
Epoch[032] Batch [0599]/[0716]	Speed: 26.180778 samples/sec	 accuracy=40.345238	 loss=2.610889	 lr=0.579956
Epoch[032] Batch [0649]/[0716]	Speed: 25.962524 samples/sec	 accuracy=40.324176	 loss=2.615758	 lr=0.581168
Epoch[032] Batch [0699]/[0716]	Speed: 26.003069 samples/sec	 accuracy=40.344388	 loss=2.617639	 lr=0.582380
Batch [0049]/[0057]: acc-top1=37.535714 acc-top5=63.821429
[Epoch 032] training: accuracy=40.290802	 loss=2.618354
[Epoch 032] speed: 26 samples/sec	time cost: 1605.250572
[Epoch 032] validation: acc-top1=37.087513 acc-top5=64.243942 loss=3.106045
Epoch[033] Batch [0049]/[0716]	Speed: 23.064106 samples/sec	 accuracy=41.642857	 loss=2.595060	 lr=0.583979
Epoch[033] Batch [0099]/[0716]	Speed: 25.766225 samples/sec	 accuracy=41.571429	 loss=2.576034	 lr=0.585191
Epoch[033] Batch [0149]/[0716]	Speed: 26.009363 samples/sec	 accuracy=41.583333	 loss=2.562437	 lr=0.586403
Epoch[033] Batch [0199]/[0716]	Speed: 25.779128 samples/sec	 accuracy=41.339286	 loss=2.562209	 lr=0.587615
Epoch[033] Batch [0249]/[0716]	Speed: 26.256692 samples/sec	 accuracy=41.142857	 loss=2.571277	 lr=0.588827
Epoch[033] Batch [0299]/[0716]	Speed: 26.181813 samples/sec	 accuracy=41.065476	 loss=2.580894	 lr=0.590039
Epoch[033] Batch [0349]/[0716]	Speed: 25.952316 samples/sec	 accuracy=40.826531	 loss=2.593261	 lr=0.591250
Epoch[033] Batch [0399]/[0716]	Speed: 26.042723 samples/sec	 accuracy=40.785714	 loss=2.594411	 lr=0.592462
Epoch[033] Batch [0449]/[0716]	Speed: 25.768670 samples/sec	 accuracy=40.551587	 loss=2.601984	 lr=0.593674
Epoch[033] Batch [0499]/[0716]	Speed: 26.709602 samples/sec	 accuracy=40.578571	 loss=2.598162	 lr=0.594886
Epoch[033] Batch [0549]/[0716]	Speed: 26.176398 samples/sec	 accuracy=40.366883	 loss=2.604803	 lr=0.596098
Epoch[033] Batch [0599]/[0716]	Speed: 26.137134 samples/sec	 accuracy=40.273810	 loss=2.607285	 lr=0.597310
Epoch[033] Batch [0649]/[0716]	Speed: 25.976853 samples/sec	 accuracy=40.200549	 loss=2.611211	 lr=0.598522
Epoch[033] Batch [0699]/[0716]	Speed: 25.769441 samples/sec	 accuracy=40.132653	 loss=2.612743	 lr=0.599733
Batch [0049]/[0057]: acc-top1=39.000000 acc-top5=66.571429
[Epoch 033] training: accuracy=40.106245	 loss=2.613255
[Epoch 033] speed: 25 samples/sec	time cost: 1605.340315
[Epoch 033] validation: acc-top1=39.029869 acc-top5=66.677109 loss=3.023628
Epoch[034] Batch [0049]/[0716]	Speed: 23.018723 samples/sec	 accuracy=40.464286	 loss=2.595147	 lr=0.600000
Epoch[034] Batch [0099]/[0716]	Speed: 25.849333 samples/sec	 accuracy=39.750000	 loss=2.631896	 lr=0.599999
Epoch[034] Batch [0149]/[0716]	Speed: 25.886694 samples/sec	 accuracy=39.630952	 loss=2.652589	 lr=0.599997
Epoch[034] Batch [0199]/[0716]	Speed: 26.168204 samples/sec	 accuracy=39.705357	 loss=2.652959	 lr=0.599995
Epoch[034] Batch [0249]/[0716]	Speed: 26.450335 samples/sec	 accuracy=40.114286	 loss=2.634724	 lr=0.599993
Epoch[034] Batch [0299]/[0716]	Speed: 25.894048 samples/sec	 accuracy=40.029762	 loss=2.639226	 lr=0.599990
Epoch[034] Batch [0349]/[0716]	Speed: 25.983282 samples/sec	 accuracy=39.974490	 loss=2.635368	 lr=0.599986
Epoch[034] Batch [0399]/[0716]	Speed: 25.870557 samples/sec	 accuracy=40.102679	 loss=2.632239	 lr=0.599982
Epoch[034] Batch [0449]/[0716]	Speed: 26.264182 samples/sec	 accuracy=40.234127	 loss=2.627281	 lr=0.599977
Epoch[034] Batch [0499]/[0716]	Speed: 26.171545 samples/sec	 accuracy=40.221429	 loss=2.625534	 lr=0.599972
Epoch[034] Batch [0549]/[0716]	Speed: 25.815388 samples/sec	 accuracy=40.230519	 loss=2.624424	 lr=0.599966
Epoch[034] Batch [0599]/[0716]	Speed: 25.863460 samples/sec	 accuracy=40.175595	 loss=2.624224	 lr=0.599960
Epoch[034] Batch [0649]/[0716]	Speed: 26.052460 samples/sec	 accuracy=40.304945	 loss=2.620148	 lr=0.599953
Epoch[034] Batch [0699]/[0716]	Speed: 26.179236 samples/sec	 accuracy=40.293367	 loss=2.621201	 lr=0.599945
Batch [0049]/[0057]: acc-top1=37.928571 acc-top5=64.892857
[Epoch 034] training: accuracy=40.335694	 loss=2.620619
[Epoch 034] speed: 25 samples/sec	time cost: 1608.123024
[Epoch 034] validation: acc-top1=37.698410 acc-top5=64.713867 loss=3.151084
Epoch[035] Batch [0049]/[0716]	Speed: 23.216549 samples/sec	 accuracy=41.250000	 loss=2.598375	 lr=0.599935
Epoch[035] Batch [0099]/[0716]	Speed: 26.157008 samples/sec	 accuracy=41.000000	 loss=2.591751	 lr=0.599926
Epoch[035] Batch [0149]/[0716]	Speed: 25.758560 samples/sec	 accuracy=41.202381	 loss=2.579619	 lr=0.599917
Epoch[035] Batch [0199]/[0716]	Speed: 26.553167 samples/sec	 accuracy=40.383929	 loss=2.615164	 lr=0.599907
Epoch[035] Batch [0249]/[0716]	Speed: 25.847235 samples/sec	 accuracy=40.392857	 loss=2.618869	 lr=0.599896
Epoch[035] Batch [0299]/[0716]	Speed: 26.560500 samples/sec	 accuracy=40.410714	 loss=2.612915	 lr=0.599886
Epoch[035] Batch [0349]/[0716]	Speed: 26.161215 samples/sec	 accuracy=40.494898	 loss=2.615025	 lr=0.599874
Epoch[035] Batch [0399]/[0716]	Speed: 25.886814 samples/sec	 accuracy=40.250000	 loss=2.620538	 lr=0.599862
Epoch[035] Batch [0449]/[0716]	Speed: 26.113213 samples/sec	 accuracy=40.146825	 loss=2.623075	 lr=0.599849
Epoch[035] Batch [0499]/[0716]	Speed: 25.974832 samples/sec	 accuracy=40.210714	 loss=2.615584	 lr=0.599836
Epoch[035] Batch [0549]/[0716]	Speed: 25.936823 samples/sec	 accuracy=40.181818	 loss=2.617834	 lr=0.599823
Epoch[035] Batch [0599]/[0716]	Speed: 25.975314 samples/sec	 accuracy=40.261905	 loss=2.619830	 lr=0.599808
Epoch[035] Batch [0649]/[0716]	Speed: 25.934366 samples/sec	 accuracy=40.195055	 loss=2.622549	 lr=0.599793
Epoch[035] Batch [0699]/[0716]	Speed: 26.152935 samples/sec	 accuracy=40.145408	 loss=2.621879	 lr=0.599778
Batch [0049]/[0057]: acc-top1=34.357143 acc-top5=62.607143
[Epoch 035] training: accuracy=40.143655	 loss=2.620094
[Epoch 035] speed: 26 samples/sec	time cost: 1602.861737
[Epoch 035] validation: acc-top1=34.111320 acc-top5=62.322472 loss=3.443533
Epoch[036] Batch [0049]/[0716]	Speed: 23.100613 samples/sec	 accuracy=41.107143	 loss=2.583909	 lr=0.599757
Epoch[036] Batch [0099]/[0716]	Speed: 25.795803 samples/sec	 accuracy=40.500000	 loss=2.596873	 lr=0.599740
Epoch[036] Batch [0149]/[0716]	Speed: 25.520905 samples/sec	 accuracy=40.583333	 loss=2.594647	 lr=0.599723
Epoch[036] Batch [0199]/[0716]	Speed: 25.731086 samples/sec	 accuracy=40.339286	 loss=2.598095	 lr=0.599706
Epoch[036] Batch [0249]/[0716]	Speed: 26.038532 samples/sec	 accuracy=40.350000	 loss=2.602128	 lr=0.599687
Epoch[036] Batch [0299]/[0716]	Speed: 25.846919 samples/sec	 accuracy=40.541667	 loss=2.599056	 lr=0.599668
Epoch[036] Batch [0349]/[0716]	Speed: 26.052455 samples/sec	 accuracy=40.367347	 loss=2.604795	 lr=0.599649
Epoch[036] Batch [0399]/[0716]	Speed: 26.259614 samples/sec	 accuracy=40.513393	 loss=2.606292	 lr=0.599629
Epoch[036] Batch [0449]/[0716]	Speed: 26.276524 samples/sec	 accuracy=40.579365	 loss=2.602590	 lr=0.599609
Epoch[036] Batch [0499]/[0716]	Speed: 26.288685 samples/sec	 accuracy=40.550000	 loss=2.600892	 lr=0.599588
Epoch[036] Batch [0549]/[0716]	Speed: 26.259032 samples/sec	 accuracy=40.464286	 loss=2.602254	 lr=0.599566
Epoch[036] Batch [0599]/[0716]	Speed: 26.104929 samples/sec	 accuracy=40.410714	 loss=2.605549	 lr=0.599544
Epoch[036] Batch [0649]/[0716]	Speed: 26.059521 samples/sec	 accuracy=40.348901	 loss=2.610037	 lr=0.599521
Epoch[036] Batch [0699]/[0716]	Speed: 26.223239 samples/sec	 accuracy=40.367347	 loss=2.608175	 lr=0.599498
Batch [0049]/[0057]: acc-top1=37.500000 acc-top5=64.928571
[Epoch 036] training: accuracy=40.373105	 loss=2.608911
[Epoch 036] speed: 25 samples/sec	time cost: 1608.144141
[Epoch 036] validation: acc-top1=37.270260 acc-top5=64.948830 loss=3.311936
Epoch[037] Batch [0049]/[0716]	Speed: 22.884770 samples/sec	 accuracy=42.321429	 loss=2.544781	 lr=0.599467
Epoch[037] Batch [0099]/[0716]	Speed: 25.732289 samples/sec	 accuracy=41.107143	 loss=2.597900	 lr=0.599442
Epoch[037] Batch [0149]/[0716]	Speed: 26.307500 samples/sec	 accuracy=41.440476	 loss=2.584603	 lr=0.599417
Epoch[037] Batch [0199]/[0716]	Speed: 25.967458 samples/sec	 accuracy=40.866071	 loss=2.597503	 lr=0.599391
Epoch[037] Batch [0249]/[0716]	Speed: 26.442186 samples/sec	 accuracy=40.850000	 loss=2.605127	 lr=0.599365
Epoch[037] Batch [0299]/[0716]	Speed: 25.838751 samples/sec	 accuracy=40.976190	 loss=2.599195	 lr=0.599339
Epoch[037] Batch [0349]/[0716]	Speed: 25.691043 samples/sec	 accuracy=40.872449	 loss=2.603590	 lr=0.599311
Epoch[037] Batch [0399]/[0716]	Speed: 26.023868 samples/sec	 accuracy=40.901786	 loss=2.599807	 lr=0.599284
Epoch[037] Batch [0449]/[0716]	Speed: 26.039679 samples/sec	 accuracy=40.908730	 loss=2.602759	 lr=0.599255
Epoch[037] Batch [0499]/[0716]	Speed: 25.970191 samples/sec	 accuracy=40.928571	 loss=2.601387	 lr=0.599226
Epoch[037] Batch [0549]/[0716]	Speed: 26.236630 samples/sec	 accuracy=40.753247	 loss=2.604611	 lr=0.599197
Epoch[037] Batch [0599]/[0716]	Speed: 25.840750 samples/sec	 accuracy=40.729167	 loss=2.602457	 lr=0.599167
Epoch[037] Batch [0649]/[0716]	Speed: 25.890329 samples/sec	 accuracy=40.774725	 loss=2.602105	 lr=0.599136
Epoch[037] Batch [0699]/[0716]	Speed: 25.825955 samples/sec	 accuracy=40.767857	 loss=2.607335	 lr=0.599105
Batch [0049]/[0057]: acc-top1=38.285714 acc-top5=64.928571
[Epoch 037] training: accuracy=40.779629	 loss=2.605270
[Epoch 037] speed: 25 samples/sec	time cost: 1612.446826
[Epoch 037] validation: acc-top1=38.575603 acc-top5=65.705933 loss=2.988366
Epoch[038] Batch [0049]/[0716]	Speed: 23.211249 samples/sec	 accuracy=42.392857	 loss=2.496944	 lr=0.599064
Epoch[038] Batch [0099]/[0716]	Speed: 26.335162 samples/sec	 accuracy=41.214286	 loss=2.568050	 lr=0.599031
Epoch[038] Batch [0149]/[0716]	Speed: 25.384271 samples/sec	 accuracy=40.916667	 loss=2.574191	 lr=0.598998
Epoch[038] Batch [0199]/[0716]	Speed: 25.951347 samples/sec	 accuracy=41.276786	 loss=2.559201	 lr=0.598965
Epoch[038] Batch [0249]/[0716]	Speed: 26.172418 samples/sec	 accuracy=41.235714	 loss=2.568069	 lr=0.598931
Epoch[038] Batch [0299]/[0716]	Speed: 25.816063 samples/sec	 accuracy=41.238095	 loss=2.566328	 lr=0.598896
Epoch[038] Batch [0349]/[0716]	Speed: 25.870401 samples/sec	 accuracy=41.163265	 loss=2.579166	 lr=0.598861
Epoch[038] Batch [0399]/[0716]	Speed: 26.471192 samples/sec	 accuracy=41.236607	 loss=2.579084	 lr=0.598826
Epoch[038] Batch [0449]/[0716]	Speed: 25.847501 samples/sec	 accuracy=41.432540	 loss=2.572993	 lr=0.598789
Epoch[038] Batch [0499]/[0716]	Speed: 26.450709 samples/sec	 accuracy=41.464286	 loss=2.576685	 lr=0.598753
Epoch[038] Batch [0549]/[0716]	Speed: 25.937391 samples/sec	 accuracy=41.545455	 loss=2.573329	 lr=0.598715
Epoch[038] Batch [0599]/[0716]	Speed: 26.020914 samples/sec	 accuracy=41.535714	 loss=2.574170	 lr=0.598678
Epoch[038] Batch [0649]/[0716]	Speed: 26.004914 samples/sec	 accuracy=41.497253	 loss=2.573536	 lr=0.598639
Epoch[038] Batch [0699]/[0716]	Speed: 25.947641 samples/sec	 accuracy=41.451531	 loss=2.574532	 lr=0.598600
Batch [0049]/[0057]: acc-top1=38.500000 acc-top5=66.714286
[Epoch 038] training: accuracy=41.433061	 loss=2.575812
[Epoch 038] speed: 25 samples/sec	time cost: 1607.562028
[Epoch 038] validation: acc-top1=39.061192 acc-top5=66.572685 loss=2.938410
Epoch[039] Batch [0049]/[0717]	Speed: 22.895729 samples/sec	 accuracy=42.750000	 loss=2.519570	 lr=0.598548
Epoch[039] Batch [0099]/[0717]	Speed: 26.233018 samples/sec	 accuracy=41.892857	 loss=2.536098	 lr=0.598508
Epoch[039] Batch [0149]/[0717]	Speed: 25.518493 samples/sec	 accuracy=41.714286	 loss=2.551341	 lr=0.598467
Epoch[039] Batch [0199]/[0717]	Speed: 25.995687 samples/sec	 accuracy=41.160714	 loss=2.560477	 lr=0.598426
Epoch[039] Batch [0249]/[0717]	Speed: 26.085421 samples/sec	 accuracy=41.392857	 loss=2.561644	 lr=0.598384
Epoch[039] Batch [0299]/[0717]	Speed: 26.560708 samples/sec	 accuracy=41.029762	 loss=2.578383	 lr=0.598342
Epoch[039] Batch [0349]/[0717]	Speed: 25.563755 samples/sec	 accuracy=40.780612	 loss=2.595518	 lr=0.598299
Epoch[039] Batch [0399]/[0717]	Speed: 26.101109 samples/sec	 accuracy=40.714286	 loss=2.595449	 lr=0.598255
Epoch[039] Batch [0449]/[0717]	Speed: 25.648612 samples/sec	 accuracy=40.992063	 loss=2.589828	 lr=0.598211
Epoch[039] Batch [0499]/[0717]	Speed: 26.135914 samples/sec	 accuracy=41.221429	 loss=2.585315	 lr=0.598167
Epoch[039] Batch [0549]/[0717]	Speed: 25.959904 samples/sec	 accuracy=41.061688	 loss=2.589984	 lr=0.598121
Epoch[039] Batch [0599]/[0717]	Speed: 25.683682 samples/sec	 accuracy=40.988095	 loss=2.591246	 lr=0.598076
Epoch[039] Batch [0649]/[0717]	Speed: 25.945568 samples/sec	 accuracy=40.868132	 loss=2.595315	 lr=0.598030
Epoch[039] Batch [0699]/[0717]	Speed: 26.051164 samples/sec	 accuracy=40.923469	 loss=2.596113	 lr=0.597983
Batch [0049]/[0057]: acc-top1=40.142857 acc-top5=68.571429
[Epoch 039] training: accuracy=40.872186	 loss=2.599686
[Epoch 039] speed: 25 samples/sec	time cost: 1614.900722
[Epoch 039] validation: acc-top1=39.745197 acc-top5=67.512527 loss=2.767448
Epoch[040] Batch [0049]/[0716]	Speed: 23.112241 samples/sec	 accuracy=43.214286	 loss=2.537515	 lr=0.597919
Epoch[040] Batch [0099]/[0716]	Speed: 25.865744 samples/sec	 accuracy=41.714286	 loss=2.554267	 lr=0.597871
Epoch[040] Batch [0149]/[0716]	Speed: 26.286731 samples/sec	 accuracy=41.642857	 loss=2.554849	 lr=0.597823
Epoch[040] Batch [0199]/[0716]	Speed: 25.775889 samples/sec	 accuracy=42.053571	 loss=2.547576	 lr=0.597774
Epoch[040] Batch [0249]/[0716]	Speed: 26.246788 samples/sec	 accuracy=41.885714	 loss=2.556390	 lr=0.597724
Epoch[040] Batch [0299]/[0716]	Speed: 26.294264 samples/sec	 accuracy=42.130952	 loss=2.546982	 lr=0.597674
Epoch[040] Batch [0349]/[0716]	Speed: 26.164829 samples/sec	 accuracy=41.984694	 loss=2.553759	 lr=0.597623
Epoch[040] Batch [0399]/[0716]	Speed: 26.058352 samples/sec	 accuracy=42.053571	 loss=2.549845	 lr=0.597572
Epoch[040] Batch [0449]/[0716]	Speed: 25.971595 samples/sec	 accuracy=41.976190	 loss=2.557489	 lr=0.597520
Epoch[040] Batch [0499]/[0716]	Speed: 25.998734 samples/sec	 accuracy=41.832143	 loss=2.559923	 lr=0.597467
Epoch[040] Batch [0549]/[0716]	Speed: 26.151548 samples/sec	 accuracy=41.633117	 loss=2.566483	 lr=0.597414
Epoch[040] Batch [0599]/[0716]	Speed: 25.829497 samples/sec	 accuracy=41.610119	 loss=2.568904	 lr=0.597361
Epoch[040] Batch [0649]/[0716]	Speed: 26.181586 samples/sec	 accuracy=41.554945	 loss=2.567654	 lr=0.597307
Epoch[040] Batch [0699]/[0716]	Speed: 26.099743 samples/sec	 accuracy=41.622449	 loss=2.563931	 lr=0.597252
Batch [0049]/[0057]: acc-top1=37.892857 acc-top5=65.678571
[Epoch 040] training: accuracy=41.597666	 loss=2.565346
[Epoch 040] speed: 26 samples/sec	time cost: 1603.684077
[Epoch 040] validation: acc-top1=37.082291 acc-top5=64.776520 loss=3.187361
Epoch[041] Batch [0049]/[0716]	Speed: 23.076317 samples/sec	 accuracy=41.071429	 loss=2.551363	 lr=0.597179
Epoch[041] Batch [0099]/[0716]	Speed: 26.176082 samples/sec	 accuracy=41.821429	 loss=2.537200	 lr=0.597123
Epoch[041] Batch [0149]/[0716]	Speed: 26.246344 samples/sec	 accuracy=41.488095	 loss=2.552508	 lr=0.597067
Epoch[041] Batch [0199]/[0716]	Speed: 25.942405 samples/sec	 accuracy=41.571429	 loss=2.547877	 lr=0.597010
Epoch[041] Batch [0249]/[0716]	Speed: 25.826344 samples/sec	 accuracy=41.678571	 loss=2.545044	 lr=0.596953
Epoch[041] Batch [0299]/[0716]	Speed: 26.542148 samples/sec	 accuracy=41.357143	 loss=2.559953	 lr=0.596895
Epoch[041] Batch [0349]/[0716]	Speed: 25.768680 samples/sec	 accuracy=41.290816	 loss=2.566765	 lr=0.596836
Epoch[041] Batch [0399]/[0716]	Speed: 26.314557 samples/sec	 accuracy=41.236607	 loss=2.569311	 lr=0.596777
Epoch[041] Batch [0449]/[0716]	Speed: 26.223474 samples/sec	 accuracy=41.281746	 loss=2.567168	 lr=0.596717
Epoch[041] Batch [0499]/[0716]	Speed: 26.264068 samples/sec	 accuracy=41.221429	 loss=2.570360	 lr=0.596657
Epoch[041] Batch [0549]/[0716]	Speed: 25.900373 samples/sec	 accuracy=41.298701	 loss=2.570690	 lr=0.596596
Epoch[041] Batch [0599]/[0716]	Speed: 25.984729 samples/sec	 accuracy=41.235119	 loss=2.574574	 lr=0.596535
Epoch[041] Batch [0649]/[0716]	Speed: 26.175119 samples/sec	 accuracy=41.425824	 loss=2.570675	 lr=0.596473
Epoch[041] Batch [0699]/[0716]	Speed: 26.411196 samples/sec	 accuracy=41.433673	 loss=2.569697	 lr=0.596411
Batch [0049]/[0057]: acc-top1=39.107143 acc-top5=66.428571
[Epoch 041] training: accuracy=41.445531	 loss=2.570545
[Epoch 041] speed: 26 samples/sec	time cost: 1600.349185
[Epoch 041] validation: acc-top1=38.664368 acc-top5=65.507515 loss=3.113148
Epoch[042] Batch [0049]/[0716]	Speed: 23.283983 samples/sec	 accuracy=42.500000	 loss=2.524979	 lr=0.596328
Epoch[042] Batch [0099]/[0716]	Speed: 26.540783 samples/sec	 accuracy=41.571429	 loss=2.546194	 lr=0.596264
Epoch[042] Batch [0149]/[0716]	Speed: 25.850998 samples/sec	 accuracy=41.166667	 loss=2.543871	 lr=0.596200
Epoch[042] Batch [0199]/[0716]	Speed: 26.035624 samples/sec	 accuracy=41.151786	 loss=2.548860	 lr=0.596135
Epoch[042] Batch [0249]/[0716]	Speed: 25.947447 samples/sec	 accuracy=41.150000	 loss=2.560257	 lr=0.596070
Epoch[042] Batch [0299]/[0716]	Speed: 26.095146 samples/sec	 accuracy=40.994048	 loss=2.571165	 lr=0.596004
Epoch[042] Batch [0349]/[0716]	Speed: 26.292415 samples/sec	 accuracy=40.887755	 loss=2.575034	 lr=0.595937
Epoch[042] Batch [0399]/[0716]	Speed: 25.603289 samples/sec	 accuracy=40.941964	 loss=2.575919	 lr=0.595871
Epoch[042] Batch [0449]/[0716]	Speed: 25.970825 samples/sec	 accuracy=40.924603	 loss=2.574126	 lr=0.595803
Epoch[042] Batch [0499]/[0716]	Speed: 25.986783 samples/sec	 accuracy=40.975000	 loss=2.571451	 lr=0.595735
Epoch[042] Batch [0549]/[0716]	Speed: 26.095077 samples/sec	 accuracy=41.081169	 loss=2.572190	 lr=0.595667
Epoch[042] Batch [0599]/[0716]	Speed: 26.489078 samples/sec	 accuracy=41.089286	 loss=2.572516	 lr=0.595598
Epoch[042] Batch [0649]/[0716]	Speed: 26.081014 samples/sec	 accuracy=41.170330	 loss=2.573830	 lr=0.595528
Epoch[042] Batch [0699]/[0716]	Speed: 25.926891 samples/sec	 accuracy=41.178571	 loss=2.568359	 lr=0.595458
Batch [0049]/[0057]: acc-top1=39.607143 acc-top5=67.357143
[Epoch 042] training: accuracy=41.173683	 loss=2.570978
[Epoch 042] speed: 26 samples/sec	time cost: 1602.927724
[Epoch 042] validation: acc-top1=40.063702 acc-top5=67.658730 loss=2.853336
Epoch[043] Batch [0049]/[0716]	Speed: 22.970421 samples/sec	 accuracy=40.892857	 loss=2.568521	 lr=0.595364
Epoch[043] Batch [0099]/[0716]	Speed: 26.100966 samples/sec	 accuracy=40.875000	 loss=2.599455	 lr=0.595293
Epoch[043] Batch [0149]/[0716]	Speed: 25.776017 samples/sec	 accuracy=41.309524	 loss=2.581089	 lr=0.595221
Epoch[043] Batch [0199]/[0716]	Speed: 26.139985 samples/sec	 accuracy=41.776786	 loss=2.560042	 lr=0.595148
Epoch[043] Batch [0249]/[0716]	Speed: 26.000183 samples/sec	 accuracy=41.728571	 loss=2.555078	 lr=0.595075
Epoch[043] Batch [0299]/[0716]	Speed: 26.136694 samples/sec	 accuracy=41.648810	 loss=2.562608	 lr=0.595002
Epoch[043] Batch [0349]/[0716]	Speed: 26.377447 samples/sec	 accuracy=41.596939	 loss=2.561207	 lr=0.594928
Epoch[043] Batch [0399]/[0716]	Speed: 25.688004 samples/sec	 accuracy=41.486607	 loss=2.565597	 lr=0.594853
Epoch[043] Batch [0449]/[0716]	Speed: 25.776501 samples/sec	 accuracy=41.591270	 loss=2.563439	 lr=0.594778
Epoch[043] Batch [0499]/[0716]	Speed: 26.173677 samples/sec	 accuracy=41.546429	 loss=2.564291	 lr=0.594702
Epoch[043] Batch [0549]/[0716]	Speed: 25.951383 samples/sec	 accuracy=41.435065	 loss=2.566072	 lr=0.594626
Epoch[043] Batch [0599]/[0716]	Speed: 25.780101 samples/sec	 accuracy=41.339286	 loss=2.567195	 lr=0.594549
Epoch[043] Batch [0649]/[0716]	Speed: 26.214896 samples/sec	 accuracy=41.291209	 loss=2.570692	 lr=0.594472
Epoch[043] Batch [0699]/[0716]	Speed: 25.618371 samples/sec	 accuracy=41.344388	 loss=2.569832	 lr=0.594394
Batch [0049]/[0057]: acc-top1=38.892857 acc-top5=66.571429
[Epoch 043] training: accuracy=41.363228	 loss=2.569593
[Epoch 043] speed: 25 samples/sec	time cost: 1609.949947
[Epoch 043] validation: acc-top1=37.588764 acc-top5=65.136795 loss=3.041454
Epoch[044] Batch [0049]/[0716]	Speed: 23.071045 samples/sec	 accuracy=41.750000	 loss=2.522653	 lr=0.594290
Epoch[044] Batch [0099]/[0716]	Speed: 26.093433 samples/sec	 accuracy=41.767857	 loss=2.533174	 lr=0.594211
Epoch[044] Batch [0149]/[0716]	Speed: 26.209539 samples/sec	 accuracy=41.666667	 loss=2.540493	 lr=0.594131
Epoch[044] Batch [0199]/[0716]	Speed: 26.070302 samples/sec	 accuracy=41.776786	 loss=2.527162	 lr=0.594051
Epoch[044] Batch [0249]/[0716]	Speed: 25.775290 samples/sec	 accuracy=41.928571	 loss=2.528205	 lr=0.593970
Epoch[044] Batch [0299]/[0716]	Speed: 25.758498 samples/sec	 accuracy=41.851190	 loss=2.536737	 lr=0.593889
Epoch[044] Batch [0349]/[0716]	Speed: 26.467934 samples/sec	 accuracy=41.846939	 loss=2.536750	 lr=0.593807
Epoch[044] Batch [0399]/[0716]	Speed: 26.337882 samples/sec	 accuracy=41.553571	 loss=2.544072	 lr=0.593725
Epoch[044] Batch [0449]/[0716]	Speed: 26.346457 samples/sec	 accuracy=41.452381	 loss=2.544995	 lr=0.593642
Epoch[044] Batch [0499]/[0716]	Speed: 25.903964 samples/sec	 accuracy=41.471429	 loss=2.545222	 lr=0.593558
Epoch[044] Batch [0549]/[0716]	Speed: 26.007588 samples/sec	 accuracy=41.577922	 loss=2.544006	 lr=0.593474
Epoch[044] Batch [0599]/[0716]	Speed: 26.031290 samples/sec	 accuracy=41.616071	 loss=2.545530	 lr=0.593390
Epoch[044] Batch [0649]/[0716]	Speed: 26.285494 samples/sec	 accuracy=41.626374	 loss=2.547979	 lr=0.593305
Epoch[044] Batch [0699]/[0716]	Speed: 25.921892 samples/sec	 accuracy=41.625000	 loss=2.546745	 lr=0.593219
Batch [0049]/[0057]: acc-top1=39.428571 acc-top5=64.928571
[Epoch 044] training: accuracy=41.647546	 loss=2.547177
[Epoch 044] speed: 26 samples/sec	time cost: 1602.067318
[Epoch 044] validation: acc-top1=39.719090 acc-top5=66.729324 loss=2.808742
Epoch[045] Batch [0049]/[0716]	Speed: 22.905383 samples/sec	 accuracy=42.464286	 loss=2.456680	 lr=0.593105
Epoch[045] Batch [0099]/[0716]	Speed: 25.986913 samples/sec	 accuracy=41.892857	 loss=2.495314	 lr=0.593018
Epoch[045] Batch [0149]/[0716]	Speed: 25.844232 samples/sec	 accuracy=42.071429	 loss=2.510984	 lr=0.592931
Epoch[045] Batch [0199]/[0716]	Speed: 26.165683 samples/sec	 accuracy=42.000000	 loss=2.520793	 lr=0.592843
Epoch[045] Batch [0249]/[0716]	Speed: 25.595584 samples/sec	 accuracy=42.171429	 loss=2.512258	 lr=0.592754
Epoch[045] Batch [0299]/[0716]	Speed: 26.200776 samples/sec	 accuracy=41.922619	 loss=2.514831	 lr=0.592665
Epoch[045] Batch [0349]/[0716]	Speed: 26.130943 samples/sec	 accuracy=41.801020	 loss=2.518199	 lr=0.592576
Epoch[045] Batch [0399]/[0716]	Speed: 26.305072 samples/sec	 accuracy=41.776786	 loss=2.526446	 lr=0.592486
Epoch[045] Batch [0449]/[0716]	Speed: 26.107087 samples/sec	 accuracy=41.809524	 loss=2.528136	 lr=0.592395
Epoch[045] Batch [0499]/[0716]	Speed: 26.400751 samples/sec	 accuracy=41.639286	 loss=2.534170	 lr=0.592304
Epoch[045] Batch [0549]/[0716]	Speed: 26.180867 samples/sec	 accuracy=41.535714	 loss=2.538995	 lr=0.592212
Epoch[045] Batch [0599]/[0716]	Speed: 25.671495 samples/sec	 accuracy=41.485119	 loss=2.544558	 lr=0.592120
Epoch[045] Batch [0649]/[0716]	Speed: 26.289344 samples/sec	 accuracy=41.453297	 loss=2.544627	 lr=0.592027
Epoch[045] Batch [0699]/[0716]	Speed: 26.065485 samples/sec	 accuracy=41.471939	 loss=2.546974	 lr=0.591934
Batch [0049]/[0057]: acc-top1=39.178571 acc-top5=65.607143
[Epoch 045] training: accuracy=41.453013	 loss=2.546984
[Epoch 045] speed: 26 samples/sec	time cost: 1602.255873
[Epoch 045] validation: acc-top1=39.343151 acc-top5=66.060982 loss=2.946098
Epoch[046] Batch [0049]/[0716]	Speed: 23.184094 samples/sec	 accuracy=42.571429	 loss=2.426802	 lr=0.591810
Epoch[046] Batch [0099]/[0716]	Speed: 26.310352 samples/sec	 accuracy=42.464286	 loss=2.450460	 lr=0.591715
Epoch[046] Batch [0149]/[0716]	Speed: 26.164802 samples/sec	 accuracy=42.380952	 loss=2.474999	 lr=0.591620
Epoch[046] Batch [0199]/[0716]	Speed: 26.211547 samples/sec	 accuracy=42.830357	 loss=2.462999	 lr=0.591525
Epoch[046] Batch [0249]/[0716]	Speed: 26.498407 samples/sec	 accuracy=42.864286	 loss=2.471603	 lr=0.591429
Epoch[046] Batch [0299]/[0716]	Speed: 26.510914 samples/sec	 accuracy=42.767857	 loss=2.480680	 lr=0.591332
Epoch[046] Batch [0349]/[0716]	Speed: 26.242053 samples/sec	 accuracy=42.423469	 loss=2.500421	 lr=0.591235
Epoch[046] Batch [0399]/[0716]	Speed: 26.016496 samples/sec	 accuracy=42.227679	 loss=2.513370	 lr=0.591137
Epoch[046] Batch [0449]/[0716]	Speed: 26.276595 samples/sec	 accuracy=42.107143	 loss=2.518077	 lr=0.591039
Epoch[046] Batch [0499]/[0716]	Speed: 26.309015 samples/sec	 accuracy=42.171429	 loss=2.520024	 lr=0.590940
Epoch[046] Batch [0549]/[0716]	Speed: 25.691037 samples/sec	 accuracy=42.175325	 loss=2.522485	 lr=0.590840
Epoch[046] Batch [0599]/[0716]	Speed: 25.744045 samples/sec	 accuracy=42.157738	 loss=2.524892	 lr=0.590740
Epoch[046] Batch [0649]/[0716]	Speed: 26.226799 samples/sec	 accuracy=42.153846	 loss=2.525662	 lr=0.590640
Epoch[046] Batch [0699]/[0716]	Speed: 25.978577 samples/sec	 accuracy=42.051020	 loss=2.532101	 lr=0.590539
Batch [0049]/[0057]: acc-top1=37.214286 acc-top5=64.785714
[Epoch 046] training: accuracy=41.981744	 loss=2.533463
[Epoch 046] speed: 26 samples/sec	time cost: 1597.698730
[Epoch 046] validation: acc-top1=38.392857 acc-top5=65.324768 loss=3.090705
Epoch[047] Batch [0049]/[0717]	Speed: 22.818811 samples/sec	 accuracy=43.250000	 loss=2.525652	 lr=0.590405
Epoch[047] Batch [0099]/[0717]	Speed: 25.975472 samples/sec	 accuracy=42.428571	 loss=2.522213	 lr=0.590303
Epoch[047] Batch [0149]/[0717]	Speed: 26.142353 samples/sec	 accuracy=42.166667	 loss=2.528513	 lr=0.590200
Epoch[047] Batch [0199]/[0717]	Speed: 25.628969 samples/sec	 accuracy=42.071429	 loss=2.525578	 lr=0.590097
Epoch[047] Batch [0249]/[0717]	Speed: 25.758700 samples/sec	 accuracy=41.821429	 loss=2.544532	 lr=0.589993
Epoch[047] Batch [0299]/[0717]	Speed: 26.122612 samples/sec	 accuracy=41.964286	 loss=2.547284	 lr=0.589889
Epoch[047] Batch [0349]/[0717]	Speed: 26.031863 samples/sec	 accuracy=41.979592	 loss=2.543991	 lr=0.589784
Epoch[047] Batch [0399]/[0717]	Speed: 26.046028 samples/sec	 accuracy=41.977679	 loss=2.543423	 lr=0.589678
Epoch[047] Batch [0449]/[0717]	Speed: 25.994431 samples/sec	 accuracy=41.916667	 loss=2.549081	 lr=0.589573
Epoch[047] Batch [0499]/[0717]	Speed: 26.279316 samples/sec	 accuracy=41.921429	 loss=2.551751	 lr=0.589466
Epoch[047] Batch [0549]/[0717]	Speed: 26.488744 samples/sec	 accuracy=41.821429	 loss=2.554188	 lr=0.589359
Epoch[047] Batch [0599]/[0717]	Speed: 25.463195 samples/sec	 accuracy=41.830357	 loss=2.554609	 lr=0.589252
Epoch[047] Batch [0649]/[0717]	Speed: 26.157907 samples/sec	 accuracy=41.769231	 loss=2.555474	 lr=0.589144
Epoch[047] Batch [0699]/[0717]	Speed: 26.741990 samples/sec	 accuracy=41.734694	 loss=2.557658	 lr=0.589035
Batch [0049]/[0057]: acc-top1=38.821429 acc-top5=66.392857
[Epoch 047] training: accuracy=41.704025	 loss=2.560012
[Epoch 047] speed: 25 samples/sec	time cost: 1609.207239
[Epoch 047] validation: acc-top1=38.883667 acc-top5=66.139313 loss=2.953452
Epoch[048] Batch [0049]/[0716]	Speed: 23.312986 samples/sec	 accuracy=42.928571	 loss=2.492467	 lr=0.588889
Epoch[048] Batch [0099]/[0716]	Speed: 26.082832 samples/sec	 accuracy=42.285714	 loss=2.510219	 lr=0.588779
Epoch[048] Batch [0149]/[0716]	Speed: 26.319483 samples/sec	 accuracy=42.190476	 loss=2.513232	 lr=0.588669
Epoch[048] Batch [0199]/[0716]	Speed: 25.896952 samples/sec	 accuracy=41.696429	 loss=2.531376	 lr=0.588558
Epoch[048] Batch [0249]/[0716]	Speed: 26.134549 samples/sec	 accuracy=41.757143	 loss=2.539494	 lr=0.588446
Epoch[048] Batch [0299]/[0716]	Speed: 26.057490 samples/sec	 accuracy=41.529762	 loss=2.546874	 lr=0.588334
Epoch[048] Batch [0349]/[0716]	Speed: 26.258867 samples/sec	 accuracy=41.658163	 loss=2.547531	 lr=0.588222
Epoch[048] Batch [0399]/[0716]	Speed: 26.329067 samples/sec	 accuracy=41.897321	 loss=2.534997	 lr=0.588109
Epoch[048] Batch [0449]/[0716]	Speed: 26.258591 samples/sec	 accuracy=41.948413	 loss=2.534463	 lr=0.587995
Epoch[048] Batch [0499]/[0716]	Speed: 26.311569 samples/sec	 accuracy=41.946429	 loss=2.535245	 lr=0.587881
Epoch[048] Batch [0549]/[0716]	Speed: 26.032512 samples/sec	 accuracy=41.795455	 loss=2.540732	 lr=0.587767
Epoch[048] Batch [0599]/[0716]	Speed: 25.941010 samples/sec	 accuracy=41.800595	 loss=2.542303	 lr=0.587652
Epoch[048] Batch [0649]/[0716]	Speed: 26.014641 samples/sec	 accuracy=41.870879	 loss=2.540178	 lr=0.587536
Epoch[048] Batch [0699]/[0716]	Speed: 25.933379 samples/sec	 accuracy=41.854592	 loss=2.539796	 lr=0.587420
Batch [0049]/[0057]: acc-top1=38.000000 acc-top5=64.321429
[Epoch 048] training: accuracy=41.872007	 loss=2.540452
[Epoch 048] speed: 26 samples/sec	time cost: 1599.934274
[Epoch 048] validation: acc-top1=39.520679 acc-top5=66.421265 loss=2.846389
Epoch[049] Batch [0049]/[0716]	Speed: 23.307317 samples/sec	 accuracy=42.285714	 loss=2.527521	 lr=0.587266
Epoch[049] Batch [0099]/[0716]	Speed: 25.921377 samples/sec	 accuracy=42.321429	 loss=2.534122	 lr=0.587148
Epoch[049] Batch [0149]/[0716]	Speed: 26.642789 samples/sec	 accuracy=42.559524	 loss=2.512904	 lr=0.587031
Epoch[049] Batch [0199]/[0716]	Speed: 26.361730 samples/sec	 accuracy=42.392857	 loss=2.521090	 lr=0.586912
Epoch[049] Batch [0249]/[0716]	Speed: 25.900284 samples/sec	 accuracy=42.007143	 loss=2.530169	 lr=0.586793
Epoch[049] Batch [0299]/[0716]	Speed: 25.562556 samples/sec	 accuracy=42.077381	 loss=2.526658	 lr=0.586674
Epoch[049] Batch [0349]/[0716]	Speed: 26.017334 samples/sec	 accuracy=41.959184	 loss=2.534137	 lr=0.586554
Epoch[049] Batch [0399]/[0716]	Speed: 26.194886 samples/sec	 accuracy=41.950893	 loss=2.536147	 lr=0.586433
Epoch[049] Batch [0449]/[0716]	Speed: 26.271712 samples/sec	 accuracy=42.043651	 loss=2.528868	 lr=0.586312
Epoch[049] Batch [0499]/[0716]	Speed: 26.382368 samples/sec	 accuracy=41.953571	 loss=2.533543	 lr=0.586190
Epoch[049] Batch [0549]/[0716]	Speed: 25.612590 samples/sec	 accuracy=41.922078	 loss=2.538448	 lr=0.586068
Epoch[049] Batch [0599]/[0716]	Speed: 25.989516 samples/sec	 accuracy=41.741071	 loss=2.547421	 lr=0.585946
Epoch[049] Batch [0649]/[0716]	Speed: 25.948841 samples/sec	 accuracy=41.780220	 loss=2.544318	 lr=0.585823
Epoch[049] Batch [0699]/[0716]	Speed: 26.425277 samples/sec	 accuracy=41.778061	 loss=2.545970	 lr=0.585699
Batch [0049]/[0057]: acc-top1=40.928571 acc-top5=67.785714
[Epoch 049] training: accuracy=41.754789	 loss=2.547766
[Epoch 049] speed: 26 samples/sec	time cost: 1604.574275
[Epoch 049] validation: acc-top1=40.742481 acc-top5=67.434219 loss=2.752674
Epoch[050] Batch [0049]/[0716]	Speed: 22.773651 samples/sec	 accuracy=42.964286	 loss=2.468011	 lr=0.585535
Epoch[050] Batch [0099]/[0716]	Speed: 25.770624 samples/sec	 accuracy=43.125000	 loss=2.469514	 lr=0.585410
Epoch[050] Batch [0149]/[0716]	Speed: 25.720305 samples/sec	 accuracy=42.797619	 loss=2.480120	 lr=0.585285
Epoch[050] Batch [0199]/[0716]	Speed: 25.864656 samples/sec	 accuracy=42.562500	 loss=2.496999	 lr=0.585159
Epoch[050] Batch [0249]/[0716]	Speed: 26.567561 samples/sec	 accuracy=42.650000	 loss=2.500235	 lr=0.585032
Epoch[050] Batch [0299]/[0716]	Speed: 25.773779 samples/sec	 accuracy=42.714286	 loss=2.507070	 lr=0.584905
Epoch[050] Batch [0349]/[0716]	Speed: 25.838622 samples/sec	 accuracy=42.693878	 loss=2.512727	 lr=0.584778
Epoch[050] Batch [0399]/[0716]	Speed: 25.891270 samples/sec	 accuracy=42.758929	 loss=2.513113	 lr=0.584650
Epoch[050] Batch [0449]/[0716]	Speed: 25.994194 samples/sec	 accuracy=42.591270	 loss=2.522643	 lr=0.584521
Epoch[050] Batch [0499]/[0716]	Speed: 25.572822 samples/sec	 accuracy=42.285714	 loss=2.526504	 lr=0.584392
Epoch[050] Batch [0549]/[0716]	Speed: 26.302255 samples/sec	 accuracy=42.207792	 loss=2.529121	 lr=0.584262
Epoch[050] Batch [0599]/[0716]	Speed: 25.873473 samples/sec	 accuracy=42.205357	 loss=2.532986	 lr=0.584132
Epoch[050] Batch [0649]/[0716]	Speed: 26.084343 samples/sec	 accuracy=42.206044	 loss=2.532388	 lr=0.584002
Epoch[050] Batch [0699]/[0716]	Speed: 26.102479 samples/sec	 accuracy=42.061224	 loss=2.537976	 lr=0.583870
Batch [0049]/[0057]: acc-top1=40.214286 acc-top5=67.535714
[Epoch 050] training: accuracy=42.011672	 loss=2.537719
[Epoch 050] speed: 25 samples/sec	time cost: 1611.373111
[Epoch 050] validation: acc-top1=39.374481 acc-top5=66.656227 loss=2.896744
Epoch[051] Batch [0049]/[0716]	Speed: 22.729073 samples/sec	 accuracy=43.607143	 loss=2.431377	 lr=0.583697
Epoch[051] Batch [0099]/[0716]	Speed: 26.132847 samples/sec	 accuracy=43.446429	 loss=2.476067	 lr=0.583564
Epoch[051] Batch [0149]/[0716]	Speed: 26.137076 samples/sec	 accuracy=43.202381	 loss=2.484554	 lr=0.583431
Epoch[051] Batch [0199]/[0716]	Speed: 25.996560 samples/sec	 accuracy=42.875000	 loss=2.502796	 lr=0.583298
Epoch[051] Batch [0249]/[0716]	Speed: 25.835420 samples/sec	 accuracy=42.864286	 loss=2.504660	 lr=0.583164
Epoch[051] Batch [0299]/[0716]	Speed: 26.217904 samples/sec	 accuracy=42.732143	 loss=2.509099	 lr=0.583029
Epoch[051] Batch [0349]/[0716]	Speed: 26.196507 samples/sec	 accuracy=42.892857	 loss=2.500819	 lr=0.582895
Epoch[051] Batch [0399]/[0716]	Speed: 25.866371 samples/sec	 accuracy=42.843750	 loss=2.503596	 lr=0.582759
Epoch[051] Batch [0449]/[0716]	Speed: 26.406142 samples/sec	 accuracy=42.932540	 loss=2.506452	 lr=0.582623
Epoch[051] Batch [0499]/[0716]	Speed: 25.889115 samples/sec	 accuracy=43.060714	 loss=2.499589	 lr=0.582487
Epoch[051] Batch [0549]/[0716]	Speed: 25.831207 samples/sec	 accuracy=43.006494	 loss=2.503796	 lr=0.582349
Epoch[051] Batch [0599]/[0716]	Speed: 25.923978 samples/sec	 accuracy=42.949405	 loss=2.504992	 lr=0.582212
Epoch[051] Batch [0649]/[0716]	Speed: 26.453781 samples/sec	 accuracy=42.785714	 loss=2.508955	 lr=0.582074
Epoch[051] Batch [0699]/[0716]	Speed: 25.746619 samples/sec	 accuracy=42.630102	 loss=2.517025	 lr=0.581935
Batch [0049]/[0057]: acc-top1=39.750000 acc-top5=66.892857
[Epoch 051] training: accuracy=42.530427	 loss=2.518466
[Epoch 051] speed: 25 samples/sec	time cost: 1605.642464
[Epoch 051] validation: acc-top1=39.494572 acc-top5=66.734543 loss=2.948211
Epoch[052] Batch [0049]/[0716]	Speed: 23.110676 samples/sec	 accuracy=42.714286	 loss=2.506616	 lr=0.581752
Epoch[052] Batch [0099]/[0716]	Speed: 26.130376 samples/sec	 accuracy=41.875000	 loss=2.530999	 lr=0.581612
Epoch[052] Batch [0149]/[0716]	Speed: 26.405341 samples/sec	 accuracy=42.095238	 loss=2.531252	 lr=0.581471
Epoch[052] Batch [0199]/[0716]	Speed: 25.865525 samples/sec	 accuracy=41.875000	 loss=2.531893	 lr=0.581331
Epoch[052] Batch [0249]/[0716]	Speed: 25.416621 samples/sec	 accuracy=41.857143	 loss=2.531675	 lr=0.581189
Epoch[052] Batch [0299]/[0716]	Speed: 26.046293 samples/sec	 accuracy=41.964286	 loss=2.536652	 lr=0.581047
Epoch[052] Batch [0349]/[0716]	Speed: 26.049615 samples/sec	 accuracy=41.867347	 loss=2.545026	 lr=0.580905
Epoch[052] Batch [0399]/[0716]	Speed: 25.925328 samples/sec	 accuracy=41.897321	 loss=2.550613	 lr=0.580762
Epoch[052] Batch [0449]/[0716]	Speed: 26.037914 samples/sec	 accuracy=41.833333	 loss=2.553627	 lr=0.580619
Epoch[052] Batch [0499]/[0716]	Speed: 25.841808 samples/sec	 accuracy=42.000000	 loss=2.548731	 lr=0.580475
Epoch[052] Batch [0549]/[0716]	Speed: 25.811066 samples/sec	 accuracy=42.064935	 loss=2.549023	 lr=0.580330
Epoch[052] Batch [0599]/[0716]	Speed: 26.398160 samples/sec	 accuracy=42.002976	 loss=2.548309	 lr=0.580185
Epoch[052] Batch [0649]/[0716]	Speed: 26.543709 samples/sec	 accuracy=41.931319	 loss=2.549497	 lr=0.580040
Epoch[052] Batch [0699]/[0716]	Speed: 26.185847 samples/sec	 accuracy=41.846939	 loss=2.553694	 lr=0.579894
Batch [0049]/[0057]: acc-top1=41.214286 acc-top5=66.285714
[Epoch 052] training: accuracy=41.929370	 loss=2.550435
[Epoch 052] speed: 25 samples/sec	time cost: 1605.998236
[Epoch 052] validation: acc-top1=41.066204 acc-top5=68.478485 loss=2.921406
Epoch[053] Batch [0049]/[0716]	Speed: 23.025249 samples/sec	 accuracy=42.500000	 loss=2.511024	 lr=0.579701
Epoch[053] Batch [0099]/[0716]	Speed: 26.177792 samples/sec	 accuracy=43.392857	 loss=2.478835	 lr=0.579553
Epoch[053] Batch [0149]/[0716]	Speed: 25.544833 samples/sec	 accuracy=43.416667	 loss=2.469080	 lr=0.579406
Epoch[053] Batch [0199]/[0716]	Speed: 25.742673 samples/sec	 accuracy=43.053571	 loss=2.485575	 lr=0.579258
Epoch[053] Batch [0249]/[0716]	Speed: 26.080647 samples/sec	 accuracy=43.185714	 loss=2.478098	 lr=0.579109
Epoch[053] Batch [0299]/[0716]	Speed: 26.107999 samples/sec	 accuracy=42.880952	 loss=2.493804	 lr=0.578960
Epoch[053] Batch [0349]/[0716]	Speed: 26.132808 samples/sec	 accuracy=42.938776	 loss=2.489992	 lr=0.578810
Epoch[053] Batch [0399]/[0716]	Speed: 26.114324 samples/sec	 accuracy=42.651786	 loss=2.500162	 lr=0.578660
Epoch[053] Batch [0449]/[0716]	Speed: 26.302844 samples/sec	 accuracy=42.742063	 loss=2.497502	 lr=0.578509
Epoch[053] Batch [0499]/[0716]	Speed: 25.833531 samples/sec	 accuracy=42.560714	 loss=2.502267	 lr=0.578358
Epoch[053] Batch [0549]/[0716]	Speed: 25.829340 samples/sec	 accuracy=42.422078	 loss=2.506249	 lr=0.578206
Epoch[053] Batch [0599]/[0716]	Speed: 25.693613 samples/sec	 accuracy=42.431548	 loss=2.508804	 lr=0.578054
Epoch[053] Batch [0649]/[0716]	Speed: 26.076234 samples/sec	 accuracy=42.425824	 loss=2.510193	 lr=0.577901
Epoch[053] Batch [0699]/[0716]	Speed: 26.213227 samples/sec	 accuracy=42.326531	 loss=2.514599	 lr=0.577748
Batch [0049]/[0057]: acc-top1=38.535714 acc-top5=66.607143
[Epoch 053] training: accuracy=42.325918	 loss=2.513107
[Epoch 053] speed: 25 samples/sec	time cost: 1607.959719
[Epoch 053] validation: acc-top1=39.520679 acc-top5=66.604012 loss=3.161140
Epoch[054] Batch [0049]/[0716]	Speed: 23.156699 samples/sec	 accuracy=44.071429	 loss=2.410261	 lr=0.577544
Epoch[054] Batch [0099]/[0716]	Speed: 25.914672 samples/sec	 accuracy=44.071429	 loss=2.439767	 lr=0.577390
Epoch[054] Batch [0149]/[0716]	Speed: 25.900686 samples/sec	 accuracy=42.976190	 loss=2.468380	 lr=0.577235
Epoch[054] Batch [0199]/[0716]	Speed: 25.773193 samples/sec	 accuracy=43.107143	 loss=2.464162	 lr=0.577079
Epoch[054] Batch [0249]/[0716]	Speed: 26.305069 samples/sec	 accuracy=42.585714	 loss=2.480342	 lr=0.576923
Epoch[054] Batch [0299]/[0716]	Speed: 25.723459 samples/sec	 accuracy=42.410714	 loss=2.494287	 lr=0.576767
Epoch[054] Batch [0349]/[0716]	Speed: 26.238151 samples/sec	 accuracy=42.352041	 loss=2.499493	 lr=0.576610
Epoch[054] Batch [0399]/[0716]	Speed: 26.282036 samples/sec	 accuracy=42.044643	 loss=2.515620	 lr=0.576452
Epoch[054] Batch [0449]/[0716]	Speed: 26.055350 samples/sec	 accuracy=41.928571	 loss=2.519702	 lr=0.576294
Epoch[054] Batch [0499]/[0716]	Speed: 26.015389 samples/sec	 accuracy=41.982143	 loss=2.523041	 lr=0.576136
Epoch[054] Batch [0549]/[0716]	Speed: 26.255806 samples/sec	 accuracy=41.824675	 loss=2.524185	 lr=0.575977
Epoch[054] Batch [0599]/[0716]	Speed: 26.002930 samples/sec	 accuracy=41.836310	 loss=2.525943	 lr=0.575817
Epoch[054] Batch [0649]/[0716]	Speed: 26.051615 samples/sec	 accuracy=41.928571	 loss=2.523430	 lr=0.575657
Epoch[054] Batch [0699]/[0716]	Speed: 25.951457 samples/sec	 accuracy=42.000000	 loss=2.523852	 lr=0.575497
Batch [0049]/[0057]: acc-top1=40.250000 acc-top5=66.928571
[Epoch 054] training: accuracy=42.036612	 loss=2.521981
[Epoch 054] speed: 26 samples/sec	time cost: 1605.373261
[Epoch 054] validation: acc-top1=40.236004 acc-top5=67.246246 loss=3.009657
Epoch[055] Batch [0049]/[0717]	Speed: 23.091927 samples/sec	 accuracy=43.714286	 loss=2.462141	 lr=0.575284
Epoch[055] Batch [0099]/[0717]	Speed: 26.268557 samples/sec	 accuracy=43.375000	 loss=2.463592	 lr=0.575122
Epoch[055] Batch [0149]/[0717]	Speed: 25.803180 samples/sec	 accuracy=43.214286	 loss=2.473555	 lr=0.574960
Epoch[055] Batch [0199]/[0717]	Speed: 25.959808 samples/sec	 accuracy=43.125000	 loss=2.477730	 lr=0.574797
Epoch[055] Batch [0249]/[0717]	Speed: 26.044306 samples/sec	 accuracy=43.121429	 loss=2.470567	 lr=0.574634
Epoch[055] Batch [0299]/[0717]	Speed: 26.427242 samples/sec	 accuracy=42.821429	 loss=2.480200	 lr=0.574470
Epoch[055] Batch [0349]/[0717]	Speed: 25.576766 samples/sec	 accuracy=42.581633	 loss=2.495041	 lr=0.574306
Epoch[055] Batch [0399]/[0717]	Speed: 25.980669 samples/sec	 accuracy=42.750000	 loss=2.487162	 lr=0.574141
Epoch[055] Batch [0449]/[0717]	Speed: 25.728635 samples/sec	 accuracy=42.869048	 loss=2.477024	 lr=0.573976
Epoch[055] Batch [0499]/[0717]	Speed: 25.716317 samples/sec	 accuracy=42.785714	 loss=2.480129	 lr=0.573810
Epoch[055] Batch [0549]/[0717]	Speed: 26.081038 samples/sec	 accuracy=42.847403	 loss=2.483527	 lr=0.573644
Epoch[055] Batch [0599]/[0717]	Speed: 25.892527 samples/sec	 accuracy=42.845238	 loss=2.485886	 lr=0.573477
Epoch[055] Batch [0649]/[0717]	Speed: 25.787485 samples/sec	 accuracy=42.799451	 loss=2.489282	 lr=0.573310
Epoch[055] Batch [0699]/[0717]	Speed: 25.849064 samples/sec	 accuracy=42.780612	 loss=2.491711	 lr=0.573142
Batch [0049]/[0057]: acc-top1=37.892857 acc-top5=67.392857
[Epoch 055] training: accuracy=42.752540	 loss=2.493271
[Epoch 055] speed: 25 samples/sec	time cost: 1614.803094
[Epoch 055] validation: acc-top1=38.993320 acc-top5=67.131371 loss=3.060701
Epoch[056] Batch [0049]/[0716]	Speed: 23.179797 samples/sec	 accuracy=41.785714	 loss=2.495860	 lr=0.572916
Epoch[056] Batch [0099]/[0716]	Speed: 25.871168 samples/sec	 accuracy=43.267857	 loss=2.437192	 lr=0.572748
Epoch[056] Batch [0149]/[0716]	Speed: 26.597291 samples/sec	 accuracy=43.202381	 loss=2.455963	 lr=0.572578
Epoch[056] Batch [0199]/[0716]	Speed: 26.322499 samples/sec	 accuracy=42.991071	 loss=2.469883	 lr=0.572408
Epoch[056] Batch [0249]/[0716]	Speed: 26.132371 samples/sec	 accuracy=42.907143	 loss=2.474549	 lr=0.572238
Epoch[056] Batch [0299]/[0716]	Speed: 26.135904 samples/sec	 accuracy=42.904762	 loss=2.471116	 lr=0.572067
Epoch[056] Batch [0349]/[0716]	Speed: 26.225850 samples/sec	 accuracy=42.714286	 loss=2.474507	 lr=0.571895
Epoch[056] Batch [0399]/[0716]	Speed: 25.610431 samples/sec	 accuracy=42.625000	 loss=2.481475	 lr=0.571723
Epoch[056] Batch [0449]/[0716]	Speed: 26.616896 samples/sec	 accuracy=42.750000	 loss=2.485590	 lr=0.571551
Epoch[056] Batch [0499]/[0716]	Speed: 25.843355 samples/sec	 accuracy=42.578571	 loss=2.496614	 lr=0.571378
Epoch[056] Batch [0549]/[0716]	Speed: 26.096387 samples/sec	 accuracy=42.613636	 loss=2.496364	 lr=0.571205
Epoch[056] Batch [0599]/[0716]	Speed: 26.098460 samples/sec	 accuracy=42.681548	 loss=2.496963	 lr=0.571031
Epoch[056] Batch [0649]/[0716]	Speed: 26.029012 samples/sec	 accuracy=42.557692	 loss=2.501544	 lr=0.570856
Epoch[056] Batch [0699]/[0716]	Speed: 25.988134 samples/sec	 accuracy=42.637755	 loss=2.499022	 lr=0.570681
Batch [0049]/[0057]: acc-top1=41.107143 acc-top5=67.857143
[Epoch 056] training: accuracy=42.592777	 loss=2.500246
[Epoch 056] speed: 26 samples/sec	time cost: 1600.939048
[Epoch 056] validation: acc-top1=41.463032 acc-top5=68.896194 loss=2.738384
Epoch[057] Batch [0049]/[0716]	Speed: 22.582123 samples/sec	 accuracy=42.642857	 loss=2.487210	 lr=0.570450
Epoch[057] Batch [0099]/[0716]	Speed: 26.608783 samples/sec	 accuracy=43.517857	 loss=2.476801	 lr=0.570274
Epoch[057] Batch [0149]/[0716]	Speed: 26.211437 samples/sec	 accuracy=43.583333	 loss=2.470407	 lr=0.570097
Epoch[057] Batch [0199]/[0716]	Speed: 25.975438 samples/sec	 accuracy=43.464286	 loss=2.473946	 lr=0.569920
Epoch[057] Batch [0249]/[0716]	Speed: 25.940447 samples/sec	 accuracy=43.285714	 loss=2.474718	 lr=0.569742
Epoch[057] Batch [0299]/[0716]	Speed: 25.929656 samples/sec	 accuracy=43.458333	 loss=2.472117	 lr=0.569564
Epoch[057] Batch [0349]/[0716]	Speed: 25.977438 samples/sec	 accuracy=43.341837	 loss=2.473211	 lr=0.569386
Epoch[057] Batch [0399]/[0716]	Speed: 25.720267 samples/sec	 accuracy=43.160714	 loss=2.476209	 lr=0.569207
Epoch[057] Batch [0449]/[0716]	Speed: 26.111476 samples/sec	 accuracy=43.150794	 loss=2.472488	 lr=0.569027
Epoch[057] Batch [0499]/[0716]	Speed: 26.598225 samples/sec	 accuracy=43.153571	 loss=2.476633	 lr=0.568847
Epoch[057] Batch [0549]/[0716]	Speed: 26.133768 samples/sec	 accuracy=43.120130	 loss=2.476331	 lr=0.568667
Epoch[057] Batch [0599]/[0716]	Speed: 26.082477 samples/sec	 accuracy=43.157738	 loss=2.475841	 lr=0.568486
Epoch[057] Batch [0649]/[0716]	Speed: 26.070195 samples/sec	 accuracy=43.030220	 loss=2.481801	 lr=0.568304
Epoch[057] Batch [0699]/[0716]	Speed: 26.214014 samples/sec	 accuracy=43.040816	 loss=2.483505	 lr=0.568122
Batch [0049]/[0057]: acc-top1=42.392857 acc-top5=69.821429
[Epoch 057] training: accuracy=42.979350	 loss=2.485999
[Epoch 057] speed: 26 samples/sec	time cost: 1604.481548
[Epoch 057] validation: acc-top1=41.828533 acc-top5=69.350456 loss=2.805144
Epoch[058] Batch [0049]/[0716]	Speed: 23.347386 samples/sec	 accuracy=43.821429	 loss=2.455577	 lr=0.567881
Epoch[058] Batch [0099]/[0716]	Speed: 25.957718 samples/sec	 accuracy=43.821429	 loss=2.452355	 lr=0.567698
Epoch[058] Batch [0149]/[0716]	Speed: 26.831222 samples/sec	 accuracy=43.500000	 loss=2.472974	 lr=0.567514
Epoch[058] Batch [0199]/[0716]	Speed: 25.763934 samples/sec	 accuracy=43.500000	 loss=2.470947	 lr=0.567330
Epoch[058] Batch [0249]/[0716]	Speed: 26.071744 samples/sec	 accuracy=43.250000	 loss=2.475041	 lr=0.567146
Epoch[058] Batch [0299]/[0716]	Speed: 25.941496 samples/sec	 accuracy=43.119048	 loss=2.476207	 lr=0.566960
Epoch[058] Batch [0349]/[0716]	Speed: 25.831162 samples/sec	 accuracy=43.025510	 loss=2.479222	 lr=0.566775
Epoch[058] Batch [0399]/[0716]	Speed: 26.423721 samples/sec	 accuracy=42.964286	 loss=2.478815	 lr=0.566589
Epoch[058] Batch [0449]/[0716]	Speed: 26.529870 samples/sec	 accuracy=43.119048	 loss=2.472584	 lr=0.566402
Epoch[058] Batch [0499]/[0716]	Speed: 26.478943 samples/sec	 accuracy=42.982143	 loss=2.482732	 lr=0.566215
Epoch[058] Batch [0549]/[0716]	Speed: 25.971930 samples/sec	 accuracy=42.935065	 loss=2.483085	 lr=0.566028
Epoch[058] Batch [0599]/[0716]	Speed: 25.834385 samples/sec	 accuracy=42.848214	 loss=2.490188	 lr=0.565840
Epoch[058] Batch [0649]/[0716]	Speed: 26.013702 samples/sec	 accuracy=42.631868	 loss=2.501662	 lr=0.565651
Epoch[058] Batch [0699]/[0716]	Speed: 26.325970 samples/sec	 accuracy=42.627551	 loss=2.500486	 lr=0.565462
Batch [0049]/[0057]: acc-top1=39.357143 acc-top5=66.928571
[Epoch 058] training: accuracy=42.592777	 loss=2.502045
[Epoch 058] speed: 26 samples/sec	time cost: 1599.260112
[Epoch 058] validation: acc-top1=40.042816 acc-top5=66.765877 loss=2.941077
Epoch[059] Batch [0049]/[0716]	Speed: 23.170876 samples/sec	 accuracy=43.357143	 loss=2.461119	 lr=0.565212
Epoch[059] Batch [0099]/[0716]	Speed: 26.277746 samples/sec	 accuracy=43.178571	 loss=2.476924	 lr=0.565022
Epoch[059] Batch [0149]/[0716]	Speed: 25.762110 samples/sec	 accuracy=43.238095	 loss=2.481467	 lr=0.564831
Epoch[059] Batch [0199]/[0716]	Speed: 25.845913 samples/sec	 accuracy=43.232143	 loss=2.471589	 lr=0.564640
Epoch[059] Batch [0249]/[0716]	Speed: 25.749571 samples/sec	 accuracy=42.950000	 loss=2.490025	 lr=0.564448
Epoch[059] Batch [0299]/[0716]	Speed: 26.102631 samples/sec	 accuracy=42.958333	 loss=2.497361	 lr=0.564256
Epoch[059] Batch [0349]/[0716]	Speed: 25.933952 samples/sec	 accuracy=42.974490	 loss=2.497082	 lr=0.564064
Epoch[059] Batch [0399]/[0716]	Speed: 25.585413 samples/sec	 accuracy=43.084821	 loss=2.485669	 lr=0.563871
Epoch[059] Batch [0449]/[0716]	Speed: 25.603228 samples/sec	 accuracy=42.940476	 loss=2.483134	 lr=0.563677
Epoch[059] Batch [0499]/[0716]	Speed: 26.482400 samples/sec	 accuracy=43.010714	 loss=2.483538	 lr=0.563483
Epoch[059] Batch [0549]/[0716]	Speed: 25.926959 samples/sec	 accuracy=43.074675	 loss=2.479947	 lr=0.563289
Epoch[059] Batch [0599]/[0716]	Speed: 26.262955 samples/sec	 accuracy=42.898810	 loss=2.487443	 lr=0.563094
Epoch[059] Batch [0649]/[0716]	Speed: 25.749233 samples/sec	 accuracy=42.821429	 loss=2.493264	 lr=0.562898
Epoch[059] Batch [0699]/[0716]	Speed: 26.108923 samples/sec	 accuracy=42.869898	 loss=2.497536	 lr=0.562702
Batch [0049]/[0057]: acc-top1=36.142857 acc-top5=63.035714
[Epoch 059] training: accuracy=42.812251	 loss=2.500397
[Epoch 059] speed: 25 samples/sec	time cost: 1609.013923
[Epoch 059] validation: acc-top1=36.429615 acc-top5=63.257099 loss=3.414975
Epoch[060] Batch [0049]/[0716]	Speed: 23.015146 samples/sec	 accuracy=42.928571	 loss=2.438546	 lr=0.562443
Epoch[060] Batch [0099]/[0716]	Speed: 26.158158 samples/sec	 accuracy=43.446429	 loss=2.428301	 lr=0.562246
Epoch[060] Batch [0149]/[0716]	Speed: 26.121919 samples/sec	 accuracy=43.761905	 loss=2.436147	 lr=0.562048
Epoch[060] Batch [0199]/[0716]	Speed: 26.013034 samples/sec	 accuracy=43.375000	 loss=2.456544	 lr=0.561850
Epoch[060] Batch [0249]/[0716]	Speed: 25.852685 samples/sec	 accuracy=42.942857	 loss=2.481559	 lr=0.561652
Epoch[060] Batch [0299]/[0716]	Speed: 25.633304 samples/sec	 accuracy=42.821429	 loss=2.491893	 lr=0.561453
Epoch[060] Batch [0349]/[0716]	Speed: 26.096820 samples/sec	 accuracy=42.994898	 loss=2.483881	 lr=0.561253
Epoch[060] Batch [0399]/[0716]	Speed: 25.858022 samples/sec	 accuracy=43.022321	 loss=2.484693	 lr=0.561053
Epoch[060] Batch [0449]/[0716]	Speed: 26.102697 samples/sec	 accuracy=42.992063	 loss=2.489432	 lr=0.560853
Epoch[060] Batch [0499]/[0716]	Speed: 26.177343 samples/sec	 accuracy=43.185714	 loss=2.484982	 lr=0.560652
Epoch[060] Batch [0549]/[0716]	Speed: 26.086566 samples/sec	 accuracy=43.165584	 loss=2.488622	 lr=0.560451
Epoch[060] Batch [0599]/[0716]	Speed: 25.967988 samples/sec	 accuracy=43.107143	 loss=2.488355	 lr=0.560249
Epoch[060] Batch [0649]/[0716]	Speed: 26.298318 samples/sec	 accuracy=43.008242	 loss=2.490205	 lr=0.560046
Epoch[060] Batch [0699]/[0716]	Speed: 25.738949 samples/sec	 accuracy=42.959184	 loss=2.490580	 lr=0.559844
Batch [0049]/[0057]: acc-top1=39.357143 acc-top5=65.642857
[Epoch 060] training: accuracy=42.921987	 loss=2.492400
[Epoch 060] speed: 25 samples/sec	time cost: 1610.992480
[Epoch 060] validation: acc-top1=39.557228 acc-top5=66.718880 loss=2.988044
Epoch[061] Batch [0049]/[0716]	Speed: 23.281654 samples/sec	 accuracy=42.535714	 loss=2.516132	 lr=0.559575
Epoch[061] Batch [0099]/[0716]	Speed: 25.787270 samples/sec	 accuracy=42.625000	 loss=2.496692	 lr=0.559371
Epoch[061] Batch [0149]/[0716]	Speed: 26.113221 samples/sec	 accuracy=42.285714	 loss=2.496680	 lr=0.559167
Epoch[061] Batch [0199]/[0716]	Speed: 26.392354 samples/sec	 accuracy=42.723214	 loss=2.483979	 lr=0.558962
Epoch[061] Batch [0249]/[0716]	Speed: 26.354177 samples/sec	 accuracy=42.800000	 loss=2.480823	 lr=0.558757
Epoch[061] Batch [0299]/[0716]	Speed: 26.120870 samples/sec	 accuracy=42.892857	 loss=2.474785	 lr=0.558551
Epoch[061] Batch [0349]/[0716]	Speed: 26.166372 samples/sec	 accuracy=42.964286	 loss=2.474926	 lr=0.558344
Epoch[061] Batch [0399]/[0716]	Speed: 26.425058 samples/sec	 accuracy=42.897321	 loss=2.484871	 lr=0.558138
Epoch[061] Batch [0449]/[0716]	Speed: 26.036577 samples/sec	 accuracy=42.976190	 loss=2.487724	 lr=0.557930
Epoch[061] Batch [0499]/[0716]	Speed: 26.099515 samples/sec	 accuracy=42.882143	 loss=2.500809	 lr=0.557723
Epoch[061] Batch [0549]/[0716]	Speed: 25.683345 samples/sec	 accuracy=43.081169	 loss=2.501436	 lr=0.557515
Epoch[061] Batch [0599]/[0716]	Speed: 25.983099 samples/sec	 accuracy=43.023810	 loss=2.498792	 lr=0.557306
Epoch[061] Batch [0649]/[0716]	Speed: 25.796132 samples/sec	 accuracy=42.945055	 loss=2.502806	 lr=0.557097
Epoch[061] Batch [0699]/[0716]	Speed: 26.142474 samples/sec	 accuracy=42.885204	 loss=2.501923	 lr=0.556887
Batch [0049]/[0057]: acc-top1=39.964286 acc-top5=67.464286
[Epoch 061] training: accuracy=42.889565	 loss=2.503233
[Epoch 061] speed: 26 samples/sec	time cost: 1604.920525
[Epoch 061] validation: acc-top1=40.006264 acc-top5=67.136589 loss=2.963165
Epoch[062] Batch [0049]/[0716]	Speed: 22.971400 samples/sec	 accuracy=43.964286	 loss=2.390341	 lr=0.556610
Epoch[062] Batch [0099]/[0716]	Speed: 25.845025 samples/sec	 accuracy=43.732143	 loss=2.417694	 lr=0.556399
Epoch[062] Batch [0149]/[0716]	Speed: 25.955818 samples/sec	 accuracy=43.952381	 loss=2.403412	 lr=0.556188
Epoch[062] Batch [0199]/[0716]	Speed: 26.281544 samples/sec	 accuracy=43.553571	 loss=2.426920	 lr=0.555976
Epoch[062] Batch [0249]/[0716]	Speed: 26.049731 samples/sec	 accuracy=43.507143	 loss=2.430466	 lr=0.555764
Epoch[062] Batch [0299]/[0716]	Speed: 26.051875 samples/sec	 accuracy=43.470238	 loss=2.438857	 lr=0.555552
Epoch[062] Batch [0349]/[0716]	Speed: 26.331733 samples/sec	 accuracy=43.244898	 loss=2.449969	 lr=0.555339
Epoch[062] Batch [0399]/[0716]	Speed: 25.483678 samples/sec	 accuracy=43.388393	 loss=2.450503	 lr=0.555125
Epoch[062] Batch [0449]/[0716]	Speed: 26.129915 samples/sec	 accuracy=43.488095	 loss=2.456473	 lr=0.554911
Epoch[062] Batch [0499]/[0716]	Speed: 26.214552 samples/sec	 accuracy=43.289286	 loss=2.460767	 lr=0.554697
Epoch[062] Batch [0549]/[0716]	Speed: 26.362048 samples/sec	 accuracy=43.188312	 loss=2.463708	 lr=0.554482
Epoch[062] Batch [0599]/[0716]	Speed: 25.721830 samples/sec	 accuracy=43.160714	 loss=2.467005	 lr=0.554266
Epoch[062] Batch [0649]/[0716]	Speed: 26.213074 samples/sec	 accuracy=43.208791	 loss=2.463924	 lr=0.554050
Epoch[062] Batch [0699]/[0716]	Speed: 26.221958 samples/sec	 accuracy=43.125000	 loss=2.469682	 lr=0.553834
Batch [0049]/[0057]: acc-top1=38.964286 acc-top5=65.285714
[Epoch 062] training: accuracy=43.193835	 loss=2.467208
[Epoch 062] speed: 26 samples/sec	time cost: 1604.166974
[Epoch 062] validation: acc-top1=39.886173 acc-top5=66.201958 loss=3.008460
Epoch[063] Batch [0049]/[0717]	Speed: 22.839651 samples/sec	 accuracy=44.392857	 loss=2.397308	 lr=0.553548
Epoch[063] Batch [0099]/[0717]	Speed: 26.307904 samples/sec	 accuracy=43.285714	 loss=2.455356	 lr=0.553331
Epoch[063] Batch [0149]/[0717]	Speed: 26.271692 samples/sec	 accuracy=43.535714	 loss=2.448130	 lr=0.553113
Epoch[063] Batch [0199]/[0717]	Speed: 25.408894 samples/sec	 accuracy=43.160714	 loss=2.464758	 lr=0.552894
Epoch[063] Batch [0249]/[0717]	Speed: 25.937212 samples/sec	 accuracy=43.407143	 loss=2.457486	 lr=0.552676
Epoch[063] Batch [0299]/[0717]	Speed: 25.992870 samples/sec	 accuracy=43.333333	 loss=2.458203	 lr=0.552456
Epoch[063] Batch [0349]/[0717]	Speed: 26.173182 samples/sec	 accuracy=43.413265	 loss=2.452277	 lr=0.552237
Epoch[063] Batch [0399]/[0717]	Speed: 25.686488 samples/sec	 accuracy=43.388393	 loss=2.452411	 lr=0.552016
Epoch[063] Batch [0449]/[0717]	Speed: 26.141044 samples/sec	 accuracy=43.309524	 loss=2.453618	 lr=0.551796
Epoch[063] Batch [0499]/[0717]	Speed: 25.438003 samples/sec	 accuracy=43.325000	 loss=2.451707	 lr=0.551575
Epoch[063] Batch [0549]/[0717]	Speed: 26.363771 samples/sec	 accuracy=43.285714	 loss=2.453653	 lr=0.551353
Epoch[063] Batch [0599]/[0717]	Speed: 26.271170 samples/sec	 accuracy=43.154762	 loss=2.457102	 lr=0.551131
Epoch[063] Batch [0649]/[0717]	Speed: 25.787078 samples/sec	 accuracy=43.184066	 loss=2.458384	 lr=0.550909
Epoch[063] Batch [0699]/[0717]	Speed: 26.456869 samples/sec	 accuracy=43.091837	 loss=2.463101	 lr=0.550686
Batch [0049]/[0057]: acc-top1=40.321429 acc-top5=66.535714
[Epoch 063] training: accuracy=43.019028	 loss=2.466686
[Epoch 063] speed: 25 samples/sec	time cost: 1610.292847
[Epoch 063] validation: acc-top1=41.149750 acc-top5=68.102554 loss=2.841919
Epoch[064] Batch [0049]/[0716]	Speed: 23.235730 samples/sec	 accuracy=44.678571	 loss=2.349533	 lr=0.550386
Epoch[064] Batch [0099]/[0716]	Speed: 25.693886 samples/sec	 accuracy=43.910714	 loss=2.428072	 lr=0.550162
Epoch[064] Batch [0149]/[0716]	Speed: 25.880864 samples/sec	 accuracy=43.607143	 loss=2.435559	 lr=0.549938
Epoch[064] Batch [0199]/[0716]	Speed: 26.241495 samples/sec	 accuracy=43.508929	 loss=2.448334	 lr=0.549713
Epoch[064] Batch [0249]/[0716]	Speed: 25.955921 samples/sec	 accuracy=43.728571	 loss=2.435516	 lr=0.549487
Epoch[064] Batch [0299]/[0716]	Speed: 26.308341 samples/sec	 accuracy=43.833333	 loss=2.434377	 lr=0.549262
Epoch[064] Batch [0349]/[0716]	Speed: 26.427532 samples/sec	 accuracy=43.607143	 loss=2.441909	 lr=0.549035
Epoch[064] Batch [0399]/[0716]	Speed: 25.865381 samples/sec	 accuracy=43.669643	 loss=2.443117	 lr=0.548809
Epoch[064] Batch [0449]/[0716]	Speed: 25.879788 samples/sec	 accuracy=43.615079	 loss=2.446724	 lr=0.548581
Epoch[064] Batch [0499]/[0716]	Speed: 26.573168 samples/sec	 accuracy=43.542857	 loss=2.448183	 lr=0.548354
Epoch[064] Batch [0549]/[0716]	Speed: 26.261189 samples/sec	 accuracy=43.428571	 loss=2.454286	 lr=0.548125
Epoch[064] Batch [0599]/[0716]	Speed: 26.487679 samples/sec	 accuracy=43.330357	 loss=2.457297	 lr=0.547897
Epoch[064] Batch [0649]/[0716]	Speed: 25.952542 samples/sec	 accuracy=43.354396	 loss=2.458874	 lr=0.547668
Epoch[064] Batch [0699]/[0716]	Speed: 25.798167 samples/sec	 accuracy=43.257653	 loss=2.459247	 lr=0.547438
Batch [0049]/[0057]: acc-top1=38.892857 acc-top5=67.750000
[Epoch 064] training: accuracy=43.248703	 loss=2.460417
[Epoch 064] speed: 26 samples/sec	time cost: 1602.417218
[Epoch 064] validation: acc-top1=41.008774 acc-top5=68.671677 loss=2.682663
Epoch[065] Batch [0049]/[0716]	Speed: 23.262798 samples/sec	 accuracy=42.928571	 loss=2.468016	 lr=0.547135
Epoch[065] Batch [0099]/[0716]	Speed: 26.283287 samples/sec	 accuracy=43.446429	 loss=2.449446	 lr=0.546904
Epoch[065] Batch [0149]/[0716]	Speed: 26.618396 samples/sec	 accuracy=43.976190	 loss=2.426527	 lr=0.546673
Epoch[065] Batch [0199]/[0716]	Speed: 25.942989 samples/sec	 accuracy=44.008929	 loss=2.427650	 lr=0.546442
Epoch[065] Batch [0249]/[0716]	Speed: 26.176362 samples/sec	 accuracy=43.914286	 loss=2.436313	 lr=0.546210
Epoch[065] Batch [0299]/[0716]	Speed: 25.895743 samples/sec	 accuracy=43.761905	 loss=2.440516	 lr=0.545978
Epoch[065] Batch [0349]/[0716]	Speed: 26.031778 samples/sec	 accuracy=43.724490	 loss=2.441108	 lr=0.545745
Epoch[065] Batch [0399]/[0716]	Speed: 25.928783 samples/sec	 accuracy=43.843750	 loss=2.438099	 lr=0.545511
Epoch[065] Batch [0449]/[0716]	Speed: 26.026049 samples/sec	 accuracy=43.892857	 loss=2.434855	 lr=0.545278
Epoch[065] Batch [0499]/[0716]	Speed: 25.999606 samples/sec	 accuracy=43.882143	 loss=2.439521	 lr=0.545044
Epoch[065] Batch [0549]/[0716]	Speed: 26.016634 samples/sec	 accuracy=43.792208	 loss=2.445448	 lr=0.544809
Epoch[065] Batch [0599]/[0716]	Speed: 26.000577 samples/sec	 accuracy=43.788690	 loss=2.446244	 lr=0.544574
Epoch[065] Batch [0649]/[0716]	Speed: 26.111158 samples/sec	 accuracy=43.760989	 loss=2.445698	 lr=0.544338
Epoch[065] Batch [0699]/[0716]	Speed: 25.979126 samples/sec	 accuracy=43.660714	 loss=2.451039	 lr=0.544102
Batch [0049]/[0057]: acc-top1=41.750000 acc-top5=68.285714
[Epoch 065] training: accuracy=43.657721	 loss=2.452405
[Epoch 065] speed: 26 samples/sec	time cost: 1601.668823
[Epoch 065] validation: acc-top1=40.690266 acc-top5=68.123436 loss=3.042933
Epoch[066] Batch [0049]/[0716]	Speed: 23.147226 samples/sec	 accuracy=44.642857	 loss=2.432985	 lr=0.543790
Epoch[066] Batch [0099]/[0716]	Speed: 26.235774 samples/sec	 accuracy=44.625000	 loss=2.397344	 lr=0.543553
Epoch[066] Batch [0149]/[0716]	Speed: 25.809773 samples/sec	 accuracy=43.797619	 loss=2.426154	 lr=0.543316
Epoch[066] Batch [0199]/[0716]	Speed: 26.068331 samples/sec	 accuracy=43.875000	 loss=2.426317	 lr=0.543078
Epoch[066] Batch [0249]/[0716]	Speed: 26.143283 samples/sec	 accuracy=43.942857	 loss=2.420179	 lr=0.542840
Epoch[066] Batch [0299]/[0716]	Speed: 25.756027 samples/sec	 accuracy=43.964286	 loss=2.419490	 lr=0.542601
Epoch[066] Batch [0349]/[0716]	Speed: 25.715248 samples/sec	 accuracy=43.989796	 loss=2.414863	 lr=0.542362
Epoch[066] Batch [0399]/[0716]	Speed: 25.976016 samples/sec	 accuracy=44.008929	 loss=2.415030	 lr=0.542122
Epoch[066] Batch [0449]/[0716]	Speed: 26.371646 samples/sec	 accuracy=43.932540	 loss=2.421894	 lr=0.541882
Epoch[066] Batch [0499]/[0716]	Speed: 25.902797 samples/sec	 accuracy=43.867857	 loss=2.425014	 lr=0.541641
Epoch[066] Batch [0549]/[0716]	Speed: 26.115873 samples/sec	 accuracy=43.798701	 loss=2.429054	 lr=0.541400
Epoch[066] Batch [0599]/[0716]	Speed: 25.759181 samples/sec	 accuracy=43.860119	 loss=2.430137	 lr=0.541159
Epoch[066] Batch [0649]/[0716]	Speed: 26.523897 samples/sec	 accuracy=43.826923	 loss=2.431872	 lr=0.540917
Epoch[066] Batch [0699]/[0716]	Speed: 25.847212 samples/sec	 accuracy=43.872449	 loss=2.431106	 lr=0.540675
Batch [0049]/[0057]: acc-top1=41.321429 acc-top5=68.285714
[Epoch 066] training: accuracy=43.899641	 loss=2.430261
[Epoch 066] speed: 25 samples/sec	time cost: 1605.569930
[Epoch 066] validation: acc-top1=40.021931 acc-top5=67.068710 loss=3.060607
Epoch[067] Batch [0049]/[0716]	Speed: 23.401869 samples/sec	 accuracy=44.714286	 loss=2.412843	 lr=0.540354
Epoch[067] Batch [0099]/[0716]	Speed: 26.147621 samples/sec	 accuracy=44.892857	 loss=2.412449	 lr=0.540111
Epoch[067] Batch [0149]/[0716]	Speed: 26.111405 samples/sec	 accuracy=44.869048	 loss=2.411014	 lr=0.539867
Epoch[067] Batch [0199]/[0716]	Speed: 26.660171 samples/sec	 accuracy=44.464286	 loss=2.404518	 lr=0.539623
Epoch[067] Batch [0249]/[0716]	Speed: 25.647391 samples/sec	 accuracy=44.328571	 loss=2.410610	 lr=0.539378
Epoch[067] Batch [0299]/[0716]	Speed: 25.747179 samples/sec	 accuracy=44.101190	 loss=2.415890	 lr=0.539133
Epoch[067] Batch [0349]/[0716]	Speed: 26.080166 samples/sec	 accuracy=44.178571	 loss=2.414392	 lr=0.538888
Epoch[067] Batch [0399]/[0716]	Speed: 25.891368 samples/sec	 accuracy=44.000000	 loss=2.417422	 lr=0.538642
Epoch[067] Batch [0449]/[0716]	Speed: 25.859047 samples/sec	 accuracy=44.003968	 loss=2.422312	 lr=0.538395
Epoch[067] Batch [0499]/[0716]	Speed: 26.211435 samples/sec	 accuracy=43.896429	 loss=2.422948	 lr=0.538148
Epoch[067] Batch [0549]/[0716]	Speed: 25.767850 samples/sec	 accuracy=43.853896	 loss=2.426984	 lr=0.537901
Epoch[067] Batch [0599]/[0716]	Speed: 26.252224 samples/sec	 accuracy=43.892857	 loss=2.427459	 lr=0.537653
Epoch[067] Batch [0649]/[0716]	Speed: 26.375791 samples/sec	 accuracy=43.906593	 loss=2.431824	 lr=0.537405
Epoch[067] Batch [0699]/[0716]	Speed: 26.314348 samples/sec	 accuracy=43.829082	 loss=2.435101	 lr=0.537157
Batch [0049]/[0057]: acc-top1=40.750000 acc-top5=67.642857
[Epoch 067] training: accuracy=43.817338	 loss=2.436144
[Epoch 067] speed: 26 samples/sec	time cost: 1602.122811
[Epoch 067] validation: acc-top1=41.818085 acc-top5=68.817886 loss=2.793845
Epoch[068] Batch [0049]/[0716]	Speed: 23.103570 samples/sec	 accuracy=44.928571	 loss=2.408274	 lr=0.536828
Epoch[068] Batch [0099]/[0716]	Speed: 26.163213 samples/sec	 accuracy=43.678571	 loss=2.457204	 lr=0.536578
Epoch[068] Batch [0149]/[0716]	Speed: 26.076575 samples/sec	 accuracy=43.761905	 loss=2.458782	 lr=0.536328
Epoch[068] Batch [0199]/[0716]	Speed: 26.270444 samples/sec	 accuracy=43.669643	 loss=2.438848	 lr=0.536078
Epoch[068] Batch [0249]/[0716]	Speed: 26.439156 samples/sec	 accuracy=44.057143	 loss=2.432165	 lr=0.535827
Epoch[068] Batch [0299]/[0716]	Speed: 25.756736 samples/sec	 accuracy=43.892857	 loss=2.442168	 lr=0.535575
Epoch[068] Batch [0349]/[0716]	Speed: 26.116675 samples/sec	 accuracy=43.719388	 loss=2.447965	 lr=0.535324
Epoch[068] Batch [0399]/[0716]	Speed: 26.245945 samples/sec	 accuracy=43.732143	 loss=2.443373	 lr=0.535071
Epoch[068] Batch [0449]/[0716]	Speed: 26.226981 samples/sec	 accuracy=43.698413	 loss=2.445033	 lr=0.534819
Epoch[068] Batch [0499]/[0716]	Speed: 26.598756 samples/sec	 accuracy=43.678571	 loss=2.450468	 lr=0.534566
Epoch[068] Batch [0549]/[0716]	Speed: 26.006740 samples/sec	 accuracy=43.688312	 loss=2.450491	 lr=0.534312
Epoch[068] Batch [0599]/[0716]	Speed: 25.996292 samples/sec	 accuracy=43.523810	 loss=2.455609	 lr=0.534058
Epoch[068] Batch [0649]/[0716]	Speed: 26.103883 samples/sec	 accuracy=43.519231	 loss=2.454543	 lr=0.533804
Epoch[068] Batch [0699]/[0716]	Speed: 25.794555 samples/sec	 accuracy=43.464286	 loss=2.453715	 lr=0.533549
Batch [0049]/[0057]: acc-top1=40.892857 acc-top5=67.464286
[Epoch 068] training: accuracy=43.468176	 loss=2.453683
[Epoch 068] speed: 26 samples/sec	time cost: 1602.531401
[Epoch 068] validation: acc-top1=40.967003 acc-top5=67.554298 loss=2.869751
Epoch[069] Batch [0049]/[0716]	Speed: 22.860760 samples/sec	 accuracy=42.571429	 loss=2.450627	 lr=0.533212
Epoch[069] Batch [0099]/[0716]	Speed: 26.001986 samples/sec	 accuracy=43.285714	 loss=2.442746	 lr=0.532956
Epoch[069] Batch [0149]/[0716]	Speed: 26.396352 samples/sec	 accuracy=42.988095	 loss=2.453716	 lr=0.532700
Epoch[069] Batch [0199]/[0716]	Speed: 25.618250 samples/sec	 accuracy=43.223214	 loss=2.454560	 lr=0.532444
Epoch[069] Batch [0249]/[0716]	Speed: 26.706536 samples/sec	 accuracy=43.250000	 loss=2.461238	 lr=0.532187
Epoch[069] Batch [0299]/[0716]	Speed: 25.767646 samples/sec	 accuracy=43.541667	 loss=2.456535	 lr=0.531929
Epoch[069] Batch [0349]/[0716]	Speed: 25.958257 samples/sec	 accuracy=43.617347	 loss=2.453847	 lr=0.531671
Epoch[069] Batch [0399]/[0716]	Speed: 26.135677 samples/sec	 accuracy=43.508929	 loss=2.460397	 lr=0.531413
Epoch[069] Batch [0449]/[0716]	Speed: 26.226734 samples/sec	 accuracy=43.492063	 loss=2.458430	 lr=0.531154
Epoch[069] Batch [0499]/[0716]	Speed: 25.956479 samples/sec	 accuracy=43.521429	 loss=2.460125	 lr=0.530895
Epoch[069] Batch [0549]/[0716]	Speed: 26.032514 samples/sec	 accuracy=43.639610	 loss=2.455150	 lr=0.530635
Epoch[069] Batch [0599]/[0716]	Speed: 26.086607 samples/sec	 accuracy=43.663690	 loss=2.452667	 lr=0.530375
Epoch[069] Batch [0649]/[0716]	Speed: 25.858718 samples/sec	 accuracy=43.601648	 loss=2.457339	 lr=0.530115
Epoch[069] Batch [0699]/[0716]	Speed: 26.722651 samples/sec	 accuracy=43.645408	 loss=2.455223	 lr=0.529854
Batch [0049]/[0057]: acc-top1=41.071429 acc-top5=69.107143
[Epoch 069] training: accuracy=43.642757	 loss=2.456492
[Epoch 069] speed: 26 samples/sec	time cost: 1602.949244
[Epoch 069] validation: acc-top1=41.353382 acc-top5=68.478485 loss=2.795874
Epoch[070] Batch [0049]/[0716]	Speed: 23.067985 samples/sec	 accuracy=45.071429	 loss=2.378514	 lr=0.529509
Epoch[070] Batch [0099]/[0716]	Speed: 26.477394 samples/sec	 accuracy=43.892857	 loss=2.418673	 lr=0.529247
Epoch[070] Batch [0149]/[0716]	Speed: 26.238877 samples/sec	 accuracy=43.583333	 loss=2.417168	 lr=0.528985
Epoch[070] Batch [0199]/[0716]	Speed: 26.216687 samples/sec	 accuracy=43.544643	 loss=2.423673	 lr=0.528722
Epoch[070] Batch [0249]/[0716]	Speed: 25.845369 samples/sec	 accuracy=44.214286	 loss=2.401533	 lr=0.528459
Epoch[070] Batch [0299]/[0716]	Speed: 25.695653 samples/sec	 accuracy=44.285714	 loss=2.404615	 lr=0.528196
Epoch[070] Batch [0349]/[0716]	Speed: 26.110357 samples/sec	 accuracy=44.239796	 loss=2.412046	 lr=0.527932
Epoch[070] Batch [0399]/[0716]	Speed: 26.120627 samples/sec	 accuracy=44.035714	 loss=2.420405	 lr=0.527667
Epoch[070] Batch [0449]/[0716]	Speed: 26.393276 samples/sec	 accuracy=44.091270	 loss=2.418398	 lr=0.527402
Epoch[070] Batch [0499]/[0716]	Speed: 26.118033 samples/sec	 accuracy=43.992857	 loss=2.418095	 lr=0.527137
Epoch[070] Batch [0549]/[0716]	Speed: 26.337514 samples/sec	 accuracy=43.834416	 loss=2.424310	 lr=0.526872
Epoch[070] Batch [0599]/[0716]	Speed: 25.906424 samples/sec	 accuracy=43.684524	 loss=2.431363	 lr=0.526606
Epoch[070] Batch [0649]/[0716]	Speed: 25.565572 samples/sec	 accuracy=43.678571	 loss=2.434862	 lr=0.526339
Epoch[070] Batch [0699]/[0716]	Speed: 26.404649 samples/sec	 accuracy=43.650510	 loss=2.435669	 lr=0.526072
Batch [0049]/[0057]: acc-top1=39.142857 acc-top5=69.035714
[Epoch 070] training: accuracy=43.677674	 loss=2.435560
[Epoch 070] speed: 26 samples/sec	time cost: 1601.218570
[Epoch 070] validation: acc-top1=40.888680 acc-top5=68.499374 loss=2.992047
Epoch[071] Batch [0049]/[0717]	Speed: 23.406457 samples/sec	 accuracy=45.642857	 loss=2.379211	 lr=0.525719
Epoch[071] Batch [0099]/[0717]	Speed: 26.249825 samples/sec	 accuracy=44.767857	 loss=2.405403	 lr=0.525452
Epoch[071] Batch [0149]/[0717]	Speed: 25.973697 samples/sec	 accuracy=44.511905	 loss=2.400347	 lr=0.525183
Epoch[071] Batch [0199]/[0717]	Speed: 26.044780 samples/sec	 accuracy=44.687500	 loss=2.399115	 lr=0.524915
Epoch[071] Batch [0249]/[0717]	Speed: 25.683913 samples/sec	 accuracy=44.742857	 loss=2.400199	 lr=0.524646
Epoch[071] Batch [0299]/[0717]	Speed: 25.970246 samples/sec	 accuracy=44.297619	 loss=2.419948	 lr=0.524376
Epoch[071] Batch [0349]/[0717]	Speed: 26.153921 samples/sec	 accuracy=44.122449	 loss=2.427710	 lr=0.524106
Epoch[071] Batch [0399]/[0717]	Speed: 25.919107 samples/sec	 accuracy=44.138393	 loss=2.430196	 lr=0.523836
Epoch[071] Batch [0449]/[0717]	Speed: 26.036909 samples/sec	 accuracy=43.996032	 loss=2.433929	 lr=0.523565
Epoch[071] Batch [0499]/[0717]	Speed: 26.117748 samples/sec	 accuracy=43.792857	 loss=2.436530	 lr=0.523294
Epoch[071] Batch [0549]/[0717]	Speed: 26.558268 samples/sec	 accuracy=43.681818	 loss=2.439919	 lr=0.523023
Epoch[071] Batch [0599]/[0717]	Speed: 26.017820 samples/sec	 accuracy=43.761905	 loss=2.440409	 lr=0.522751
Epoch[071] Batch [0649]/[0717]	Speed: 26.221182 samples/sec	 accuracy=43.821429	 loss=2.442722	 lr=0.522478
Epoch[071] Batch [0699]/[0717]	Speed: 25.740427 samples/sec	 accuracy=43.721939	 loss=2.444624	 lr=0.522206
Batch [0049]/[0057]: acc-top1=42.107143 acc-top5=69.500000
[Epoch 071] training: accuracy=43.741283	 loss=2.445881
[Epoch 071] speed: 26 samples/sec	time cost: 1605.067238
[Epoch 071] validation: acc-top1=40.966999 acc-top5=67.930237 loss=2.853765
Epoch[072] Batch [0049]/[0716]	Speed: 23.198759 samples/sec	 accuracy=44.285714	 loss=2.392240	 lr=0.521839
Epoch[072] Batch [0099]/[0716]	Speed: 25.766168 samples/sec	 accuracy=44.303571	 loss=2.381234	 lr=0.521566
Epoch[072] Batch [0149]/[0716]	Speed: 25.948673 samples/sec	 accuracy=44.642857	 loss=2.388246	 lr=0.521292
Epoch[072] Batch [0199]/[0716]	Speed: 25.904296 samples/sec	 accuracy=44.473214	 loss=2.387052	 lr=0.521017
Epoch[072] Batch [0249]/[0716]	Speed: 25.550399 samples/sec	 accuracy=44.535714	 loss=2.394848	 lr=0.520742
Epoch[072] Batch [0299]/[0716]	Speed: 26.297710 samples/sec	 accuracy=44.363095	 loss=2.403663	 lr=0.520467
Epoch[072] Batch [0349]/[0716]	Speed: 25.587306 samples/sec	 accuracy=44.147959	 loss=2.410893	 lr=0.520191
Epoch[072] Batch [0399]/[0716]	Speed: 25.718726 samples/sec	 accuracy=44.035714	 loss=2.411634	 lr=0.519915
Epoch[072] Batch [0449]/[0716]	Speed: 25.579157 samples/sec	 accuracy=44.031746	 loss=2.415038	 lr=0.519638
Epoch[072] Batch [0499]/[0716]	Speed: 26.392239 samples/sec	 accuracy=43.903571	 loss=2.418544	 lr=0.519362
Epoch[072] Batch [0549]/[0716]	Speed: 26.675352 samples/sec	 accuracy=43.750000	 loss=2.425878	 lr=0.519084
Epoch[072] Batch [0599]/[0716]	Speed: 26.168145 samples/sec	 accuracy=43.869048	 loss=2.421270	 lr=0.518806
Epoch[072] Batch [0649]/[0716]	Speed: 26.125955 samples/sec	 accuracy=43.821429	 loss=2.420699	 lr=0.518528
Epoch[072] Batch [0699]/[0716]	Speed: 26.215158 samples/sec	 accuracy=43.801020	 loss=2.420088	 lr=0.518250
Batch [0049]/[0057]: acc-top1=43.321429 acc-top5=72.142857
[Epoch 072] training: accuracy=43.767458	 loss=2.420655
[Epoch 072] speed: 25 samples/sec	time cost: 1607.725872
[Epoch 072] validation: acc-top1=42.987679 acc-top5=70.123222 loss=2.800656
Epoch[073] Batch [0049]/[0716]	Speed: 22.969648 samples/sec	 accuracy=46.500000	 loss=2.336602	 lr=0.517881
Epoch[073] Batch [0099]/[0716]	Speed: 26.305797 samples/sec	 accuracy=45.642857	 loss=2.387312	 lr=0.517602
Epoch[073] Batch [0149]/[0716]	Speed: 25.410886 samples/sec	 accuracy=45.404762	 loss=2.373659	 lr=0.517322
Epoch[073] Batch [0199]/[0716]	Speed: 25.566048 samples/sec	 accuracy=45.062500	 loss=2.385849	 lr=0.517042
Epoch[073] Batch [0249]/[0716]	Speed: 26.307119 samples/sec	 accuracy=45.100000	 loss=2.386060	 lr=0.516761
Epoch[073] Batch [0299]/[0716]	Speed: 26.504475 samples/sec	 accuracy=45.101190	 loss=2.378966	 lr=0.516480
Epoch[073] Batch [0349]/[0716]	Speed: 25.858731 samples/sec	 accuracy=45.316327	 loss=2.382519	 lr=0.516199
Epoch[073] Batch [0399]/[0716]	Speed: 25.858879 samples/sec	 accuracy=45.214286	 loss=2.387182	 lr=0.515917
Epoch[073] Batch [0449]/[0716]	Speed: 26.105358 samples/sec	 accuracy=45.150794	 loss=2.390880	 lr=0.515635
Epoch[073] Batch [0499]/[0716]	Speed: 26.131855 samples/sec	 accuracy=45.067857	 loss=2.393914	 lr=0.515352
Epoch[073] Batch [0549]/[0716]	Speed: 25.949734 samples/sec	 accuracy=45.000000	 loss=2.394829	 lr=0.515069
Epoch[073] Batch [0599]/[0716]	Speed: 25.766171 samples/sec	 accuracy=44.886905	 loss=2.401782	 lr=0.514785
Epoch[073] Batch [0649]/[0716]	Speed: 26.108954 samples/sec	 accuracy=44.766484	 loss=2.406399	 lr=0.514502
Epoch[073] Batch [0699]/[0716]	Speed: 26.215695 samples/sec	 accuracy=44.721939	 loss=2.406531	 lr=0.514217
Batch [0049]/[0057]: acc-top1=41.642857 acc-top5=70.107143
[Epoch 073] training: accuracy=44.757582	 loss=2.406077
[Epoch 073] speed: 25 samples/sec	time cost: 1609.535450
[Epoch 073] validation: acc-top1=41.729321 acc-top5=69.444443 loss=2.824228
Epoch[074] Batch [0049]/[0716]	Speed: 23.002810 samples/sec	 accuracy=44.892857	 loss=2.379684	 lr=0.513842
Epoch[074] Batch [0099]/[0716]	Speed: 25.746898 samples/sec	 accuracy=45.071429	 loss=2.354800	 lr=0.513556
Epoch[074] Batch [0149]/[0716]	Speed: 26.261543 samples/sec	 accuracy=44.761905	 loss=2.371797	 lr=0.513271
Epoch[074] Batch [0199]/[0716]	Speed: 26.298929 samples/sec	 accuracy=44.723214	 loss=2.371928	 lr=0.512985
Epoch[074] Batch [0249]/[0716]	Speed: 25.853670 samples/sec	 accuracy=44.500000	 loss=2.384011	 lr=0.512699
Epoch[074] Batch [0299]/[0716]	Speed: 26.190701 samples/sec	 accuracy=44.392857	 loss=2.390239	 lr=0.512412
Epoch[074] Batch [0349]/[0716]	Speed: 26.226612 samples/sec	 accuracy=44.280612	 loss=2.404402	 lr=0.512125
Epoch[074] Batch [0399]/[0716]	Speed: 25.728882 samples/sec	 accuracy=44.486607	 loss=2.400007	 lr=0.511837
Epoch[074] Batch [0449]/[0716]	Speed: 26.008901 samples/sec	 accuracy=44.472222	 loss=2.394610	 lr=0.511550
Epoch[074] Batch [0499]/[0716]	Speed: 25.657063 samples/sec	 accuracy=44.667857	 loss=2.392195	 lr=0.511261
Epoch[074] Batch [0549]/[0716]	Speed: 25.784078 samples/sec	 accuracy=44.691558	 loss=2.392625	 lr=0.510973
Epoch[074] Batch [0599]/[0716]	Speed: 26.073645 samples/sec	 accuracy=44.592262	 loss=2.398749	 lr=0.510684
Epoch[074] Batch [0649]/[0716]	Speed: 25.960869 samples/sec	 accuracy=44.593407	 loss=2.401814	 lr=0.510394
Epoch[074] Batch [0699]/[0716]	Speed: 26.474302 samples/sec	 accuracy=44.573980	 loss=2.403665	 lr=0.510104
Batch [0049]/[0057]: acc-top1=43.107143 acc-top5=70.035714
[Epoch 074] training: accuracy=44.535615	 loss=2.404005
[Epoch 074] speed: 25 samples/sec	time cost: 1606.860744
[Epoch 074] validation: acc-top1=42.789265 acc-top5=69.825607 loss=2.723371
Epoch[075] Batch [0049]/[0716]	Speed: 23.172050 samples/sec	 accuracy=45.785714	 loss=2.336177	 lr=0.509721
Epoch[075] Batch [0099]/[0716]	Speed: 25.946687 samples/sec	 accuracy=45.517857	 loss=2.320613	 lr=0.509431
Epoch[075] Batch [0149]/[0716]	Speed: 26.087114 samples/sec	 accuracy=45.226190	 loss=2.341942	 lr=0.509139
Epoch[075] Batch [0199]/[0716]	Speed: 26.289557 samples/sec	 accuracy=45.250000	 loss=2.352072	 lr=0.508848
Epoch[075] Batch [0249]/[0716]	Speed: 26.495430 samples/sec	 accuracy=45.128571	 loss=2.363980	 lr=0.508556
Epoch[075] Batch [0299]/[0716]	Speed: 26.143467 samples/sec	 accuracy=45.029762	 loss=2.371724	 lr=0.508264
Epoch[075] Batch [0349]/[0716]	Speed: 26.510488 samples/sec	 accuracy=44.928571	 loss=2.375475	 lr=0.507971
Epoch[075] Batch [0399]/[0716]	Speed: 25.745837 samples/sec	 accuracy=44.830357	 loss=2.380143	 lr=0.507678
Epoch[075] Batch [0449]/[0716]	Speed: 26.188688 samples/sec	 accuracy=44.662698	 loss=2.381130	 lr=0.507385
Epoch[075] Batch [0499]/[0716]	Speed: 25.780570 samples/sec	 accuracy=44.496429	 loss=2.393644	 lr=0.507091
Epoch[075] Batch [0549]/[0716]	Speed: 26.487037 samples/sec	 accuracy=44.418831	 loss=2.398479	 lr=0.506797
Epoch[075] Batch [0599]/[0716]	Speed: 25.784205 samples/sec	 accuracy=44.351190	 loss=2.402474	 lr=0.506502
Epoch[075] Batch [0649]/[0716]	Speed: 26.077547 samples/sec	 accuracy=44.274725	 loss=2.406109	 lr=0.506208
Epoch[075] Batch [0699]/[0716]	Speed: 25.946895 samples/sec	 accuracy=44.209184	 loss=2.409020	 lr=0.505912
Batch [0049]/[0057]: acc-top1=40.428571 acc-top5=66.535714
[Epoch 075] training: accuracy=44.183958	 loss=2.410411
[Epoch 075] speed: 26 samples/sec	time cost: 1601.589232
[Epoch 075] validation: acc-top1=40.048035 acc-top5=66.922516 loss=3.139496
Epoch[076] Batch [0049]/[0716]	Speed: 22.671116 samples/sec	 accuracy=43.071429	 loss=2.454869	 lr=0.505522
Epoch[076] Batch [0099]/[0716]	Speed: 26.549003 samples/sec	 accuracy=44.642857	 loss=2.394578	 lr=0.505226
Epoch[076] Batch [0149]/[0716]	Speed: 25.591065 samples/sec	 accuracy=44.214286	 loss=2.415413	 lr=0.504929
Epoch[076] Batch [0199]/[0716]	Speed: 25.998560 samples/sec	 accuracy=44.330357	 loss=2.405917	 lr=0.504632
Epoch[076] Batch [0249]/[0716]	Speed: 25.616690 samples/sec	 accuracy=44.207143	 loss=2.425976	 lr=0.504335
Epoch[076] Batch [0299]/[0716]	Speed: 25.947414 samples/sec	 accuracy=44.363095	 loss=2.420168	 lr=0.504037
Epoch[076] Batch [0349]/[0716]	Speed: 25.773952 samples/sec	 accuracy=44.530612	 loss=2.412350	 lr=0.503739
Epoch[076] Batch [0399]/[0716]	Speed: 26.377132 samples/sec	 accuracy=44.598214	 loss=2.409635	 lr=0.503441
Epoch[076] Batch [0449]/[0716]	Speed: 26.313026 samples/sec	 accuracy=44.500000	 loss=2.408631	 lr=0.503142
Epoch[076] Batch [0499]/[0716]	Speed: 26.000360 samples/sec	 accuracy=44.514286	 loss=2.404146	 lr=0.502843
Epoch[076] Batch [0549]/[0716]	Speed: 25.789546 samples/sec	 accuracy=44.435065	 loss=2.407751	 lr=0.502544
Epoch[076] Batch [0599]/[0716]	Speed: 26.150036 samples/sec	 accuracy=44.491071	 loss=2.405747	 lr=0.502244
Epoch[076] Batch [0649]/[0716]	Speed: 26.391861 samples/sec	 accuracy=44.381868	 loss=2.410854	 lr=0.501944
Epoch[076] Batch [0699]/[0716]	Speed: 25.890727 samples/sec	 accuracy=44.405612	 loss=2.405552	 lr=0.501643
Batch [0049]/[0057]: acc-top1=38.892857 acc-top5=67.035714
[Epoch 076] training: accuracy=44.405926	 loss=2.404109
[Epoch 076] speed: 25 samples/sec	time cost: 1606.361213
[Epoch 076] validation: acc-top1=40.230785 acc-top5=67.444656 loss=2.920368
Epoch[077] Batch [0049]/[0716]	Speed: 23.097465 samples/sec	 accuracy=44.964286	 loss=2.430983	 lr=0.501245
Epoch[077] Batch [0099]/[0716]	Speed: 25.851090 samples/sec	 accuracy=45.571429	 loss=2.383869	 lr=0.500944
Epoch[077] Batch [0149]/[0716]	Speed: 25.875944 samples/sec	 accuracy=45.345238	 loss=2.378647	 lr=0.500642
Epoch[077] Batch [0199]/[0716]	Speed: 26.065404 samples/sec	 accuracy=45.437500	 loss=2.368531	 lr=0.500340
Epoch[077] Batch [0249]/[0716]	Speed: 26.031530 samples/sec	 accuracy=44.957143	 loss=2.382514	 lr=0.500037
Epoch[077] Batch [0299]/[0716]	Speed: 25.658319 samples/sec	 accuracy=45.059524	 loss=2.383542	 lr=0.499734
Epoch[077] Batch [0349]/[0716]	Speed: 25.853526 samples/sec	 accuracy=44.979592	 loss=2.392363	 lr=0.499431
Epoch[077] Batch [0399]/[0716]	Speed: 26.143280 samples/sec	 accuracy=45.049107	 loss=2.386654	 lr=0.499127
Epoch[077] Batch [0449]/[0716]	Speed: 25.911927 samples/sec	 accuracy=45.023810	 loss=2.385740	 lr=0.498823
Epoch[077] Batch [0499]/[0716]	Speed: 26.323991 samples/sec	 accuracy=45.057143	 loss=2.386281	 lr=0.498519
Epoch[077] Batch [0549]/[0716]	Speed: 26.117546 samples/sec	 accuracy=45.224026	 loss=2.381358	 lr=0.498214
Epoch[077] Batch [0599]/[0716]	Speed: 26.000612 samples/sec	 accuracy=45.172619	 loss=2.384519	 lr=0.497909
Epoch[077] Batch [0649]/[0716]	Speed: 26.356952 samples/sec	 accuracy=45.054945	 loss=2.389487	 lr=0.497603
Epoch[077] Batch [0699]/[0716]	Speed: 25.727795 samples/sec	 accuracy=44.928571	 loss=2.396559	 lr=0.497298
Batch [0049]/[0057]: acc-top1=42.071429 acc-top5=69.250000
[Epoch 077] training: accuracy=44.894753	 loss=2.398433
[Epoch 077] speed: 25 samples/sec	time cost: 1608.372682
[Epoch 077] validation: acc-top1=41.891190 acc-top5=68.796989 loss=2.867748
Epoch[078] Batch [0049]/[0716]	Speed: 23.278814 samples/sec	 accuracy=44.928571	 loss=2.396739	 lr=0.496893
Epoch[078] Batch [0099]/[0716]	Speed: 26.188315 samples/sec	 accuracy=44.178571	 loss=2.411941	 lr=0.496587
Epoch[078] Batch [0149]/[0716]	Speed: 25.668092 samples/sec	 accuracy=45.023810	 loss=2.373260	 lr=0.496280
Epoch[078] Batch [0199]/[0716]	Speed: 25.339846 samples/sec	 accuracy=45.017857	 loss=2.377513	 lr=0.495972
Epoch[078] Batch [0249]/[0716]	Speed: 26.157409 samples/sec	 accuracy=44.828571	 loss=2.385636	 lr=0.495664
Epoch[078] Batch [0299]/[0716]	Speed: 26.168416 samples/sec	 accuracy=44.982143	 loss=2.380968	 lr=0.495356
Epoch[078] Batch [0349]/[0716]	Speed: 26.475441 samples/sec	 accuracy=45.071429	 loss=2.377102	 lr=0.495048
Epoch[078] Batch [0399]/[0716]	Speed: 26.033952 samples/sec	 accuracy=45.000000	 loss=2.378960	 lr=0.494739
Epoch[078] Batch [0449]/[0716]	Speed: 25.991706 samples/sec	 accuracy=45.027778	 loss=2.377862	 lr=0.494430
Epoch[078] Batch [0499]/[0716]	Speed: 26.063573 samples/sec	 accuracy=44.928571	 loss=2.380890	 lr=0.494120
Epoch[078] Batch [0549]/[0716]	Speed: 26.181915 samples/sec	 accuracy=44.870130	 loss=2.381927	 lr=0.493810
Epoch[078] Batch [0599]/[0716]	Speed: 26.144970 samples/sec	 accuracy=44.776786	 loss=2.384954	 lr=0.493500
Epoch[078] Batch [0649]/[0716]	Speed: 26.185477 samples/sec	 accuracy=44.717033	 loss=2.386574	 lr=0.493189
Epoch[078] Batch [0699]/[0716]	Speed: 25.999758 samples/sec	 accuracy=44.923469	 loss=2.377679	 lr=0.492878
Batch [0049]/[0057]: acc-top1=43.250000 acc-top5=69.357143
[Epoch 078] training: accuracy=44.897247	 loss=2.380318
[Epoch 078] speed: 25 samples/sec	time cost: 1605.968143
[Epoch 078] validation: acc-top1=43.269634 acc-top5=70.154556 loss=2.789466
Epoch[079] Batch [0049]/[0717]	Speed: 23.124014 samples/sec	 accuracy=46.107143	 loss=2.325978	 lr=0.492467
Epoch[079] Batch [0099]/[0717]	Speed: 26.307693 samples/sec	 accuracy=45.053571	 loss=2.369039	 lr=0.492155
Epoch[079] Batch [0149]/[0717]	Speed: 25.828592 samples/sec	 accuracy=44.928571	 loss=2.380627	 lr=0.491843
Epoch[079] Batch [0199]/[0717]	Speed: 26.000804 samples/sec	 accuracy=45.339286	 loss=2.366814	 lr=0.491531
Epoch[079] Batch [0249]/[0717]	Speed: 26.110604 samples/sec	 accuracy=45.592857	 loss=2.360579	 lr=0.491218
Epoch[079] Batch [0299]/[0717]	Speed: 26.317627 samples/sec	 accuracy=45.363095	 loss=2.367996	 lr=0.490904
Epoch[079] Batch [0349]/[0717]	Speed: 26.471791 samples/sec	 accuracy=45.295918	 loss=2.363162	 lr=0.490591
Epoch[079] Batch [0399]/[0717]	Speed: 25.823440 samples/sec	 accuracy=45.250000	 loss=2.362819	 lr=0.490277
Epoch[079] Batch [0449]/[0717]	Speed: 25.414308 samples/sec	 accuracy=45.214286	 loss=2.362631	 lr=0.489963
Epoch[079] Batch [0499]/[0717]	Speed: 26.112489 samples/sec	 accuracy=45.171429	 loss=2.372036	 lr=0.489648
Epoch[079] Batch [0549]/[0717]	Speed: 26.353423 samples/sec	 accuracy=45.113636	 loss=2.376169	 lr=0.489333
Epoch[079] Batch [0599]/[0717]	Speed: 25.598737 samples/sec	 accuracy=44.916667	 loss=2.383979	 lr=0.489018
Epoch[079] Batch [0649]/[0717]	Speed: 25.923816 samples/sec	 accuracy=44.829670	 loss=2.391792	 lr=0.488702
Epoch[079] Batch [0699]/[0717]	Speed: 26.191213 samples/sec	 accuracy=44.757653	 loss=2.395384	 lr=0.488386
Batch [0049]/[0057]: acc-top1=43.464286 acc-top5=70.357143
[Epoch 079] training: accuracy=44.772365	 loss=2.394470
[Epoch 079] speed: 25 samples/sec	time cost: 1609.372520
[Epoch 079] validation: acc-top1=42.141815 acc-top5=68.723892 loss=3.033501
Epoch[080] Batch [0049]/[0716]	Speed: 22.808097 samples/sec	 accuracy=46.928571	 loss=2.283147	 lr=0.487962
Epoch[080] Batch [0099]/[0716]	Speed: 25.944199 samples/sec	 accuracy=45.571429	 loss=2.342856	 lr=0.487645
Epoch[080] Batch [0149]/[0716]	Speed: 25.788907 samples/sec	 accuracy=45.059524	 loss=2.366530	 lr=0.487328
Epoch[080] Batch [0199]/[0716]	Speed: 25.795813 samples/sec	 accuracy=44.910714	 loss=2.366834	 lr=0.487011
Epoch[080] Batch [0249]/[0716]	Speed: 26.060481 samples/sec	 accuracy=44.842857	 loss=2.376543	 lr=0.486693
Epoch[080] Batch [0299]/[0716]	Speed: 25.668623 samples/sec	 accuracy=45.101190	 loss=2.372032	 lr=0.486375
Epoch[080] Batch [0349]/[0716]	Speed: 26.195676 samples/sec	 accuracy=44.770408	 loss=2.382877	 lr=0.486056
Epoch[080] Batch [0399]/[0716]	Speed: 26.206682 samples/sec	 accuracy=44.656250	 loss=2.385989	 lr=0.485737
Epoch[080] Batch [0449]/[0716]	Speed: 25.873674 samples/sec	 accuracy=44.769841	 loss=2.378411	 lr=0.485418
Epoch[080] Batch [0499]/[0716]	Speed: 26.422970 samples/sec	 accuracy=44.796429	 loss=2.376110	 lr=0.485098
Epoch[080] Batch [0549]/[0716]	Speed: 26.501956 samples/sec	 accuracy=44.753247	 loss=2.377391	 lr=0.484779
Epoch[080] Batch [0599]/[0716]	Speed: 26.327303 samples/sec	 accuracy=44.669643	 loss=2.382689	 lr=0.484458
Epoch[080] Batch [0649]/[0716]	Speed: 26.162578 samples/sec	 accuracy=44.604396	 loss=2.385213	 lr=0.484138
Epoch[080] Batch [0699]/[0716]	Speed: 26.454476 samples/sec	 accuracy=44.632653	 loss=2.387180	 lr=0.483817
Batch [0049]/[0057]: acc-top1=41.035714 acc-top5=69.357143
[Epoch 080] training: accuracy=44.670291	 loss=2.384873
[Epoch 080] speed: 25 samples/sec	time cost: 1605.227296
[Epoch 080] validation: acc-top1=42.622185 acc-top5=69.266914 loss=2.822556
Epoch[081] Batch [0049]/[0716]	Speed: 23.561263 samples/sec	 accuracy=45.642857	 loss=2.324919	 lr=0.483393
Epoch[081] Batch [0099]/[0716]	Speed: 26.211141 samples/sec	 accuracy=45.517857	 loss=2.325213	 lr=0.483071
Epoch[081] Batch [0149]/[0716]	Speed: 26.106941 samples/sec	 accuracy=45.654762	 loss=2.320202	 lr=0.482749
Epoch[081] Batch [0199]/[0716]	Speed: 25.891026 samples/sec	 accuracy=45.116071	 loss=2.353549	 lr=0.482427
Epoch[081] Batch [0249]/[0716]	Speed: 26.156657 samples/sec	 accuracy=45.192857	 loss=2.360398	 lr=0.482104
Epoch[081] Batch [0299]/[0716]	Speed: 25.966955 samples/sec	 accuracy=44.857143	 loss=2.371437	 lr=0.481781
Epoch[081] Batch [0349]/[0716]	Speed: 26.150418 samples/sec	 accuracy=44.816327	 loss=2.369786	 lr=0.481458
Epoch[081] Batch [0399]/[0716]	Speed: 26.088055 samples/sec	 accuracy=45.017857	 loss=2.363780	 lr=0.481134
Epoch[081] Batch [0449]/[0716]	Speed: 26.137118 samples/sec	 accuracy=44.876984	 loss=2.367804	 lr=0.480810
Epoch[081] Batch [0499]/[0716]	Speed: 25.516834 samples/sec	 accuracy=45.060714	 loss=2.364420	 lr=0.480485
Epoch[081] Batch [0549]/[0716]	Speed: 26.493659 samples/sec	 accuracy=45.012987	 loss=2.368180	 lr=0.480161
Epoch[081] Batch [0599]/[0716]	Speed: 25.898088 samples/sec	 accuracy=44.988095	 loss=2.372234	 lr=0.479836
Epoch[081] Batch [0649]/[0716]	Speed: 26.362334 samples/sec	 accuracy=45.068681	 loss=2.369769	 lr=0.479510
Epoch[081] Batch [0699]/[0716]	Speed: 25.733942 samples/sec	 accuracy=45.033163	 loss=2.369084	 lr=0.479185
Batch [0049]/[0057]: acc-top1=42.500000 acc-top5=68.035714
[Epoch 081] training: accuracy=45.041899	 loss=2.369308
[Epoch 081] speed: 26 samples/sec	time cost: 1603.071998
[Epoch 081] validation: acc-top1=42.376770 acc-top5=69.204262 loss=2.788123
Epoch[082] Batch [0049]/[0716]	Speed: 22.825864 samples/sec	 accuracy=45.107143	 loss=2.379617	 lr=0.478754
Epoch[082] Batch [0099]/[0716]	Speed: 25.743898 samples/sec	 accuracy=45.232143	 loss=2.379589	 lr=0.478428
Epoch[082] Batch [0149]/[0716]	Speed: 26.382477 samples/sec	 accuracy=45.154762	 loss=2.379984	 lr=0.478101
Epoch[082] Batch [0199]/[0716]	Speed: 25.423801 samples/sec	 accuracy=45.160714	 loss=2.373138	 lr=0.477774
Epoch[082] Batch [0249]/[0716]	Speed: 26.035143 samples/sec	 accuracy=45.385714	 loss=2.354906	 lr=0.477447
Epoch[082] Batch [0299]/[0716]	Speed: 26.254729 samples/sec	 accuracy=45.351190	 loss=2.362687	 lr=0.477119
Epoch[082] Batch [0349]/[0716]	Speed: 26.229444 samples/sec	 accuracy=45.270408	 loss=2.367208	 lr=0.476791
Epoch[082] Batch [0399]/[0716]	Speed: 26.051430 samples/sec	 accuracy=44.955357	 loss=2.374214	 lr=0.476462
Epoch[082] Batch [0449]/[0716]	Speed: 25.837576 samples/sec	 accuracy=44.873016	 loss=2.378350	 lr=0.476134
Epoch[082] Batch [0499]/[0716]	Speed: 26.382628 samples/sec	 accuracy=44.775000	 loss=2.383967	 lr=0.475805
Epoch[082] Batch [0549]/[0716]	Speed: 25.999401 samples/sec	 accuracy=44.769481	 loss=2.383345	 lr=0.475475
Epoch[082] Batch [0599]/[0716]	Speed: 26.625729 samples/sec	 accuracy=44.851190	 loss=2.375375	 lr=0.475146
Epoch[082] Batch [0649]/[0716]	Speed: 25.752373 samples/sec	 accuracy=44.859890	 loss=2.377482	 lr=0.474816
Epoch[082] Batch [0699]/[0716]	Speed: 26.218214 samples/sec	 accuracy=44.752551	 loss=2.379843	 lr=0.474485
Batch [0049]/[0057]: acc-top1=41.678571 acc-top5=70.571429
[Epoch 082] training: accuracy=44.730148	 loss=2.380542
[Epoch 082] speed: 26 samples/sec	time cost: 1603.933185
[Epoch 082] validation: acc-top1=41.812862 acc-top5=69.251251 loss=2.875904
Epoch[083] Batch [0049]/[0716]	Speed: 23.371366 samples/sec	 accuracy=47.285714	 loss=2.274792	 lr=0.474049
Epoch[083] Batch [0099]/[0716]	Speed: 26.498655 samples/sec	 accuracy=47.017857	 loss=2.286047	 lr=0.473718
Epoch[083] Batch [0149]/[0716]	Speed: 26.209460 samples/sec	 accuracy=46.142857	 loss=2.324047	 lr=0.473386
Epoch[083] Batch [0199]/[0716]	Speed: 25.841822 samples/sec	 accuracy=45.910714	 loss=2.331223	 lr=0.473055
Epoch[083] Batch [0249]/[0716]	Speed: 26.572493 samples/sec	 accuracy=45.792857	 loss=2.338819	 lr=0.472723
Epoch[083] Batch [0299]/[0716]	Speed: 25.791310 samples/sec	 accuracy=45.821429	 loss=2.338186	 lr=0.472390
Epoch[083] Batch [0349]/[0716]	Speed: 25.689375 samples/sec	 accuracy=45.719388	 loss=2.342686	 lr=0.472058
Epoch[083] Batch [0399]/[0716]	Speed: 26.320921 samples/sec	 accuracy=45.723214	 loss=2.345139	 lr=0.471725
Epoch[083] Batch [0449]/[0716]	Speed: 25.685024 samples/sec	 accuracy=45.563492	 loss=2.354642	 lr=0.471391
Epoch[083] Batch [0499]/[0716]	Speed: 26.013447 samples/sec	 accuracy=45.457143	 loss=2.356091	 lr=0.471058
Epoch[083] Batch [0549]/[0716]	Speed: 26.176701 samples/sec	 accuracy=45.474026	 loss=2.354614	 lr=0.470724
Epoch[083] Batch [0599]/[0716]	Speed: 26.394157 samples/sec	 accuracy=45.410714	 loss=2.355438	 lr=0.470390
Epoch[083] Batch [0649]/[0716]	Speed: 26.181261 samples/sec	 accuracy=45.368132	 loss=2.356707	 lr=0.470055
Epoch[083] Batch [0699]/[0716]	Speed: 25.836021 samples/sec	 accuracy=45.367347	 loss=2.355218	 lr=0.469720
Batch [0049]/[0057]: acc-top1=41.928571 acc-top5=69.964286
[Epoch 083] training: accuracy=45.435954	 loss=2.352233
[Epoch 083] speed: 26 samples/sec	time cost: 1600.973226
[Epoch 083] validation: acc-top1=42.256687 acc-top5=69.366119 loss=3.131407
Epoch[084] Batch [0049]/[0716]	Speed: 22.884197 samples/sec	 accuracy=46.678571	 loss=2.353265	 lr=0.469278
Epoch[084] Batch [0099]/[0716]	Speed: 26.435101 samples/sec	 accuracy=46.107143	 loss=2.348376	 lr=0.468942
Epoch[084] Batch [0149]/[0716]	Speed: 26.233424 samples/sec	 accuracy=45.595238	 loss=2.367087	 lr=0.468606
Epoch[084] Batch [0199]/[0716]	Speed: 26.446113 samples/sec	 accuracy=45.723214	 loss=2.371681	 lr=0.468270
Epoch[084] Batch [0249]/[0716]	Speed: 25.812279 samples/sec	 accuracy=45.807143	 loss=2.366158	 lr=0.467934
Epoch[084] Batch [0299]/[0716]	Speed: 26.100165 samples/sec	 accuracy=45.589286	 loss=2.368139	 lr=0.467597
Epoch[084] Batch [0349]/[0716]	Speed: 26.683852 samples/sec	 accuracy=45.739796	 loss=2.363552	 lr=0.467260
Epoch[084] Batch [0399]/[0716]	Speed: 26.500098 samples/sec	 accuracy=45.825893	 loss=2.356518	 lr=0.466922
Epoch[084] Batch [0449]/[0716]	Speed: 26.027047 samples/sec	 accuracy=45.682540	 loss=2.355014	 lr=0.466584
Epoch[084] Batch [0499]/[0716]	Speed: 25.845210 samples/sec	 accuracy=45.503571	 loss=2.362494	 lr=0.466246
Epoch[084] Batch [0549]/[0716]	Speed: 26.031519 samples/sec	 accuracy=45.314935	 loss=2.364093	 lr=0.465908
Epoch[084] Batch [0599]/[0716]	Speed: 26.084025 samples/sec	 accuracy=45.467262	 loss=2.356535	 lr=0.465569
Epoch[084] Batch [0649]/[0716]	Speed: 25.847745 samples/sec	 accuracy=45.346154	 loss=2.359848	 lr=0.465231
Epoch[084] Batch [0699]/[0716]	Speed: 26.054394 samples/sec	 accuracy=45.354592	 loss=2.363230	 lr=0.464891
Batch [0049]/[0057]: acc-top1=44.857143 acc-top5=71.892857
[Epoch 084] training: accuracy=45.336193	 loss=2.363715
[Epoch 084] speed: 26 samples/sec	time cost: 1600.281159
[Epoch 084] validation: acc-top1=43.937973 acc-top5=71.287590 loss=2.626245
Epoch[085] Batch [0049]/[0716]	Speed: 23.193098 samples/sec	 accuracy=44.892857	 loss=2.329619	 lr=0.464443
Epoch[085] Batch [0099]/[0716]	Speed: 26.115306 samples/sec	 accuracy=46.089286	 loss=2.308730	 lr=0.464103
Epoch[085] Batch [0149]/[0716]	Speed: 26.145958 samples/sec	 accuracy=45.404762	 loss=2.333436	 lr=0.463763
Epoch[085] Batch [0199]/[0716]	Speed: 26.267487 samples/sec	 accuracy=45.571429	 loss=2.344233	 lr=0.463422
Epoch[085] Batch [0249]/[0716]	Speed: 26.067919 samples/sec	 accuracy=45.457143	 loss=2.352803	 lr=0.463081
Epoch[085] Batch [0299]/[0716]	Speed: 25.648503 samples/sec	 accuracy=45.255952	 loss=2.358160	 lr=0.462740
Epoch[085] Batch [0349]/[0716]	Speed: 26.001575 samples/sec	 accuracy=45.244898	 loss=2.362873	 lr=0.462399
Epoch[085] Batch [0399]/[0716]	Speed: 26.175745 samples/sec	 accuracy=45.276786	 loss=2.361339	 lr=0.462057
Epoch[085] Batch [0449]/[0716]	Speed: 26.002799 samples/sec	 accuracy=45.484127	 loss=2.355822	 lr=0.461715
Epoch[085] Batch [0499]/[0716]	Speed: 26.326955 samples/sec	 accuracy=45.585714	 loss=2.354113	 lr=0.461373
Epoch[085] Batch [0549]/[0716]	Speed: 25.857633 samples/sec	 accuracy=45.428571	 loss=2.360066	 lr=0.461030
Epoch[085] Batch [0599]/[0716]	Speed: 25.870297 samples/sec	 accuracy=45.330357	 loss=2.361939	 lr=0.460687
Epoch[085] Batch [0649]/[0716]	Speed: 25.867533 samples/sec	 accuracy=45.252747	 loss=2.362701	 lr=0.460344
Epoch[085] Batch [0699]/[0716]	Speed: 26.370878 samples/sec	 accuracy=45.313776	 loss=2.359483	 lr=0.460000
Batch [0049]/[0057]: acc-top1=42.750000 acc-top5=68.642857
[Epoch 085] training: accuracy=45.326217	 loss=2.359581
[Epoch 085] speed: 26 samples/sec	time cost: 1604.283344
[Epoch 085] validation: acc-top1=42.152252 acc-top5=69.021515 loss=2.840499
Epoch[086] Batch [0049]/[0716]	Speed: 23.377388 samples/sec	 accuracy=47.785714	 loss=2.280717	 lr=0.459546
Epoch[086] Batch [0099]/[0716]	Speed: 26.314189 samples/sec	 accuracy=46.803571	 loss=2.309709	 lr=0.459202
Epoch[086] Batch [0149]/[0716]	Speed: 26.216114 samples/sec	 accuracy=46.357143	 loss=2.324360	 lr=0.458858
Epoch[086] Batch [0199]/[0716]	Speed: 26.032511 samples/sec	 accuracy=45.866071	 loss=2.333078	 lr=0.458513
Epoch[086] Batch [0249]/[0716]	Speed: 26.027279 samples/sec	 accuracy=45.721429	 loss=2.332279	 lr=0.458168
Epoch[086] Batch [0299]/[0716]	Speed: 26.141863 samples/sec	 accuracy=45.827381	 loss=2.330319	 lr=0.457823
Epoch[086] Batch [0349]/[0716]	Speed: 26.050658 samples/sec	 accuracy=45.658163	 loss=2.335449	 lr=0.457477
Epoch[086] Batch [0399]/[0716]	Speed: 26.112390 samples/sec	 accuracy=45.727679	 loss=2.334755	 lr=0.457131
Epoch[086] Batch [0449]/[0716]	Speed: 26.147844 samples/sec	 accuracy=45.587302	 loss=2.338318	 lr=0.456785
Epoch[086] Batch [0499]/[0716]	Speed: 26.163355 samples/sec	 accuracy=45.578571	 loss=2.334691	 lr=0.456438
Epoch[086] Batch [0549]/[0716]	Speed: 26.062837 samples/sec	 accuracy=45.629870	 loss=2.334109	 lr=0.456091
Epoch[086] Batch [0599]/[0716]	Speed: 25.960071 samples/sec	 accuracy=45.639881	 loss=2.332653	 lr=0.455744
Epoch[086] Batch [0649]/[0716]	Speed: 26.203422 samples/sec	 accuracy=45.587912	 loss=2.340907	 lr=0.455397
Epoch[086] Batch [0699]/[0716]	Speed: 25.855851 samples/sec	 accuracy=45.607143	 loss=2.340724	 lr=0.455049
Batch [0049]/[0057]: acc-top1=45.535714 acc-top5=71.964286
[Epoch 086] training: accuracy=45.632981	 loss=2.342140
[Epoch 086] speed: 26 samples/sec	time cost: 1600.653061
[Epoch 086] validation: acc-top1=44.313908 acc-top5=71.245819 loss=2.676919
Epoch[087] Batch [0049]/[0717]	Speed: 22.460058 samples/sec	 accuracy=46.142857	 loss=2.286670	 lr=0.454590
Epoch[087] Batch [0099]/[0717]	Speed: 26.035280 samples/sec	 accuracy=45.964286	 loss=2.310531	 lr=0.454242
Epoch[087] Batch [0149]/[0717]	Speed: 26.130978 samples/sec	 accuracy=46.214286	 loss=2.307792	 lr=0.453893
Epoch[087] Batch [0199]/[0717]	Speed: 26.228082 samples/sec	 accuracy=45.892857	 loss=2.317253	 lr=0.453544
Epoch[087] Batch [0249]/[0717]	Speed: 25.326583 samples/sec	 accuracy=46.007143	 loss=2.309451	 lr=0.453195
Epoch[087] Batch [0299]/[0717]	Speed: 25.967731 samples/sec	 accuracy=45.666667	 loss=2.326918	 lr=0.452845
Epoch[087] Batch [0349]/[0717]	Speed: 26.362487 samples/sec	 accuracy=45.607143	 loss=2.327071	 lr=0.452496
Epoch[087] Batch [0399]/[0717]	Speed: 26.147387 samples/sec	 accuracy=45.732143	 loss=2.319196	 lr=0.452146
Epoch[087] Batch [0449]/[0717]	Speed: 26.119721 samples/sec	 accuracy=45.559524	 loss=2.320487	 lr=0.451795
Epoch[087] Batch [0499]/[0717]	Speed: 26.288937 samples/sec	 accuracy=45.667857	 loss=2.321626	 lr=0.451445
Epoch[087] Batch [0549]/[0717]	Speed: 26.012939 samples/sec	 accuracy=45.568182	 loss=2.326881	 lr=0.451094
Epoch[087] Batch [0599]/[0717]	Speed: 25.785797 samples/sec	 accuracy=45.479167	 loss=2.332955	 lr=0.450743
Epoch[087] Batch [0649]/[0717]	Speed: 26.016009 samples/sec	 accuracy=45.653846	 loss=2.328770	 lr=0.450392
Epoch[087] Batch [0699]/[0717]	Speed: 26.162801 samples/sec	 accuracy=45.591837	 loss=2.333623	 lr=0.450040
Batch [0049]/[0057]: acc-top1=40.678571 acc-top5=67.750000
[Epoch 087] training: accuracy=45.524507	 loss=2.334735
[Epoch 087] speed: 25 samples/sec	time cost: 1612.326814
[Epoch 087] validation: acc-top1=41.442146 acc-top5=69.068504 loss=2.993769
Epoch[088] Batch [0049]/[0716]	Speed: 22.871819 samples/sec	 accuracy=47.071429	 loss=2.286020	 lr=0.449568
Epoch[088] Batch [0099]/[0716]	Speed: 26.228000 samples/sec	 accuracy=46.357143	 loss=2.295942	 lr=0.449216
Epoch[088] Batch [0149]/[0716]	Speed: 25.815277 samples/sec	 accuracy=46.226190	 loss=2.306707	 lr=0.448863
Epoch[088] Batch [0199]/[0716]	Speed: 25.920588 samples/sec	 accuracy=46.026786	 loss=2.321526	 lr=0.448510
Epoch[088] Batch [0249]/[0716]	Speed: 26.257467 samples/sec	 accuracy=45.957143	 loss=2.324768	 lr=0.448157
Epoch[088] Batch [0299]/[0716]	Speed: 25.951525 samples/sec	 accuracy=45.952381	 loss=2.323309	 lr=0.447804
Epoch[088] Batch [0349]/[0716]	Speed: 26.138581 samples/sec	 accuracy=46.010204	 loss=2.324819	 lr=0.447450
Epoch[088] Batch [0399]/[0716]	Speed: 25.838119 samples/sec	 accuracy=45.883929	 loss=2.323752	 lr=0.447096
Epoch[088] Batch [0449]/[0716]	Speed: 25.927199 samples/sec	 accuracy=45.972222	 loss=2.323302	 lr=0.446742
Epoch[088] Batch [0499]/[0716]	Speed: 26.433236 samples/sec	 accuracy=45.975000	 loss=2.326976	 lr=0.446388
Epoch[088] Batch [0549]/[0716]	Speed: 25.609947 samples/sec	 accuracy=45.808442	 loss=2.336396	 lr=0.446033
Epoch[088] Batch [0599]/[0716]	Speed: 26.110486 samples/sec	 accuracy=45.744048	 loss=2.340477	 lr=0.445678
Epoch[088] Batch [0649]/[0716]	Speed: 26.027142 samples/sec	 accuracy=45.703297	 loss=2.341286	 lr=0.445322
Epoch[088] Batch [0699]/[0716]	Speed: 25.996083 samples/sec	 accuracy=45.658163	 loss=2.339189	 lr=0.444967
Batch [0049]/[0057]: acc-top1=42.107143 acc-top5=68.214286
[Epoch 088] training: accuracy=45.697825	 loss=2.337225
[Epoch 088] speed: 25 samples/sec	time cost: 1608.418452
[Epoch 088] validation: acc-top1=40.998329 acc-top5=67.564743 loss=3.123027
Epoch[089] Batch [0049]/[0716]	Speed: 23.017657 samples/sec	 accuracy=46.071429	 loss=2.301125	 lr=0.444497
Epoch[089] Batch [0099]/[0716]	Speed: 25.765505 samples/sec	 accuracy=46.321429	 loss=2.290817	 lr=0.444141
Epoch[089] Batch [0149]/[0716]	Speed: 26.449410 samples/sec	 accuracy=46.369048	 loss=2.297805	 lr=0.443785
Epoch[089] Batch [0199]/[0716]	Speed: 25.918573 samples/sec	 accuracy=46.553571	 loss=2.291566	 lr=0.443428
Epoch[089] Batch [0249]/[0716]	Speed: 26.044368 samples/sec	 accuracy=46.471429	 loss=2.295350	 lr=0.443071
Epoch[089] Batch [0299]/[0716]	Speed: 25.654134 samples/sec	 accuracy=46.529762	 loss=2.296830	 lr=0.442714
Epoch[089] Batch [0349]/[0716]	Speed: 26.251893 samples/sec	 accuracy=46.433673	 loss=2.302449	 lr=0.442356
Epoch[089] Batch [0399]/[0716]	Speed: 25.885622 samples/sec	 accuracy=46.437500	 loss=2.300115	 lr=0.441998
Epoch[089] Batch [0449]/[0716]	Speed: 26.420242 samples/sec	 accuracy=46.349206	 loss=2.304315	 lr=0.441640
Epoch[089] Batch [0499]/[0716]	Speed: 25.858551 samples/sec	 accuracy=46.282143	 loss=2.309923	 lr=0.441282
Epoch[089] Batch [0549]/[0716]	Speed: 25.801376 samples/sec	 accuracy=46.272727	 loss=2.313646	 lr=0.440924
Epoch[089] Batch [0599]/[0716]	Speed: 26.251657 samples/sec	 accuracy=46.181548	 loss=2.316645	 lr=0.440565
Epoch[089] Batch [0649]/[0716]	Speed: 26.118688 samples/sec	 accuracy=46.142857	 loss=2.319623	 lr=0.440206
Epoch[089] Batch [0699]/[0716]	Speed: 26.058687 samples/sec	 accuracy=46.224490	 loss=2.316755	 lr=0.439847
Batch [0049]/[0057]: acc-top1=43.428571 acc-top5=71.035714
[Epoch 089] training: accuracy=46.176676	 loss=2.318661
[Epoch 089] speed: 25 samples/sec	time cost: 1607.697698
[Epoch 089] validation: acc-top1=43.969299 acc-top5=70.995193 loss=2.697686
Epoch[090] Batch [0049]/[0716]	Speed: 22.937280 samples/sec	 accuracy=47.142857	 loss=2.266439	 lr=0.439372
Epoch[090] Batch [0099]/[0716]	Speed: 25.848959 samples/sec	 accuracy=46.000000	 loss=2.298873	 lr=0.439012
Epoch[090] Batch [0149]/[0716]	Speed: 25.321542 samples/sec	 accuracy=46.714286	 loss=2.287000	 lr=0.438652
Epoch[090] Batch [0199]/[0716]	Speed: 26.099797 samples/sec	 accuracy=46.973214	 loss=2.281825	 lr=0.438291
Epoch[090] Batch [0249]/[0716]	Speed: 26.124272 samples/sec	 accuracy=46.957143	 loss=2.278361	 lr=0.437931
Epoch[090] Batch [0299]/[0716]	Speed: 26.418417 samples/sec	 accuracy=46.922619	 loss=2.278062	 lr=0.437570
Epoch[090] Batch [0349]/[0716]	Speed: 26.076945 samples/sec	 accuracy=46.576531	 loss=2.299538	 lr=0.437209
Epoch[090] Batch [0399]/[0716]	Speed: 25.832018 samples/sec	 accuracy=46.633929	 loss=2.300109	 lr=0.436847
Epoch[090] Batch [0449]/[0716]	Speed: 26.157351 samples/sec	 accuracy=46.440476	 loss=2.307742	 lr=0.436486
Epoch[090] Batch [0499]/[0716]	Speed: 25.824320 samples/sec	 accuracy=46.360714	 loss=2.310705	 lr=0.436124
Epoch[090] Batch [0549]/[0716]	Speed: 26.088897 samples/sec	 accuracy=46.370130	 loss=2.312925	 lr=0.435761
Epoch[090] Batch [0599]/[0716]	Speed: 26.258958 samples/sec	 accuracy=46.294643	 loss=2.314017	 lr=0.435399
Epoch[090] Batch [0649]/[0716]	Speed: 26.008466 samples/sec	 accuracy=46.266484	 loss=2.315517	 lr=0.435036
Epoch[090] Batch [0699]/[0716]	Speed: 25.929954 samples/sec	 accuracy=46.198980	 loss=2.317231	 lr=0.434674
Batch [0049]/[0057]: acc-top1=43.964286 acc-top5=70.214286
[Epoch 090] training: accuracy=46.201616	 loss=2.315967
[Epoch 090] speed: 25 samples/sec	time cost: 1609.648763
[Epoch 090] validation: acc-top1=44.585423 acc-top5=71.506889 loss=2.784477
Epoch[091] Batch [0049]/[0716]	Speed: 23.031075 samples/sec	 accuracy=46.607143	 loss=2.301460	 lr=0.434194
Epoch[091] Batch [0099]/[0716]	Speed: 25.866898 samples/sec	 accuracy=46.553571	 loss=2.307793	 lr=0.433831
Epoch[091] Batch [0149]/[0716]	Speed: 26.434484 samples/sec	 accuracy=46.500000	 loss=2.296277	 lr=0.433467
Epoch[091] Batch [0199]/[0716]	Speed: 26.006717 samples/sec	 accuracy=46.580357	 loss=2.303345	 lr=0.433103
Epoch[091] Batch [0249]/[0716]	Speed: 25.831458 samples/sec	 accuracy=46.500000	 loss=2.313273	 lr=0.432739
Epoch[091] Batch [0299]/[0716]	Speed: 25.954575 samples/sec	 accuracy=46.571429	 loss=2.308364	 lr=0.432374
Epoch[091] Batch [0349]/[0716]	Speed: 25.949095 samples/sec	 accuracy=46.382653	 loss=2.311689	 lr=0.432010
Epoch[091] Batch [0399]/[0716]	Speed: 25.833218 samples/sec	 accuracy=46.580357	 loss=2.305030	 lr=0.431645
Epoch[091] Batch [0449]/[0716]	Speed: 26.292097 samples/sec	 accuracy=46.511905	 loss=2.306407	 lr=0.431279
Epoch[091] Batch [0499]/[0716]	Speed: 25.426089 samples/sec	 accuracy=46.353571	 loss=2.307934	 lr=0.430914
Epoch[091] Batch [0549]/[0716]	Speed: 25.935839 samples/sec	 accuracy=46.292208	 loss=2.306842	 lr=0.430548
Epoch[091] Batch [0599]/[0716]	Speed: 26.027967 samples/sec	 accuracy=46.407738	 loss=2.301577	 lr=0.430182
Epoch[091] Batch [0649]/[0716]	Speed: 26.048682 samples/sec	 accuracy=46.387363	 loss=2.303361	 lr=0.429816
Epoch[091] Batch [0699]/[0716]	Speed: 26.117049 samples/sec	 accuracy=46.443878	 loss=2.305365	 lr=0.429450
Batch [0049]/[0057]: acc-top1=43.750000 acc-top5=69.607143
[Epoch 091] training: accuracy=46.418595	 loss=2.305780
[Epoch 091] speed: 25 samples/sec	time cost: 1607.864465
[Epoch 091] validation: acc-top1=42.737053 acc-top5=69.512329 loss=2.655267
Epoch[092] Batch [0049]/[0716]	Speed: 23.266459 samples/sec	 accuracy=48.571429	 loss=2.232197	 lr=0.428966
Epoch[092] Batch [0099]/[0716]	Speed: 25.868553 samples/sec	 accuracy=46.982143	 loss=2.255635	 lr=0.428599
Epoch[092] Batch [0149]/[0716]	Speed: 25.926780 samples/sec	 accuracy=46.797619	 loss=2.276275	 lr=0.428232
Epoch[092] Batch [0199]/[0716]	Speed: 25.785860 samples/sec	 accuracy=46.991071	 loss=2.287836	 lr=0.427864
Epoch[092] Batch [0249]/[0716]	Speed: 26.412228 samples/sec	 accuracy=46.900000	 loss=2.288112	 lr=0.427497
Epoch[092] Batch [0299]/[0716]	Speed: 26.167851 samples/sec	 accuracy=46.761905	 loss=2.281593	 lr=0.427129
Epoch[092] Batch [0349]/[0716]	Speed: 25.908682 samples/sec	 accuracy=46.612245	 loss=2.292003	 lr=0.426761
Epoch[092] Batch [0399]/[0716]	Speed: 26.042342 samples/sec	 accuracy=46.584821	 loss=2.290198	 lr=0.426392
Epoch[092] Batch [0449]/[0716]	Speed: 25.898438 samples/sec	 accuracy=46.539683	 loss=2.295615	 lr=0.426024
Epoch[092] Batch [0499]/[0716]	Speed: 26.174108 samples/sec	 accuracy=46.632143	 loss=2.294016	 lr=0.425655
Epoch[092] Batch [0549]/[0716]	Speed: 26.475934 samples/sec	 accuracy=46.461039	 loss=2.302951	 lr=0.425286
Epoch[092] Batch [0599]/[0716]	Speed: 25.595072 samples/sec	 accuracy=46.604167	 loss=2.298109	 lr=0.424917
Epoch[092] Batch [0649]/[0716]	Speed: 26.216996 samples/sec	 accuracy=46.565934	 loss=2.296899	 lr=0.424547
Epoch[092] Batch [0699]/[0716]	Speed: 25.850667 samples/sec	 accuracy=46.538265	 loss=2.295254	 lr=0.424178
Batch [0049]/[0057]: acc-top1=44.964286 acc-top5=70.357143
[Epoch 092] training: accuracy=46.538308	 loss=2.295572
[Epoch 092] speed: 25 samples/sec	time cost: 1606.030910
[Epoch 092] validation: acc-top1=43.750000 acc-top5=70.446953 loss=2.828297
Epoch[093] Batch [0049]/[0716]	Speed: 23.181789 samples/sec	 accuracy=46.785714	 loss=2.301805	 lr=0.423689
Epoch[093] Batch [0099]/[0716]	Speed: 26.320456 samples/sec	 accuracy=46.964286	 loss=2.303644	 lr=0.423319
Epoch[093] Batch [0149]/[0716]	Speed: 26.337969 samples/sec	 accuracy=46.750000	 loss=2.309200	 lr=0.422948
Epoch[093] Batch [0199]/[0716]	Speed: 25.654886 samples/sec	 accuracy=46.535714	 loss=2.320028	 lr=0.422578
Epoch[093] Batch [0249]/[0716]	Speed: 26.016533 samples/sec	 accuracy=46.778571	 loss=2.312908	 lr=0.422207
Epoch[093] Batch [0299]/[0716]	Speed: 25.909333 samples/sec	 accuracy=46.827381	 loss=2.302509	 lr=0.421836
Epoch[093] Batch [0349]/[0716]	Speed: 25.905493 samples/sec	 accuracy=46.994898	 loss=2.297885	 lr=0.421464
Epoch[093] Batch [0399]/[0716]	Speed: 25.967414 samples/sec	 accuracy=47.339286	 loss=2.284589	 lr=0.421093
Epoch[093] Batch [0449]/[0716]	Speed: 26.075247 samples/sec	 accuracy=47.269841	 loss=2.283740	 lr=0.420721
Epoch[093] Batch [0499]/[0716]	Speed: 26.375904 samples/sec	 accuracy=47.225000	 loss=2.285130	 lr=0.420349
Epoch[093] Batch [0549]/[0716]	Speed: 25.938655 samples/sec	 accuracy=47.243506	 loss=2.283396	 lr=0.419977
Epoch[093] Batch [0599]/[0716]	Speed: 25.898387 samples/sec	 accuracy=47.086310	 loss=2.287364	 lr=0.419604
Epoch[093] Batch [0649]/[0716]	Speed: 26.268628 samples/sec	 accuracy=47.046703	 loss=2.287311	 lr=0.419231
Epoch[093] Batch [0699]/[0716]	Speed: 26.109562 samples/sec	 accuracy=46.971939	 loss=2.289378	 lr=0.418858
Batch [0049]/[0057]: acc-top1=44.464286 acc-top5=72.142857
[Epoch 093] training: accuracy=46.939844	 loss=2.291557
[Epoch 093] speed: 26 samples/sec	time cost: 1603.541827
[Epoch 093] validation: acc-top1=45.321636 acc-top5=71.997711 loss=2.602662
Epoch[094] Batch [0049]/[0716]	Speed: 23.078382 samples/sec	 accuracy=46.857143	 loss=2.228924	 lr=0.418366
Epoch[094] Batch [0099]/[0716]	Speed: 25.907138 samples/sec	 accuracy=47.410714	 loss=2.230793	 lr=0.417992
Epoch[094] Batch [0149]/[0716]	Speed: 26.009860 samples/sec	 accuracy=46.916667	 loss=2.252451	 lr=0.417619
Epoch[094] Batch [0199]/[0716]	Speed: 26.076339 samples/sec	 accuracy=47.107143	 loss=2.249332	 lr=0.417245
Epoch[094] Batch [0249]/[0716]	Speed: 26.072236 samples/sec	 accuracy=47.471429	 loss=2.240280	 lr=0.416871
Epoch[094] Batch [0299]/[0716]	Speed: 26.085304 samples/sec	 accuracy=47.172619	 loss=2.244901	 lr=0.416497
Epoch[094] Batch [0349]/[0716]	Speed: 25.803775 samples/sec	 accuracy=47.295918	 loss=2.247894	 lr=0.416122
Epoch[094] Batch [0399]/[0716]	Speed: 26.267734 samples/sec	 accuracy=47.187500	 loss=2.251124	 lr=0.415747
Epoch[094] Batch [0449]/[0716]	Speed: 25.825419 samples/sec	 accuracy=47.246032	 loss=2.248265	 lr=0.415372
Epoch[094] Batch [0499]/[0716]	Speed: 26.192726 samples/sec	 accuracy=47.146429	 loss=2.256109	 lr=0.414997
Epoch[094] Batch [0549]/[0716]	Speed: 25.880142 samples/sec	 accuracy=47.133117	 loss=2.254321	 lr=0.414622
Epoch[094] Batch [0599]/[0716]	Speed: 26.249670 samples/sec	 accuracy=47.008929	 loss=2.258235	 lr=0.414246
Epoch[094] Batch [0649]/[0716]	Speed: 26.014584 samples/sec	 accuracy=46.956044	 loss=2.259600	 lr=0.413871
Epoch[094] Batch [0699]/[0716]	Speed: 25.808785 samples/sec	 accuracy=46.933673	 loss=2.260601	 lr=0.413495
Batch [0049]/[0057]: acc-top1=44.821429 acc-top5=71.785714
[Epoch 094] training: accuracy=46.894952	 loss=2.262553
[Epoch 094] speed: 25 samples/sec	time cost: 1606.033824
[Epoch 094] validation: acc-top1=44.031952 acc-top5=70.979530 loss=2.704370
Epoch[095] Batch [0049]/[0717]	Speed: 23.251273 samples/sec	 accuracy=45.607143	 loss=2.296947	 lr=0.412998
Epoch[095] Batch [0099]/[0717]	Speed: 25.937559 samples/sec	 accuracy=46.678571	 loss=2.261054	 lr=0.412622
Epoch[095] Batch [0149]/[0717]	Speed: 25.942823 samples/sec	 accuracy=46.892857	 loss=2.264453	 lr=0.412245
Epoch[095] Batch [0199]/[0717]	Speed: 25.950971 samples/sec	 accuracy=46.946429	 loss=2.271193	 lr=0.411868
Epoch[095] Batch [0249]/[0717]	Speed: 25.992761 samples/sec	 accuracy=47.035714	 loss=2.272267	 lr=0.411491
Epoch[095] Batch [0299]/[0717]	Speed: 26.155193 samples/sec	 accuracy=47.214286	 loss=2.256472	 lr=0.411114
Epoch[095] Batch [0349]/[0717]	Speed: 25.925663 samples/sec	 accuracy=47.193878	 loss=2.258147	 lr=0.410736
Epoch[095] Batch [0399]/[0717]	Speed: 26.060882 samples/sec	 accuracy=46.928571	 loss=2.269473	 lr=0.410359
Epoch[095] Batch [0449]/[0717]	Speed: 26.157835 samples/sec	 accuracy=47.146825	 loss=2.262530	 lr=0.409981
Epoch[095] Batch [0499]/[0717]	Speed: 26.081232 samples/sec	 accuracy=46.914286	 loss=2.271763	 lr=0.409603
Epoch[095] Batch [0549]/[0717]	Speed: 26.396810 samples/sec	 accuracy=46.909091	 loss=2.275010	 lr=0.409224
Epoch[095] Batch [0599]/[0717]	Speed: 26.137187 samples/sec	 accuracy=46.741071	 loss=2.277616	 lr=0.408846
Epoch[095] Batch [0649]/[0717]	Speed: 26.134149 samples/sec	 accuracy=46.796703	 loss=2.277420	 lr=0.408467
Epoch[095] Batch [0699]/[0717]	Speed: 25.918899 samples/sec	 accuracy=46.798469	 loss=2.277003	 lr=0.408088
Batch [0049]/[0057]: acc-top1=43.857143 acc-top5=70.250000
[Epoch 095] training: accuracy=46.744869	 loss=2.278601
[Epoch 095] speed: 26 samples/sec	time cost: 1606.247702
[Epoch 095] validation: acc-top1=45.091896 acc-top5=71.663528 loss=2.651692
Epoch[096] Batch [0049]/[0716]	Speed: 23.238023 samples/sec	 accuracy=49.107143	 loss=2.183147	 lr=0.407580
Epoch[096] Batch [0099]/[0716]	Speed: 26.412865 samples/sec	 accuracy=47.910714	 loss=2.247379	 lr=0.407201
Epoch[096] Batch [0149]/[0716]	Speed: 25.860352 samples/sec	 accuracy=47.214286	 loss=2.272848	 lr=0.406821
Epoch[096] Batch [0199]/[0716]	Speed: 25.869359 samples/sec	 accuracy=47.062500	 loss=2.270124	 lr=0.406442
Epoch[096] Batch [0249]/[0716]	Speed: 26.240615 samples/sec	 accuracy=47.300000	 loss=2.261504	 lr=0.406062
Epoch[096] Batch [0299]/[0716]	Speed: 25.916974 samples/sec	 accuracy=47.232143	 loss=2.266717	 lr=0.405682
Epoch[096] Batch [0349]/[0716]	Speed: 26.003339 samples/sec	 accuracy=47.341837	 loss=2.264020	 lr=0.405301
Epoch[096] Batch [0399]/[0716]	Speed: 26.364252 samples/sec	 accuracy=47.316964	 loss=2.264120	 lr=0.404921
Epoch[096] Batch [0449]/[0716]	Speed: 26.092413 samples/sec	 accuracy=47.261905	 loss=2.271556	 lr=0.404540
Epoch[096] Batch [0499]/[0716]	Speed: 25.721910 samples/sec	 accuracy=47.050000	 loss=2.280428	 lr=0.404159
Epoch[096] Batch [0549]/[0716]	Speed: 26.150504 samples/sec	 accuracy=47.107143	 loss=2.277063	 lr=0.403778
Epoch[096] Batch [0599]/[0716]	Speed: 25.824411 samples/sec	 accuracy=47.276786	 loss=2.274996	 lr=0.403397
Epoch[096] Batch [0649]/[0716]	Speed: 25.967865 samples/sec	 accuracy=47.156593	 loss=2.278700	 lr=0.403015
Epoch[096] Batch [0699]/[0716]	Speed: 26.078720 samples/sec	 accuracy=47.155612	 loss=2.279069	 lr=0.402634
Batch [0049]/[0057]: acc-top1=43.750000 acc-top5=72.321429
[Epoch 096] training: accuracy=47.106943	 loss=2.280643
[Epoch 096] speed: 26 samples/sec	time cost: 1603.926570
[Epoch 096] validation: acc-top1=44.736843 acc-top5=71.360687 loss=2.757918
Epoch[097] Batch [0049]/[0716]	Speed: 23.119490 samples/sec	 accuracy=45.428571	 loss=2.316740	 lr=0.402130
Epoch[097] Batch [0099]/[0716]	Speed: 25.859243 samples/sec	 accuracy=46.464286	 loss=2.288652	 lr=0.401747
Epoch[097] Batch [0149]/[0716]	Speed: 25.700304 samples/sec	 accuracy=47.130952	 loss=2.254588	 lr=0.401365
Epoch[097] Batch [0199]/[0716]	Speed: 26.353057 samples/sec	 accuracy=47.580357	 loss=2.247510	 lr=0.400983
Epoch[097] Batch [0249]/[0716]	Speed: 26.293262 samples/sec	 accuracy=47.557143	 loss=2.260517	 lr=0.400600
Epoch[097] Batch [0299]/[0716]	Speed: 26.125745 samples/sec	 accuracy=47.494048	 loss=2.260711	 lr=0.400217
Epoch[097] Batch [0349]/[0716]	Speed: 26.042022 samples/sec	 accuracy=47.469388	 loss=2.256926	 lr=0.399834
Epoch[097] Batch [0399]/[0716]	Speed: 26.264596 samples/sec	 accuracy=47.397321	 loss=2.260363	 lr=0.399451
Epoch[097] Batch [0449]/[0716]	Speed: 26.297114 samples/sec	 accuracy=47.476190	 loss=2.259949	 lr=0.399068
Epoch[097] Batch [0499]/[0716]	Speed: 26.235696 samples/sec	 accuracy=47.435714	 loss=2.262716	 lr=0.398684
Epoch[097] Batch [0549]/[0716]	Speed: 26.474595 samples/sec	 accuracy=47.347403	 loss=2.265027	 lr=0.398300
Epoch[097] Batch [0599]/[0716]	Speed: 25.955863 samples/sec	 accuracy=47.294643	 loss=2.265269	 lr=0.397916
Epoch[097] Batch [0649]/[0716]	Speed: 26.075531 samples/sec	 accuracy=47.354396	 loss=2.263278	 lr=0.397532
Epoch[097] Batch [0699]/[0716]	Speed: 25.722292 samples/sec	 accuracy=47.313776	 loss=2.264993	 lr=0.397148
Batch [0049]/[0057]: acc-top1=45.535714 acc-top5=72.035714
[Epoch 097] training: accuracy=47.291500	 loss=2.266287
[Epoch 097] speed: 26 samples/sec	time cost: 1602.079549
[Epoch 097] validation: acc-top1=45.608814 acc-top5=72.237892 loss=2.578363
Epoch[098] Batch [0049]/[0716]	Speed: 23.205650 samples/sec	 accuracy=49.750000	 loss=2.168904	 lr=0.396640
Epoch[098] Batch [0099]/[0716]	Speed: 25.861827 samples/sec	 accuracy=48.607143	 loss=2.204996	 lr=0.396256
Epoch[098] Batch [0149]/[0716]	Speed: 26.047609 samples/sec	 accuracy=48.619048	 loss=2.210171	 lr=0.395871
Epoch[098] Batch [0199]/[0716]	Speed: 26.051384 samples/sec	 accuracy=48.169643	 loss=2.231426	 lr=0.395486
Epoch[098] Batch [0249]/[0716]	Speed: 25.925506 samples/sec	 accuracy=48.035714	 loss=2.240152	 lr=0.395100
Epoch[098] Batch [0299]/[0716]	Speed: 25.860319 samples/sec	 accuracy=48.232143	 loss=2.235235	 lr=0.394715
Epoch[098] Batch [0349]/[0716]	Speed: 26.080927 samples/sec	 accuracy=47.989796	 loss=2.244630	 lr=0.394330
Epoch[098] Batch [0399]/[0716]	Speed: 26.285364 samples/sec	 accuracy=47.968750	 loss=2.241039	 lr=0.393944
Epoch[098] Batch [0449]/[0716]	Speed: 26.145074 samples/sec	 accuracy=47.821429	 loss=2.248379	 lr=0.393558
Epoch[098] Batch [0499]/[0716]	Speed: 26.268150 samples/sec	 accuracy=47.753571	 loss=2.245193	 lr=0.393172
Epoch[098] Batch [0549]/[0716]	Speed: 26.142858 samples/sec	 accuracy=47.655844	 loss=2.248750	 lr=0.392785
Epoch[098] Batch [0599]/[0716]	Speed: 25.838964 samples/sec	 accuracy=47.705357	 loss=2.246578	 lr=0.392399
Epoch[098] Batch [0649]/[0716]	Speed: 25.744904 samples/sec	 accuracy=47.793956	 loss=2.244601	 lr=0.392012
Epoch[098] Batch [0699]/[0716]	Speed: 26.286131 samples/sec	 accuracy=47.683673	 loss=2.248984	 lr=0.391626
Batch [0049]/[0057]: acc-top1=45.285714 acc-top5=72.571429
[Epoch 098] training: accuracy=47.653132	 loss=2.249828
[Epoch 098] speed: 26 samples/sec	time cost: 1602.390732
[Epoch 098] validation: acc-top1=45.744572 acc-top5=71.841057 loss=2.585088
Epoch[099] Batch [0049]/[0716]	Speed: 23.544002 samples/sec	 accuracy=48.500000	 loss=2.172277	 lr=0.391115
Epoch[099] Batch [0099]/[0716]	Speed: 26.070051 samples/sec	 accuracy=48.678571	 loss=2.188288	 lr=0.390728
Epoch[099] Batch [0149]/[0716]	Speed: 26.086906 samples/sec	 accuracy=47.964286	 loss=2.218192	 lr=0.390340
Epoch[099] Batch [0199]/[0716]	Speed: 25.956862 samples/sec	 accuracy=47.955357	 loss=2.217801	 lr=0.389953
Epoch[099] Batch [0249]/[0716]	Speed: 26.311824 samples/sec	 accuracy=47.785714	 loss=2.227496	 lr=0.389565
Epoch[099] Batch [0299]/[0716]	Speed: 26.323959 samples/sec	 accuracy=47.761905	 loss=2.232505	 lr=0.389177
Epoch[099] Batch [0349]/[0716]	Speed: 26.285079 samples/sec	 accuracy=47.576531	 loss=2.239829	 lr=0.388789
Epoch[099] Batch [0399]/[0716]	Speed: 26.253831 samples/sec	 accuracy=47.732143	 loss=2.232929	 lr=0.388401
Epoch[099] Batch [0449]/[0716]	Speed: 26.059382 samples/sec	 accuracy=47.519841	 loss=2.237337	 lr=0.388013
Epoch[099] Batch [0499]/[0716]	Speed: 26.115811 samples/sec	 accuracy=47.503571	 loss=2.236927	 lr=0.387624
Epoch[099] Batch [0549]/[0716]	Speed: 25.895042 samples/sec	 accuracy=47.561688	 loss=2.234700	 lr=0.387236
Epoch[099] Batch [0599]/[0716]	Speed: 26.255450 samples/sec	 accuracy=47.541667	 loss=2.236723	 lr=0.386847
Epoch[099] Batch [0649]/[0716]	Speed: 25.973124 samples/sec	 accuracy=47.508242	 loss=2.238703	 lr=0.386458
Epoch[099] Batch [0699]/[0716]	Speed: 25.987374 samples/sec	 accuracy=47.551020	 loss=2.240502	 lr=0.386069
Batch [0049]/[0057]: acc-top1=46.964286 acc-top5=72.178571
[Epoch 099] training: accuracy=47.563348	 loss=2.240144
[Epoch 099] speed: 26 samples/sec	time cost: 1600.439679
[Epoch 099] validation: acc-top1=45.713242 acc-top5=71.710518 loss=2.714948
Epoch[100] Batch [0049]/[0716]	Speed: 22.968518 samples/sec	 accuracy=50.500000	 loss=2.084585	 lr=0.385555
Epoch[100] Batch [0099]/[0716]	Speed: 25.756578 samples/sec	 accuracy=48.607143	 loss=2.140666	 lr=0.385166
Epoch[100] Batch [0149]/[0716]	Speed: 26.607313 samples/sec	 accuracy=48.202381	 loss=2.174658	 lr=0.384776
Epoch[100] Batch [0199]/[0716]	Speed: 26.132887 samples/sec	 accuracy=48.196429	 loss=2.186213	 lr=0.384386
Epoch[100] Batch [0249]/[0716]	Speed: 26.222213 samples/sec	 accuracy=48.200000	 loss=2.194834	 lr=0.383996
Epoch[100] Batch [0299]/[0716]	Speed: 26.264422 samples/sec	 accuracy=48.125000	 loss=2.199405	 lr=0.383606
Epoch[100] Batch [0349]/[0716]	Speed: 26.043290 samples/sec	 accuracy=48.183673	 loss=2.202829	 lr=0.383216
Epoch[100] Batch [0399]/[0716]	Speed: 25.932255 samples/sec	 accuracy=48.535714	 loss=2.191714	 lr=0.382825
Epoch[100] Batch [0449]/[0716]	Speed: 25.711330 samples/sec	 accuracy=48.242063	 loss=2.201310	 lr=0.382435
Epoch[100] Batch [0499]/[0716]	Speed: 26.629768 samples/sec	 accuracy=48.260714	 loss=2.199803	 lr=0.382044
Epoch[100] Batch [0549]/[0716]	Speed: 25.764278 samples/sec	 accuracy=48.198052	 loss=2.206520	 lr=0.381653
Epoch[100] Batch [0599]/[0716]	Speed: 26.388894 samples/sec	 accuracy=48.187500	 loss=2.204567	 lr=0.381262
Epoch[100] Batch [0649]/[0716]	Speed: 25.937647 samples/sec	 accuracy=48.203297	 loss=2.209068	 lr=0.380871
Epoch[100] Batch [0699]/[0716]	Speed: 26.181561 samples/sec	 accuracy=48.125000	 loss=2.214226	 lr=0.380480
Batch [0049]/[0057]: acc-top1=48.178571 acc-top5=72.892857
[Epoch 100] training: accuracy=48.156923	 loss=2.212254
[Epoch 100] speed: 26 samples/sec	time cost: 1601.562607
[Epoch 100] validation: acc-top1=46.611320 acc-top5=72.582504 loss=2.550340
Epoch[101] Batch [0049]/[0716]	Speed: 23.212791 samples/sec	 accuracy=48.357143	 loss=2.198730	 lr=0.379963
Epoch[101] Batch [0099]/[0716]	Speed: 26.202156 samples/sec	 accuracy=49.125000	 loss=2.191054	 lr=0.379571
Epoch[101] Batch [0149]/[0716]	Speed: 26.053836 samples/sec	 accuracy=48.785714	 loss=2.195514	 lr=0.379180
Epoch[101] Batch [0199]/[0716]	Speed: 26.099070 samples/sec	 accuracy=48.553571	 loss=2.203007	 lr=0.378788
Epoch[101] Batch [0249]/[0716]	Speed: 26.083876 samples/sec	 accuracy=48.400000	 loss=2.207826	 lr=0.378396
Epoch[101] Batch [0299]/[0716]	Speed: 25.918945 samples/sec	 accuracy=48.392857	 loss=2.215184	 lr=0.378003
Epoch[101] Batch [0349]/[0716]	Speed: 25.874962 samples/sec	 accuracy=48.352041	 loss=2.216014	 lr=0.377611
Epoch[101] Batch [0399]/[0716]	Speed: 25.699962 samples/sec	 accuracy=48.267857	 loss=2.221352	 lr=0.377219
Epoch[101] Batch [0449]/[0716]	Speed: 25.950860 samples/sec	 accuracy=48.273810	 loss=2.219996	 lr=0.376826
Epoch[101] Batch [0499]/[0716]	Speed: 26.075966 samples/sec	 accuracy=48.332143	 loss=2.225167	 lr=0.376433
Epoch[101] Batch [0549]/[0716]	Speed: 25.885371 samples/sec	 accuracy=48.204545	 loss=2.231243	 lr=0.376040
Epoch[101] Batch [0599]/[0716]	Speed: 25.965559 samples/sec	 accuracy=48.193452	 loss=2.231065	 lr=0.375647
Epoch[101] Batch [0649]/[0716]	Speed: 26.317019 samples/sec	 accuracy=48.153846	 loss=2.229973	 lr=0.375254
Epoch[101] Batch [0699]/[0716]	Speed: 26.209230 samples/sec	 accuracy=48.081633	 loss=2.228706	 lr=0.374861
Batch [0049]/[0057]: acc-top1=46.071429 acc-top5=71.785714
[Epoch 101] training: accuracy=48.112031	 loss=2.227753
[Epoch 101] speed: 26 samples/sec	time cost: 1603.994938
[Epoch 101] validation: acc-top1=46.063076 acc-top5=72.462410 loss=2.698689
Epoch[102] Batch [0049]/[0716]	Speed: 22.783388 samples/sec	 accuracy=49.000000	 loss=2.197139	 lr=0.374341
Epoch[102] Batch [0099]/[0716]	Speed: 25.996013 samples/sec	 accuracy=49.232143	 loss=2.171425	 lr=0.373947
Epoch[102] Batch [0149]/[0716]	Speed: 25.915311 samples/sec	 accuracy=48.666667	 loss=2.214336	 lr=0.373554
Epoch[102] Batch [0199]/[0716]	Speed: 26.150287 samples/sec	 accuracy=48.741071	 loss=2.200831	 lr=0.373160
Epoch[102] Batch [0249]/[0716]	Speed: 25.606943 samples/sec	 accuracy=48.385714	 loss=2.215352	 lr=0.372766
Epoch[102] Batch [0299]/[0716]	Speed: 26.285388 samples/sec	 accuracy=48.220238	 loss=2.219305	 lr=0.372371
Epoch[102] Batch [0349]/[0716]	Speed: 26.071573 samples/sec	 accuracy=48.158163	 loss=2.220104	 lr=0.371977
Epoch[102] Batch [0399]/[0716]	Speed: 26.777899 samples/sec	 accuracy=48.183036	 loss=2.217381	 lr=0.371583
Epoch[102] Batch [0449]/[0716]	Speed: 26.129962 samples/sec	 accuracy=48.345238	 loss=2.212545	 lr=0.371188
Epoch[102] Batch [0499]/[0716]	Speed: 26.250416 samples/sec	 accuracy=48.400000	 loss=2.209725	 lr=0.370793
Epoch[102] Batch [0549]/[0716]	Speed: 25.632378 samples/sec	 accuracy=48.470779	 loss=2.207734	 lr=0.370398
Epoch[102] Batch [0599]/[0716]	Speed: 25.692969 samples/sec	 accuracy=48.616071	 loss=2.203482	 lr=0.370003
Epoch[102] Batch [0649]/[0716]	Speed: 25.931263 samples/sec	 accuracy=48.587912	 loss=2.204528	 lr=0.369608
Epoch[102] Batch [0699]/[0716]	Speed: 26.335901 samples/sec	 accuracy=48.451531	 loss=2.208927	 lr=0.369213
Batch [0049]/[0057]: acc-top1=43.607143 acc-top5=70.678571
[Epoch 102] training: accuracy=48.428771	 loss=2.208046
[Epoch 102] speed: 25 samples/sec	time cost: 1607.550055
[Epoch 102] validation: acc-top1=44.099831 acc-top5=70.415619 loss=2.959004
Epoch[103] Batch [0049]/[0717]	Speed: 23.512875 samples/sec	 accuracy=49.571429	 loss=2.123572	 lr=0.368691
Epoch[103] Batch [0099]/[0717]	Speed: 26.120141 samples/sec	 accuracy=48.553571	 loss=2.170473	 lr=0.368296
Epoch[103] Batch [0149]/[0717]	Speed: 26.243787 samples/sec	 accuracy=47.857143	 loss=2.207685	 lr=0.367900
Epoch[103] Batch [0199]/[0717]	Speed: 26.173145 samples/sec	 accuracy=47.625000	 loss=2.224715	 lr=0.367504
Epoch[103] Batch [0249]/[0717]	Speed: 26.064672 samples/sec	 accuracy=47.821429	 loss=2.220428	 lr=0.367108
Epoch[103] Batch [0299]/[0717]	Speed: 25.728205 samples/sec	 accuracy=48.125000	 loss=2.212609	 lr=0.366712
Epoch[103] Batch [0349]/[0717]	Speed: 26.180357 samples/sec	 accuracy=48.188776	 loss=2.207716	 lr=0.366316
Epoch[103] Batch [0399]/[0717]	Speed: 26.212975 samples/sec	 accuracy=48.205357	 loss=2.203766	 lr=0.365920
Epoch[103] Batch [0449]/[0717]	Speed: 26.558787 samples/sec	 accuracy=48.226190	 loss=2.204715	 lr=0.365523
Epoch[103] Batch [0499]/[0717]	Speed: 26.448843 samples/sec	 accuracy=48.310714	 loss=2.206522	 lr=0.365127
Epoch[103] Batch [0549]/[0717]	Speed: 26.442614 samples/sec	 accuracy=48.279221	 loss=2.207851	 lr=0.364730
Epoch[103] Batch [0599]/[0717]	Speed: 25.917902 samples/sec	 accuracy=48.288690	 loss=2.205814	 lr=0.364333
Epoch[103] Batch [0649]/[0717]	Speed: 25.954682 samples/sec	 accuracy=48.304945	 loss=2.206058	 lr=0.363936
Epoch[103] Batch [0699]/[0717]	Speed: 25.954841 samples/sec	 accuracy=48.334184	 loss=2.205189	 lr=0.363539
Batch [0049]/[0057]: acc-top1=45.857143 acc-top5=71.857143
[Epoch 103] training: accuracy=48.326360	 loss=2.207076
[Epoch 103] speed: 26 samples/sec	time cost: 1598.389559
[Epoch 103] validation: acc-top1=45.530491 acc-top5=71.778397 loss=2.604163
Epoch[104] Batch [0049]/[0716]	Speed: 23.093983 samples/sec	 accuracy=49.464286	 loss=2.162721	 lr=0.363007
Epoch[104] Batch [0099]/[0716]	Speed: 25.847513 samples/sec	 accuracy=48.910714	 loss=2.184398	 lr=0.362610
Epoch[104] Batch [0149]/[0716]	Speed: 26.457543 samples/sec	 accuracy=49.297619	 loss=2.172781	 lr=0.362213
Epoch[104] Batch [0199]/[0716]	Speed: 26.095546 samples/sec	 accuracy=49.035714	 loss=2.181140	 lr=0.361815
Epoch[104] Batch [0249]/[0716]	Speed: 25.731018 samples/sec	 accuracy=49.085714	 loss=2.182612	 lr=0.361418
Epoch[104] Batch [0299]/[0716]	Speed: 26.089432 samples/sec	 accuracy=49.005952	 loss=2.184726	 lr=0.361020
Epoch[104] Batch [0349]/[0716]	Speed: 26.333699 samples/sec	 accuracy=48.948980	 loss=2.185050	 lr=0.360622
Epoch[104] Batch [0399]/[0716]	Speed: 26.197763 samples/sec	 accuracy=49.111607	 loss=2.181475	 lr=0.360224
Epoch[104] Batch [0449]/[0716]	Speed: 26.080382 samples/sec	 accuracy=49.011905	 loss=2.181302	 lr=0.359826
Epoch[104] Batch [0499]/[0716]	Speed: 25.906338 samples/sec	 accuracy=48.978571	 loss=2.182572	 lr=0.359428
Epoch[104] Batch [0549]/[0716]	Speed: 25.887849 samples/sec	 accuracy=49.009740	 loss=2.183873	 lr=0.359030
Epoch[104] Batch [0599]/[0716]	Speed: 26.287361 samples/sec	 accuracy=49.002976	 loss=2.184241	 lr=0.358631
Epoch[104] Batch [0649]/[0716]	Speed: 26.101661 samples/sec	 accuracy=48.967033	 loss=2.185898	 lr=0.358233
Epoch[104] Batch [0699]/[0716]	Speed: 26.007991 samples/sec	 accuracy=48.910714	 loss=2.189029	 lr=0.357834
Batch [0049]/[0057]: acc-top1=46.071429 acc-top5=72.071429
[Epoch 104] training: accuracy=48.887670	 loss=2.189347
[Epoch 104] speed: 26 samples/sec	time cost: 1603.557539
[Epoch 104] validation: acc-top1=46.689640 acc-top5=72.592941 loss=2.541006
Epoch[105] Batch [0049]/[0716]	Speed: 23.034111 samples/sec	 accuracy=51.071429	 loss=2.060008	 lr=0.357308
Epoch[105] Batch [0099]/[0716]	Speed: 26.017497 samples/sec	 accuracy=50.071429	 loss=2.132019	 lr=0.356909
Epoch[105] Batch [0149]/[0716]	Speed: 25.831476 samples/sec	 accuracy=49.773810	 loss=2.142152	 lr=0.356510
Epoch[105] Batch [0199]/[0716]	Speed: 25.863404 samples/sec	 accuracy=49.491071	 loss=2.151962	 lr=0.356111
Epoch[105] Batch [0249]/[0716]	Speed: 26.496168 samples/sec	 accuracy=49.314286	 loss=2.163516	 lr=0.355712
Epoch[105] Batch [0299]/[0716]	Speed: 26.237001 samples/sec	 accuracy=49.339286	 loss=2.164404	 lr=0.355313
Epoch[105] Batch [0349]/[0716]	Speed: 26.142160 samples/sec	 accuracy=49.280612	 loss=2.168407	 lr=0.354913
Epoch[105] Batch [0399]/[0716]	Speed: 26.315115 samples/sec	 accuracy=49.071429	 loss=2.178177	 lr=0.354514
Epoch[105] Batch [0449]/[0716]	Speed: 25.977577 samples/sec	 accuracy=49.174603	 loss=2.174899	 lr=0.354114
Epoch[105] Batch [0499]/[0716]	Speed: 26.179601 samples/sec	 accuracy=49.114286	 loss=2.178582	 lr=0.353715
Epoch[105] Batch [0549]/[0716]	Speed: 26.500552 samples/sec	 accuracy=48.915584	 loss=2.183390	 lr=0.353315
Epoch[105] Batch [0599]/[0716]	Speed: 26.223854 samples/sec	 accuracy=48.797619	 loss=2.188953	 lr=0.352915
Epoch[105] Batch [0649]/[0716]	Speed: 26.205564 samples/sec	 accuracy=48.791209	 loss=2.190632	 lr=0.352515
Epoch[105] Batch [0699]/[0716]	Speed: 26.291020 samples/sec	 accuracy=48.663265	 loss=2.197586	 lr=0.352115
Batch [0049]/[0057]: acc-top1=46.821429 acc-top5=73.928571
[Epoch 105] training: accuracy=48.663208	 loss=2.195925
[Epoch 105] speed: 26 samples/sec	time cost: 1597.995429
[Epoch 105] validation: acc-top1=46.574772 acc-top5=73.094193 loss=2.678097
Epoch[106] Batch [0049]/[0716]	Speed: 23.276535 samples/sec	 accuracy=49.035714	 loss=2.196632	 lr=0.351587
Epoch[106] Batch [0099]/[0716]	Speed: 25.630651 samples/sec	 accuracy=49.571429	 loss=2.184723	 lr=0.351186
Epoch[106] Batch [0149]/[0716]	Speed: 26.161800 samples/sec	 accuracy=49.535714	 loss=2.165907	 lr=0.350786
Epoch[106] Batch [0199]/[0716]	Speed: 26.124607 samples/sec	 accuracy=49.535714	 loss=2.157730	 lr=0.350386
Epoch[106] Batch [0249]/[0716]	Speed: 25.984391 samples/sec	 accuracy=49.435714	 loss=2.163598	 lr=0.349985
Epoch[106] Batch [0299]/[0716]	Speed: 26.060642 samples/sec	 accuracy=49.416667	 loss=2.153382	 lr=0.349584
Epoch[106] Batch [0349]/[0716]	Speed: 26.256870 samples/sec	 accuracy=49.260204	 loss=2.159257	 lr=0.349184
Epoch[106] Batch [0399]/[0716]	Speed: 26.063149 samples/sec	 accuracy=49.352679	 loss=2.160032	 lr=0.348783
Epoch[106] Batch [0449]/[0716]	Speed: 26.038329 samples/sec	 accuracy=49.281746	 loss=2.162949	 lr=0.348382
Epoch[106] Batch [0499]/[0716]	Speed: 26.296921 samples/sec	 accuracy=49.342857	 loss=2.161528	 lr=0.347981
Epoch[106] Batch [0549]/[0716]	Speed: 26.489358 samples/sec	 accuracy=49.438312	 loss=2.158287	 lr=0.347580
Epoch[106] Batch [0599]/[0716]	Speed: 26.205312 samples/sec	 accuracy=49.508929	 loss=2.159021	 lr=0.347179
Epoch[106] Batch [0649]/[0716]	Speed: 26.336437 samples/sec	 accuracy=49.456044	 loss=2.161214	 lr=0.346777
Epoch[106] Batch [0699]/[0716]	Speed: 26.005508 samples/sec	 accuracy=49.510204	 loss=2.157352	 lr=0.346376
Batch [0049]/[0057]: acc-top1=46.821429 acc-top5=73.250000
[Epoch 106] training: accuracy=49.453811	 loss=2.159873
[Epoch 106] speed: 26 samples/sec	time cost: 1598.744288
[Epoch 106] validation: acc-top1=46.726189 acc-top5=73.553673 loss=2.613043
Epoch[107] Batch [0049]/[0716]	Speed: 23.310485 samples/sec	 accuracy=49.142857	 loss=2.151872	 lr=0.345846
Epoch[107] Batch [0099]/[0716]	Speed: 26.007390 samples/sec	 accuracy=49.160714	 loss=2.148183	 lr=0.345445
Epoch[107] Batch [0149]/[0716]	Speed: 25.833026 samples/sec	 accuracy=49.392857	 loss=2.141829	 lr=0.345043
Epoch[107] Batch [0199]/[0716]	Speed: 26.002757 samples/sec	 accuracy=49.223214	 loss=2.142655	 lr=0.344641
Epoch[107] Batch [0249]/[0716]	Speed: 26.445412 samples/sec	 accuracy=49.442857	 loss=2.144949	 lr=0.344240
Epoch[107] Batch [0299]/[0716]	Speed: 26.082844 samples/sec	 accuracy=49.434524	 loss=2.151814	 lr=0.343838
Epoch[107] Batch [0349]/[0716]	Speed: 26.416064 samples/sec	 accuracy=49.500000	 loss=2.153427	 lr=0.343436
Epoch[107] Batch [0399]/[0716]	Speed: 26.200207 samples/sec	 accuracy=49.508929	 loss=2.158603	 lr=0.343034
Epoch[107] Batch [0449]/[0716]	Speed: 26.063194 samples/sec	 accuracy=49.432540	 loss=2.160773	 lr=0.342632
Epoch[107] Batch [0499]/[0716]	Speed: 26.181896 samples/sec	 accuracy=49.432143	 loss=2.165821	 lr=0.342229
Epoch[107] Batch [0549]/[0716]	Speed: 26.092485 samples/sec	 accuracy=49.399351	 loss=2.168791	 lr=0.341827
Epoch[107] Batch [0599]/[0716]	Speed: 26.152061 samples/sec	 accuracy=49.375000	 loss=2.168716	 lr=0.341425
Epoch[107] Batch [0649]/[0716]	Speed: 26.350023 samples/sec	 accuracy=49.351648	 loss=2.170689	 lr=0.341022
Epoch[107] Batch [0699]/[0716]	Speed: 25.993693 samples/sec	 accuracy=49.255102	 loss=2.176871	 lr=0.340620
Batch [0049]/[0057]: acc-top1=46.321429 acc-top5=72.750000
[Epoch 107] training: accuracy=49.266760	 loss=2.176249
[Epoch 107] speed: 26 samples/sec	time cost: 1598.231520
[Epoch 107] validation: acc-top1=47.347538 acc-top5=73.647659 loss=2.558908
Epoch[108] Batch [0049]/[0716]	Speed: 23.092278 samples/sec	 accuracy=51.250000	 loss=2.067594	 lr=0.340088
Epoch[108] Batch [0099]/[0716]	Speed: 26.031309 samples/sec	 accuracy=50.642857	 loss=2.103135	 lr=0.339686
Epoch[108] Batch [0149]/[0716]	Speed: 25.882948 samples/sec	 accuracy=50.023810	 loss=2.118083	 lr=0.339283
Epoch[108] Batch [0199]/[0716]	Speed: 26.006662 samples/sec	 accuracy=49.562500	 loss=2.127493	 lr=0.338880
Epoch[108] Batch [0249]/[0716]	Speed: 26.063696 samples/sec	 accuracy=49.321429	 loss=2.141204	 lr=0.338477
Epoch[108] Batch [0299]/[0716]	Speed: 26.096577 samples/sec	 accuracy=49.553571	 loss=2.138048	 lr=0.338074
Epoch[108] Batch [0349]/[0716]	Speed: 25.868779 samples/sec	 accuracy=49.525510	 loss=2.136374	 lr=0.337671
Epoch[108] Batch [0399]/[0716]	Speed: 26.151259 samples/sec	 accuracy=49.450893	 loss=2.144806	 lr=0.337268
Epoch[108] Batch [0449]/[0716]	Speed: 25.948686 samples/sec	 accuracy=49.503968	 loss=2.147515	 lr=0.336865
Epoch[108] Batch [0499]/[0716]	Speed: 25.723861 samples/sec	 accuracy=49.500000	 loss=2.151817	 lr=0.336462
Epoch[108] Batch [0549]/[0716]	Speed: 25.977589 samples/sec	 accuracy=49.509740	 loss=2.153468	 lr=0.336059
Epoch[108] Batch [0599]/[0716]	Speed: 26.189881 samples/sec	 accuracy=49.532738	 loss=2.154635	 lr=0.335655
Epoch[108] Batch [0649]/[0716]	Speed: 26.335482 samples/sec	 accuracy=49.516484	 loss=2.154076	 lr=0.335252
Epoch[108] Batch [0699]/[0716]	Speed: 25.786893 samples/sec	 accuracy=49.497449	 loss=2.155148	 lr=0.334848
Batch [0049]/[0057]: acc-top1=45.785714 acc-top5=71.750000
[Epoch 108] training: accuracy=49.453811	 loss=2.156130
[Epoch 108] speed: 25 samples/sec	time cost: 1609.747872
[Epoch 108] validation: acc-top1=46.762737 acc-top5=72.833130 loss=2.608585
Epoch[109] Batch [0049]/[0716]	Speed: 23.548677 samples/sec	 accuracy=49.321429	 loss=2.136171	 lr=0.334316
Epoch[109] Batch [0099]/[0716]	Speed: 25.828264 samples/sec	 accuracy=50.446429	 loss=2.094652	 lr=0.333912
Epoch[109] Batch [0149]/[0716]	Speed: 26.014588 samples/sec	 accuracy=50.404762	 loss=2.106550	 lr=0.333508
Epoch[109] Batch [0199]/[0716]	Speed: 25.808628 samples/sec	 accuracy=49.696429	 loss=2.146763	 lr=0.333105
Epoch[109] Batch [0249]/[0716]	Speed: 25.833256 samples/sec	 accuracy=49.878571	 loss=2.141269	 lr=0.332701
Epoch[109] Batch [0299]/[0716]	Speed: 26.141860 samples/sec	 accuracy=49.928571	 loss=2.140121	 lr=0.332297
Epoch[109] Batch [0349]/[0716]	Speed: 25.955874 samples/sec	 accuracy=49.928571	 loss=2.138272	 lr=0.331893
Epoch[109] Batch [0399]/[0716]	Speed: 25.715453 samples/sec	 accuracy=50.062500	 loss=2.134974	 lr=0.331489
Epoch[109] Batch [0449]/[0716]	Speed: 26.172350 samples/sec	 accuracy=49.984127	 loss=2.138226	 lr=0.331085
Epoch[109] Batch [0499]/[0716]	Speed: 26.278936 samples/sec	 accuracy=49.860714	 loss=2.140576	 lr=0.330681
Epoch[109] Batch [0549]/[0716]	Speed: 25.571745 samples/sec	 accuracy=49.814935	 loss=2.141936	 lr=0.330277
Epoch[109] Batch [0599]/[0716]	Speed: 26.126311 samples/sec	 accuracy=49.875000	 loss=2.143204	 lr=0.329872
Epoch[109] Batch [0649]/[0716]	Speed: 25.999887 samples/sec	 accuracy=49.821429	 loss=2.139000	 lr=0.329468
Epoch[109] Batch [0699]/[0716]	Speed: 26.106839 samples/sec	 accuracy=49.719388	 loss=2.140386	 lr=0.329064
Batch [0049]/[0057]: acc-top1=45.642857 acc-top5=73.500000
[Epoch 109] training: accuracy=49.710694	 loss=2.141461
[Epoch 109] speed: 25 samples/sec	time cost: 1607.960494
[Epoch 109] validation: acc-top1=47.519840 acc-top5=74.248123 loss=2.563932
Epoch[110] Batch [0049]/[0716]	Speed: 22.824179 samples/sec	 accuracy=51.285714	 loss=2.105177	 lr=0.328530
Epoch[110] Batch [0099]/[0716]	Speed: 26.767123 samples/sec	 accuracy=50.642857	 loss=2.128228	 lr=0.328125
Epoch[110] Batch [0149]/[0716]	Speed: 26.148879 samples/sec	 accuracy=50.619048	 loss=2.105784	 lr=0.327721
Epoch[110] Batch [0199]/[0716]	Speed: 26.140637 samples/sec	 accuracy=50.875000	 loss=2.093589	 lr=0.327316
Epoch[110] Batch [0249]/[0716]	Speed: 26.368023 samples/sec	 accuracy=50.678571	 loss=2.104339	 lr=0.326912
Epoch[110] Batch [0299]/[0716]	Speed: 25.961101 samples/sec	 accuracy=50.601190	 loss=2.108917	 lr=0.326507
Epoch[110] Batch [0349]/[0716]	Speed: 25.656036 samples/sec	 accuracy=50.607143	 loss=2.107859	 lr=0.326102
Epoch[110] Batch [0399]/[0716]	Speed: 26.131178 samples/sec	 accuracy=50.589286	 loss=2.103472	 lr=0.325698
Epoch[110] Batch [0449]/[0716]	Speed: 26.038611 samples/sec	 accuracy=50.500000	 loss=2.103390	 lr=0.325293
Epoch[110] Batch [0499]/[0716]	Speed: 26.165797 samples/sec	 accuracy=50.450000	 loss=2.107555	 lr=0.324888
Epoch[110] Batch [0549]/[0716]	Speed: 26.105654 samples/sec	 accuracy=50.360390	 loss=2.108049	 lr=0.324483
Epoch[110] Batch [0599]/[0716]	Speed: 26.070857 samples/sec	 accuracy=50.276786	 loss=2.109632	 lr=0.324078
Epoch[110] Batch [0649]/[0716]	Speed: 26.106472 samples/sec	 accuracy=50.082418	 loss=2.117106	 lr=0.323673
Epoch[110] Batch [0699]/[0716]	Speed: 26.288812 samples/sec	 accuracy=50.028061	 loss=2.117755	 lr=0.323268
Batch [0049]/[0057]: acc-top1=46.821429 acc-top5=73.321429
[Epoch 110] training: accuracy=50.102255	 loss=2.115009
[Epoch 110] speed: 26 samples/sec	time cost: 1603.205288
[Epoch 110] validation: acc-top1=47.504177 acc-top5=73.731201 loss=2.523980
Epoch[111] Batch [0049]/[0717]	Speed: 23.102199 samples/sec	 accuracy=51.214286	 loss=2.037167	 lr=0.322733
Epoch[111] Batch [0099]/[0717]	Speed: 25.635575 samples/sec	 accuracy=50.946429	 loss=2.063476	 lr=0.322328
Epoch[111] Batch [0149]/[0717]	Speed: 25.793559 samples/sec	 accuracy=50.250000	 loss=2.100757	 lr=0.321923
Epoch[111] Batch [0199]/[0717]	Speed: 26.036062 samples/sec	 accuracy=50.339286	 loss=2.093653	 lr=0.321518
Epoch[111] Batch [0249]/[0717]	Speed: 26.621982 samples/sec	 accuracy=50.421429	 loss=2.102596	 lr=0.321113
Epoch[111] Batch [0299]/[0717]	Speed: 25.938431 samples/sec	 accuracy=50.309524	 loss=2.108243	 lr=0.320707
Epoch[111] Batch [0349]/[0717]	Speed: 26.370781 samples/sec	 accuracy=50.306122	 loss=2.108025	 lr=0.320302
Epoch[111] Batch [0399]/[0717]	Speed: 26.196834 samples/sec	 accuracy=49.933036	 loss=2.113919	 lr=0.319897
Epoch[111] Batch [0449]/[0717]	Speed: 26.230639 samples/sec	 accuracy=49.904762	 loss=2.116995	 lr=0.319491
Epoch[111] Batch [0499]/[0717]	Speed: 25.980469 samples/sec	 accuracy=49.950000	 loss=2.116768	 lr=0.319086
Epoch[111] Batch [0549]/[0717]	Speed: 26.337197 samples/sec	 accuracy=49.935065	 loss=2.119459	 lr=0.318680
Epoch[111] Batch [0599]/[0717]	Speed: 26.106551 samples/sec	 accuracy=50.130952	 loss=2.115708	 lr=0.318275
Epoch[111] Batch [0649]/[0717]	Speed: 26.396355 samples/sec	 accuracy=50.250000	 loss=2.114071	 lr=0.317869
Epoch[111] Batch [0699]/[0717]	Speed: 26.250851 samples/sec	 accuracy=50.188776	 loss=2.116811	 lr=0.317464
Batch [0049]/[0057]: acc-top1=48.535714 acc-top5=73.964286
[Epoch 111] training: accuracy=50.196752	 loss=2.115615
[Epoch 111] speed: 26 samples/sec	time cost: 1600.927123
[Epoch 111] validation: acc-top1=48.391811 acc-top5=74.921677 loss=2.501327
Epoch[112] Batch [0049]/[0716]	Speed: 23.030768 samples/sec	 accuracy=51.250000	 loss=2.072886	 lr=0.316920
Epoch[112] Batch [0099]/[0716]	Speed: 25.861697 samples/sec	 accuracy=52.375000	 loss=2.070801	 lr=0.316515
Epoch[112] Batch [0149]/[0716]	Speed: 25.261624 samples/sec	 accuracy=51.559524	 loss=2.085841	 lr=0.316109
Epoch[112] Batch [0199]/[0716]	Speed: 26.170383 samples/sec	 accuracy=51.089286	 loss=2.083508	 lr=0.315703
Epoch[112] Batch [0249]/[0716]	Speed: 26.247543 samples/sec	 accuracy=50.800000	 loss=2.091100	 lr=0.315298
Epoch[112] Batch [0299]/[0716]	Speed: 25.784765 samples/sec	 accuracy=50.875000	 loss=2.090731	 lr=0.314892
Epoch[112] Batch [0349]/[0716]	Speed: 26.389741 samples/sec	 accuracy=50.489796	 loss=2.100872	 lr=0.314486
Epoch[112] Batch [0399]/[0716]	Speed: 25.802423 samples/sec	 accuracy=50.526786	 loss=2.104342	 lr=0.314080
Epoch[112] Batch [0449]/[0716]	Speed: 26.252728 samples/sec	 accuracy=50.289683	 loss=2.112847	 lr=0.313674
Epoch[112] Batch [0499]/[0716]	Speed: 25.932300 samples/sec	 accuracy=50.189286	 loss=2.119356	 lr=0.313269
Epoch[112] Batch [0549]/[0716]	Speed: 25.745442 samples/sec	 accuracy=50.259740	 loss=2.114752	 lr=0.312863
Epoch[112] Batch [0599]/[0716]	Speed: 25.856621 samples/sec	 accuracy=50.276786	 loss=2.113057	 lr=0.312457
Epoch[112] Batch [0649]/[0716]	Speed: 26.033973 samples/sec	 accuracy=50.280220	 loss=2.115742	 lr=0.312051
Epoch[112] Batch [0699]/[0716]	Speed: 26.206550 samples/sec	 accuracy=50.301020	 loss=2.116177	 lr=0.311645
Batch [0049]/[0057]: acc-top1=47.785714 acc-top5=74.392857
[Epoch 112] training: accuracy=50.386572	 loss=2.114083
[Epoch 112] speed: 25 samples/sec	time cost: 1610.042785
[Epoch 112] validation: acc-top1=48.438801 acc-top5=74.550964 loss=2.466636
Epoch[113] Batch [0049]/[0716]	Speed: 22.910038 samples/sec	 accuracy=49.607143	 loss=2.124283	 lr=0.311109
Epoch[113] Batch [0099]/[0716]	Speed: 25.869620 samples/sec	 accuracy=49.571429	 loss=2.122840	 lr=0.310703
Epoch[113] Batch [0149]/[0716]	Speed: 26.209165 samples/sec	 accuracy=50.047619	 loss=2.089698	 lr=0.310297
Epoch[113] Batch [0199]/[0716]	Speed: 26.113813 samples/sec	 accuracy=49.937500	 loss=2.096614	 lr=0.309891
Epoch[113] Batch [0249]/[0716]	Speed: 25.961180 samples/sec	 accuracy=50.200000	 loss=2.087514	 lr=0.309485
Epoch[113] Batch [0299]/[0716]	Speed: 26.298023 samples/sec	 accuracy=50.398810	 loss=2.082297	 lr=0.309079
Epoch[113] Batch [0349]/[0716]	Speed: 26.315549 samples/sec	 accuracy=50.362245	 loss=2.085630	 lr=0.308673
Epoch[113] Batch [0399]/[0716]	Speed: 26.081641 samples/sec	 accuracy=50.290179	 loss=2.091438	 lr=0.308267
Epoch[113] Batch [0449]/[0716]	Speed: 26.377882 samples/sec	 accuracy=50.083333	 loss=2.102207	 lr=0.307860
Epoch[113] Batch [0499]/[0716]	Speed: 25.486518 samples/sec	 accuracy=50.078571	 loss=2.100430	 lr=0.307454
Epoch[113] Batch [0549]/[0716]	Speed: 26.057821 samples/sec	 accuracy=50.211039	 loss=2.095264	 lr=0.307048
Epoch[113] Batch [0599]/[0716]	Speed: 26.106959 samples/sec	 accuracy=50.122024	 loss=2.096269	 lr=0.306642
Epoch[113] Batch [0649]/[0716]	Speed: 26.025188 samples/sec	 accuracy=50.126374	 loss=2.097503	 lr=0.306236
Epoch[113] Batch [0699]/[0716]	Speed: 26.161933 samples/sec	 accuracy=50.122449	 loss=2.098604	 lr=0.305830
Batch [0049]/[0057]: acc-top1=49.071429 acc-top5=74.107143
[Epoch 113] training: accuracy=50.064844	 loss=2.100799
[Epoch 113] speed: 26 samples/sec	time cost: 1603.943660
[Epoch 113] validation: acc-top1=48.725983 acc-top5=74.718048 loss=2.451997
Epoch[114] Batch [0049]/[0716]	Speed: 23.216580 samples/sec	 accuracy=51.285714	 loss=2.083250	 lr=0.305293
Epoch[114] Batch [0099]/[0716]	Speed: 26.216908 samples/sec	 accuracy=50.785714	 loss=2.088707	 lr=0.304887
Epoch[114] Batch [0149]/[0716]	Speed: 26.429191 samples/sec	 accuracy=51.119048	 loss=2.067310	 lr=0.304481
Epoch[114] Batch [0199]/[0716]	Speed: 26.144440 samples/sec	 accuracy=50.991071	 loss=2.071142	 lr=0.304075
Epoch[114] Batch [0249]/[0716]	Speed: 26.044257 samples/sec	 accuracy=50.650000	 loss=2.086177	 lr=0.303669
Epoch[114] Batch [0299]/[0716]	Speed: 26.280565 samples/sec	 accuracy=50.809524	 loss=2.077639	 lr=0.303262
Epoch[114] Batch [0349]/[0716]	Speed: 26.217463 samples/sec	 accuracy=50.729592	 loss=2.081532	 lr=0.302856
Epoch[114] Batch [0399]/[0716]	Speed: 25.708849 samples/sec	 accuracy=50.669643	 loss=2.083062	 lr=0.302450
Epoch[114] Batch [0449]/[0716]	Speed: 26.092647 samples/sec	 accuracy=50.623016	 loss=2.089529	 lr=0.302044
Epoch[114] Batch [0499]/[0716]	Speed: 26.017120 samples/sec	 accuracy=50.853571	 loss=2.087317	 lr=0.301637
Epoch[114] Batch [0549]/[0716]	Speed: 25.802966 samples/sec	 accuracy=50.746753	 loss=2.089578	 lr=0.301231
Epoch[114] Batch [0599]/[0716]	Speed: 25.353590 samples/sec	 accuracy=50.779762	 loss=2.089470	 lr=0.300825
Epoch[114] Batch [0649]/[0716]	Speed: 26.009510 samples/sec	 accuracy=50.750000	 loss=2.088003	 lr=0.300418
Epoch[114] Batch [0699]/[0716]	Speed: 25.788731 samples/sec	 accuracy=50.653061	 loss=2.093522	 lr=0.300012
Batch [0049]/[0057]: acc-top1=49.892857 acc-top5=76.357143
[Epoch 114] training: accuracy=50.698324	 loss=2.090666
[Epoch 114] speed: 25 samples/sec	time cost: 1607.978704
[Epoch 114] validation: acc-top1=50.120090 acc-top5=76.164368 loss=2.542341
Epoch[115] Batch [0049]/[0716]	Speed: 23.176179 samples/sec	 accuracy=51.750000	 loss=2.052821	 lr=0.299476
Epoch[115] Batch [0099]/[0716]	Speed: 25.874587 samples/sec	 accuracy=51.821429	 loss=2.037234	 lr=0.299070
Epoch[115] Batch [0149]/[0716]	Speed: 26.237654 samples/sec	 accuracy=51.309524	 loss=2.069650	 lr=0.298663
Epoch[115] Batch [0199]/[0716]	Speed: 26.013172 samples/sec	 accuracy=51.348214	 loss=2.067037	 lr=0.298257
Epoch[115] Batch [0249]/[0716]	Speed: 26.068197 samples/sec	 accuracy=51.328571	 loss=2.064886	 lr=0.297851
Epoch[115] Batch [0299]/[0716]	Speed: 25.902094 samples/sec	 accuracy=50.928571	 loss=2.078412	 lr=0.297445
Epoch[115] Batch [0349]/[0716]	Speed: 25.716697 samples/sec	 accuracy=50.938776	 loss=2.076588	 lr=0.297038
Epoch[115] Batch [0399]/[0716]	Speed: 26.101068 samples/sec	 accuracy=51.218750	 loss=2.068777	 lr=0.296632
Epoch[115] Batch [0449]/[0716]	Speed: 26.189899 samples/sec	 accuracy=50.904762	 loss=2.083169	 lr=0.296226
Epoch[115] Batch [0499]/[0716]	Speed: 25.877034 samples/sec	 accuracy=50.857143	 loss=2.089165	 lr=0.295820
Epoch[115] Batch [0549]/[0716]	Speed: 26.069876 samples/sec	 accuracy=50.788961	 loss=2.089881	 lr=0.295413
Epoch[115] Batch [0599]/[0716]	Speed: 25.888736 samples/sec	 accuracy=50.773810	 loss=2.089265	 lr=0.295007
Epoch[115] Batch [0649]/[0716]	Speed: 26.265822 samples/sec	 accuracy=50.791209	 loss=2.088968	 lr=0.294601
Epoch[115] Batch [0699]/[0716]	Speed: 26.614812 samples/sec	 accuracy=50.826531	 loss=2.087685	 lr=0.294195
Batch [0049]/[0057]: acc-top1=49.392857 acc-top5=75.214286
[Epoch 115] training: accuracy=50.830507	 loss=2.087434
[Epoch 115] speed: 26 samples/sec	time cost: 1603.877617
[Epoch 115] validation: acc-top1=48.585007 acc-top5=74.530075 loss=2.485775
Epoch[116] Batch [0049]/[0716]	Speed: 23.093470 samples/sec	 accuracy=52.714286	 loss=2.021294	 lr=0.293659
Epoch[116] Batch [0099]/[0716]	Speed: 26.105532 samples/sec	 accuracy=52.392857	 loss=2.035160	 lr=0.293252
Epoch[116] Batch [0149]/[0716]	Speed: 25.649322 samples/sec	 accuracy=52.023810	 loss=2.052100	 lr=0.292846
Epoch[116] Batch [0199]/[0716]	Speed: 25.872757 samples/sec	 accuracy=51.455357	 loss=2.078722	 lr=0.292440
Epoch[116] Batch [0249]/[0716]	Speed: 25.914788 samples/sec	 accuracy=51.685714	 loss=2.075761	 lr=0.292034
Epoch[116] Batch [0299]/[0716]	Speed: 25.981183 samples/sec	 accuracy=51.464286	 loss=2.082878	 lr=0.291628
Epoch[116] Batch [0349]/[0716]	Speed: 26.166624 samples/sec	 accuracy=51.178571	 loss=2.085155	 lr=0.291222
Epoch[116] Batch [0399]/[0716]	Speed: 26.058724 samples/sec	 accuracy=51.325893	 loss=2.076888	 lr=0.290816
Epoch[116] Batch [0449]/[0716]	Speed: 25.866330 samples/sec	 accuracy=51.337302	 loss=2.076499	 lr=0.290410
Epoch[116] Batch [0499]/[0716]	Speed: 25.826052 samples/sec	 accuracy=51.328571	 loss=2.079823	 lr=0.290003
Epoch[116] Batch [0549]/[0716]	Speed: 26.012473 samples/sec	 accuracy=51.399351	 loss=2.072623	 lr=0.289597
Epoch[116] Batch [0599]/[0716]	Speed: 25.935256 samples/sec	 accuracy=51.196429	 loss=2.074595	 lr=0.289191
Epoch[116] Batch [0649]/[0716]	Speed: 25.719550 samples/sec	 accuracy=51.134615	 loss=2.080045	 lr=0.288785
Epoch[116] Batch [0699]/[0716]	Speed: 26.626010 samples/sec	 accuracy=51.038265	 loss=2.083321	 lr=0.288379
Batch [0049]/[0057]: acc-top1=49.285714 acc-top5=75.321429
[Epoch 116] training: accuracy=50.990124	 loss=2.084148
[Epoch 116] speed: 25 samples/sec	time cost: 1608.599106
[Epoch 116] validation: acc-top1=49.665833 acc-top5=75.297615 loss=2.449111
Epoch[117] Batch [0049]/[0716]	Speed: 23.219921 samples/sec	 accuracy=50.821429	 loss=2.072106	 lr=0.287844
Epoch[117] Batch [0099]/[0716]	Speed: 25.964694 samples/sec	 accuracy=52.053571	 loss=2.023539	 lr=0.287438
Epoch[117] Batch [0149]/[0716]	Speed: 26.108558 samples/sec	 accuracy=51.357143	 loss=2.036267	 lr=0.287032
Epoch[117] Batch [0199]/[0716]	Speed: 25.944929 samples/sec	 accuracy=51.553571	 loss=2.037042	 lr=0.286626
Epoch[117] Batch [0249]/[0716]	Speed: 25.801973 samples/sec	 accuracy=51.807143	 loss=2.035781	 lr=0.286220
Epoch[117] Batch [0299]/[0716]	Speed: 26.043657 samples/sec	 accuracy=51.619048	 loss=2.051234	 lr=0.285814
Epoch[117] Batch [0349]/[0716]	Speed: 26.432257 samples/sec	 accuracy=51.668367	 loss=2.045214	 lr=0.285408
Epoch[117] Batch [0399]/[0716]	Speed: 26.181706 samples/sec	 accuracy=51.633929	 loss=2.043202	 lr=0.285003
Epoch[117] Batch [0449]/[0716]	Speed: 26.269666 samples/sec	 accuracy=51.670635	 loss=2.038891	 lr=0.284597
Epoch[117] Batch [0499]/[0716]	Speed: 25.922235 samples/sec	 accuracy=51.632143	 loss=2.040119	 lr=0.284191
Epoch[117] Batch [0549]/[0716]	Speed: 25.993260 samples/sec	 accuracy=51.646104	 loss=2.044811	 lr=0.283785
Epoch[117] Batch [0599]/[0716]	Speed: 26.028866 samples/sec	 accuracy=51.645833	 loss=2.041795	 lr=0.283380
Epoch[117] Batch [0649]/[0716]	Speed: 25.959605 samples/sec	 accuracy=51.590659	 loss=2.044269	 lr=0.282974
Epoch[117] Batch [0699]/[0716]	Speed: 25.977651 samples/sec	 accuracy=51.609694	 loss=2.045216	 lr=0.282569
Batch [0049]/[0057]: acc-top1=50.750000 acc-top5=76.464286
[Epoch 117] training: accuracy=51.521349	 loss=2.048718
[Epoch 117] speed: 26 samples/sec	time cost: 1604.464727
[Epoch 117] validation: acc-top1=50.287174 acc-top5=75.746658 loss=2.422518
Epoch[118] Batch [0049]/[0716]	Speed: 23.079859 samples/sec	 accuracy=52.607143	 loss=1.965751	 lr=0.282033
Epoch[118] Batch [0099]/[0716]	Speed: 25.979924 samples/sec	 accuracy=52.053571	 loss=2.012898	 lr=0.281628
Epoch[118] Batch [0149]/[0716]	Speed: 26.160377 samples/sec	 accuracy=51.916667	 loss=2.033304	 lr=0.281222
Epoch[118] Batch [0199]/[0716]	Speed: 25.687200 samples/sec	 accuracy=51.821429	 loss=2.027833	 lr=0.280817
Epoch[118] Batch [0249]/[0716]	Speed: 25.860172 samples/sec	 accuracy=51.850000	 loss=2.038666	 lr=0.280411
Epoch[118] Batch [0299]/[0716]	Speed: 26.463700 samples/sec	 accuracy=51.898810	 loss=2.033842	 lr=0.280006
Epoch[118] Batch [0349]/[0716]	Speed: 26.394923 samples/sec	 accuracy=51.811224	 loss=2.046931	 lr=0.279601
Epoch[118] Batch [0399]/[0716]	Speed: 25.792069 samples/sec	 accuracy=51.897321	 loss=2.042685	 lr=0.279195
Epoch[118] Batch [0449]/[0716]	Speed: 25.840175 samples/sec	 accuracy=51.694444	 loss=2.048361	 lr=0.278790
Epoch[118] Batch [0499]/[0716]	Speed: 26.502705 samples/sec	 accuracy=51.514286	 loss=2.057184	 lr=0.278385
Epoch[118] Batch [0549]/[0716]	Speed: 25.756881 samples/sec	 accuracy=51.435065	 loss=2.057890	 lr=0.277980
Epoch[118] Batch [0599]/[0716]	Speed: 25.854614 samples/sec	 accuracy=51.633929	 loss=2.050769	 lr=0.277574
Epoch[118] Batch [0649]/[0716]	Speed: 25.942605 samples/sec	 accuracy=51.519231	 loss=2.053935	 lr=0.277169
Epoch[118] Batch [0699]/[0716]	Speed: 25.670003 samples/sec	 accuracy=51.594388	 loss=2.051432	 lr=0.276764
Batch [0049]/[0057]: acc-top1=48.321429 acc-top5=74.535714
[Epoch 118] training: accuracy=51.613627	 loss=2.050407
[Epoch 118] speed: 25 samples/sec	time cost: 1610.071445
[Epoch 118] validation: acc-top1=48.809525 acc-top5=74.937347 loss=2.497165
Epoch[119] Batch [0049]/[0717]	Speed: 22.882063 samples/sec	 accuracy=52.714286	 loss=2.024311	 lr=0.276230
Epoch[119] Batch [0099]/[0717]	Speed: 26.105887 samples/sec	 accuracy=52.571429	 loss=2.026003	 lr=0.275825
Epoch[119] Batch [0149]/[0717]	Speed: 26.286711 samples/sec	 accuracy=52.142857	 loss=2.029593	 lr=0.275420
Epoch[119] Batch [0199]/[0717]	Speed: 25.943533 samples/sec	 accuracy=52.500000	 loss=2.011154	 lr=0.275015
Epoch[119] Batch [0249]/[0717]	Speed: 25.895338 samples/sec	 accuracy=52.250000	 loss=2.017375	 lr=0.274610
Epoch[119] Batch [0299]/[0717]	Speed: 26.008137 samples/sec	 accuracy=51.970238	 loss=2.027230	 lr=0.274205
Epoch[119] Batch [0349]/[0717]	Speed: 26.201902 samples/sec	 accuracy=52.071429	 loss=2.024761	 lr=0.273800
Epoch[119] Batch [0399]/[0717]	Speed: 25.903238 samples/sec	 accuracy=51.977679	 loss=2.026515	 lr=0.273396
Epoch[119] Batch [0449]/[0717]	Speed: 25.808433 samples/sec	 accuracy=51.964286	 loss=2.028708	 lr=0.272991
Epoch[119] Batch [0499]/[0717]	Speed: 26.221352 samples/sec	 accuracy=51.900000	 loss=2.037195	 lr=0.272586
Epoch[119] Batch [0549]/[0717]	Speed: 26.458347 samples/sec	 accuracy=51.853896	 loss=2.038640	 lr=0.272182
Epoch[119] Batch [0599]/[0717]	Speed: 26.037594 samples/sec	 accuracy=51.812500	 loss=2.039322	 lr=0.271777
Epoch[119] Batch [0649]/[0717]	Speed: 26.057660 samples/sec	 accuracy=51.774725	 loss=2.043142	 lr=0.271373
Epoch[119] Batch [0699]/[0717]	Speed: 26.252939 samples/sec	 accuracy=51.788265	 loss=2.039768	 lr=0.270969
Batch [0049]/[0057]: acc-top1=50.035714 acc-top5=76.071429
[Epoch 119] training: accuracy=51.798167	 loss=2.039487
[Epoch 119] speed: 26 samples/sec	time cost: 1606.365022
[Epoch 119] validation: acc-top1=50.125313 acc-top5=75.997284 loss=2.374837
Epoch[120] Batch [0049]/[0716]	Speed: 22.769055 samples/sec	 accuracy=53.000000	 loss=1.985976	 lr=0.270427
Epoch[120] Batch [0099]/[0716]	Speed: 26.199789 samples/sec	 accuracy=52.946429	 loss=1.982276	 lr=0.270023
Epoch[120] Batch [0149]/[0716]	Speed: 26.005800 samples/sec	 accuracy=52.654762	 loss=1.991625	 lr=0.269618
Epoch[120] Batch [0199]/[0716]	Speed: 26.075724 samples/sec	 accuracy=52.232143	 loss=2.004796	 lr=0.269214
Epoch[120] Batch [0249]/[0716]	Speed: 25.900280 samples/sec	 accuracy=52.192857	 loss=2.014418	 lr=0.268810
Epoch[120] Batch [0299]/[0716]	Speed: 25.518933 samples/sec	 accuracy=52.196429	 loss=2.013135	 lr=0.268406
Epoch[120] Batch [0349]/[0716]	Speed: 26.238685 samples/sec	 accuracy=52.244898	 loss=2.013109	 lr=0.268002
Epoch[120] Batch [0399]/[0716]	Speed: 26.188400 samples/sec	 accuracy=52.049107	 loss=2.020970	 lr=0.267598
Epoch[120] Batch [0449]/[0716]	Speed: 26.090619 samples/sec	 accuracy=52.079365	 loss=2.015606	 lr=0.267194
Epoch[120] Batch [0499]/[0716]	Speed: 26.086136 samples/sec	 accuracy=52.010714	 loss=2.019833	 lr=0.266790
Epoch[120] Batch [0549]/[0716]	Speed: 25.815983 samples/sec	 accuracy=52.077922	 loss=2.018662	 lr=0.266387
Epoch[120] Batch [0599]/[0716]	Speed: 25.819484 samples/sec	 accuracy=52.127976	 loss=2.018220	 lr=0.265983
Epoch[120] Batch [0649]/[0716]	Speed: 25.875602 samples/sec	 accuracy=52.038462	 loss=2.022200	 lr=0.265579
Epoch[120] Batch [0699]/[0716]	Speed: 26.219907 samples/sec	 accuracy=51.969388	 loss=2.022784	 lr=0.265176
Batch [0049]/[0057]: acc-top1=47.321429 acc-top5=72.750000
[Epoch 120] training: accuracy=52.020152	 loss=2.019904
[Epoch 120] speed: 25 samples/sec	time cost: 1608.295011
[Epoch 120] validation: acc-top1=47.070801 acc-top5=73.480583 loss=2.622640
Epoch[121] Batch [0049]/[0716]	Speed: 23.243565 samples/sec	 accuracy=52.607143	 loss=2.006941	 lr=0.264643
Epoch[121] Batch [0099]/[0716]	Speed: 25.884350 samples/sec	 accuracy=52.392857	 loss=2.016710	 lr=0.264240
Epoch[121] Batch [0149]/[0716]	Speed: 25.964673 samples/sec	 accuracy=52.654762	 loss=2.003221	 lr=0.263837
Epoch[121] Batch [0199]/[0716]	Speed: 25.888251 samples/sec	 accuracy=52.571429	 loss=2.010816	 lr=0.263433
Epoch[121] Batch [0249]/[0716]	Speed: 26.517961 samples/sec	 accuracy=52.514286	 loss=2.018355	 lr=0.263030
Epoch[121] Batch [0299]/[0716]	Speed: 25.936922 samples/sec	 accuracy=52.404762	 loss=2.021932	 lr=0.262627
Epoch[121] Batch [0349]/[0716]	Speed: 26.419799 samples/sec	 accuracy=52.352041	 loss=2.023878	 lr=0.262224
Epoch[121] Batch [0399]/[0716]	Speed: 26.513850 samples/sec	 accuracy=52.388393	 loss=2.021580	 lr=0.261821
Epoch[121] Batch [0449]/[0716]	Speed: 26.047962 samples/sec	 accuracy=52.388889	 loss=2.019458	 lr=0.261418
Epoch[121] Batch [0499]/[0716]	Speed: 26.042369 samples/sec	 accuracy=52.371429	 loss=2.023046	 lr=0.261015
Epoch[121] Batch [0549]/[0716]	Speed: 26.218370 samples/sec	 accuracy=52.230519	 loss=2.029018	 lr=0.260612
Epoch[121] Batch [0599]/[0716]	Speed: 25.730430 samples/sec	 accuracy=52.202381	 loss=2.029217	 lr=0.260210
Epoch[121] Batch [0649]/[0716]	Speed: 25.949699 samples/sec	 accuracy=52.118132	 loss=2.031916	 lr=0.259807
Epoch[121] Batch [0699]/[0716]	Speed: 26.056880 samples/sec	 accuracy=52.160714	 loss=2.031814	 lr=0.259404
Batch [0049]/[0057]: acc-top1=48.464286 acc-top5=75.214286
[Epoch 121] training: accuracy=52.137370	 loss=2.032061
[Epoch 121] speed: 26 samples/sec	time cost: 1601.192400
[Epoch 121] validation: acc-top1=49.096699 acc-top5=75.083542 loss=2.509492
Epoch[122] Batch [0049]/[0716]	Speed: 23.090246 samples/sec	 accuracy=53.892857	 loss=1.983618	 lr=0.258873
Epoch[122] Batch [0099]/[0716]	Speed: 25.989517 samples/sec	 accuracy=54.000000	 loss=1.979620	 lr=0.258471
Epoch[122] Batch [0149]/[0716]	Speed: 25.888680 samples/sec	 accuracy=53.964286	 loss=1.948319	 lr=0.258068
Epoch[122] Batch [0199]/[0716]	Speed: 26.097300 samples/sec	 accuracy=53.776786	 loss=1.957919	 lr=0.257666
Epoch[122] Batch [0249]/[0716]	Speed: 26.151025 samples/sec	 accuracy=53.578571	 loss=1.963100	 lr=0.257264
Epoch[122] Batch [0299]/[0716]	Speed: 26.360459 samples/sec	 accuracy=53.583333	 loss=1.960026	 lr=0.256862
Epoch[122] Batch [0349]/[0716]	Speed: 26.000513 samples/sec	 accuracy=53.474490	 loss=1.960644	 lr=0.256460
Epoch[122] Batch [0399]/[0716]	Speed: 25.948921 samples/sec	 accuracy=53.218750	 loss=1.966457	 lr=0.256058
Epoch[122] Batch [0449]/[0716]	Speed: 25.880624 samples/sec	 accuracy=52.992063	 loss=1.976753	 lr=0.255656
Epoch[122] Batch [0499]/[0716]	Speed: 25.812253 samples/sec	 accuracy=52.978571	 loss=1.976152	 lr=0.255254
Epoch[122] Batch [0549]/[0716]	Speed: 25.797913 samples/sec	 accuracy=52.977273	 loss=1.982027	 lr=0.254853
Epoch[122] Batch [0599]/[0716]	Speed: 26.370745 samples/sec	 accuracy=52.940476	 loss=1.984175	 lr=0.254451
Epoch[122] Batch [0649]/[0716]	Speed: 25.647243 samples/sec	 accuracy=52.802198	 loss=1.986734	 lr=0.254049
Epoch[122] Batch [0699]/[0716]	Speed: 25.974884 samples/sec	 accuracy=52.640306	 loss=1.992386	 lr=0.253648
Batch [0049]/[0057]: acc-top1=48.785714 acc-top5=75.464286
[Epoch 122] training: accuracy=52.666101	 loss=1.990504
[Epoch 122] speed: 25 samples/sec	time cost: 1609.967700
[Epoch 122] validation: acc-top1=50.214077 acc-top5=75.882408 loss=2.467929
Epoch[123] Batch [0049]/[0716]	Speed: 23.017136 samples/sec	 accuracy=54.071429	 loss=1.934000	 lr=0.253118
Epoch[123] Batch [0099]/[0716]	Speed: 26.260275 samples/sec	 accuracy=53.464286	 loss=1.945120	 lr=0.252717
Epoch[123] Batch [0149]/[0716]	Speed: 25.950420 samples/sec	 accuracy=53.630952	 loss=1.943873	 lr=0.252316
Epoch[123] Batch [0199]/[0716]	Speed: 26.378050 samples/sec	 accuracy=53.366071	 loss=1.957519	 lr=0.251915
Epoch[123] Batch [0249]/[0716]	Speed: 26.116301 samples/sec	 accuracy=53.542857	 loss=1.954628	 lr=0.251514
Epoch[123] Batch [0299]/[0716]	Speed: 25.906324 samples/sec	 accuracy=53.077381	 loss=1.965772	 lr=0.251113
Epoch[123] Batch [0349]/[0716]	Speed: 26.331877 samples/sec	 accuracy=53.056122	 loss=1.968029	 lr=0.250712
Epoch[123] Batch [0399]/[0716]	Speed: 26.148088 samples/sec	 accuracy=53.254464	 loss=1.965047	 lr=0.250311
Epoch[123] Batch [0449]/[0716]	Speed: 25.674227 samples/sec	 accuracy=53.234127	 loss=1.967928	 lr=0.249911
Epoch[123] Batch [0499]/[0716]	Speed: 25.689079 samples/sec	 accuracy=53.335714	 loss=1.965976	 lr=0.249510
Epoch[123] Batch [0549]/[0716]	Speed: 25.787312 samples/sec	 accuracy=53.259740	 loss=1.969536	 lr=0.249110
Epoch[123] Batch [0599]/[0716]	Speed: 25.808950 samples/sec	 accuracy=53.169643	 loss=1.970967	 lr=0.248709
Epoch[123] Batch [0649]/[0716]	Speed: 25.906063 samples/sec	 accuracy=53.032967	 loss=1.973727	 lr=0.248309
Epoch[123] Batch [0699]/[0716]	Speed: 26.256682 samples/sec	 accuracy=52.936224	 loss=1.975971	 lr=0.247909
Batch [0049]/[0057]: acc-top1=51.214286 acc-top5=75.857143
[Epoch 123] training: accuracy=52.947925	 loss=1.974048
[Epoch 123] speed: 25 samples/sec	time cost: 1609.528483
[Epoch 123] validation: acc-top1=51.315792 acc-top5=76.133041 loss=2.451721
Epoch[124] Batch [0049]/[0716]	Speed: 22.839673 samples/sec	 accuracy=52.821429	 loss=1.984106	 lr=0.247381
Epoch[124] Batch [0099]/[0716]	Speed: 25.974956 samples/sec	 accuracy=53.196429	 loss=1.957119	 lr=0.246981
Epoch[124] Batch [0149]/[0716]	Speed: 26.055502 samples/sec	 accuracy=53.500000	 loss=1.944030	 lr=0.246581
Epoch[124] Batch [0199]/[0716]	Speed: 26.200527 samples/sec	 accuracy=53.258929	 loss=1.952854	 lr=0.246182
Epoch[124] Batch [0249]/[0716]	Speed: 25.752089 samples/sec	 accuracy=53.271429	 loss=1.955766	 lr=0.245782
Epoch[124] Batch [0299]/[0716]	Speed: 26.484256 samples/sec	 accuracy=53.232143	 loss=1.966730	 lr=0.245382
Epoch[124] Batch [0349]/[0716]	Speed: 25.945591 samples/sec	 accuracy=53.290816	 loss=1.971032	 lr=0.244983
Epoch[124] Batch [0399]/[0716]	Speed: 25.974222 samples/sec	 accuracy=53.026786	 loss=1.975582	 lr=0.244584
Epoch[124] Batch [0449]/[0716]	Speed: 25.582949 samples/sec	 accuracy=52.698413	 loss=1.981633	 lr=0.244184
Epoch[124] Batch [0499]/[0716]	Speed: 26.572876 samples/sec	 accuracy=52.546429	 loss=1.989712	 lr=0.243785
Epoch[124] Batch [0549]/[0716]	Speed: 26.161577 samples/sec	 accuracy=52.522727	 loss=1.994038	 lr=0.243386
Epoch[124] Batch [0599]/[0716]	Speed: 26.236561 samples/sec	 accuracy=52.598214	 loss=1.996118	 lr=0.242987
Epoch[124] Batch [0649]/[0716]	Speed: 26.268884 samples/sec	 accuracy=52.615385	 loss=1.993926	 lr=0.242589
Epoch[124] Batch [0699]/[0716]	Speed: 25.929595 samples/sec	 accuracy=52.655612	 loss=1.991728	 lr=0.242190
Batch [0049]/[0057]: acc-top1=52.142857 acc-top5=77.821429
[Epoch 124] training: accuracy=52.651137	 loss=1.993060
[Epoch 124] speed: 26 samples/sec	time cost: 1605.062933
[Epoch 124] validation: acc-top1=50.569130 acc-top5=76.555977 loss=2.417765
Epoch[125] Batch [0049]/[0716]	Speed: 22.742521 samples/sec	 accuracy=54.714286	 loss=1.908431	 lr=0.241664
Epoch[125] Batch [0099]/[0716]	Speed: 26.232560 samples/sec	 accuracy=54.821429	 loss=1.902452	 lr=0.241265
Epoch[125] Batch [0149]/[0716]	Speed: 25.734084 samples/sec	 accuracy=54.297619	 loss=1.921110	 lr=0.240867
Epoch[125] Batch [0199]/[0716]	Speed: 25.854114 samples/sec	 accuracy=54.000000	 loss=1.930885	 lr=0.240469
Epoch[125] Batch [0249]/[0716]	Speed: 26.632231 samples/sec	 accuracy=53.707143	 loss=1.952011	 lr=0.240070
Epoch[125] Batch [0299]/[0716]	Speed: 25.768713 samples/sec	 accuracy=53.339286	 loss=1.960414	 lr=0.239672
Epoch[125] Batch [0349]/[0716]	Speed: 25.443930 samples/sec	 accuracy=53.336735	 loss=1.960448	 lr=0.239275
Epoch[125] Batch [0399]/[0716]	Speed: 26.018668 samples/sec	 accuracy=53.562500	 loss=1.958254	 lr=0.238877
Epoch[125] Batch [0449]/[0716]	Speed: 25.545383 samples/sec	 accuracy=53.626984	 loss=1.954252	 lr=0.238479
Epoch[125] Batch [0499]/[0716]	Speed: 26.114195 samples/sec	 accuracy=53.621429	 loss=1.950270	 lr=0.238081
Epoch[125] Batch [0549]/[0716]	Speed: 25.834352 samples/sec	 accuracy=53.532468	 loss=1.952529	 lr=0.237684
Epoch[125] Batch [0599]/[0716]	Speed: 26.316679 samples/sec	 accuracy=53.622024	 loss=1.951294	 lr=0.237287
Epoch[125] Batch [0649]/[0716]	Speed: 26.045663 samples/sec	 accuracy=53.590659	 loss=1.951584	 lr=0.236889
Epoch[125] Batch [0699]/[0716]	Speed: 26.223612 samples/sec	 accuracy=53.573980	 loss=1.955990	 lr=0.236492
Batch [0049]/[0057]: acc-top1=52.678571 acc-top5=77.071429
[Epoch 125] training: accuracy=53.553970	 loss=1.958274
[Epoch 125] speed: 25 samples/sec	time cost: 1610.059434
[Epoch 125] validation: acc-top1=51.472431 acc-top5=76.362785 loss=2.352927
Epoch[126] Batch [0049]/[0716]	Speed: 22.989647 samples/sec	 accuracy=55.464286	 loss=1.932810	 lr=0.235968
Epoch[126] Batch [0099]/[0716]	Speed: 26.167757 samples/sec	 accuracy=54.803571	 loss=1.931493	 lr=0.235571
Epoch[126] Batch [0149]/[0716]	Speed: 26.431602 samples/sec	 accuracy=54.702381	 loss=1.915833	 lr=0.235175
Epoch[126] Batch [0199]/[0716]	Speed: 25.863258 samples/sec	 accuracy=53.883929	 loss=1.939438	 lr=0.234778
Epoch[126] Batch [0249]/[0716]	Speed: 26.023510 samples/sec	 accuracy=53.757143	 loss=1.939728	 lr=0.234382
Epoch[126] Batch [0299]/[0716]	Speed: 26.157803 samples/sec	 accuracy=53.678571	 loss=1.947969	 lr=0.233985
Epoch[126] Batch [0349]/[0716]	Speed: 25.953210 samples/sec	 accuracy=53.790816	 loss=1.948094	 lr=0.233589
Epoch[126] Batch [0399]/[0716]	Speed: 26.496476 samples/sec	 accuracy=54.004464	 loss=1.943167	 lr=0.233193
Epoch[126] Batch [0449]/[0716]	Speed: 25.942393 samples/sec	 accuracy=53.761905	 loss=1.954374	 lr=0.232797
Epoch[126] Batch [0499]/[0716]	Speed: 26.137025 samples/sec	 accuracy=53.664286	 loss=1.958061	 lr=0.232401
Epoch[126] Batch [0549]/[0716]	Speed: 26.216346 samples/sec	 accuracy=53.590909	 loss=1.959088	 lr=0.232005
Epoch[126] Batch [0599]/[0716]	Speed: 26.378162 samples/sec	 accuracy=53.431548	 loss=1.963913	 lr=0.231610
Epoch[126] Batch [0649]/[0716]	Speed: 26.489955 samples/sec	 accuracy=53.351648	 loss=1.964569	 lr=0.231214
Epoch[126] Batch [0699]/[0716]	Speed: 26.329070 samples/sec	 accuracy=53.382653	 loss=1.963824	 lr=0.230819
Batch [0049]/[0057]: acc-top1=48.857143 acc-top5=76.571429
[Epoch 126] training: accuracy=53.329509	 loss=1.964057
[Epoch 126] speed: 26 samples/sec	time cost: 1596.811809
[Epoch 126] validation: acc-top1=50.287174 acc-top5=76.477654 loss=2.397378
Epoch[127] Batch [0049]/[0717]	Speed: 23.148194 samples/sec	 accuracy=54.178571	 loss=1.924729	 lr=0.230297
Epoch[127] Batch [0099]/[0717]	Speed: 26.073013 samples/sec	 accuracy=53.857143	 loss=1.926973	 lr=0.229902
Epoch[127] Batch [0149]/[0717]	Speed: 25.929375 samples/sec	 accuracy=53.904762	 loss=1.934422	 lr=0.229507
Epoch[127] Batch [0199]/[0717]	Speed: 26.086902 samples/sec	 accuracy=53.589286	 loss=1.952870	 lr=0.229112
Epoch[127] Batch [0249]/[0717]	Speed: 25.705180 samples/sec	 accuracy=53.435714	 loss=1.951909	 lr=0.228717
Epoch[127] Batch [0299]/[0717]	Speed: 26.328137 samples/sec	 accuracy=53.511905	 loss=1.951885	 lr=0.228323
Epoch[127] Batch [0349]/[0717]	Speed: 26.074283 samples/sec	 accuracy=53.581633	 loss=1.945757	 lr=0.227928
Epoch[127] Batch [0399]/[0717]	Speed: 25.762759 samples/sec	 accuracy=53.513393	 loss=1.946793	 lr=0.227534
Epoch[127] Batch [0449]/[0717]	Speed: 26.262747 samples/sec	 accuracy=53.559524	 loss=1.945042	 lr=0.227140
Epoch[127] Batch [0499]/[0717]	Speed: 25.882983 samples/sec	 accuracy=53.703571	 loss=1.942802	 lr=0.226746
Epoch[127] Batch [0549]/[0717]	Speed: 25.632267 samples/sec	 accuracy=53.737013	 loss=1.945237	 lr=0.226352
Epoch[127] Batch [0599]/[0717]	Speed: 26.358959 samples/sec	 accuracy=53.761905	 loss=1.944443	 lr=0.225958
Epoch[127] Batch [0649]/[0717]	Speed: 25.978134 samples/sec	 accuracy=53.648352	 loss=1.952988	 lr=0.225564
Epoch[127] Batch [0699]/[0717]	Speed: 26.477814 samples/sec	 accuracy=53.599490	 loss=1.954319	 lr=0.225171
Batch [0049]/[0057]: acc-top1=53.035714 acc-top5=77.571429
[Epoch 127] training: accuracy=53.611277	 loss=1.953943
[Epoch 127] speed: 25 samples/sec	time cost: 1608.112376
[Epoch 127] validation: acc-top1=53.080612 acc-top5=78.158936 loss=2.234040
Epoch[128] Batch [0049]/[0716]	Speed: 23.200899 samples/sec	 accuracy=56.214286	 loss=1.844853	 lr=0.224644
Epoch[128] Batch [0099]/[0716]	Speed: 25.839697 samples/sec	 accuracy=54.535714	 loss=1.911971	 lr=0.224251
Epoch[128] Batch [0149]/[0716]	Speed: 25.904307 samples/sec	 accuracy=55.214286	 loss=1.889606	 lr=0.223858
Epoch[128] Batch [0199]/[0716]	Speed: 25.862234 samples/sec	 accuracy=55.035714	 loss=1.882483	 lr=0.223465
Epoch[128] Batch [0249]/[0716]	Speed: 26.471104 samples/sec	 accuracy=54.714286	 loss=1.899710	 lr=0.223072
Epoch[128] Batch [0299]/[0716]	Speed: 26.067939 samples/sec	 accuracy=54.892857	 loss=1.889523	 lr=0.222679
Epoch[128] Batch [0349]/[0716]	Speed: 26.180525 samples/sec	 accuracy=54.617347	 loss=1.900043	 lr=0.222287
Epoch[128] Batch [0399]/[0716]	Speed: 26.497851 samples/sec	 accuracy=54.736607	 loss=1.904814	 lr=0.221895
Epoch[128] Batch [0449]/[0716]	Speed: 26.612568 samples/sec	 accuracy=54.650794	 loss=1.907336	 lr=0.221502
Epoch[128] Batch [0499]/[0716]	Speed: 26.576909 samples/sec	 accuracy=54.535714	 loss=1.908748	 lr=0.221110
Epoch[128] Batch [0549]/[0716]	Speed: 26.522718 samples/sec	 accuracy=54.535714	 loss=1.913100	 lr=0.220718
Epoch[128] Batch [0599]/[0716]	Speed: 25.947680 samples/sec	 accuracy=54.467262	 loss=1.917809	 lr=0.220327
Epoch[128] Batch [0649]/[0716]	Speed: 26.469437 samples/sec	 accuracy=54.417582	 loss=1.917187	 lr=0.219935
Epoch[128] Batch [0699]/[0716]	Speed: 25.961169 samples/sec	 accuracy=54.323980	 loss=1.919733	 lr=0.219544
Batch [0049]/[0057]: acc-top1=51.642857 acc-top5=77.357143
[Epoch 128] training: accuracy=54.262271	 loss=1.921768
[Epoch 128] speed: 26 samples/sec	time cost: 1594.140931
[Epoch 128] validation: acc-top1=51.268791 acc-top5=76.686508 loss=2.310278
Epoch[129] Batch [0049]/[0716]	Speed: 22.955271 samples/sec	 accuracy=56.392857	 loss=1.808235	 lr=0.219027
Epoch[129] Batch [0099]/[0716]	Speed: 26.191497 samples/sec	 accuracy=55.607143	 loss=1.842401	 lr=0.218636
Epoch[129] Batch [0149]/[0716]	Speed: 26.457178 samples/sec	 accuracy=55.583333	 loss=1.861906	 lr=0.218245
Epoch[129] Batch [0199]/[0716]	Speed: 26.314708 samples/sec	 accuracy=55.098214	 loss=1.888351	 lr=0.217854
Epoch[129] Batch [0249]/[0716]	Speed: 26.309155 samples/sec	 accuracy=55.050000	 loss=1.887381	 lr=0.217464
Epoch[129] Batch [0299]/[0716]	Speed: 26.029642 samples/sec	 accuracy=54.982143	 loss=1.893757	 lr=0.217073
Epoch[129] Batch [0349]/[0716]	Speed: 26.155430 samples/sec	 accuracy=54.933673	 loss=1.902209	 lr=0.216683
Epoch[129] Batch [0399]/[0716]	Speed: 26.009912 samples/sec	 accuracy=54.928571	 loss=1.902714	 lr=0.216292
Epoch[129] Batch [0449]/[0716]	Speed: 26.333937 samples/sec	 accuracy=54.833333	 loss=1.907325	 lr=0.215902
Epoch[129] Batch [0499]/[0716]	Speed: 25.800876 samples/sec	 accuracy=54.882143	 loss=1.906997	 lr=0.215512
Epoch[129] Batch [0549]/[0716]	Speed: 26.296109 samples/sec	 accuracy=54.775974	 loss=1.910704	 lr=0.215123
Epoch[129] Batch [0599]/[0716]	Speed: 26.627425 samples/sec	 accuracy=54.699405	 loss=1.910518	 lr=0.214733
Epoch[129] Batch [0649]/[0716]	Speed: 26.237194 samples/sec	 accuracy=54.582418	 loss=1.915878	 lr=0.214344
Epoch[129] Batch [0699]/[0716]	Speed: 25.788794 samples/sec	 accuracy=54.683673	 loss=1.914052	 lr=0.213954
Batch [0049]/[0057]: acc-top1=53.107143 acc-top5=77.857143
[Epoch 129] training: accuracy=54.641361	 loss=1.915276
[Epoch 129] speed: 26 samples/sec	time cost: 1598.056671
[Epoch 129] validation: acc-top1=53.273804 acc-top5=78.279037 loss=2.172907
Epoch[130] Batch [0049]/[0716]	Speed: 22.637126 samples/sec	 accuracy=56.357143	 loss=1.797633	 lr=0.213441
Epoch[130] Batch [0099]/[0716]	Speed: 26.077640 samples/sec	 accuracy=56.500000	 loss=1.814184	 lr=0.213052
Epoch[130] Batch [0149]/[0716]	Speed: 26.475324 samples/sec	 accuracy=56.083333	 loss=1.827437	 lr=0.212663
Epoch[130] Batch [0199]/[0716]	Speed: 26.248477 samples/sec	 accuracy=55.366071	 loss=1.842296	 lr=0.212275
Epoch[130] Batch [0249]/[0716]	Speed: 25.837922 samples/sec	 accuracy=55.185714	 loss=1.866051	 lr=0.211886
Epoch[130] Batch [0299]/[0716]	Speed: 26.188827 samples/sec	 accuracy=55.392857	 loss=1.864089	 lr=0.211498
Epoch[130] Batch [0349]/[0716]	Speed: 25.908169 samples/sec	 accuracy=55.086735	 loss=1.880509	 lr=0.211110
Epoch[130] Batch [0399]/[0716]	Speed: 26.407013 samples/sec	 accuracy=55.308036	 loss=1.873386	 lr=0.210722
Epoch[130] Batch [0449]/[0716]	Speed: 25.962478 samples/sec	 accuracy=55.186508	 loss=1.877988	 lr=0.210334
Epoch[130] Batch [0499]/[0716]	Speed: 26.081038 samples/sec	 accuracy=55.121429	 loss=1.881061	 lr=0.209946
Epoch[130] Batch [0549]/[0716]	Speed: 25.720819 samples/sec	 accuracy=55.090909	 loss=1.882948	 lr=0.209559
Epoch[130] Batch [0599]/[0716]	Speed: 26.038298 samples/sec	 accuracy=54.872024	 loss=1.891803	 lr=0.209172
Epoch[130] Batch [0649]/[0716]	Speed: 26.107639 samples/sec	 accuracy=54.898352	 loss=1.893955	 lr=0.208785
Epoch[130] Batch [0699]/[0716]	Speed: 25.882247 samples/sec	 accuracy=54.818878	 loss=1.897634	 lr=0.208398
Batch [0049]/[0057]: acc-top1=53.142857 acc-top5=77.750000
[Epoch 130] training: accuracy=54.768555	 loss=1.898218
[Epoch 130] speed: 26 samples/sec	time cost: 1606.028534
[Epoch 130] validation: acc-top1=52.866535 acc-top5=78.367798 loss=2.245100
Epoch[131] Batch [0049]/[0716]	Speed: 23.013989 samples/sec	 accuracy=55.142857	 loss=1.839870	 lr=0.207887
Epoch[131] Batch [0099]/[0716]	Speed: 25.857819 samples/sec	 accuracy=54.982143	 loss=1.857827	 lr=0.207500
Epoch[131] Batch [0149]/[0716]	Speed: 25.552609 samples/sec	 accuracy=55.428571	 loss=1.838142	 lr=0.207114
Epoch[131] Batch [0199]/[0716]	Speed: 26.140095 samples/sec	 accuracy=55.446429	 loss=1.841749	 lr=0.206728
Epoch[131] Batch [0249]/[0716]	Speed: 26.103613 samples/sec	 accuracy=55.564286	 loss=1.845018	 lr=0.206342
Epoch[131] Batch [0299]/[0716]	Speed: 26.282955 samples/sec	 accuracy=55.321429	 loss=1.862224	 lr=0.205956
Epoch[131] Batch [0349]/[0716]	Speed: 25.811507 samples/sec	 accuracy=55.255102	 loss=1.870997	 lr=0.205570
Epoch[131] Batch [0399]/[0716]	Speed: 25.721041 samples/sec	 accuracy=55.334821	 loss=1.869817	 lr=0.205185
Epoch[131] Batch [0449]/[0716]	Speed: 26.006357 samples/sec	 accuracy=55.313492	 loss=1.866224	 lr=0.204799
Epoch[131] Batch [0499]/[0716]	Speed: 25.935012 samples/sec	 accuracy=55.342857	 loss=1.867333	 lr=0.204414
Epoch[131] Batch [0549]/[0716]	Speed: 26.289569 samples/sec	 accuracy=55.376623	 loss=1.869127	 lr=0.204029
Epoch[131] Batch [0599]/[0716]	Speed: 26.098301 samples/sec	 accuracy=55.276786	 loss=1.874546	 lr=0.203644
Epoch[131] Batch [0649]/[0716]	Speed: 26.125832 samples/sec	 accuracy=55.244505	 loss=1.879237	 lr=0.203260
Epoch[131] Batch [0699]/[0716]	Speed: 26.056784 samples/sec	 accuracy=55.206633	 loss=1.882977	 lr=0.202875
Batch [0049]/[0057]: acc-top1=53.285714 acc-top5=78.285714
[Epoch 131] training: accuracy=55.172586	 loss=1.883412
[Epoch 131] speed: 25 samples/sec	time cost: 1607.203243
[Epoch 131] validation: acc-top1=52.313072 acc-top5=77.730782 loss=2.379662
Epoch[132] Batch [0049]/[0716]	Speed: 23.022509 samples/sec	 accuracy=57.071429	 loss=1.784685	 lr=0.202368
Epoch[132] Batch [0099]/[0716]	Speed: 26.265893 samples/sec	 accuracy=56.589286	 loss=1.842489	 lr=0.201984
Epoch[132] Batch [0149]/[0716]	Speed: 26.070630 samples/sec	 accuracy=56.011905	 loss=1.862970	 lr=0.201600
Epoch[132] Batch [0199]/[0716]	Speed: 26.536463 samples/sec	 accuracy=55.625000	 loss=1.864953	 lr=0.201216
Epoch[132] Batch [0249]/[0716]	Speed: 25.974270 samples/sec	 accuracy=55.378571	 loss=1.868557	 lr=0.200833
Epoch[132] Batch [0299]/[0716]	Speed: 26.335108 samples/sec	 accuracy=55.505952	 loss=1.865323	 lr=0.200449
Epoch[132] Batch [0349]/[0716]	Speed: 26.250153 samples/sec	 accuracy=55.505102	 loss=1.867420	 lr=0.200066
Epoch[132] Batch [0399]/[0716]	Speed: 26.071340 samples/sec	 accuracy=55.357143	 loss=1.871642	 lr=0.199683
Epoch[132] Batch [0449]/[0716]	Speed: 26.437092 samples/sec	 accuracy=55.337302	 loss=1.871824	 lr=0.199300
Epoch[132] Batch [0499]/[0716]	Speed: 26.091730 samples/sec	 accuracy=55.328571	 loss=1.873727	 lr=0.198918
Epoch[132] Batch [0549]/[0716]	Speed: 25.650333 samples/sec	 accuracy=55.181818	 loss=1.878320	 lr=0.198535
Epoch[132] Batch [0599]/[0716]	Speed: 26.404395 samples/sec	 accuracy=55.142857	 loss=1.882401	 lr=0.198153
Epoch[132] Batch [0649]/[0716]	Speed: 25.615476 samples/sec	 accuracy=55.054945	 loss=1.883837	 lr=0.197771
Epoch[132] Batch [0699]/[0716]	Speed: 25.546363 samples/sec	 accuracy=54.992347	 loss=1.888099	 lr=0.197389
Batch [0049]/[0057]: acc-top1=55.107143 acc-top5=78.071429
[Epoch 132] training: accuracy=54.958101	 loss=1.889224
[Epoch 132] speed: 26 samples/sec	time cost: 1600.723612
[Epoch 132] validation: acc-top1=54.380745 acc-top5=79.025681 loss=2.141023
Epoch[133] Batch [0049]/[0716]	Speed: 22.531925 samples/sec	 accuracy=54.500000	 loss=1.896985	 lr=0.196886
Epoch[133] Batch [0099]/[0716]	Speed: 26.101419 samples/sec	 accuracy=54.160714	 loss=1.901558	 lr=0.196504
Epoch[133] Batch [0149]/[0716]	Speed: 25.625970 samples/sec	 accuracy=55.035714	 loss=1.866698	 lr=0.196123
Epoch[133] Batch [0199]/[0716]	Speed: 26.055383 samples/sec	 accuracy=55.303571	 loss=1.862107	 lr=0.195742
Epoch[133] Batch [0249]/[0716]	Speed: 25.731174 samples/sec	 accuracy=55.371429	 loss=1.852786	 lr=0.195361
Epoch[133] Batch [0299]/[0716]	Speed: 26.318245 samples/sec	 accuracy=55.351190	 loss=1.850572	 lr=0.194980
Epoch[133] Batch [0349]/[0716]	Speed: 25.675862 samples/sec	 accuracy=55.484694	 loss=1.847678	 lr=0.194600
Epoch[133] Batch [0399]/[0716]	Speed: 26.055629 samples/sec	 accuracy=55.477679	 loss=1.846215	 lr=0.194220
Epoch[133] Batch [0449]/[0716]	Speed: 25.726773 samples/sec	 accuracy=55.380952	 loss=1.849336	 lr=0.193839
Epoch[133] Batch [0499]/[0716]	Speed: 25.986596 samples/sec	 accuracy=55.278571	 loss=1.852767	 lr=0.193460
Epoch[133] Batch [0549]/[0716]	Speed: 26.222273 samples/sec	 accuracy=55.292208	 loss=1.849195	 lr=0.193080
Epoch[133] Batch [0599]/[0716]	Speed: 26.389227 samples/sec	 accuracy=55.380952	 loss=1.847796	 lr=0.192700
Epoch[133] Batch [0649]/[0716]	Speed: 26.380647 samples/sec	 accuracy=55.346154	 loss=1.849601	 lr=0.192321
Epoch[133] Batch [0699]/[0716]	Speed: 26.321722 samples/sec	 accuracy=55.431122	 loss=1.848981	 lr=0.191942
Batch [0049]/[0057]: acc-top1=54.250000 acc-top5=79.178571
[Epoch 133] training: accuracy=55.471868	 loss=1.848609
[Epoch 133] speed: 25 samples/sec	time cost: 1607.641676
[Epoch 133] validation: acc-top1=53.686298 acc-top5=78.477448 loss=2.196155
Epoch[134] Batch [0049]/[0716]	Speed: 23.178763 samples/sec	 accuracy=55.928571	 loss=1.822104	 lr=0.191442
Epoch[134] Batch [0099]/[0716]	Speed: 26.139718 samples/sec	 accuracy=55.589286	 loss=1.832825	 lr=0.191063
Epoch[134] Batch [0149]/[0716]	Speed: 26.045184 samples/sec	 accuracy=55.261905	 loss=1.851339	 lr=0.190685
Epoch[134] Batch [0199]/[0716]	Speed: 25.811563 samples/sec	 accuracy=55.812500	 loss=1.834586	 lr=0.190307
Epoch[134] Batch [0249]/[0716]	Speed: 25.977940 samples/sec	 accuracy=55.800000	 loss=1.839628	 lr=0.189929
Epoch[134] Batch [0299]/[0716]	Speed: 26.050677 samples/sec	 accuracy=55.517857	 loss=1.850393	 lr=0.189551
Epoch[134] Batch [0349]/[0716]	Speed: 25.766496 samples/sec	 accuracy=55.428571	 loss=1.851968	 lr=0.189173
Epoch[134] Batch [0399]/[0716]	Speed: 25.948321 samples/sec	 accuracy=55.441964	 loss=1.851436	 lr=0.188796
Epoch[134] Batch [0449]/[0716]	Speed: 26.196393 samples/sec	 accuracy=55.484127	 loss=1.849697	 lr=0.188418
Epoch[134] Batch [0499]/[0716]	Speed: 26.262693 samples/sec	 accuracy=55.407143	 loss=1.853266	 lr=0.188041
Epoch[134] Batch [0549]/[0716]	Speed: 26.259448 samples/sec	 accuracy=55.503247	 loss=1.852554	 lr=0.187665
Epoch[134] Batch [0599]/[0716]	Speed: 26.131052 samples/sec	 accuracy=55.651786	 loss=1.846480	 lr=0.187288
Epoch[134] Batch [0649]/[0716]	Speed: 26.065524 samples/sec	 accuracy=55.609890	 loss=1.849579	 lr=0.186912
Epoch[134] Batch [0699]/[0716]	Speed: 25.903030 samples/sec	 accuracy=55.663265	 loss=1.850080	 lr=0.186535
Batch [0049]/[0057]: acc-top1=52.571429 acc-top5=78.142857
[Epoch 134] training: accuracy=55.673883	 loss=1.851072
[Epoch 134] speed: 26 samples/sec	time cost: 1604.673366
[Epoch 134] validation: acc-top1=52.621132 acc-top5=77.730782 loss=2.472890
Epoch[135] Batch [0049]/[0717]	Speed: 23.006527 samples/sec	 accuracy=54.821429	 loss=1.849285	 lr=0.186039
Epoch[135] Batch [0099]/[0717]	Speed: 26.176963 samples/sec	 accuracy=56.910714	 loss=1.768071	 lr=0.185663
Epoch[135] Batch [0149]/[0717]	Speed: 25.898293 samples/sec	 accuracy=56.750000	 loss=1.783429	 lr=0.185288
Epoch[135] Batch [0199]/[0717]	Speed: 26.037392 samples/sec	 accuracy=56.687500	 loss=1.785488	 lr=0.184913
Epoch[135] Batch [0249]/[0717]	Speed: 26.260930 samples/sec	 accuracy=56.721429	 loss=1.789649	 lr=0.184537
Epoch[135] Batch [0299]/[0717]	Speed: 25.868719 samples/sec	 accuracy=56.601190	 loss=1.796899	 lr=0.184163
Epoch[135] Batch [0349]/[0717]	Speed: 26.042828 samples/sec	 accuracy=56.418367	 loss=1.800922	 lr=0.183788
Epoch[135] Batch [0399]/[0717]	Speed: 26.004236 samples/sec	 accuracy=56.504464	 loss=1.800654	 lr=0.183414
Epoch[135] Batch [0449]/[0717]	Speed: 25.961598 samples/sec	 accuracy=56.468254	 loss=1.808777	 lr=0.183039
Epoch[135] Batch [0499]/[0717]	Speed: 25.666500 samples/sec	 accuracy=56.278571	 loss=1.819799	 lr=0.182665
Epoch[135] Batch [0549]/[0717]	Speed: 26.383469 samples/sec	 accuracy=56.253247	 loss=1.822245	 lr=0.182291
Epoch[135] Batch [0599]/[0717]	Speed: 25.963549 samples/sec	 accuracy=56.366071	 loss=1.820179	 lr=0.181918
Epoch[135] Batch [0649]/[0717]	Speed: 25.764613 samples/sec	 accuracy=56.326923	 loss=1.821516	 lr=0.181545
Epoch[135] Batch [0699]/[0717]	Speed: 26.511100 samples/sec	 accuracy=56.234694	 loss=1.825419	 lr=0.181171
Batch [0049]/[0057]: acc-top1=53.500000 acc-top5=78.607143
[Epoch 135] training: accuracy=56.258717	 loss=1.825048
[Epoch 135] speed: 25 samples/sec	time cost: 1609.002787
[Epoch 135] validation: acc-top1=54.500835 acc-top5=78.942146 loss=2.085424
Epoch[136] Batch [0049]/[0716]	Speed: 23.122293 samples/sec	 accuracy=58.357143	 loss=1.682513	 lr=0.180672
Epoch[136] Batch [0099]/[0716]	Speed: 26.692521 samples/sec	 accuracy=56.839286	 loss=1.772056	 lr=0.180299
Epoch[136] Batch [0149]/[0716]	Speed: 26.308612 samples/sec	 accuracy=56.869048	 loss=1.776437	 lr=0.179927
Epoch[136] Batch [0199]/[0716]	Speed: 25.579092 samples/sec	 accuracy=56.517857	 loss=1.796239	 lr=0.179554
Epoch[136] Batch [0249]/[0716]	Speed: 26.084120 samples/sec	 accuracy=56.535714	 loss=1.796785	 lr=0.179182
Epoch[136] Batch [0299]/[0716]	Speed: 26.136917 samples/sec	 accuracy=56.339286	 loss=1.804688	 lr=0.178811
Epoch[136] Batch [0349]/[0716]	Speed: 26.323328 samples/sec	 accuracy=56.403061	 loss=1.811151	 lr=0.178439
Epoch[136] Batch [0399]/[0716]	Speed: 26.021724 samples/sec	 accuracy=56.450893	 loss=1.815655	 lr=0.178068
Epoch[136] Batch [0449]/[0716]	Speed: 25.981573 samples/sec	 accuracy=56.369048	 loss=1.817480	 lr=0.177697
Epoch[136] Batch [0499]/[0716]	Speed: 26.390871 samples/sec	 accuracy=56.521429	 loss=1.811483	 lr=0.177326
Epoch[136] Batch [0549]/[0716]	Speed: 26.398206 samples/sec	 accuracy=56.474026	 loss=1.811873	 lr=0.176955
Epoch[136] Batch [0599]/[0716]	Speed: 25.995207 samples/sec	 accuracy=56.440476	 loss=1.817723	 lr=0.176585
Epoch[136] Batch [0649]/[0716]	Speed: 26.201441 samples/sec	 accuracy=56.417582	 loss=1.818298	 lr=0.176215
Epoch[136] Batch [0699]/[0716]	Speed: 26.093950 samples/sec	 accuracy=56.331633	 loss=1.822006	 lr=0.175845
Batch [0049]/[0057]: acc-top1=55.071429 acc-top5=78.714286
[Epoch 136] training: accuracy=56.314844	 loss=1.821363
[Epoch 136] speed: 26 samples/sec	time cost: 1599.373784
[Epoch 136] validation: acc-top1=54.782791 acc-top5=78.963020 loss=2.194348
Epoch[137] Batch [0049]/[0716]	Speed: 23.288088 samples/sec	 accuracy=57.392857	 loss=1.773130	 lr=0.175357
Epoch[137] Batch [0099]/[0716]	Speed: 26.005348 samples/sec	 accuracy=56.571429	 loss=1.798391	 lr=0.174987
Epoch[137] Batch [0149]/[0716]	Speed: 25.916174 samples/sec	 accuracy=56.892857	 loss=1.790983	 lr=0.174618
Epoch[137] Batch [0199]/[0716]	Speed: 25.989908 samples/sec	 accuracy=56.848214	 loss=1.806099	 lr=0.174249
Epoch[137] Batch [0249]/[0716]	Speed: 26.201569 samples/sec	 accuracy=56.978571	 loss=1.799087	 lr=0.173880
Epoch[137] Batch [0299]/[0716]	Speed: 25.744376 samples/sec	 accuracy=57.154762	 loss=1.796486	 lr=0.173512
Epoch[137] Batch [0349]/[0716]	Speed: 25.973769 samples/sec	 accuracy=56.760204	 loss=1.809936	 lr=0.173144
Epoch[137] Batch [0399]/[0716]	Speed: 25.916858 samples/sec	 accuracy=56.821429	 loss=1.808279	 lr=0.172775
Epoch[137] Batch [0449]/[0716]	Speed: 25.783260 samples/sec	 accuracy=56.765873	 loss=1.810021	 lr=0.172408
Epoch[137] Batch [0499]/[0716]	Speed: 25.769409 samples/sec	 accuracy=56.746429	 loss=1.812548	 lr=0.172040
Epoch[137] Batch [0549]/[0716]	Speed: 25.915509 samples/sec	 accuracy=56.766234	 loss=1.812101	 lr=0.171673
Epoch[137] Batch [0599]/[0716]	Speed: 25.449017 samples/sec	 accuracy=57.008929	 loss=1.799822	 lr=0.171306
Epoch[137] Batch [0649]/[0716]	Speed: 25.998328 samples/sec	 accuracy=56.947802	 loss=1.802676	 lr=0.170939
Epoch[137] Batch [0699]/[0716]	Speed: 25.904995 samples/sec	 accuracy=56.933673	 loss=1.806134	 lr=0.170572
Batch [0049]/[0057]: acc-top1=55.857143 acc-top5=79.464286
[Epoch 137] training: accuracy=56.856045	 loss=1.807872
[Epoch 137] speed: 25 samples/sec	time cost: 1613.107699
[Epoch 137] validation: acc-top1=54.850666 acc-top5=79.349419 loss=2.243663
Epoch[138] Batch [0049]/[0716]	Speed: 23.029916 samples/sec	 accuracy=57.500000	 loss=1.760058	 lr=0.170089
Epoch[138] Batch [0099]/[0716]	Speed: 26.030702 samples/sec	 accuracy=57.553571	 loss=1.754579	 lr=0.169722
Epoch[138] Batch [0149]/[0716]	Speed: 26.270498 samples/sec	 accuracy=57.892857	 loss=1.737122	 lr=0.169357
Epoch[138] Batch [0199]/[0716]	Speed: 26.186148 samples/sec	 accuracy=57.607143	 loss=1.758625	 lr=0.168991
Epoch[138] Batch [0249]/[0716]	Speed: 26.283745 samples/sec	 accuracy=57.571429	 loss=1.763400	 lr=0.168626
Epoch[138] Batch [0299]/[0716]	Speed: 25.742724 samples/sec	 accuracy=57.535714	 loss=1.763076	 lr=0.168261
Epoch[138] Batch [0349]/[0716]	Speed: 26.286942 samples/sec	 accuracy=57.505102	 loss=1.767577	 lr=0.167896
Epoch[138] Batch [0399]/[0716]	Speed: 26.064374 samples/sec	 accuracy=57.401786	 loss=1.773028	 lr=0.167531
Epoch[138] Batch [0449]/[0716]	Speed: 25.529319 samples/sec	 accuracy=57.329365	 loss=1.773316	 lr=0.167167
Epoch[138] Batch [0499]/[0716]	Speed: 26.291271 samples/sec	 accuracy=57.242857	 loss=1.775380	 lr=0.166802
Epoch[138] Batch [0549]/[0716]	Speed: 26.127777 samples/sec	 accuracy=57.175325	 loss=1.781399	 lr=0.166439
Epoch[138] Batch [0599]/[0716]	Speed: 26.279371 samples/sec	 accuracy=57.080357	 loss=1.782258	 lr=0.166075
Epoch[138] Batch [0649]/[0716]	Speed: 25.904204 samples/sec	 accuracy=57.000000	 loss=1.788161	 lr=0.165711
Epoch[138] Batch [0699]/[0716]	Speed: 26.225721 samples/sec	 accuracy=56.910714	 loss=1.789855	 lr=0.165348
Batch [0049]/[0057]: acc-top1=55.750000 acc-top5=80.178571
[Epoch 138] training: accuracy=56.898444	 loss=1.791240
[Epoch 138] speed: 26 samples/sec	time cost: 1600.584702
[Epoch 138] validation: acc-top1=55.357147 acc-top5=79.579163 loss=2.097714
Epoch[139] Batch [0049]/[0716]	Speed: 23.482821 samples/sec	 accuracy=57.785714	 loss=1.753735	 lr=0.164869
Epoch[139] Batch [0099]/[0716]	Speed: 26.021918 samples/sec	 accuracy=57.767857	 loss=1.744990	 lr=0.164507
Epoch[139] Batch [0149]/[0716]	Speed: 26.176457 samples/sec	 accuracy=57.821429	 loss=1.749972	 lr=0.164144
Epoch[139] Batch [0199]/[0716]	Speed: 25.924143 samples/sec	 accuracy=58.294643	 loss=1.734031	 lr=0.163782
Epoch[139] Batch [0249]/[0716]	Speed: 25.715323 samples/sec	 accuracy=58.335714	 loss=1.731629	 lr=0.163420
Epoch[139] Batch [0299]/[0716]	Speed: 26.201653 samples/sec	 accuracy=58.279762	 loss=1.730702	 lr=0.163059
Epoch[139] Batch [0349]/[0716]	Speed: 26.110166 samples/sec	 accuracy=58.193878	 loss=1.745696	 lr=0.162697
Epoch[139] Batch [0399]/[0716]	Speed: 25.915423 samples/sec	 accuracy=57.977679	 loss=1.752920	 lr=0.162336
Epoch[139] Batch [0449]/[0716]	Speed: 26.324047 samples/sec	 accuracy=57.797619	 loss=1.764534	 lr=0.161975
Epoch[139] Batch [0499]/[0716]	Speed: 25.819982 samples/sec	 accuracy=57.725000	 loss=1.766287	 lr=0.161615
Epoch[139] Batch [0549]/[0716]	Speed: 26.162517 samples/sec	 accuracy=57.642857	 loss=1.765627	 lr=0.161255
Epoch[139] Batch [0599]/[0716]	Speed: 26.414165 samples/sec	 accuracy=57.681548	 loss=1.767443	 lr=0.160894
Epoch[139] Batch [0649]/[0716]	Speed: 26.480556 samples/sec	 accuracy=57.780220	 loss=1.764826	 lr=0.160535
Epoch[139] Batch [0699]/[0716]	Speed: 26.004417 samples/sec	 accuracy=57.724490	 loss=1.767916	 lr=0.160175
Batch [0049]/[0057]: acc-top1=53.571429 acc-top5=78.142857
[Epoch 139] training: accuracy=57.684058	 loss=1.768494
[Epoch 139] speed: 26 samples/sec	time cost: 1600.880159
[Epoch 139] validation: acc-top1=54.725353 acc-top5=79.297203 loss=2.098644
Epoch[140] Batch [0049]/[0716]	Speed: 23.164992 samples/sec	 accuracy=58.857143	 loss=1.737894	 lr=0.159701
Epoch[140] Batch [0099]/[0716]	Speed: 26.092565 samples/sec	 accuracy=58.607143	 loss=1.713796	 lr=0.159342
Epoch[140] Batch [0149]/[0716]	Speed: 25.773692 samples/sec	 accuracy=58.416667	 loss=1.722940	 lr=0.158983
Epoch[140] Batch [0199]/[0716]	Speed: 25.856212 samples/sec	 accuracy=58.205357	 loss=1.737876	 lr=0.158625
Epoch[140] Batch [0249]/[0716]	Speed: 25.875809 samples/sec	 accuracy=58.328571	 loss=1.741276	 lr=0.158266
Epoch[140] Batch [0299]/[0716]	Speed: 26.078076 samples/sec	 accuracy=58.470238	 loss=1.738421	 lr=0.157909
Epoch[140] Batch [0349]/[0716]	Speed: 25.808431 samples/sec	 accuracy=58.153061	 loss=1.746493	 lr=0.157551
Epoch[140] Batch [0399]/[0716]	Speed: 25.857677 samples/sec	 accuracy=58.223214	 loss=1.741126	 lr=0.157193
Epoch[140] Batch [0449]/[0716]	Speed: 26.420128 samples/sec	 accuracy=58.150794	 loss=1.745814	 lr=0.156836
Epoch[140] Batch [0499]/[0716]	Speed: 25.983716 samples/sec	 accuracy=57.925000	 loss=1.756793	 lr=0.156479
Epoch[140] Batch [0549]/[0716]	Speed: 25.461363 samples/sec	 accuracy=57.938312	 loss=1.752784	 lr=0.156123
Epoch[140] Batch [0599]/[0716]	Speed: 25.528122 samples/sec	 accuracy=57.955357	 loss=1.753520	 lr=0.155766
Epoch[140] Batch [0649]/[0716]	Speed: 26.324525 samples/sec	 accuracy=57.947802	 loss=1.754628	 lr=0.155410
Epoch[140] Batch [0699]/[0716]	Speed: 26.258901 samples/sec	 accuracy=57.816327	 loss=1.759279	 lr=0.155054
Batch [0049]/[0057]: acc-top1=56.250000 acc-top5=79.214286
[Epoch 140] training: accuracy=57.851157	 loss=1.758308
[Epoch 140] speed: 25 samples/sec	time cost: 1609.203290
[Epoch 140] validation: acc-top1=55.263161 acc-top5=79.156227 loss=2.107921
Epoch[141] Batch [0049]/[0716]	Speed: 23.291537 samples/sec	 accuracy=58.321429	 loss=1.721211	 lr=0.154585
Epoch[141] Batch [0099]/[0716]	Speed: 25.711055 samples/sec	 accuracy=58.482143	 loss=1.727772	 lr=0.154230
Epoch[141] Batch [0149]/[0716]	Speed: 25.969176 samples/sec	 accuracy=58.250000	 loss=1.735589	 lr=0.153875
Epoch[141] Batch [0199]/[0716]	Speed: 26.349219 samples/sec	 accuracy=58.187500	 loss=1.746518	 lr=0.153520
Epoch[141] Batch [0249]/[0716]	Speed: 26.322719 samples/sec	 accuracy=58.100000	 loss=1.739937	 lr=0.153166
Epoch[141] Batch [0299]/[0716]	Speed: 26.307406 samples/sec	 accuracy=57.869048	 loss=1.744407	 lr=0.152812
Epoch[141] Batch [0349]/[0716]	Speed: 26.387105 samples/sec	 accuracy=57.943878	 loss=1.741998	 lr=0.152458
Epoch[141] Batch [0399]/[0716]	Speed: 26.189843 samples/sec	 accuracy=57.888393	 loss=1.747268	 lr=0.152104
Epoch[141] Batch [0449]/[0716]	Speed: 25.934998 samples/sec	 accuracy=57.817460	 loss=1.747770	 lr=0.151751
Epoch[141] Batch [0499]/[0716]	Speed: 25.982367 samples/sec	 accuracy=57.875000	 loss=1.749248	 lr=0.151398
Epoch[141] Batch [0549]/[0716]	Speed: 26.318645 samples/sec	 accuracy=57.870130	 loss=1.748324	 lr=0.151045
Epoch[141] Batch [0599]/[0716]	Speed: 26.270721 samples/sec	 accuracy=57.955357	 loss=1.744333	 lr=0.150692
Epoch[141] Batch [0649]/[0716]	Speed: 26.096087 samples/sec	 accuracy=57.961538	 loss=1.745075	 lr=0.150340
Epoch[141] Batch [0699]/[0716]	Speed: 26.146070 samples/sec	 accuracy=57.892857	 loss=1.748865	 lr=0.149988
Batch [0049]/[0057]: acc-top1=55.321429 acc-top5=80.571429
[Epoch 141] training: accuracy=57.911014	 loss=1.745998
[Epoch 141] speed: 26 samples/sec	time cost: 1598.914586
[Epoch 141] validation: acc-top1=55.555557 acc-top5=80.116959 loss=2.058811
Epoch[142] Batch [0049]/[0716]	Speed: 23.454176 samples/sec	 accuracy=58.000000	 loss=1.742108	 lr=0.149524
Epoch[142] Batch [0099]/[0716]	Speed: 25.862995 samples/sec	 accuracy=57.589286	 loss=1.752736	 lr=0.149173
Epoch[142] Batch [0149]/[0716]	Speed: 25.945285 samples/sec	 accuracy=58.214286	 loss=1.733848	 lr=0.148822
Epoch[142] Batch [0199]/[0716]	Speed: 26.307974 samples/sec	 accuracy=57.973214	 loss=1.744380	 lr=0.148471
Epoch[142] Batch [0249]/[0716]	Speed: 25.982680 samples/sec	 accuracy=58.178571	 loss=1.735374	 lr=0.148120
Epoch[142] Batch [0299]/[0716]	Speed: 25.945323 samples/sec	 accuracy=58.369048	 loss=1.728427	 lr=0.147770
Epoch[142] Batch [0349]/[0716]	Speed: 26.202834 samples/sec	 accuracy=58.346939	 loss=1.724254	 lr=0.147420
Epoch[142] Batch [0399]/[0716]	Speed: 25.780543 samples/sec	 accuracy=58.366071	 loss=1.724397	 lr=0.147071
Epoch[142] Batch [0449]/[0716]	Speed: 26.283966 samples/sec	 accuracy=58.337302	 loss=1.728363	 lr=0.146721
Epoch[142] Batch [0499]/[0716]	Speed: 26.186466 samples/sec	 accuracy=58.310714	 loss=1.722018	 lr=0.146372
Epoch[142] Batch [0549]/[0716]	Speed: 25.993483 samples/sec	 accuracy=58.126623	 loss=1.729135	 lr=0.146023
Epoch[142] Batch [0599]/[0716]	Speed: 25.826364 samples/sec	 accuracy=58.080357	 loss=1.735141	 lr=0.145675
Epoch[142] Batch [0649]/[0716]	Speed: 25.757350 samples/sec	 accuracy=58.068681	 loss=1.737963	 lr=0.145327
Epoch[142] Batch [0699]/[0716]	Speed: 26.173385 samples/sec	 accuracy=58.130102	 loss=1.734961	 lr=0.144979
Batch [0049]/[0057]: acc-top1=56.714286 acc-top5=81.178571
[Epoch 142] training: accuracy=58.170391	 loss=1.734324
[Epoch 142] speed: 25 samples/sec	time cost: 1604.290571
[Epoch 142] validation: acc-top1=55.806183 acc-top5=80.033417 loss=2.148709
Epoch[143] Batch [0049]/[0717]	Speed: 23.256988 samples/sec	 accuracy=59.892857	 loss=1.667155	 lr=0.144520
Epoch[143] Batch [0099]/[0717]	Speed: 25.781386 samples/sec	 accuracy=59.857143	 loss=1.654332	 lr=0.144172
Epoch[143] Batch [0149]/[0717]	Speed: 26.313034 samples/sec	 accuracy=59.261905	 loss=1.674931	 lr=0.143825
Epoch[143] Batch [0199]/[0717]	Speed: 25.698423 samples/sec	 accuracy=59.339286	 loss=1.674144	 lr=0.143479
Epoch[143] Batch [0249]/[0717]	Speed: 26.160387 samples/sec	 accuracy=59.628571	 loss=1.668592	 lr=0.143132
Epoch[143] Batch [0299]/[0717]	Speed: 25.991899 samples/sec	 accuracy=59.351190	 loss=1.679329	 lr=0.142786
Epoch[143] Batch [0349]/[0717]	Speed: 26.266653 samples/sec	 accuracy=58.954082	 loss=1.699347	 lr=0.142440
Epoch[143] Batch [0399]/[0717]	Speed: 26.315252 samples/sec	 accuracy=59.044643	 loss=1.698913	 lr=0.142095
Epoch[143] Batch [0449]/[0717]	Speed: 26.288476 samples/sec	 accuracy=58.992063	 loss=1.697647	 lr=0.141749
Epoch[143] Batch [0499]/[0717]	Speed: 25.945498 samples/sec	 accuracy=58.839286	 loss=1.697115	 lr=0.141404
Epoch[143] Batch [0549]/[0717]	Speed: 26.319629 samples/sec	 accuracy=58.707792	 loss=1.704064	 lr=0.141060
Epoch[143] Batch [0599]/[0717]	Speed: 26.211209 samples/sec	 accuracy=58.717262	 loss=1.705374	 lr=0.140715
Epoch[143] Batch [0649]/[0717]	Speed: 26.162862 samples/sec	 accuracy=58.752747	 loss=1.701595	 lr=0.140371
Epoch[143] Batch [0699]/[0717]	Speed: 26.258688 samples/sec	 accuracy=58.813776	 loss=1.702246	 lr=0.140027
Batch [0049]/[0057]: acc-top1=57.892857 acc-top5=81.785714
[Epoch 143] training: accuracy=58.736800	 loss=1.705881
[Epoch 143] speed: 26 samples/sec	time cost: 1601.752241
[Epoch 143] validation: acc-top1=57.059311 acc-top5=80.905388 loss=2.061232
Epoch[144] Batch [0049]/[0716]	Speed: 22.888015 samples/sec	 accuracy=60.357143	 loss=1.644247	 lr=0.139567
Epoch[144] Batch [0099]/[0716]	Speed: 26.255169 samples/sec	 accuracy=59.428571	 loss=1.672273	 lr=0.139224
Epoch[144] Batch [0149]/[0716]	Speed: 26.294361 samples/sec	 accuracy=58.845238	 loss=1.700942	 lr=0.138881
Epoch[144] Batch [0199]/[0716]	Speed: 26.044433 samples/sec	 accuracy=58.607143	 loss=1.722841	 lr=0.138538
Epoch[144] Batch [0249]/[0716]	Speed: 26.077413 samples/sec	 accuracy=58.428571	 loss=1.727945	 lr=0.138196
Epoch[144] Batch [0299]/[0716]	Speed: 26.049258 samples/sec	 accuracy=58.726190	 loss=1.718530	 lr=0.137854
Epoch[144] Batch [0349]/[0716]	Speed: 26.360128 samples/sec	 accuracy=58.734694	 loss=1.725072	 lr=0.137512
Epoch[144] Batch [0399]/[0716]	Speed: 26.098252 samples/sec	 accuracy=58.852679	 loss=1.717129	 lr=0.137171
Epoch[144] Batch [0449]/[0716]	Speed: 26.151567 samples/sec	 accuracy=58.960317	 loss=1.712765	 lr=0.136830
Epoch[144] Batch [0499]/[0716]	Speed: 26.095053 samples/sec	 accuracy=58.982143	 loss=1.714322	 lr=0.136489
Epoch[144] Batch [0549]/[0716]	Speed: 26.251953 samples/sec	 accuracy=58.941558	 loss=1.714938	 lr=0.136149
Epoch[144] Batch [0599]/[0716]	Speed: 25.958132 samples/sec	 accuracy=59.014881	 loss=1.712417	 lr=0.135809
Epoch[144] Batch [0649]/[0716]	Speed: 26.086101 samples/sec	 accuracy=58.903846	 loss=1.712611	 lr=0.135469
Epoch[144] Batch [0699]/[0716]	Speed: 26.386121 samples/sec	 accuracy=58.826531	 loss=1.714022	 lr=0.135129
Batch [0049]/[0057]: acc-top1=57.678571 acc-top5=81.321429
[Epoch 144] training: accuracy=58.861233	 loss=1.714947
[Epoch 144] speed: 26 samples/sec	time cost: 1600.300980
[Epoch 144] validation: acc-top1=57.325600 acc-top5=80.936722 loss=1.985472
Epoch[145] Batch [0049]/[0716]	Speed: 23.051969 samples/sec	 accuracy=59.571429	 loss=1.657805	 lr=0.134681
Epoch[145] Batch [0099]/[0716]	Speed: 25.739765 samples/sec	 accuracy=59.928571	 loss=1.664806	 lr=0.134342
Epoch[145] Batch [0149]/[0716]	Speed: 25.749456 samples/sec	 accuracy=59.880952	 loss=1.669006	 lr=0.134004
Epoch[145] Batch [0199]/[0716]	Speed: 26.415639 samples/sec	 accuracy=59.580357	 loss=1.672979	 lr=0.133666
Epoch[145] Batch [0249]/[0716]	Speed: 26.001888 samples/sec	 accuracy=59.557143	 loss=1.687842	 lr=0.133328
Epoch[145] Batch [0299]/[0716]	Speed: 25.849389 samples/sec	 accuracy=59.315476	 loss=1.690989	 lr=0.132990
Epoch[145] Batch [0349]/[0716]	Speed: 26.235968 samples/sec	 accuracy=59.295918	 loss=1.687560	 lr=0.132653
Epoch[145] Batch [0399]/[0716]	Speed: 26.067429 samples/sec	 accuracy=59.205357	 loss=1.690112	 lr=0.132316
Epoch[145] Batch [0449]/[0716]	Speed: 26.202869 samples/sec	 accuracy=59.428571	 loss=1.684311	 lr=0.131979
Epoch[145] Batch [0499]/[0716]	Speed: 25.950236 samples/sec	 accuracy=59.375000	 loss=1.685186	 lr=0.131642
Epoch[145] Batch [0549]/[0716]	Speed: 26.340752 samples/sec	 accuracy=59.269481	 loss=1.688084	 lr=0.131306
Epoch[145] Batch [0599]/[0716]	Speed: 25.938761 samples/sec	 accuracy=59.252976	 loss=1.694190	 lr=0.130971
Epoch[145] Batch [0649]/[0716]	Speed: 25.664451 samples/sec	 accuracy=59.206044	 loss=1.696795	 lr=0.130635
Epoch[145] Batch [0699]/[0716]	Speed: 25.723426 samples/sec	 accuracy=59.232143	 loss=1.695831	 lr=0.130300
Batch [0049]/[0057]: acc-top1=55.821429 acc-top5=80.750000
[Epoch 145] training: accuracy=59.225359	 loss=1.695280
[Epoch 145] speed: 25 samples/sec	time cost: 1606.277691
[Epoch 145] validation: acc-top1=56.725143 acc-top5=80.675652 loss=2.144149
Epoch[146] Batch [0049]/[0716]	Speed: 23.190926 samples/sec	 accuracy=61.464286	 loss=1.632392	 lr=0.129858
Epoch[146] Batch [0099]/[0716]	Speed: 26.233024 samples/sec	 accuracy=60.642857	 loss=1.640585	 lr=0.129523
Epoch[146] Batch [0149]/[0716]	Speed: 26.025876 samples/sec	 accuracy=60.369048	 loss=1.651815	 lr=0.129189
Epoch[146] Batch [0199]/[0716]	Speed: 26.090123 samples/sec	 accuracy=60.223214	 loss=1.647289	 lr=0.128856
Epoch[146] Batch [0249]/[0716]	Speed: 25.607764 samples/sec	 accuracy=60.078571	 loss=1.653674	 lr=0.128522
Epoch[146] Batch [0299]/[0716]	Speed: 26.347100 samples/sec	 accuracy=59.958333	 loss=1.658165	 lr=0.128189
Epoch[146] Batch [0349]/[0716]	Speed: 26.063771 samples/sec	 accuracy=59.811224	 loss=1.667599	 lr=0.127856
Epoch[146] Batch [0399]/[0716]	Speed: 25.867475 samples/sec	 accuracy=60.017857	 loss=1.663363	 lr=0.127523
Epoch[146] Batch [0449]/[0716]	Speed: 25.680036 samples/sec	 accuracy=60.099206	 loss=1.656567	 lr=0.127191
Epoch[146] Batch [0499]/[0716]	Speed: 25.998805 samples/sec	 accuracy=59.985714	 loss=1.663109	 lr=0.126859
Epoch[146] Batch [0549]/[0716]	Speed: 26.049118 samples/sec	 accuracy=59.837662	 loss=1.670278	 lr=0.126528
Epoch[146] Batch [0599]/[0716]	Speed: 26.347314 samples/sec	 accuracy=59.919643	 loss=1.666204	 lr=0.126196
Epoch[146] Batch [0649]/[0716]	Speed: 25.574864 samples/sec	 accuracy=59.862637	 loss=1.667496	 lr=0.125865
Epoch[146] Batch [0699]/[0716]	Speed: 25.508821 samples/sec	 accuracy=59.859694	 loss=1.669930	 lr=0.125535
Batch [0049]/[0057]: acc-top1=57.107143 acc-top5=79.857143
[Epoch 146] training: accuracy=59.826417	 loss=1.671864
[Epoch 146] speed: 25 samples/sec	time cost: 1609.327133
[Epoch 146] validation: acc-top1=57.550121 acc-top5=81.119461 loss=2.034708
Epoch[147] Batch [0049]/[0716]	Speed: 23.113629 samples/sec	 accuracy=60.464286	 loss=1.660534	 lr=0.125099
Epoch[147] Batch [0099]/[0716]	Speed: 26.528261 samples/sec	 accuracy=60.553571	 loss=1.643535	 lr=0.124769
Epoch[147] Batch [0149]/[0716]	Speed: 26.073340 samples/sec	 accuracy=60.404762	 loss=1.651764	 lr=0.124439
Epoch[147] Batch [0199]/[0716]	Speed: 26.181057 samples/sec	 accuracy=60.294643	 loss=1.656580	 lr=0.124110
Epoch[147] Batch [0249]/[0716]	Speed: 26.054264 samples/sec	 accuracy=60.142857	 loss=1.659886	 lr=0.123781
Epoch[147] Batch [0299]/[0716]	Speed: 25.857109 samples/sec	 accuracy=60.166667	 loss=1.657359	 lr=0.123452
Epoch[147] Batch [0349]/[0716]	Speed: 25.896989 samples/sec	 accuracy=59.984694	 loss=1.658703	 lr=0.123124
Epoch[147] Batch [0399]/[0716]	Speed: 26.256625 samples/sec	 accuracy=59.888393	 loss=1.664077	 lr=0.122796
Epoch[147] Batch [0449]/[0716]	Speed: 25.956406 samples/sec	 accuracy=60.055556	 loss=1.661642	 lr=0.122468
Epoch[147] Batch [0499]/[0716]	Speed: 26.257602 samples/sec	 accuracy=59.957143	 loss=1.664538	 lr=0.122141
Epoch[147] Batch [0549]/[0716]	Speed: 26.028877 samples/sec	 accuracy=59.853896	 loss=1.667007	 lr=0.121814
Epoch[147] Batch [0599]/[0716]	Speed: 25.268693 samples/sec	 accuracy=59.815476	 loss=1.668116	 lr=0.121487
Epoch[147] Batch [0649]/[0716]	Speed: 26.401872 samples/sec	 accuracy=59.884615	 loss=1.662979	 lr=0.121161
Epoch[147] Batch [0699]/[0716]	Speed: 26.149873 samples/sec	 accuracy=59.839286	 loss=1.662753	 lr=0.120835
Batch [0049]/[0057]: acc-top1=57.000000 acc-top5=80.750000
[Epoch 147] training: accuracy=59.843875	 loss=1.661579
[Epoch 147] speed: 26 samples/sec	time cost: 1602.241425
[Epoch 147] validation: acc-top1=57.174183 acc-top5=80.769638 loss=2.032716
Epoch[148] Batch [0049]/[0716]	Speed: 22.997010 samples/sec	 accuracy=59.571429	 loss=1.648094	 lr=0.120405
Epoch[148] Batch [0099]/[0716]	Speed: 26.371513 samples/sec	 accuracy=59.464286	 loss=1.659399	 lr=0.120080
Epoch[148] Batch [0149]/[0716]	Speed: 26.096484 samples/sec	 accuracy=60.071429	 loss=1.655994	 lr=0.119755
Epoch[148] Batch [0199]/[0716]	Speed: 25.772120 samples/sec	 accuracy=60.875000	 loss=1.627246	 lr=0.119430
Epoch[148] Batch [0249]/[0716]	Speed: 26.360089 samples/sec	 accuracy=60.800000	 loss=1.630410	 lr=0.119106
Epoch[148] Batch [0299]/[0716]	Speed: 25.748601 samples/sec	 accuracy=61.035714	 loss=1.617404	 lr=0.118782
Epoch[148] Batch [0349]/[0716]	Speed: 26.026237 samples/sec	 accuracy=61.015306	 loss=1.614647	 lr=0.118458
Epoch[148] Batch [0399]/[0716]	Speed: 26.255443 samples/sec	 accuracy=60.924107	 loss=1.616224	 lr=0.118135
Epoch[148] Batch [0449]/[0716]	Speed: 26.293213 samples/sec	 accuracy=60.833333	 loss=1.612924	 lr=0.117812
Epoch[148] Batch [0499]/[0716]	Speed: 26.790591 samples/sec	 accuracy=60.560714	 loss=1.625215	 lr=0.117490
Epoch[148] Batch [0549]/[0716]	Speed: 25.600851 samples/sec	 accuracy=60.379870	 loss=1.633360	 lr=0.117167
Epoch[148] Batch [0599]/[0716]	Speed: 26.222487 samples/sec	 accuracy=60.113095	 loss=1.643993	 lr=0.116845
Epoch[148] Batch [0649]/[0716]	Speed: 25.997490 samples/sec	 accuracy=60.115385	 loss=1.647926	 lr=0.116524
Epoch[148] Batch [0699]/[0716]	Speed: 25.775693 samples/sec	 accuracy=60.204082	 loss=1.644917	 lr=0.116202
Batch [0049]/[0057]: acc-top1=55.571429 acc-top5=80.785714
[Epoch 148] training: accuracy=60.193037	 loss=1.645199
[Epoch 148] speed: 26 samples/sec	time cost: 1601.832743
[Epoch 148] validation: acc-top1=56.850456 acc-top5=80.513779 loss=2.124585
Epoch[149] Batch [0049]/[0716]	Speed: 23.088119 samples/sec	 accuracy=62.321429	 loss=1.549100	 lr=0.115779
Epoch[149] Batch [0099]/[0716]	Speed: 26.274375 samples/sec	 accuracy=62.053571	 loss=1.563403	 lr=0.115458
Epoch[149] Batch [0149]/[0716]	Speed: 25.678762 samples/sec	 accuracy=61.630952	 loss=1.572230	 lr=0.115138
Epoch[149] Batch [0199]/[0716]	Speed: 26.289245 samples/sec	 accuracy=61.464286	 loss=1.568391	 lr=0.114818
Epoch[149] Batch [0249]/[0716]	Speed: 26.368746 samples/sec	 accuracy=61.385714	 loss=1.578520	 lr=0.114499
Epoch[149] Batch [0299]/[0716]	Speed: 26.032727 samples/sec	 accuracy=61.339286	 loss=1.587324	 lr=0.114180
Epoch[149] Batch [0349]/[0716]	Speed: 26.319952 samples/sec	 accuracy=61.377551	 loss=1.582426	 lr=0.113861
Epoch[149] Batch [0399]/[0716]	Speed: 26.319843 samples/sec	 accuracy=61.316964	 loss=1.580836	 lr=0.113543
Epoch[149] Batch [0449]/[0716]	Speed: 25.496950 samples/sec	 accuracy=61.297619	 loss=1.581191	 lr=0.113225
Epoch[149] Batch [0499]/[0716]	Speed: 25.877069 samples/sec	 accuracy=61.328571	 loss=1.581988	 lr=0.112907
Epoch[149] Batch [0549]/[0716]	Speed: 25.918674 samples/sec	 accuracy=61.376623	 loss=1.581252	 lr=0.112589
Epoch[149] Batch [0599]/[0716]	Speed: 25.648089 samples/sec	 accuracy=61.330357	 loss=1.583148	 lr=0.112272
Epoch[149] Batch [0649]/[0716]	Speed: 26.062174 samples/sec	 accuracy=61.230769	 loss=1.586185	 lr=0.111956
Epoch[149] Batch [0699]/[0716]	Speed: 26.126121 samples/sec	 accuracy=61.206633	 loss=1.586277	 lr=0.111639
Batch [0049]/[0057]: acc-top1=59.071429 acc-top5=81.607143
[Epoch 149] training: accuracy=61.210595	 loss=1.586248
[Epoch 149] speed: 25 samples/sec	time cost: 1606.946788
[Epoch 149] validation: acc-top1=58.610065 acc-top5=81.845245 loss=1.938214
Epoch[150] Batch [0049]/[0716]	Speed: 22.895453 samples/sec	 accuracy=60.964286	 loss=1.583975	 lr=0.111222
Epoch[150] Batch [0099]/[0716]	Speed: 26.287372 samples/sec	 accuracy=61.535714	 loss=1.578227	 lr=0.110907
Epoch[150] Batch [0149]/[0716]	Speed: 25.997563 samples/sec	 accuracy=61.333333	 loss=1.587344	 lr=0.110591
Epoch[150] Batch [0199]/[0716]	Speed: 26.219337 samples/sec	 accuracy=61.348214	 loss=1.588487	 lr=0.110276
Epoch[150] Batch [0249]/[0716]	Speed: 26.322137 samples/sec	 accuracy=61.785714	 loss=1.580724	 lr=0.109962
Epoch[150] Batch [0299]/[0716]	Speed: 25.949365 samples/sec	 accuracy=61.732143	 loss=1.590531	 lr=0.109648
Epoch[150] Batch [0349]/[0716]	Speed: 25.941728 samples/sec	 accuracy=61.668367	 loss=1.592219	 lr=0.109334
Epoch[150] Batch [0399]/[0716]	Speed: 26.115907 samples/sec	 accuracy=61.330357	 loss=1.601857	 lr=0.109020
Epoch[150] Batch [0449]/[0716]	Speed: 26.035375 samples/sec	 accuracy=61.158730	 loss=1.605386	 lr=0.108707
Epoch[150] Batch [0499]/[0716]	Speed: 25.749304 samples/sec	 accuracy=61.042857	 loss=1.609150	 lr=0.108394
Epoch[150] Batch [0549]/[0716]	Speed: 25.816579 samples/sec	 accuracy=61.035714	 loss=1.605967	 lr=0.108082
Epoch[150] Batch [0599]/[0716]	Speed: 26.130813 samples/sec	 accuracy=61.095238	 loss=1.604796	 lr=0.107770
Epoch[150] Batch [0649]/[0716]	Speed: 26.277990 samples/sec	 accuracy=61.074176	 loss=1.605933	 lr=0.107458
Epoch[150] Batch [0699]/[0716]	Speed: 26.230721 samples/sec	 accuracy=61.102041	 loss=1.603803	 lr=0.107147
Batch [0049]/[0057]: acc-top1=58.000000 acc-top5=81.500000
[Epoch 150] training: accuracy=61.053472	 loss=1.604957
[Epoch 150] speed: 26 samples/sec	time cost: 1603.309336
[Epoch 150] validation: acc-top1=58.965122 acc-top5=82.184631 loss=1.959241
Epoch[151] Batch [0049]/[0717]	Speed: 22.942653 samples/sec	 accuracy=62.928571	 loss=1.522884	 lr=0.106736
Epoch[151] Batch [0099]/[0717]	Speed: 25.866319 samples/sec	 accuracy=62.464286	 loss=1.535916	 lr=0.106426
Epoch[151] Batch [0149]/[0717]	Speed: 26.095730 samples/sec	 accuracy=62.738095	 loss=1.535478	 lr=0.106116
Epoch[151] Batch [0199]/[0717]	Speed: 26.061485 samples/sec	 accuracy=62.794643	 loss=1.539003	 lr=0.105806
Epoch[151] Batch [0249]/[0717]	Speed: 25.959848 samples/sec	 accuracy=62.492857	 loss=1.549603	 lr=0.105496
Epoch[151] Batch [0299]/[0717]	Speed: 26.246686 samples/sec	 accuracy=62.345238	 loss=1.555253	 lr=0.105187
Epoch[151] Batch [0349]/[0717]	Speed: 26.038975 samples/sec	 accuracy=62.214286	 loss=1.559304	 lr=0.104878
Epoch[151] Batch [0399]/[0717]	Speed: 26.174106 samples/sec	 accuracy=62.120536	 loss=1.564272	 lr=0.104570
Epoch[151] Batch [0449]/[0717]	Speed: 26.341068 samples/sec	 accuracy=62.003968	 loss=1.567983	 lr=0.104262
Epoch[151] Batch [0499]/[0717]	Speed: 26.109269 samples/sec	 accuracy=61.803571	 loss=1.573536	 lr=0.103954
Epoch[151] Batch [0549]/[0717]	Speed: 26.040650 samples/sec	 accuracy=61.782468	 loss=1.572655	 lr=0.103647
Epoch[151] Batch [0599]/[0717]	Speed: 25.958293 samples/sec	 accuracy=61.741071	 loss=1.573044	 lr=0.103340
Epoch[151] Batch [0649]/[0717]	Speed: 26.206768 samples/sec	 accuracy=61.780220	 loss=1.572200	 lr=0.103033
Epoch[151] Batch [0699]/[0717]	Speed: 25.573432 samples/sec	 accuracy=61.665816	 loss=1.574783	 lr=0.102727
Batch [0049]/[0057]: acc-top1=57.142857 acc-top5=80.785714
[Epoch 151] training: accuracy=61.698047	 loss=1.575263
[Epoch 151] speed: 25 samples/sec	time cost: 1607.335438
[Epoch 151] validation: acc-top1=58.025272 acc-top5=81.558067 loss=2.058017
Epoch[152] Batch [0049]/[0716]	Speed: 22.862649 samples/sec	 accuracy=60.857143	 loss=1.565149	 lr=0.102317
Epoch[152] Batch [0099]/[0716]	Speed: 26.088948 samples/sec	 accuracy=61.053571	 loss=1.564176	 lr=0.102012
Epoch[152] Batch [0149]/[0716]	Speed: 25.959651 samples/sec	 accuracy=61.404762	 loss=1.553364	 lr=0.101707
Epoch[152] Batch [0199]/[0716]	Speed: 25.900323 samples/sec	 accuracy=61.616071	 loss=1.550664	 lr=0.101402
Epoch[152] Batch [0249]/[0716]	Speed: 25.733373 samples/sec	 accuracy=61.821429	 loss=1.553222	 lr=0.101098
Epoch[152] Batch [0299]/[0716]	Speed: 25.568486 samples/sec	 accuracy=61.732143	 loss=1.551177	 lr=0.100794
Epoch[152] Batch [0349]/[0716]	Speed: 26.295359 samples/sec	 accuracy=61.780612	 loss=1.548287	 lr=0.100490
Epoch[152] Batch [0399]/[0716]	Speed: 26.036634 samples/sec	 accuracy=61.790179	 loss=1.549056	 lr=0.100187
Epoch[152] Batch [0449]/[0716]	Speed: 25.605811 samples/sec	 accuracy=61.797619	 loss=1.555708	 lr=0.099884
Epoch[152] Batch [0499]/[0716]	Speed: 25.909358 samples/sec	 accuracy=61.914286	 loss=1.548851	 lr=0.099581
Epoch[152] Batch [0549]/[0716]	Speed: 26.404667 samples/sec	 accuracy=61.759740	 loss=1.554494	 lr=0.099279
Epoch[152] Batch [0599]/[0716]	Speed: 25.975850 samples/sec	 accuracy=61.729167	 loss=1.559013	 lr=0.098978
Epoch[152] Batch [0649]/[0716]	Speed: 26.231991 samples/sec	 accuracy=61.730769	 loss=1.562436	 lr=0.098676
Epoch[152] Batch [0699]/[0716]	Speed: 25.953714 samples/sec	 accuracy=61.742347	 loss=1.562704	 lr=0.098375
Batch [0049]/[0057]: acc-top1=59.857143 acc-top5=82.928571
[Epoch 152] training: accuracy=61.731844	 loss=1.561606
[Epoch 152] speed: 25 samples/sec	time cost: 1610.108165
[Epoch 152] validation: acc-top1=59.393280 acc-top5=82.242065 loss=1.885594
Epoch[153] Batch [0049]/[0716]	Speed: 23.051906 samples/sec	 accuracy=62.928571	 loss=1.512202	 lr=0.097978
Epoch[153] Batch [0099]/[0716]	Speed: 26.084584 samples/sec	 accuracy=62.857143	 loss=1.500112	 lr=0.097678
Epoch[153] Batch [0149]/[0716]	Speed: 26.113104 samples/sec	 accuracy=63.142857	 loss=1.492424	 lr=0.097378
Epoch[153] Batch [0199]/[0716]	Speed: 26.018331 samples/sec	 accuracy=63.035714	 loss=1.500112	 lr=0.097079
Epoch[153] Batch [0249]/[0716]	Speed: 25.671338 samples/sec	 accuracy=62.800000	 loss=1.514850	 lr=0.096780
Epoch[153] Batch [0299]/[0716]	Speed: 25.681417 samples/sec	 accuracy=62.815476	 loss=1.512977	 lr=0.096481
Epoch[153] Batch [0349]/[0716]	Speed: 25.527433 samples/sec	 accuracy=62.775510	 loss=1.516888	 lr=0.096183
Epoch[153] Batch [0399]/[0716]	Speed: 25.992368 samples/sec	 accuracy=62.808036	 loss=1.519128	 lr=0.095885
Epoch[153] Batch [0449]/[0716]	Speed: 26.187363 samples/sec	 accuracy=62.619048	 loss=1.530321	 lr=0.095588
Epoch[153] Batch [0499]/[0716]	Speed: 26.176638 samples/sec	 accuracy=62.514286	 loss=1.536593	 lr=0.095290
Epoch[153] Batch [0549]/[0716]	Speed: 25.982380 samples/sec	 accuracy=62.500000	 loss=1.538822	 lr=0.094994
Epoch[153] Batch [0599]/[0716]	Speed: 26.051919 samples/sec	 accuracy=62.497024	 loss=1.537523	 lr=0.094697
Epoch[153] Batch [0649]/[0716]	Speed: 25.910008 samples/sec	 accuracy=62.508242	 loss=1.539398	 lr=0.094401
Epoch[153] Batch [0699]/[0716]	Speed: 26.014105 samples/sec	 accuracy=62.538265	 loss=1.540597	 lr=0.094105
Batch [0049]/[0057]: acc-top1=58.857143 acc-top5=81.357143
[Epoch 153] training: accuracy=62.537410	 loss=1.541108
[Epoch 153] speed: 25 samples/sec	time cost: 1610.024583
[Epoch 153] validation: acc-top1=59.325401 acc-top5=81.892235 loss=2.026371
Epoch[154] Batch [0049]/[0716]	Speed: 23.154573 samples/sec	 accuracy=64.607143	 loss=1.430339	 lr=0.093716
Epoch[154] Batch [0099]/[0716]	Speed: 26.107755 samples/sec	 accuracy=62.875000	 loss=1.505139	 lr=0.093421
Epoch[154] Batch [0149]/[0716]	Speed: 26.316136 samples/sec	 accuracy=62.869048	 loss=1.500987	 lr=0.093126
Epoch[154] Batch [0199]/[0716]	Speed: 25.867081 samples/sec	 accuracy=62.910714	 loss=1.507730	 lr=0.092832
Epoch[154] Batch [0249]/[0716]	Speed: 26.154359 samples/sec	 accuracy=62.714286	 loss=1.520572	 lr=0.092539
Epoch[154] Batch [0299]/[0716]	Speed: 26.072378 samples/sec	 accuracy=62.946429	 loss=1.515145	 lr=0.092246
Epoch[154] Batch [0349]/[0716]	Speed: 26.320352 samples/sec	 accuracy=63.239796	 loss=1.507482	 lr=0.091953
Epoch[154] Batch [0399]/[0716]	Speed: 25.608138 samples/sec	 accuracy=63.035714	 loss=1.518556	 lr=0.091660
Epoch[154] Batch [0449]/[0716]	Speed: 25.920753 samples/sec	 accuracy=63.023810	 loss=1.519061	 lr=0.091368
Epoch[154] Batch [0499]/[0716]	Speed: 26.063208 samples/sec	 accuracy=62.964286	 loss=1.520853	 lr=0.091076
Epoch[154] Batch [0549]/[0716]	Speed: 25.640062 samples/sec	 accuracy=62.912338	 loss=1.523644	 lr=0.090785
Epoch[154] Batch [0599]/[0716]	Speed: 26.139583 samples/sec	 accuracy=62.943452	 loss=1.522065	 lr=0.090494
Epoch[154] Batch [0649]/[0716]	Speed: 26.172274 samples/sec	 accuracy=62.865385	 loss=1.523548	 lr=0.090203
Epoch[154] Batch [0699]/[0716]	Speed: 26.251845 samples/sec	 accuracy=62.849490	 loss=1.523434	 lr=0.089913
Batch [0049]/[0057]: acc-top1=59.714286 acc-top5=82.642857
[Epoch 154] training: accuracy=62.846668	 loss=1.524234
[Epoch 154] speed: 25 samples/sec	time cost: 1607.899178
[Epoch 154] validation: acc-top1=59.189640 acc-top5=82.544907 loss=1.987990
Epoch[155] Batch [0049]/[0716]	Speed: 22.740545 samples/sec	 accuracy=62.928571	 loss=1.494830	 lr=0.089531
Epoch[155] Batch [0099]/[0716]	Speed: 25.738628 samples/sec	 accuracy=62.750000	 loss=1.499756	 lr=0.089241
Epoch[155] Batch [0149]/[0716]	Speed: 26.227733 samples/sec	 accuracy=62.988095	 loss=1.494784	 lr=0.088952
Epoch[155] Batch [0199]/[0716]	Speed: 26.007830 samples/sec	 accuracy=63.107143	 loss=1.500086	 lr=0.088664
Epoch[155] Batch [0249]/[0716]	Speed: 25.721752 samples/sec	 accuracy=63.542857	 loss=1.492876	 lr=0.088376
Epoch[155] Batch [0299]/[0716]	Speed: 25.974365 samples/sec	 accuracy=63.392857	 loss=1.502733	 lr=0.088088
Epoch[155] Batch [0349]/[0716]	Speed: 26.194337 samples/sec	 accuracy=63.275510	 loss=1.503660	 lr=0.087800
Epoch[155] Batch [0399]/[0716]	Speed: 25.624298 samples/sec	 accuracy=63.375000	 loss=1.502438	 lr=0.087513
Epoch[155] Batch [0449]/[0716]	Speed: 26.157061 samples/sec	 accuracy=63.313492	 loss=1.503009	 lr=0.087227
Epoch[155] Batch [0499]/[0716]	Speed: 26.439571 samples/sec	 accuracy=63.360714	 loss=1.503410	 lr=0.086941
Epoch[155] Batch [0549]/[0716]	Speed: 25.586415 samples/sec	 accuracy=63.363636	 loss=1.503843	 lr=0.086655
Epoch[155] Batch [0599]/[0716]	Speed: 26.204346 samples/sec	 accuracy=63.351190	 loss=1.504934	 lr=0.086369
Epoch[155] Batch [0649]/[0716]	Speed: 25.683995 samples/sec	 accuracy=63.222527	 loss=1.509986	 lr=0.086084
Epoch[155] Batch [0699]/[0716]	Speed: 25.759411 samples/sec	 accuracy=63.285714	 loss=1.508795	 lr=0.085800
Batch [0049]/[0057]: acc-top1=59.571429 acc-top5=82.250000
[Epoch 155] training: accuracy=63.265662	 loss=1.508521
[Epoch 155] speed: 25 samples/sec	time cost: 1611.388453
[Epoch 155] validation: acc-top1=59.309738 acc-top5=82.283836 loss=1.977328
Epoch[156] Batch [0049]/[0716]	Speed: 22.961563 samples/sec	 accuracy=63.857143	 loss=1.491897	 lr=0.085425
Epoch[156] Batch [0099]/[0716]	Speed: 25.836168 samples/sec	 accuracy=64.107143	 loss=1.465586	 lr=0.085141
Epoch[156] Batch [0149]/[0716]	Speed: 26.056089 samples/sec	 accuracy=64.369048	 loss=1.454447	 lr=0.084858
Epoch[156] Batch [0199]/[0716]	Speed: 25.902889 samples/sec	 accuracy=64.571429	 loss=1.451661	 lr=0.084575
Epoch[156] Batch [0249]/[0716]	Speed: 25.749020 samples/sec	 accuracy=64.307143	 loss=1.467210	 lr=0.084292
Epoch[156] Batch [0299]/[0716]	Speed: 25.804555 samples/sec	 accuracy=64.196429	 loss=1.475428	 lr=0.084010
Epoch[156] Batch [0349]/[0716]	Speed: 25.781981 samples/sec	 accuracy=64.076531	 loss=1.473391	 lr=0.083728
Epoch[156] Batch [0399]/[0716]	Speed: 26.176830 samples/sec	 accuracy=64.125000	 loss=1.465898	 lr=0.083447
Epoch[156] Batch [0449]/[0716]	Speed: 26.207363 samples/sec	 accuracy=64.047619	 loss=1.471453	 lr=0.083166
Epoch[156] Batch [0499]/[0716]	Speed: 26.288167 samples/sec	 accuracy=64.021429	 loss=1.468103	 lr=0.082885
Epoch[156] Batch [0549]/[0716]	Speed: 26.259888 samples/sec	 accuracy=63.977273	 loss=1.468971	 lr=0.082605
Epoch[156] Batch [0599]/[0716]	Speed: 25.994894 samples/sec	 accuracy=63.982143	 loss=1.468469	 lr=0.082325
Epoch[156] Batch [0649]/[0716]	Speed: 25.758963 samples/sec	 accuracy=63.936813	 loss=1.472020	 lr=0.082046
Epoch[156] Batch [0699]/[0716]	Speed: 26.240774 samples/sec	 accuracy=63.913265	 loss=1.471924	 lr=0.081767
Batch [0049]/[0057]: acc-top1=60.714286 acc-top5=83.500000
[Epoch 156] training: accuracy=63.916600	 loss=1.470520
[Epoch 156] speed: 25 samples/sec	time cost: 1609.677390
[Epoch 156] validation: acc-top1=59.915417 acc-top5=82.852966 loss=1.912395
Epoch[157] Batch [0049]/[0716]	Speed: 22.707919 samples/sec	 accuracy=64.107143	 loss=1.482040	 lr=0.081399
Epoch[157] Batch [0099]/[0716]	Speed: 26.347992 samples/sec	 accuracy=64.714286	 loss=1.444995	 lr=0.081121
Epoch[157] Batch [0149]/[0716]	Speed: 26.108812 samples/sec	 accuracy=64.214286	 loss=1.469580	 lr=0.080844
Epoch[157] Batch [0199]/[0716]	Speed: 25.676350 samples/sec	 accuracy=64.366071	 loss=1.462756	 lr=0.080566
Epoch[157] Batch [0249]/[0716]	Speed: 25.760871 samples/sec	 accuracy=63.935714	 loss=1.474756	 lr=0.080290
Epoch[157] Batch [0299]/[0716]	Speed: 25.975137 samples/sec	 accuracy=64.279762	 loss=1.462790	 lr=0.080013
Epoch[157] Batch [0349]/[0716]	Speed: 26.119575 samples/sec	 accuracy=64.147959	 loss=1.464291	 lr=0.079737
Epoch[157] Batch [0399]/[0716]	Speed: 26.013144 samples/sec	 accuracy=64.084821	 loss=1.465603	 lr=0.079461
Epoch[157] Batch [0449]/[0716]	Speed: 26.008319 samples/sec	 accuracy=64.126984	 loss=1.467898	 lr=0.079186
Epoch[157] Batch [0499]/[0716]	Speed: 26.065879 samples/sec	 accuracy=64.160714	 loss=1.467652	 lr=0.078911
Epoch[157] Batch [0549]/[0716]	Speed: 26.037563 samples/sec	 accuracy=64.045455	 loss=1.473135	 lr=0.078637
Epoch[157] Batch [0599]/[0716]	Speed: 26.053995 samples/sec	 accuracy=63.898810	 loss=1.480642	 lr=0.078363
Epoch[157] Batch [0649]/[0716]	Speed: 26.171808 samples/sec	 accuracy=63.975275	 loss=1.475031	 lr=0.078089
Epoch[157] Batch [0699]/[0716]	Speed: 26.114453 samples/sec	 accuracy=63.977041	 loss=1.472324	 lr=0.077816
Batch [0049]/[0057]: acc-top1=59.464286 acc-top5=82.392857
[Epoch 157] training: accuracy=63.939046	 loss=1.473732
[Epoch 157] speed: 25 samples/sec	time cost: 1608.807719
[Epoch 157] validation: acc-top1=60.312241 acc-top5=82.967834 loss=1.845192
Epoch[158] Batch [0049]/[0716]	Speed: 22.633261 samples/sec	 accuracy=66.000000	 loss=1.402757	 lr=0.077456
Epoch[158] Batch [0099]/[0716]	Speed: 26.291740 samples/sec	 accuracy=64.678571	 loss=1.439389	 lr=0.077184
Epoch[158] Batch [0149]/[0716]	Speed: 25.783937 samples/sec	 accuracy=64.714286	 loss=1.441065	 lr=0.076912
Epoch[158] Batch [0199]/[0716]	Speed: 26.198712 samples/sec	 accuracy=64.919643	 loss=1.439223	 lr=0.076641
Epoch[158] Batch [0249]/[0716]	Speed: 26.018310 samples/sec	 accuracy=64.942857	 loss=1.435768	 lr=0.076370
Epoch[158] Batch [0299]/[0716]	Speed: 25.972217 samples/sec	 accuracy=64.845238	 loss=1.433480	 lr=0.076099
Epoch[158] Batch [0349]/[0716]	Speed: 26.078553 samples/sec	 accuracy=64.785714	 loss=1.438371	 lr=0.075829
Epoch[158] Batch [0399]/[0716]	Speed: 26.066046 samples/sec	 accuracy=64.714286	 loss=1.440911	 lr=0.075559
Epoch[158] Batch [0449]/[0716]	Speed: 26.090073 samples/sec	 accuracy=64.646825	 loss=1.445047	 lr=0.075290
Epoch[158] Batch [0499]/[0716]	Speed: 26.308085 samples/sec	 accuracy=64.664286	 loss=1.446202	 lr=0.075021
Epoch[158] Batch [0549]/[0716]	Speed: 26.119550 samples/sec	 accuracy=64.636364	 loss=1.446797	 lr=0.074752
Epoch[158] Batch [0599]/[0716]	Speed: 26.396265 samples/sec	 accuracy=64.660714	 loss=1.448345	 lr=0.074484
Epoch[158] Batch [0649]/[0716]	Speed: 26.044689 samples/sec	 accuracy=64.645604	 loss=1.449049	 lr=0.074216
Epoch[158] Batch [0699]/[0716]	Speed: 26.048516 samples/sec	 accuracy=64.670918	 loss=1.449036	 lr=0.073949
Batch [0049]/[0057]: acc-top1=59.678571 acc-top5=83.392857
[Epoch 158] training: accuracy=64.689745	 loss=1.448515
[Epoch 158] speed: 26 samples/sec	time cost: 1603.382214
[Epoch 158] validation: acc-top1=60.985802 acc-top5=82.978279 loss=1.891393
Epoch[159] Batch [0049]/[0717]	Speed: 23.105546 samples/sec	 accuracy=66.678571	 loss=1.377351	 lr=0.073597
Epoch[159] Batch [0099]/[0717]	Speed: 26.273816 samples/sec	 accuracy=66.982143	 loss=1.359614	 lr=0.073331
Epoch[159] Batch [0149]/[0717]	Speed: 26.171741 samples/sec	 accuracy=66.476190	 loss=1.374396	 lr=0.073065
Epoch[159] Batch [0199]/[0717]	Speed: 26.027355 samples/sec	 accuracy=66.571429	 loss=1.378260	 lr=0.072799
Epoch[159] Batch [0249]/[0717]	Speed: 26.414314 samples/sec	 accuracy=66.150000	 loss=1.386419	 lr=0.072534
Epoch[159] Batch [0299]/[0717]	Speed: 26.088142 samples/sec	 accuracy=66.017857	 loss=1.390637	 lr=0.072269
Epoch[159] Batch [0349]/[0717]	Speed: 26.088626 samples/sec	 accuracy=65.704082	 loss=1.403290	 lr=0.072005
Epoch[159] Batch [0399]/[0717]	Speed: 26.106578 samples/sec	 accuracy=65.553571	 loss=1.407896	 lr=0.071741
Epoch[159] Batch [0449]/[0717]	Speed: 26.129924 samples/sec	 accuracy=65.523810	 loss=1.409516	 lr=0.071478
Epoch[159] Batch [0499]/[0717]	Speed: 25.825813 samples/sec	 accuracy=65.378571	 loss=1.415099	 lr=0.071215
Epoch[159] Batch [0549]/[0717]	Speed: 26.213926 samples/sec	 accuracy=65.331169	 loss=1.417923	 lr=0.070952
Epoch[159] Batch [0599]/[0717]	Speed: 25.976619 samples/sec	 accuracy=65.241071	 loss=1.421311	 lr=0.070690
Epoch[159] Batch [0649]/[0717]	Speed: 25.817294 samples/sec	 accuracy=65.142857	 loss=1.425196	 lr=0.070428
Epoch[159] Batch [0699]/[0717]	Speed: 26.033443 samples/sec	 accuracy=64.979592	 loss=1.430659	 lr=0.070167
Batch [0049]/[0057]: acc-top1=58.714286 acc-top5=81.857143
[Epoch 159] training: accuracy=64.965631	 loss=1.431754
[Epoch 159] speed: 26 samples/sec	time cost: 1604.097546
[Epoch 159] validation: acc-top1=60.333126 acc-top5=83.009605 loss=1.875652
Epoch[160] Batch [0049]/[0716]	Speed: 23.345391 samples/sec	 accuracy=66.464286	 loss=1.365518	 lr=0.069817
Epoch[160] Batch [0099]/[0716]	Speed: 25.996440 samples/sec	 accuracy=66.553571	 loss=1.342901	 lr=0.069557
Epoch[160] Batch [0149]/[0716]	Speed: 25.738077 samples/sec	 accuracy=66.309524	 loss=1.348465	 lr=0.069297
Epoch[160] Batch [0199]/[0716]	Speed: 25.926331 samples/sec	 accuracy=66.482143	 loss=1.341958	 lr=0.069038
Epoch[160] Batch [0249]/[0716]	Speed: 26.086214 samples/sec	 accuracy=66.471429	 loss=1.346607	 lr=0.068779
Epoch[160] Batch [0299]/[0716]	Speed: 26.194904 samples/sec	 accuracy=66.327381	 loss=1.358275	 lr=0.068520
Epoch[160] Batch [0349]/[0716]	Speed: 25.999384 samples/sec	 accuracy=66.112245	 loss=1.361626	 lr=0.068262
Epoch[160] Batch [0399]/[0716]	Speed: 26.040612 samples/sec	 accuracy=66.147321	 loss=1.362294	 lr=0.068004
Epoch[160] Batch [0449]/[0716]	Speed: 26.148761 samples/sec	 accuracy=66.035714	 loss=1.367570	 lr=0.067747
Epoch[160] Batch [0499]/[0716]	Speed: 26.254521 samples/sec	 accuracy=65.864286	 loss=1.376173	 lr=0.067490
Epoch[160] Batch [0549]/[0716]	Speed: 25.786791 samples/sec	 accuracy=65.814935	 loss=1.379047	 lr=0.067233
Epoch[160] Batch [0599]/[0716]	Speed: 26.278089 samples/sec	 accuracy=65.714286	 loss=1.385045	 lr=0.066977
Epoch[160] Batch [0649]/[0716]	Speed: 25.963507 samples/sec	 accuracy=65.675824	 loss=1.388263	 lr=0.066721
Epoch[160] Batch [0699]/[0716]	Speed: 26.243628 samples/sec	 accuracy=65.625000	 loss=1.391347	 lr=0.066466
Batch [0049]/[0057]: acc-top1=62.785714 acc-top5=83.714286
[Epoch 160] training: accuracy=65.602554	 loss=1.392177
[Epoch 160] speed: 25 samples/sec	time cost: 1605.790432
[Epoch 160] validation: acc-top1=61.455727 acc-top5=83.594414 loss=1.785459
Epoch[161] Batch [0049]/[0716]	Speed: 22.829889 samples/sec	 accuracy=66.642857	 loss=1.351585	 lr=0.066130
Epoch[161] Batch [0099]/[0716]	Speed: 26.300450 samples/sec	 accuracy=65.857143	 loss=1.375065	 lr=0.065876
Epoch[161] Batch [0149]/[0716]	Speed: 25.951386 samples/sec	 accuracy=65.476190	 loss=1.388189	 lr=0.065622
Epoch[161] Batch [0199]/[0716]	Speed: 26.158661 samples/sec	 accuracy=65.464286	 loss=1.388242	 lr=0.065368
Epoch[161] Batch [0249]/[0716]	Speed: 25.638168 samples/sec	 accuracy=65.335714	 loss=1.394886	 lr=0.065115
Epoch[161] Batch [0299]/[0716]	Speed: 26.034769 samples/sec	 accuracy=65.476190	 loss=1.390825	 lr=0.064863
Epoch[161] Batch [0349]/[0716]	Speed: 26.215268 samples/sec	 accuracy=65.525510	 loss=1.389832	 lr=0.064611
Epoch[161] Batch [0399]/[0716]	Speed: 25.794472 samples/sec	 accuracy=65.562500	 loss=1.389822	 lr=0.064359
Epoch[161] Batch [0449]/[0716]	Speed: 25.922013 samples/sec	 accuracy=65.515873	 loss=1.390529	 lr=0.064108
Epoch[161] Batch [0499]/[0716]	Speed: 26.258078 samples/sec	 accuracy=65.539286	 loss=1.389781	 lr=0.063857
Epoch[161] Batch [0549]/[0716]	Speed: 26.232940 samples/sec	 accuracy=65.500000	 loss=1.389628	 lr=0.063607
Epoch[161] Batch [0599]/[0716]	Speed: 25.912013 samples/sec	 accuracy=65.651786	 loss=1.383863	 lr=0.063357
Epoch[161] Batch [0649]/[0716]	Speed: 25.628594 samples/sec	 accuracy=65.618132	 loss=1.386608	 lr=0.063107
Epoch[161] Batch [0699]/[0716]	Speed: 25.927784 samples/sec	 accuracy=65.599490	 loss=1.389625	 lr=0.062858
Batch [0049]/[0057]: acc-top1=62.178571 acc-top5=84.607143
[Epoch 161] training: accuracy=65.587590	 loss=1.388732
[Epoch 161] speed: 25 samples/sec	time cost: 1610.086663
[Epoch 161] validation: acc-top1=62.416458 acc-top5=84.283630 loss=1.839121
Epoch[162] Batch [0049]/[0716]	Speed: 23.333896 samples/sec	 accuracy=65.035714	 loss=1.409161	 lr=0.062530
Epoch[162] Batch [0099]/[0716]	Speed: 26.236330 samples/sec	 accuracy=66.660714	 loss=1.344192	 lr=0.062282
Epoch[162] Batch [0149]/[0716]	Speed: 25.842051 samples/sec	 accuracy=66.535714	 loss=1.334842	 lr=0.062035
Epoch[162] Batch [0199]/[0716]	Speed: 26.058767 samples/sec	 accuracy=66.339286	 loss=1.348659	 lr=0.061787
Epoch[162] Batch [0249]/[0716]	Speed: 26.262109 samples/sec	 accuracy=66.350000	 loss=1.347318	 lr=0.061541
Epoch[162] Batch [0299]/[0716]	Speed: 26.171612 samples/sec	 accuracy=66.339286	 loss=1.351082	 lr=0.061294
Epoch[162] Batch [0349]/[0716]	Speed: 26.115961 samples/sec	 accuracy=66.280612	 loss=1.353302	 lr=0.061049
Epoch[162] Batch [0399]/[0716]	Speed: 25.813373 samples/sec	 accuracy=66.281250	 loss=1.353120	 lr=0.060803
Epoch[162] Batch [0449]/[0716]	Speed: 25.888051 samples/sec	 accuracy=66.154762	 loss=1.356766	 lr=0.060558
Epoch[162] Batch [0499]/[0716]	Speed: 26.452376 samples/sec	 accuracy=66.057143	 loss=1.361136	 lr=0.060314
Epoch[162] Batch [0549]/[0716]	Speed: 26.267947 samples/sec	 accuracy=66.094156	 loss=1.361838	 lr=0.060069
Epoch[162] Batch [0599]/[0716]	Speed: 26.421802 samples/sec	 accuracy=66.038690	 loss=1.365672	 lr=0.059826
Epoch[162] Batch [0649]/[0716]	Speed: 26.012949 samples/sec	 accuracy=66.016484	 loss=1.366979	 lr=0.059583
Epoch[162] Batch [0699]/[0716]	Speed: 26.504084 samples/sec	 accuracy=66.000000	 loss=1.366870	 lr=0.059340
Batch [0049]/[0057]: acc-top1=62.714286 acc-top5=83.321429
[Epoch 162] training: accuracy=66.058958	 loss=1.365394
[Epoch 162] speed: 26 samples/sec	time cost: 1597.661607
[Epoch 162] validation: acc-top1=61.742897 acc-top5=83.761497 loss=1.836916
Epoch[163] Batch [0049]/[0716]	Speed: 22.930472 samples/sec	 accuracy=68.642857	 loss=1.279044	 lr=0.059020
Epoch[163] Batch [0099]/[0716]	Speed: 25.803527 samples/sec	 accuracy=67.785714	 loss=1.303082	 lr=0.058778
Epoch[163] Batch [0149]/[0716]	Speed: 26.209217 samples/sec	 accuracy=67.738095	 loss=1.307904	 lr=0.058537
Epoch[163] Batch [0199]/[0716]	Speed: 25.870789 samples/sec	 accuracy=67.562500	 loss=1.316056	 lr=0.058296
Epoch[163] Batch [0249]/[0716]	Speed: 26.501079 samples/sec	 accuracy=67.328571	 loss=1.327131	 lr=0.058056
Epoch[163] Batch [0299]/[0716]	Speed: 26.318848 samples/sec	 accuracy=67.113095	 loss=1.331364	 lr=0.057816
Epoch[163] Batch [0349]/[0716]	Speed: 26.318461 samples/sec	 accuracy=66.933673	 loss=1.331430	 lr=0.057576
Epoch[163] Batch [0399]/[0716]	Speed: 26.222307 samples/sec	 accuracy=66.750000	 loss=1.342358	 lr=0.057337
Epoch[163] Batch [0449]/[0716]	Speed: 26.265291 samples/sec	 accuracy=66.420635	 loss=1.353568	 lr=0.057098
Epoch[163] Batch [0499]/[0716]	Speed: 25.903424 samples/sec	 accuracy=66.453571	 loss=1.355246	 lr=0.056860
Epoch[163] Batch [0549]/[0716]	Speed: 26.064860 samples/sec	 accuracy=66.574675	 loss=1.352458	 lr=0.056622
Epoch[163] Batch [0599]/[0716]	Speed: 26.273051 samples/sec	 accuracy=66.571429	 loss=1.348236	 lr=0.056385
Epoch[163] Batch [0649]/[0716]	Speed: 25.925468 samples/sec	 accuracy=66.609890	 loss=1.347487	 lr=0.056148
Epoch[163] Batch [0699]/[0716]	Speed: 25.933337 samples/sec	 accuracy=66.602041	 loss=1.347465	 lr=0.055912
Batch [0049]/[0057]: acc-top1=63.214286 acc-top5=84.357143
[Epoch 163] training: accuracy=66.607642	 loss=1.346712
[Epoch 163] speed: 26 samples/sec	time cost: 1600.934185
[Epoch 163] validation: acc-top1=62.583542 acc-top5=84.330627 loss=1.792784
Epoch[164] Batch [0049]/[0716]	Speed: 23.415716 samples/sec	 accuracy=68.892857	 loss=1.222675	 lr=0.055600
Epoch[164] Batch [0099]/[0716]	Speed: 26.110931 samples/sec	 accuracy=68.714286	 loss=1.269159	 lr=0.055365
Epoch[164] Batch [0149]/[0716]	Speed: 26.286688 samples/sec	 accuracy=68.071429	 loss=1.308895	 lr=0.055130
Epoch[164] Batch [0199]/[0716]	Speed: 26.248428 samples/sec	 accuracy=68.098214	 loss=1.301762	 lr=0.054895
Epoch[164] Batch [0249]/[0716]	Speed: 26.193519 samples/sec	 accuracy=68.171429	 loss=1.296982	 lr=0.054661
Epoch[164] Batch [0299]/[0716]	Speed: 25.544512 samples/sec	 accuracy=68.095238	 loss=1.298265	 lr=0.054428
Epoch[164] Batch [0349]/[0716]	Speed: 26.005627 samples/sec	 accuracy=67.969388	 loss=1.301205	 lr=0.054195
Epoch[164] Batch [0399]/[0716]	Speed: 26.493930 samples/sec	 accuracy=68.066964	 loss=1.295755	 lr=0.053962
Epoch[164] Batch [0449]/[0716]	Speed: 26.204625 samples/sec	 accuracy=68.063492	 loss=1.302049	 lr=0.053730
Epoch[164] Batch [0499]/[0716]	Speed: 26.135504 samples/sec	 accuracy=68.128571	 loss=1.302841	 lr=0.053498
Epoch[164] Batch [0549]/[0716]	Speed: 26.168486 samples/sec	 accuracy=68.000000	 loss=1.307934	 lr=0.053267
Epoch[164] Batch [0599]/[0716]	Speed: 26.155024 samples/sec	 accuracy=67.907738	 loss=1.311214	 lr=0.053036
Epoch[164] Batch [0649]/[0716]	Speed: 26.100813 samples/sec	 accuracy=67.881868	 loss=1.308408	 lr=0.052805
Epoch[164] Batch [0699]/[0716]	Speed: 26.681891 samples/sec	 accuracy=67.714286	 loss=1.311374	 lr=0.052575
Batch [0049]/[0057]: acc-top1=62.928571 acc-top5=84.392857
[Epoch 164] training: accuracy=67.695032	 loss=1.312428
[Epoch 164] speed: 26 samples/sec	time cost: 1594.988328
[Epoch 164] validation: acc-top1=63.283203 acc-top5=84.884087 loss=1.726602
Epoch[165] Batch [0049]/[0716]	Speed: 22.922245 samples/sec	 accuracy=69.750000	 loss=1.222496	 lr=0.052273
Epoch[165] Batch [0099]/[0716]	Speed: 25.674615 samples/sec	 accuracy=69.071429	 loss=1.252396	 lr=0.052044
Epoch[165] Batch [0149]/[0716]	Speed: 25.813318 samples/sec	 accuracy=68.904762	 loss=1.264341	 lr=0.051815
Epoch[165] Batch [0199]/[0716]	Speed: 26.178891 samples/sec	 accuracy=68.526786	 loss=1.272305	 lr=0.051587
Epoch[165] Batch [0249]/[0716]	Speed: 25.992023 samples/sec	 accuracy=68.528571	 loss=1.273996	 lr=0.051360
Epoch[165] Batch [0299]/[0716]	Speed: 26.145870 samples/sec	 accuracy=68.428571	 loss=1.272416	 lr=0.051132
Epoch[165] Batch [0349]/[0716]	Speed: 26.229403 samples/sec	 accuracy=68.397959	 loss=1.277327	 lr=0.050906
Epoch[165] Batch [0399]/[0716]	Speed: 25.789030 samples/sec	 accuracy=68.397321	 loss=1.276271	 lr=0.050680
Epoch[165] Batch [0449]/[0716]	Speed: 25.908971 samples/sec	 accuracy=68.182540	 loss=1.285891	 lr=0.050454
Epoch[165] Batch [0499]/[0716]	Speed: 26.005394 samples/sec	 accuracy=68.189286	 loss=1.282320	 lr=0.050229
Epoch[165] Batch [0549]/[0716]	Speed: 25.696952 samples/sec	 accuracy=68.113636	 loss=1.288438	 lr=0.050004
Epoch[165] Batch [0599]/[0716]	Speed: 26.001604 samples/sec	 accuracy=68.116071	 loss=1.288259	 lr=0.049779
Epoch[165] Batch [0649]/[0716]	Speed: 26.220864 samples/sec	 accuracy=67.989011	 loss=1.292061	 lr=0.049556
Epoch[165] Batch [0699]/[0716]	Speed: 25.911857 samples/sec	 accuracy=67.974490	 loss=1.291928	 lr=0.049332
Batch [0049]/[0057]: acc-top1=63.678571 acc-top5=84.535714
[Epoch 165] training: accuracy=67.954409	 loss=1.291277
[Epoch 165] speed: 25 samples/sec	time cost: 1607.991193
[Epoch 165] validation: acc-top1=63.126564 acc-top5=84.816208 loss=1.771560
Epoch[166] Batch [0049]/[0716]	Speed: 23.238423 samples/sec	 accuracy=70.035714	 loss=1.177669	 lr=0.049038
Epoch[166] Batch [0099]/[0716]	Speed: 26.367941 samples/sec	 accuracy=69.160714	 loss=1.218949	 lr=0.048816
Epoch[166] Batch [0149]/[0716]	Speed: 26.262647 samples/sec	 accuracy=69.523810	 loss=1.228616	 lr=0.048594
Epoch[166] Batch [0199]/[0716]	Speed: 26.107409 samples/sec	 accuracy=69.205357	 loss=1.242827	 lr=0.048372
Epoch[166] Batch [0249]/[0716]	Speed: 25.984873 samples/sec	 accuracy=68.814286	 loss=1.253820	 lr=0.048151
Epoch[166] Batch [0299]/[0716]	Speed: 26.190675 samples/sec	 accuracy=68.565476	 loss=1.262333	 lr=0.047931
Epoch[166] Batch [0349]/[0716]	Speed: 26.408403 samples/sec	 accuracy=68.637755	 loss=1.261040	 lr=0.047711
Epoch[166] Batch [0399]/[0716]	Speed: 26.006882 samples/sec	 accuracy=68.714286	 loss=1.262112	 lr=0.047491
Epoch[166] Batch [0449]/[0716]	Speed: 26.189025 samples/sec	 accuracy=68.769841	 loss=1.262190	 lr=0.047272
Epoch[166] Batch [0499]/[0716]	Speed: 26.199041 samples/sec	 accuracy=68.782143	 loss=1.257385	 lr=0.047053
Epoch[166] Batch [0549]/[0716]	Speed: 26.051744 samples/sec	 accuracy=68.678571	 loss=1.262043	 lr=0.046835
Epoch[166] Batch [0599]/[0716]	Speed: 26.206281 samples/sec	 accuracy=68.592262	 loss=1.263039	 lr=0.046617
Epoch[166] Batch [0649]/[0716]	Speed: 26.328620 samples/sec	 accuracy=68.626374	 loss=1.261450	 lr=0.046400
Epoch[166] Batch [0699]/[0716]	Speed: 26.083413 samples/sec	 accuracy=68.604592	 loss=1.261769	 lr=0.046183
Batch [0049]/[0057]: acc-top1=64.750000 acc-top5=85.428571
[Epoch 166] training: accuracy=68.622805	 loss=1.260990
[Epoch 166] speed: 26 samples/sec	time cost: 1597.142760
[Epoch 166] validation: acc-top1=63.455517 acc-top5=84.623024 loss=1.767986
Epoch[167] Batch [0049]/[0717]	Speed: 23.419944 samples/sec	 accuracy=72.071429	 loss=1.106493	 lr=0.045898
Epoch[167] Batch [0099]/[0717]	Speed: 25.990792 samples/sec	 accuracy=71.357143	 loss=1.150814	 lr=0.045682
Epoch[167] Batch [0149]/[0717]	Speed: 25.893915 samples/sec	 accuracy=70.761905	 loss=1.182114	 lr=0.045467
Epoch[167] Batch [0199]/[0717]	Speed: 25.721069 samples/sec	 accuracy=70.160714	 loss=1.202252	 lr=0.045252
Epoch[167] Batch [0249]/[0717]	Speed: 26.143545 samples/sec	 accuracy=69.778571	 loss=1.208499	 lr=0.045038
Epoch[167] Batch [0299]/[0717]	Speed: 26.572799 samples/sec	 accuracy=69.732143	 loss=1.207790	 lr=0.044824
Epoch[167] Batch [0349]/[0717]	Speed: 26.059700 samples/sec	 accuracy=69.683673	 loss=1.208903	 lr=0.044610
Epoch[167] Batch [0399]/[0717]	Speed: 25.793941 samples/sec	 accuracy=69.589286	 loss=1.214389	 lr=0.044397
Epoch[167] Batch [0449]/[0717]	Speed: 25.960233 samples/sec	 accuracy=69.468254	 loss=1.216152	 lr=0.044185
Epoch[167] Batch [0499]/[0717]	Speed: 26.078639 samples/sec	 accuracy=69.567857	 loss=1.217735	 lr=0.043973
Epoch[167] Batch [0549]/[0717]	Speed: 25.849686 samples/sec	 accuracy=69.512987	 loss=1.219048	 lr=0.043761
Epoch[167] Batch [0599]/[0717]	Speed: 26.082981 samples/sec	 accuracy=69.488095	 loss=1.219405	 lr=0.043550
Epoch[167] Batch [0649]/[0717]	Speed: 25.931892 samples/sec	 accuracy=69.587912	 loss=1.219225	 lr=0.043340
Epoch[167] Batch [0699]/[0717]	Speed: 25.741485 samples/sec	 accuracy=69.420918	 loss=1.224852	 lr=0.043130
Batch [0049]/[0057]: acc-top1=64.357143 acc-top5=85.214286
[Epoch 167] training: accuracy=69.396294	 loss=1.224063
[Epoch 167] speed: 25 samples/sec	time cost: 1606.557085
[Epoch 167] validation: acc-top1=63.633038 acc-top5=84.972855 loss=1.741207
Epoch[168] Batch [0049]/[0716]	Speed: 22.912117 samples/sec	 accuracy=70.250000	 loss=1.161138	 lr=0.042849
Epoch[168] Batch [0099]/[0716]	Speed: 25.718355 samples/sec	 accuracy=70.446429	 loss=1.168595	 lr=0.042640
Epoch[168] Batch [0149]/[0716]	Speed: 26.387279 samples/sec	 accuracy=70.357143	 loss=1.183504	 lr=0.042431
Epoch[168] Batch [0199]/[0716]	Speed: 26.048448 samples/sec	 accuracy=70.133929	 loss=1.195450	 lr=0.042223
Epoch[168] Batch [0249]/[0716]	Speed: 26.161486 samples/sec	 accuracy=69.878571	 loss=1.198974	 lr=0.042016
Epoch[168] Batch [0299]/[0716]	Speed: 25.499070 samples/sec	 accuracy=70.059524	 loss=1.191274	 lr=0.041809
Epoch[168] Batch [0349]/[0716]	Speed: 26.024262 samples/sec	 accuracy=70.142857	 loss=1.186516	 lr=0.041602
Epoch[168] Batch [0399]/[0716]	Speed: 25.397170 samples/sec	 accuracy=70.218750	 loss=1.187683	 lr=0.041396
Epoch[168] Batch [0449]/[0716]	Speed: 26.237142 samples/sec	 accuracy=70.126984	 loss=1.192176	 lr=0.041190
Epoch[168] Batch [0499]/[0716]	Speed: 26.359162 samples/sec	 accuracy=70.107143	 loss=1.194533	 lr=0.040985
Epoch[168] Batch [0549]/[0716]	Speed: 25.445404 samples/sec	 accuracy=70.045455	 loss=1.200869	 lr=0.040780
Epoch[168] Batch [0599]/[0716]	Speed: 26.279012 samples/sec	 accuracy=69.943452	 loss=1.201384	 lr=0.040576
Epoch[168] Batch [0649]/[0716]	Speed: 26.006767 samples/sec	 accuracy=69.854396	 loss=1.203674	 lr=0.040372
Epoch[168] Batch [0699]/[0716]	Speed: 26.559947 samples/sec	 accuracy=69.862245	 loss=1.206877	 lr=0.040169
Batch [0049]/[0057]: acc-top1=62.964286 acc-top5=86.285714
[Epoch 168] training: accuracy=69.899741	 loss=1.204885
[Epoch 168] speed: 25 samples/sec	time cost: 1605.822752
[Epoch 168] validation: acc-top1=64.092522 acc-top5=85.244362 loss=1.687557
Epoch[169] Batch [0049]/[0716]	Speed: 23.164763 samples/sec	 accuracy=70.214286	 loss=1.174901	 lr=0.039901
Epoch[169] Batch [0099]/[0716]	Speed: 26.071693 samples/sec	 accuracy=70.250000	 loss=1.172190	 lr=0.039699
Epoch[169] Batch [0149]/[0716]	Speed: 26.332736 samples/sec	 accuracy=70.440476	 loss=1.161574	 lr=0.039497
Epoch[169] Batch [0199]/[0716]	Speed: 26.257360 samples/sec	 accuracy=70.446429	 loss=1.161757	 lr=0.039296
Epoch[169] Batch [0249]/[0716]	Speed: 25.772894 samples/sec	 accuracy=70.285714	 loss=1.172649	 lr=0.039095
Epoch[169] Batch [0299]/[0716]	Speed: 25.933724 samples/sec	 accuracy=70.410714	 loss=1.168778	 lr=0.038895
Epoch[169] Batch [0349]/[0716]	Speed: 25.869323 samples/sec	 accuracy=70.428571	 loss=1.172899	 lr=0.038695
Epoch[169] Batch [0399]/[0716]	Speed: 25.831236 samples/sec	 accuracy=70.348214	 loss=1.176883	 lr=0.038496
Epoch[169] Batch [0449]/[0716]	Speed: 25.712711 samples/sec	 accuracy=70.341270	 loss=1.182367	 lr=0.038297
Epoch[169] Batch [0499]/[0716]	Speed: 26.415397 samples/sec	 accuracy=70.335714	 loss=1.182350	 lr=0.038098
Epoch[169] Batch [0549]/[0716]	Speed: 26.275452 samples/sec	 accuracy=70.379870	 loss=1.180907	 lr=0.037900
Epoch[169] Batch [0599]/[0716]	Speed: 26.288253 samples/sec	 accuracy=70.312500	 loss=1.184182	 lr=0.037703
Epoch[169] Batch [0649]/[0716]	Speed: 26.087342 samples/sec	 accuracy=70.335165	 loss=1.185758	 lr=0.037506
Epoch[169] Batch [0699]/[0716]	Speed: 26.146447 samples/sec	 accuracy=70.372449	 loss=1.186563	 lr=0.037310
Batch [0049]/[0057]: acc-top1=64.214286 acc-top5=84.857143
[Epoch 169] training: accuracy=70.376097	 loss=1.187212
[Epoch 169] speed: 26 samples/sec	time cost: 1602.130380
[Epoch 169] validation: acc-top1=64.249161 acc-top5=84.910194 loss=1.736770
Epoch[170] Batch [0049]/[0716]	Speed: 23.222844 samples/sec	 accuracy=72.535714	 loss=1.077916	 lr=0.037051
Epoch[170] Batch [0099]/[0716]	Speed: 25.721570 samples/sec	 accuracy=72.375000	 loss=1.095660	 lr=0.036856
Epoch[170] Batch [0149]/[0716]	Speed: 25.844916 samples/sec	 accuracy=71.904762	 loss=1.113809	 lr=0.036661
Epoch[170] Batch [0199]/[0716]	Speed: 26.067057 samples/sec	 accuracy=71.883929	 loss=1.115651	 lr=0.036466
Epoch[170] Batch [0249]/[0716]	Speed: 25.531901 samples/sec	 accuracy=71.535714	 loss=1.135769	 lr=0.036273
Epoch[170] Batch [0299]/[0716]	Speed: 26.273868 samples/sec	 accuracy=71.553571	 loss=1.136029	 lr=0.036079
Epoch[170] Batch [0349]/[0716]	Speed: 25.974781 samples/sec	 accuracy=71.387755	 loss=1.142894	 lr=0.035886
Epoch[170] Batch [0399]/[0716]	Speed: 25.898069 samples/sec	 accuracy=71.223214	 loss=1.147289	 lr=0.035694
Epoch[170] Batch [0449]/[0716]	Speed: 25.902683 samples/sec	 accuracy=71.333333	 loss=1.146819	 lr=0.035502
Epoch[170] Batch [0499]/[0716]	Speed: 26.250161 samples/sec	 accuracy=71.207143	 loss=1.151786	 lr=0.035310
Epoch[170] Batch [0549]/[0716]	Speed: 26.068458 samples/sec	 accuracy=71.237013	 loss=1.148911	 lr=0.035119
Epoch[170] Batch [0599]/[0716]	Speed: 26.076997 samples/sec	 accuracy=71.211310	 loss=1.151347	 lr=0.034929
Epoch[170] Batch [0649]/[0716]	Speed: 26.115094 samples/sec	 accuracy=71.162088	 loss=1.154106	 lr=0.034739
Epoch[170] Batch [0699]/[0716]	Speed: 26.183365 samples/sec	 accuracy=71.219388	 loss=1.152464	 lr=0.034549
Batch [0049]/[0057]: acc-top1=65.142857 acc-top5=85.392857
[Epoch 170] training: accuracy=71.191640	 loss=1.152531
[Epoch 170] speed: 25 samples/sec	time cost: 1604.955878
[Epoch 170] validation: acc-top1=64.609436 acc-top5=85.286133 loss=1.701700
Epoch[171] Batch [0049]/[0716]	Speed: 23.223934 samples/sec	 accuracy=72.071429	 loss=1.102844	 lr=0.034300
Epoch[171] Batch [0099]/[0716]	Speed: 25.856847 samples/sec	 accuracy=71.017857	 loss=1.136992	 lr=0.034112
Epoch[171] Batch [0149]/[0716]	Speed: 26.394313 samples/sec	 accuracy=70.988095	 loss=1.128050	 lr=0.033924
Epoch[171] Batch [0199]/[0716]	Speed: 26.215563 samples/sec	 accuracy=71.339286	 loss=1.122710	 lr=0.033736
Epoch[171] Batch [0249]/[0716]	Speed: 26.321017 samples/sec	 accuracy=71.264286	 loss=1.128432	 lr=0.033549
Epoch[171] Batch [0299]/[0716]	Speed: 26.366707 samples/sec	 accuracy=71.214286	 loss=1.133738	 lr=0.033363
Epoch[171] Batch [0349]/[0716]	Speed: 26.116988 samples/sec	 accuracy=71.147959	 loss=1.139348	 lr=0.033177
Epoch[171] Batch [0399]/[0716]	Speed: 25.841067 samples/sec	 accuracy=71.053571	 loss=1.149366	 lr=0.032991
Epoch[171] Batch [0449]/[0716]	Speed: 25.989841 samples/sec	 accuracy=71.115079	 loss=1.146334	 lr=0.032806
Epoch[171] Batch [0499]/[0716]	Speed: 25.965587 samples/sec	 accuracy=71.071429	 loss=1.143730	 lr=0.032622
Epoch[171] Batch [0549]/[0716]	Speed: 26.231211 samples/sec	 accuracy=71.136364	 loss=1.142256	 lr=0.032438
Epoch[171] Batch [0599]/[0716]	Speed: 26.284886 samples/sec	 accuracy=71.098214	 loss=1.142947	 lr=0.032254
Epoch[171] Batch [0649]/[0716]	Speed: 26.015050 samples/sec	 accuracy=71.101648	 loss=1.144592	 lr=0.032071
Epoch[171] Batch [0699]/[0716]	Speed: 26.472515 samples/sec	 accuracy=71.104592	 loss=1.146479	 lr=0.031889
Batch [0049]/[0057]: acc-top1=65.000000 acc-top5=86.464286
[Epoch 171] training: accuracy=71.111832	 loss=1.145096
[Epoch 171] speed: 26 samples/sec	time cost: 1597.050462
[Epoch 171] validation: acc-top1=64.969711 acc-top5=85.876152 loss=1.677788
Epoch[172] Batch [0049]/[0716]	Speed: 22.692751 samples/sec	 accuracy=72.535714	 loss=1.107741	 lr=0.031649
Epoch[172] Batch [0099]/[0716]	Speed: 25.803102 samples/sec	 accuracy=71.875000	 loss=1.111641	 lr=0.031467
Epoch[172] Batch [0149]/[0716]	Speed: 26.133912 samples/sec	 accuracy=71.690476	 loss=1.124428	 lr=0.031286
Epoch[172] Batch [0199]/[0716]	Speed: 25.976281 samples/sec	 accuracy=72.133929	 loss=1.109397	 lr=0.031106
Epoch[172] Batch [0249]/[0716]	Speed: 26.064262 samples/sec	 accuracy=72.128571	 loss=1.108202	 lr=0.030926
Epoch[172] Batch [0299]/[0716]	Speed: 25.935327 samples/sec	 accuracy=72.321429	 loss=1.095865	 lr=0.030747
Epoch[172] Batch [0349]/[0716]	Speed: 26.217297 samples/sec	 accuracy=72.469388	 loss=1.089269	 lr=0.030568
Epoch[172] Batch [0399]/[0716]	Speed: 25.872089 samples/sec	 accuracy=72.500000	 loss=1.091262	 lr=0.030389
Epoch[172] Batch [0449]/[0716]	Speed: 25.991114 samples/sec	 accuracy=72.257937	 loss=1.098721	 lr=0.030211
Epoch[172] Batch [0499]/[0716]	Speed: 25.907922 samples/sec	 accuracy=72.200000	 loss=1.099660	 lr=0.030034
Epoch[172] Batch [0549]/[0716]	Speed: 26.433694 samples/sec	 accuracy=72.133117	 loss=1.104641	 lr=0.029857
Epoch[172] Batch [0599]/[0716]	Speed: 25.942969 samples/sec	 accuracy=72.125000	 loss=1.105040	 lr=0.029681
Epoch[172] Batch [0649]/[0716]	Speed: 25.713275 samples/sec	 accuracy=72.118132	 loss=1.103601	 lr=0.029505
Epoch[172] Batch [0699]/[0716]	Speed: 25.976355 samples/sec	 accuracy=72.145408	 loss=1.104728	 lr=0.029329
Batch [0049]/[0057]: acc-top1=64.785714 acc-top5=85.678571
[Epoch 172] training: accuracy=72.141860	 loss=1.104286
[Epoch 172] speed: 25 samples/sec	time cost: 1608.424189
[Epoch 172] validation: acc-top1=65.867790 acc-top5=86.372185 loss=1.741165
Epoch[173] Batch [0049]/[0716]	Speed: 22.972252 samples/sec	 accuracy=75.178571	 loss=1.028058	 lr=0.029098
Epoch[173] Batch [0099]/[0716]	Speed: 25.989383 samples/sec	 accuracy=74.589286	 loss=1.043382	 lr=0.028924
Epoch[173] Batch [0149]/[0716]	Speed: 26.066992 samples/sec	 accuracy=73.880952	 loss=1.060967	 lr=0.028750
Epoch[173] Batch [0199]/[0716]	Speed: 25.824859 samples/sec	 accuracy=73.875000	 loss=1.064459	 lr=0.028577
Epoch[173] Batch [0249]/[0716]	Speed: 26.175012 samples/sec	 accuracy=73.728571	 loss=1.065131	 lr=0.028404
Epoch[173] Batch [0299]/[0716]	Speed: 25.746061 samples/sec	 accuracy=73.791667	 loss=1.059371	 lr=0.028232
Epoch[173] Batch [0349]/[0716]	Speed: 25.985125 samples/sec	 accuracy=73.826531	 loss=1.055369	 lr=0.028060
Epoch[173] Batch [0399]/[0716]	Speed: 25.640821 samples/sec	 accuracy=73.808036	 loss=1.055721	 lr=0.027889
Epoch[173] Batch [0449]/[0716]	Speed: 26.370964 samples/sec	 accuracy=73.833333	 loss=1.055901	 lr=0.027718
Epoch[173] Batch [0499]/[0716]	Speed: 25.795257 samples/sec	 accuracy=73.764286	 loss=1.054333	 lr=0.027548
Epoch[173] Batch [0549]/[0716]	Speed: 25.963277 samples/sec	 accuracy=73.577922	 loss=1.057050	 lr=0.027378
Epoch[173] Batch [0599]/[0716]	Speed: 26.174433 samples/sec	 accuracy=73.517857	 loss=1.058149	 lr=0.027209
Epoch[173] Batch [0649]/[0716]	Speed: 26.248333 samples/sec	 accuracy=73.434066	 loss=1.062680	 lr=0.027040
Epoch[173] Batch [0699]/[0716]	Speed: 25.982840 samples/sec	 accuracy=73.438776	 loss=1.064263	 lr=0.026871
Batch [0049]/[0057]: acc-top1=64.571429 acc-top5=85.750000
[Epoch 173] training: accuracy=73.446229	 loss=1.064557
[Epoch 173] speed: 25 samples/sec	time cost: 1607.491744
[Epoch 173] validation: acc-top1=65.862564 acc-top5=86.340858 loss=1.659081
Epoch[174] Batch [0049]/[0716]	Speed: 22.957355 samples/sec	 accuracy=73.964286	 loss=1.023089	 lr=0.026650
Epoch[174] Batch [0099]/[0716]	Speed: 26.294753 samples/sec	 accuracy=73.732143	 loss=1.037058	 lr=0.026483
Epoch[174] Batch [0149]/[0716]	Speed: 26.269208 samples/sec	 accuracy=73.964286	 loss=1.026539	 lr=0.026316
Epoch[174] Batch [0199]/[0716]	Speed: 26.078178 samples/sec	 accuracy=74.080357	 loss=1.029130	 lr=0.026150
Epoch[174] Batch [0249]/[0716]	Speed: 26.492167 samples/sec	 accuracy=74.057143	 loss=1.028247	 lr=0.025984
Epoch[174] Batch [0299]/[0716]	Speed: 26.079813 samples/sec	 accuracy=73.821429	 loss=1.040520	 lr=0.025819
Epoch[174] Batch [0349]/[0716]	Speed: 26.390494 samples/sec	 accuracy=73.551020	 loss=1.052065	 lr=0.025655
Epoch[174] Batch [0399]/[0716]	Speed: 25.882915 samples/sec	 accuracy=73.607143	 loss=1.049871	 lr=0.025491
Epoch[174] Batch [0449]/[0716]	Speed: 25.983639 samples/sec	 accuracy=73.571429	 loss=1.051434	 lr=0.025327
Epoch[174] Batch [0499]/[0716]	Speed: 25.951642 samples/sec	 accuracy=73.764286	 loss=1.045008	 lr=0.025164
Epoch[174] Batch [0549]/[0716]	Speed: 25.938846 samples/sec	 accuracy=73.581169	 loss=1.049779	 lr=0.025001
Epoch[174] Batch [0599]/[0716]	Speed: 25.915648 samples/sec	 accuracy=73.541667	 loss=1.052846	 lr=0.024839
Epoch[174] Batch [0649]/[0716]	Speed: 25.622723 samples/sec	 accuracy=73.453297	 loss=1.054547	 lr=0.024677
Epoch[174] Batch [0699]/[0716]	Speed: 26.116134 samples/sec	 accuracy=73.395408	 loss=1.057777	 lr=0.024516
Batch [0049]/[0057]: acc-top1=65.928571 acc-top5=86.357143
[Epoch 174] training: accuracy=73.326516	 loss=1.059772
[Epoch 174] speed: 26 samples/sec	time cost: 1602.587183
[Epoch 174] validation: acc-top1=65.946106 acc-top5=86.085007 loss=1.626634
Epoch[175] Batch [0049]/[0717]	Speed: 22.877740 samples/sec	 accuracy=72.321429	 loss=1.093256	 lr=0.024304
Epoch[175] Batch [0099]/[0717]	Speed: 26.554973 samples/sec	 accuracy=73.000000	 loss=1.064666	 lr=0.024144
Epoch[175] Batch [0149]/[0717]	Speed: 25.826447 samples/sec	 accuracy=73.500000	 loss=1.051342	 lr=0.023985
Epoch[175] Batch [0199]/[0717]	Speed: 26.063639 samples/sec	 accuracy=73.633929	 loss=1.043040	 lr=0.023826
Epoch[175] Batch [0249]/[0717]	Speed: 25.855003 samples/sec	 accuracy=73.650000	 loss=1.039828	 lr=0.023668
Epoch[175] Batch [0299]/[0717]	Speed: 25.854973 samples/sec	 accuracy=73.666667	 loss=1.041437	 lr=0.023510
Epoch[175] Batch [0349]/[0717]	Speed: 26.236592 samples/sec	 accuracy=73.709184	 loss=1.040394	 lr=0.023352
Epoch[175] Batch [0399]/[0717]	Speed: 26.104784 samples/sec	 accuracy=73.852679	 loss=1.040791	 lr=0.023195
Epoch[175] Batch [0449]/[0717]	Speed: 26.242107 samples/sec	 accuracy=73.789683	 loss=1.042282	 lr=0.023039
Epoch[175] Batch [0499]/[0717]	Speed: 26.148975 samples/sec	 accuracy=73.857143	 loss=1.038968	 lr=0.022883
Epoch[175] Batch [0549]/[0717]	Speed: 26.420782 samples/sec	 accuracy=74.003247	 loss=1.032185	 lr=0.022728
Epoch[175] Batch [0599]/[0717]	Speed: 25.918946 samples/sec	 accuracy=73.985119	 loss=1.032438	 lr=0.022573
Epoch[175] Batch [0649]/[0717]	Speed: 26.460622 samples/sec	 accuracy=73.837912	 loss=1.035178	 lr=0.022419
Epoch[175] Batch [0699]/[0717]	Speed: 26.097265 samples/sec	 accuracy=73.811224	 loss=1.035560	 lr=0.022265
Batch [0049]/[0057]: acc-top1=66.714286 acc-top5=85.571429
[Epoch 175] training: accuracy=73.772166	 loss=1.036807
[Epoch 175] speed: 26 samples/sec	time cost: 1603.372062
[Epoch 175] validation: acc-top1=66.280273 acc-top5=86.382629 loss=1.668609
Epoch[176] Batch [0049]/[0716]	Speed: 23.419842 samples/sec	 accuracy=73.392857	 loss=1.058146	 lr=0.022059
Epoch[176] Batch [0099]/[0716]	Speed: 25.998168 samples/sec	 accuracy=74.500000	 loss=1.009564	 lr=0.021907
Epoch[176] Batch [0149]/[0716]	Speed: 26.290350 samples/sec	 accuracy=74.666667	 loss=1.004495	 lr=0.021755
Epoch[176] Batch [0199]/[0716]	Speed: 25.973856 samples/sec	 accuracy=74.875000	 loss=0.995071	 lr=0.021603
Epoch[176] Batch [0249]/[0716]	Speed: 25.895177 samples/sec	 accuracy=74.821429	 loss=0.997192	 lr=0.021452
Epoch[176] Batch [0299]/[0716]	Speed: 25.819095 samples/sec	 accuracy=74.958333	 loss=0.991770	 lr=0.021301
Epoch[176] Batch [0349]/[0716]	Speed: 25.947361 samples/sec	 accuracy=75.091837	 loss=0.984889	 lr=0.021151
Epoch[176] Batch [0399]/[0716]	Speed: 26.035359 samples/sec	 accuracy=75.147321	 loss=0.984019	 lr=0.021002
Epoch[176] Batch [0449]/[0716]	Speed: 26.479282 samples/sec	 accuracy=75.007937	 loss=0.989185	 lr=0.020852
Epoch[176] Batch [0499]/[0716]	Speed: 25.923141 samples/sec	 accuracy=74.925000	 loss=0.991814	 lr=0.020704
Epoch[176] Batch [0549]/[0716]	Speed: 26.545653 samples/sec	 accuracy=74.909091	 loss=0.994157	 lr=0.020556
Epoch[176] Batch [0599]/[0716]	Speed: 26.086697 samples/sec	 accuracy=74.922619	 loss=0.992789	 lr=0.020408
Epoch[176] Batch [0649]/[0716]	Speed: 25.937320 samples/sec	 accuracy=74.837912	 loss=0.994159	 lr=0.020261
Epoch[176] Batch [0699]/[0716]	Speed: 25.401506 samples/sec	 accuracy=74.783163	 loss=0.994619	 lr=0.020115
Batch [0049]/[0057]: acc-top1=65.785714 acc-top5=86.250000
[Epoch 176] training: accuracy=74.773045	 loss=0.995385
[Epoch 176] speed: 26 samples/sec	time cost: 1603.774513
[Epoch 176] validation: acc-top1=66.478691 acc-top5=86.372185 loss=1.643527
Epoch[177] Batch [0049]/[0716]	Speed: 22.959274 samples/sec	 accuracy=75.285714	 loss=0.979581	 lr=0.019922
Epoch[177] Batch [0099]/[0716]	Speed: 25.675826 samples/sec	 accuracy=75.053571	 loss=0.992955	 lr=0.019777
Epoch[177] Batch [0149]/[0716]	Speed: 26.225198 samples/sec	 accuracy=74.380952	 loss=1.008884	 lr=0.019632
Epoch[177] Batch [0199]/[0716]	Speed: 25.738195 samples/sec	 accuracy=74.857143	 loss=0.991351	 lr=0.019488
Epoch[177] Batch [0249]/[0716]	Speed: 25.828854 samples/sec	 accuracy=75.307143	 loss=0.978754	 lr=0.019344
Epoch[177] Batch [0299]/[0716]	Speed: 26.070742 samples/sec	 accuracy=75.226190	 loss=0.976608	 lr=0.019201
Epoch[177] Batch [0349]/[0716]	Speed: 26.001096 samples/sec	 accuracy=75.311224	 loss=0.977532	 lr=0.019058
Epoch[177] Batch [0399]/[0716]	Speed: 26.059100 samples/sec	 accuracy=75.410714	 loss=0.972879	 lr=0.018916
Epoch[177] Batch [0449]/[0716]	Speed: 25.590969 samples/sec	 accuracy=75.412698	 loss=0.972276	 lr=0.018774
Epoch[177] Batch [0499]/[0716]	Speed: 26.202636 samples/sec	 accuracy=75.325000	 loss=0.976783	 lr=0.018633
Epoch[177] Batch [0549]/[0716]	Speed: 26.031487 samples/sec	 accuracy=75.353896	 loss=0.974951	 lr=0.018492
Epoch[177] Batch [0599]/[0716]	Speed: 26.273180 samples/sec	 accuracy=75.485119	 loss=0.971400	 lr=0.018352
Epoch[177] Batch [0649]/[0716]	Speed: 25.725638 samples/sec	 accuracy=75.502747	 loss=0.969893	 lr=0.018212
Epoch[177] Batch [0699]/[0716]	Speed: 25.897686 samples/sec	 accuracy=75.545918	 loss=0.968821	 lr=0.018073
Batch [0049]/[0057]: acc-top1=66.321429 acc-top5=86.535714
[Epoch 177] training: accuracy=75.586093	 loss=0.968734
[Epoch 177] speed: 25 samples/sec	time cost: 1610.834152
[Epoch 177] validation: acc-top1=66.917297 acc-top5=86.737679 loss=1.617292
Epoch[178] Batch [0049]/[0716]	Speed: 22.922802 samples/sec	 accuracy=77.285714	 loss=0.900357	 lr=0.017890
Epoch[178] Batch [0099]/[0716]	Speed: 26.054566 samples/sec	 accuracy=76.142857	 loss=0.930330	 lr=0.017752
Epoch[178] Batch [0149]/[0716]	Speed: 25.861079 samples/sec	 accuracy=76.857143	 loss=0.919520	 lr=0.017615
Epoch[178] Batch [0199]/[0716]	Speed: 26.412428 samples/sec	 accuracy=76.785714	 loss=0.922003	 lr=0.017478
Epoch[178] Batch [0249]/[0716]	Speed: 25.994119 samples/sec	 accuracy=76.821429	 loss=0.917635	 lr=0.017342
Epoch[178] Batch [0299]/[0716]	Speed: 25.806261 samples/sec	 accuracy=76.666667	 loss=0.920145	 lr=0.017206
Epoch[178] Batch [0349]/[0716]	Speed: 26.147844 samples/sec	 accuracy=76.658163	 loss=0.921260	 lr=0.017070
Epoch[178] Batch [0399]/[0716]	Speed: 26.037676 samples/sec	 accuracy=76.508929	 loss=0.926065	 lr=0.016935
Epoch[178] Batch [0449]/[0716]	Speed: 26.534280 samples/sec	 accuracy=76.519841	 loss=0.925741	 lr=0.016801
Epoch[178] Batch [0499]/[0716]	Speed: 26.702973 samples/sec	 accuracy=76.500000	 loss=0.928565	 lr=0.016667
Epoch[178] Batch [0549]/[0716]	Speed: 26.065061 samples/sec	 accuracy=76.383117	 loss=0.932865	 lr=0.016534
Epoch[178] Batch [0599]/[0716]	Speed: 25.933433 samples/sec	 accuracy=76.214286	 loss=0.936904	 lr=0.016401
Epoch[178] Batch [0649]/[0716]	Speed: 25.352323 samples/sec	 accuracy=76.173077	 loss=0.937442	 lr=0.016269
Epoch[178] Batch [0699]/[0716]	Speed: 26.073803 samples/sec	 accuracy=76.091837	 loss=0.940175	 lr=0.016137
Batch [0049]/[0057]: acc-top1=67.428571 acc-top5=86.714286
[Epoch 178] training: accuracy=76.117318	 loss=0.939857
[Epoch 178] speed: 26 samples/sec	time cost: 1603.329882
[Epoch 178] validation: acc-top1=67.314117 acc-top5=86.680244 loss=1.624144
Epoch[179] Batch [0049]/[0716]	Speed: 23.202872 samples/sec	 accuracy=75.571429	 loss=0.969203	 lr=0.015964
Epoch[179] Batch [0099]/[0716]	Speed: 25.870863 samples/sec	 accuracy=75.910714	 loss=0.939029	 lr=0.015834
Epoch[179] Batch [0149]/[0716]	Speed: 26.287226 samples/sec	 accuracy=75.988095	 loss=0.941883	 lr=0.015704
Epoch[179] Batch [0199]/[0716]	Speed: 26.249153 samples/sec	 accuracy=76.178571	 loss=0.935506	 lr=0.015574
Epoch[179] Batch [0249]/[0716]	Speed: 26.172039 samples/sec	 accuracy=76.250000	 loss=0.935189	 lr=0.015445
Epoch[179] Batch [0299]/[0716]	Speed: 25.744717 samples/sec	 accuracy=76.511905	 loss=0.921846	 lr=0.015317
Epoch[179] Batch [0349]/[0716]	Speed: 26.286922 samples/sec	 accuracy=76.663265	 loss=0.918877	 lr=0.015189
Epoch[179] Batch [0399]/[0716]	Speed: 25.884898 samples/sec	 accuracy=76.674107	 loss=0.917085	 lr=0.015062
Epoch[179] Batch [0449]/[0716]	Speed: 26.423446 samples/sec	 accuracy=76.619048	 loss=0.918414	 lr=0.014935
Epoch[179] Batch [0499]/[0716]	Speed: 26.026209 samples/sec	 accuracy=76.685714	 loss=0.916331	 lr=0.014809
Epoch[179] Batch [0549]/[0716]	Speed: 26.214155 samples/sec	 accuracy=76.792208	 loss=0.914676	 lr=0.014683
Epoch[179] Batch [0599]/[0716]	Speed: 25.638813 samples/sec	 accuracy=76.797619	 loss=0.912756	 lr=0.014558
Epoch[179] Batch [0649]/[0716]	Speed: 25.768152 samples/sec	 accuracy=76.763736	 loss=0.913550	 lr=0.014433
Epoch[179] Batch [0699]/[0716]	Speed: 26.352163 samples/sec	 accuracy=76.632653	 loss=0.918597	 lr=0.014309
Batch [0049]/[0057]: acc-top1=67.357143 acc-top5=86.678571
[Epoch 179] training: accuracy=76.626097	 loss=0.917803
[Epoch 179] speed: 26 samples/sec	time cost: 1602.787073
[Epoch 179] validation: acc-top1=67.371552 acc-top5=87.030075 loss=1.630648
Epoch[180] Batch [0049]/[0716]	Speed: 23.139284 samples/sec	 accuracy=76.821429	 loss=0.903936	 lr=0.014145
Epoch[180] Batch [0099]/[0716]	Speed: 26.022454 samples/sec	 accuracy=77.357143	 loss=0.891527	 lr=0.014022
Epoch[180] Batch [0149]/[0716]	Speed: 26.003390 samples/sec	 accuracy=77.845238	 loss=0.862142	 lr=0.013900
Epoch[180] Batch [0199]/[0716]	Speed: 25.993845 samples/sec	 accuracy=78.017857	 loss=0.855075	 lr=0.013778
Epoch[180] Batch [0249]/[0716]	Speed: 26.046196 samples/sec	 accuracy=77.885714	 loss=0.869804	 lr=0.013656
Epoch[180] Batch [0299]/[0716]	Speed: 26.061534 samples/sec	 accuracy=78.005952	 loss=0.863991	 lr=0.013535
Epoch[180] Batch [0349]/[0716]	Speed: 26.433842 samples/sec	 accuracy=77.923469	 loss=0.864498	 lr=0.013415
Epoch[180] Batch [0399]/[0716]	Speed: 26.059903 samples/sec	 accuracy=77.785714	 loss=0.868086	 lr=0.013295
Epoch[180] Batch [0449]/[0716]	Speed: 25.968186 samples/sec	 accuracy=77.833333	 loss=0.871082	 lr=0.013176
Epoch[180] Batch [0499]/[0716]	Speed: 26.012976 samples/sec	 accuracy=77.707143	 loss=0.878284	 lr=0.013057
Epoch[180] Batch [0549]/[0716]	Speed: 26.058015 samples/sec	 accuracy=77.678571	 loss=0.876464	 lr=0.012939
Epoch[180] Batch [0599]/[0716]	Speed: 26.042453 samples/sec	 accuracy=77.708333	 loss=0.877098	 lr=0.012821
Epoch[180] Batch [0649]/[0716]	Speed: 26.348282 samples/sec	 accuracy=77.673077	 loss=0.875353	 lr=0.012704
Epoch[180] Batch [0699]/[0716]	Speed: 26.335670 samples/sec	 accuracy=77.663265	 loss=0.877744	 lr=0.012587
Batch [0049]/[0057]: acc-top1=67.714286 acc-top5=87.821429
[Epoch 180] training: accuracy=77.671089	 loss=0.877792
[Epoch 180] speed: 26 samples/sec	time cost: 1602.001294
[Epoch 180] validation: acc-top1=67.700508 acc-top5=86.993530 loss=1.604697
Epoch[181] Batch [0049]/[0716]	Speed: 23.120481 samples/sec	 accuracy=78.285714	 loss=0.828191	 lr=0.012434
Epoch[181] Batch [0099]/[0716]	Speed: 26.277116 samples/sec	 accuracy=78.142857	 loss=0.841774	 lr=0.012318
Epoch[181] Batch [0149]/[0716]	Speed: 25.842471 samples/sec	 accuracy=78.238095	 loss=0.840846	 lr=0.012203
Epoch[181] Batch [0199]/[0716]	Speed: 26.098811 samples/sec	 accuracy=78.455357	 loss=0.841415	 lr=0.012089
Epoch[181] Batch [0249]/[0716]	Speed: 26.260056 samples/sec	 accuracy=78.071429	 loss=0.852725	 lr=0.011975
Epoch[181] Batch [0299]/[0716]	Speed: 26.458572 samples/sec	 accuracy=78.166667	 loss=0.850628	 lr=0.011862
Epoch[181] Batch [0349]/[0716]	Speed: 25.854005 samples/sec	 accuracy=78.137755	 loss=0.851158	 lr=0.011749
Epoch[181] Batch [0399]/[0716]	Speed: 25.890761 samples/sec	 accuracy=78.191964	 loss=0.850256	 lr=0.011636
Epoch[181] Batch [0449]/[0716]	Speed: 26.576222 samples/sec	 accuracy=78.071429	 loss=0.852569	 lr=0.011525
Epoch[181] Batch [0499]/[0716]	Speed: 25.969383 samples/sec	 accuracy=78.275000	 loss=0.847957	 lr=0.011413
Epoch[181] Batch [0549]/[0716]	Speed: 26.383174 samples/sec	 accuracy=78.256494	 loss=0.849110	 lr=0.011303
Epoch[181] Batch [0599]/[0716]	Speed: 26.479347 samples/sec	 accuracy=78.383929	 loss=0.848154	 lr=0.011192
Epoch[181] Batch [0649]/[0716]	Speed: 25.932227 samples/sec	 accuracy=78.417582	 loss=0.845831	 lr=0.011083
Epoch[181] Batch [0699]/[0716]	Speed: 26.021838 samples/sec	 accuracy=78.469388	 loss=0.844740	 lr=0.010974
Batch [0049]/[0057]: acc-top1=66.607143 acc-top5=87.892857
[Epoch 181] training: accuracy=78.491620	 loss=0.844952
[Epoch 181] speed: 26 samples/sec	time cost: 1596.225785
[Epoch 181] validation: acc-top1=67.919800 acc-top5=86.962196 loss=1.605520
Epoch[182] Batch [0049]/[0716]	Speed: 23.705464 samples/sec	 accuracy=78.571429	 loss=0.846659	 lr=0.010830
Epoch[182] Batch [0099]/[0716]	Speed: 26.011720 samples/sec	 accuracy=78.625000	 loss=0.837098	 lr=0.010723
Epoch[182] Batch [0149]/[0716]	Speed: 26.274585 samples/sec	 accuracy=78.333333	 loss=0.856064	 lr=0.010615
Epoch[182] Batch [0199]/[0716]	Speed: 25.778323 samples/sec	 accuracy=78.276786	 loss=0.855571	 lr=0.010508
Epoch[182] Batch [0249]/[0716]	Speed: 26.019985 samples/sec	 accuracy=78.371429	 loss=0.851388	 lr=0.010402
Epoch[182] Batch [0299]/[0716]	Speed: 26.121419 samples/sec	 accuracy=78.386905	 loss=0.850154	 lr=0.010296
Epoch[182] Batch [0349]/[0716]	Speed: 26.243749 samples/sec	 accuracy=78.413265	 loss=0.850691	 lr=0.010191
Epoch[182] Batch [0399]/[0716]	Speed: 25.916992 samples/sec	 accuracy=78.633929	 loss=0.845558	 lr=0.010086
Epoch[182] Batch [0449]/[0716]	Speed: 25.677403 samples/sec	 accuracy=78.607143	 loss=0.843567	 lr=0.009982
Epoch[182] Batch [0499]/[0716]	Speed: 26.378110 samples/sec	 accuracy=78.775000	 loss=0.838028	 lr=0.009878
Epoch[182] Batch [0549]/[0716]	Speed: 26.537168 samples/sec	 accuracy=78.717532	 loss=0.841770	 lr=0.009775
Epoch[182] Batch [0599]/[0716]	Speed: 26.004818 samples/sec	 accuracy=78.693452	 loss=0.842645	 lr=0.009673
Epoch[182] Batch [0649]/[0716]	Speed: 26.294456 samples/sec	 accuracy=78.741758	 loss=0.838779	 lr=0.009571
Epoch[182] Batch [0699]/[0716]	Speed: 25.756261 samples/sec	 accuracy=78.821429	 loss=0.835919	 lr=0.009469
Batch [0049]/[0057]: acc-top1=68.678571 acc-top5=87.642857
[Epoch 182] training: accuracy=78.833300	 loss=0.835301
[Epoch 182] speed: 26 samples/sec	time cost: 1600.714018
[Epoch 182] validation: acc-top1=67.909355 acc-top5=87.280701 loss=1.621893
Epoch[183] Batch [0049]/[0717]	Speed: 23.013876 samples/sec	 accuracy=81.428571	 loss=0.735629	 lr=0.009336
Epoch[183] Batch [0099]/[0717]	Speed: 26.404282 samples/sec	 accuracy=80.785714	 loss=0.755034	 lr=0.009235
Epoch[183] Batch [0149]/[0717]	Speed: 25.912578 samples/sec	 accuracy=80.690476	 loss=0.770339	 lr=0.009136
Epoch[183] Batch [0199]/[0717]	Speed: 26.266312 samples/sec	 accuracy=80.526786	 loss=0.780029	 lr=0.009036
Epoch[183] Batch [0249]/[0717]	Speed: 26.293290 samples/sec	 accuracy=80.164286	 loss=0.788609	 lr=0.008938
Epoch[183] Batch [0299]/[0717]	Speed: 26.130888 samples/sec	 accuracy=80.089286	 loss=0.791668	 lr=0.008840
Epoch[183] Batch [0349]/[0717]	Speed: 26.266407 samples/sec	 accuracy=80.005102	 loss=0.796588	 lr=0.008742
Epoch[183] Batch [0399]/[0717]	Speed: 26.254983 samples/sec	 accuracy=80.107143	 loss=0.791371	 lr=0.008645
Epoch[183] Batch [0449]/[0717]	Speed: 26.103693 samples/sec	 accuracy=80.000000	 loss=0.793108	 lr=0.008548
Epoch[183] Batch [0499]/[0717]	Speed: 26.008319 samples/sec	 accuracy=80.025000	 loss=0.787877	 lr=0.008452
Epoch[183] Batch [0549]/[0717]	Speed: 26.070748 samples/sec	 accuracy=79.961039	 loss=0.790985	 lr=0.008357
Epoch[183] Batch [0599]/[0717]	Speed: 26.053116 samples/sec	 accuracy=79.880952	 loss=0.794623	 lr=0.008262
Epoch[183] Batch [0649]/[0717]	Speed: 25.900053 samples/sec	 accuracy=79.862637	 loss=0.795050	 lr=0.008167
Epoch[183] Batch [0699]/[0717]	Speed: 26.279502 samples/sec	 accuracy=79.872449	 loss=0.795006	 lr=0.008074
Batch [0049]/[0057]: acc-top1=67.321429 acc-top5=87.500000
[Epoch 183] training: accuracy=79.864017	 loss=0.794946
[Epoch 183] speed: 26 samples/sec	time cost: 1601.633394
[Epoch 183] validation: acc-top1=68.066002 acc-top5=87.296364 loss=1.588425
Epoch[184] Batch [0049]/[0716]	Speed: 23.667808 samples/sec	 accuracy=79.964286	 loss=0.802126	 lr=0.007949
Epoch[184] Batch [0099]/[0716]	Speed: 26.403049 samples/sec	 accuracy=80.714286	 loss=0.790846	 lr=0.007856
Epoch[184] Batch [0149]/[0716]	Speed: 26.276367 samples/sec	 accuracy=80.452381	 loss=0.796389	 lr=0.007764
Epoch[184] Batch [0199]/[0716]	Speed: 26.083549 samples/sec	 accuracy=80.357143	 loss=0.788613	 lr=0.007672
Epoch[184] Batch [0249]/[0716]	Speed: 25.739832 samples/sec	 accuracy=80.321429	 loss=0.785504	 lr=0.007581
Epoch[184] Batch [0299]/[0716]	Speed: 26.346514 samples/sec	 accuracy=80.202381	 loss=0.782944	 lr=0.007491
Epoch[184] Batch [0349]/[0716]	Speed: 26.285109 samples/sec	 accuracy=80.311224	 loss=0.775506	 lr=0.007401
Epoch[184] Batch [0399]/[0716]	Speed: 26.076848 samples/sec	 accuracy=80.392857	 loss=0.773284	 lr=0.007311
Epoch[184] Batch [0449]/[0716]	Speed: 26.444090 samples/sec	 accuracy=80.277778	 loss=0.776957	 lr=0.007223
Epoch[184] Batch [0499]/[0716]	Speed: 25.903112 samples/sec	 accuracy=80.264286	 loss=0.776595	 lr=0.007134
Epoch[184] Batch [0549]/[0716]	Speed: 26.133263 samples/sec	 accuracy=80.282468	 loss=0.776773	 lr=0.007046
Epoch[184] Batch [0599]/[0716]	Speed: 26.304456 samples/sec	 accuracy=80.255952	 loss=0.775930	 lr=0.006959
Epoch[184] Batch [0649]/[0716]	Speed: 26.307222 samples/sec	 accuracy=80.280220	 loss=0.775952	 lr=0.006872
Epoch[184] Batch [0699]/[0716]	Speed: 26.054401 samples/sec	 accuracy=80.329082	 loss=0.772760	 lr=0.006786
Batch [0049]/[0057]: acc-top1=67.857143 acc-top5=87.785714
[Epoch 184] training: accuracy=80.364625	 loss=0.770720
[Epoch 184] speed: 26 samples/sec	time cost: 1593.981218
[Epoch 184] validation: acc-top1=68.410614 acc-top5=87.265038 loss=1.573905
Epoch[185] Batch [0049]/[0716]	Speed: 22.915911 samples/sec	 accuracy=81.250000	 loss=0.715366	 lr=0.006673
Epoch[185] Batch [0099]/[0716]	Speed: 25.867785 samples/sec	 accuracy=82.017857	 loss=0.697668	 lr=0.006588
Epoch[185] Batch [0149]/[0716]	Speed: 26.239591 samples/sec	 accuracy=81.666667	 loss=0.705230	 lr=0.006504
Epoch[185] Batch [0199]/[0716]	Speed: 26.309520 samples/sec	 accuracy=82.062500	 loss=0.697992	 lr=0.006420
Epoch[185] Batch [0249]/[0716]	Speed: 25.996621 samples/sec	 accuracy=81.757143	 loss=0.707978	 lr=0.006337
Epoch[185] Batch [0299]/[0716]	Speed: 26.084233 samples/sec	 accuracy=81.779762	 loss=0.710639	 lr=0.006254
Epoch[185] Batch [0349]/[0716]	Speed: 26.301485 samples/sec	 accuracy=81.551020	 loss=0.716352	 lr=0.006172
Epoch[185] Batch [0399]/[0716]	Speed: 25.920702 samples/sec	 accuracy=81.441964	 loss=0.720836	 lr=0.006090
Epoch[185] Batch [0449]/[0716]	Speed: 25.839538 samples/sec	 accuracy=81.420635	 loss=0.720600	 lr=0.006009
Epoch[185] Batch [0499]/[0716]	Speed: 26.149014 samples/sec	 accuracy=81.557143	 loss=0.716825	 lr=0.005928
Epoch[185] Batch [0549]/[0716]	Speed: 26.175305 samples/sec	 accuracy=81.360390	 loss=0.721812	 lr=0.005848
Epoch[185] Batch [0599]/[0716]	Speed: 25.919116 samples/sec	 accuracy=81.333333	 loss=0.723109	 lr=0.005768
Epoch[185] Batch [0649]/[0716]	Speed: 25.855938 samples/sec	 accuracy=81.236264	 loss=0.725876	 lr=0.005689
Epoch[185] Batch [0699]/[0716]	Speed: 26.340367 samples/sec	 accuracy=81.214286	 loss=0.726563	 lr=0.005611
Batch [0049]/[0057]: acc-top1=68.285714 acc-top5=86.571429
[Epoch 185] training: accuracy=81.240024	 loss=0.726158
[Epoch 185] speed: 26 samples/sec	time cost: 1603.135146
[Epoch 185] validation: acc-top1=68.415833 acc-top5=87.567879 loss=1.601925
Epoch[186] Batch [0049]/[0716]	Speed: 23.162203 samples/sec	 accuracy=82.071429	 loss=0.717179	 lr=0.005508
Epoch[186] Batch [0099]/[0716]	Speed: 26.209784 samples/sec	 accuracy=81.625000	 loss=0.731542	 lr=0.005431
Epoch[186] Batch [0149]/[0716]	Speed: 26.191662 samples/sec	 accuracy=81.333333	 loss=0.738723	 lr=0.005354
Epoch[186] Batch [0199]/[0716]	Speed: 26.131568 samples/sec	 accuracy=81.553571	 loss=0.735545	 lr=0.005278
Epoch[186] Batch [0249]/[0716]	Speed: 26.089573 samples/sec	 accuracy=81.657143	 loss=0.730200	 lr=0.005203
Epoch[186] Batch [0299]/[0716]	Speed: 26.051816 samples/sec	 accuracy=81.565476	 loss=0.734415	 lr=0.005127
Epoch[186] Batch [0349]/[0716]	Speed: 25.740889 samples/sec	 accuracy=81.632653	 loss=0.731164	 lr=0.005053
Epoch[186] Batch [0399]/[0716]	Speed: 25.844988 samples/sec	 accuracy=81.718750	 loss=0.726898	 lr=0.004979
Epoch[186] Batch [0449]/[0716]	Speed: 25.991857 samples/sec	 accuracy=81.714286	 loss=0.729129	 lr=0.004906
Epoch[186] Batch [0499]/[0716]	Speed: 26.240970 samples/sec	 accuracy=81.653571	 loss=0.728983	 lr=0.004833
Epoch[186] Batch [0549]/[0716]	Speed: 26.364761 samples/sec	 accuracy=81.590909	 loss=0.730761	 lr=0.004760
Epoch[186] Batch [0599]/[0716]	Speed: 26.303584 samples/sec	 accuracy=81.627976	 loss=0.729530	 lr=0.004688
Epoch[186] Batch [0649]/[0716]	Speed: 26.321513 samples/sec	 accuracy=81.516484	 loss=0.732335	 lr=0.004617
Epoch[186] Batch [0699]/[0716]	Speed: 25.644760 samples/sec	 accuracy=81.589286	 loss=0.728266	 lr=0.004546
Batch [0049]/[0057]: acc-top1=68.428571 acc-top5=87.285714
[Epoch 186] training: accuracy=81.589186	 loss=0.728765
[Epoch 186] speed: 26 samples/sec	time cost: 1600.265389
[Epoch 186] validation: acc-top1=68.703011 acc-top5=87.593987 loss=1.589565
Epoch[187] Batch [0049]/[0716]	Speed: 23.310923 samples/sec	 accuracy=82.821429	 loss=0.677723	 lr=0.004454
Epoch[187] Batch [0099]/[0716]	Speed: 25.843185 samples/sec	 accuracy=81.214286	 loss=0.729654	 lr=0.004384
Epoch[187] Batch [0149]/[0716]	Speed: 26.684688 samples/sec	 accuracy=81.880952	 loss=0.710103	 lr=0.004316
Epoch[187] Batch [0199]/[0716]	Speed: 26.151722 samples/sec	 accuracy=82.071429	 loss=0.706161	 lr=0.004247
Epoch[187] Batch [0249]/[0716]	Speed: 25.555506 samples/sec	 accuracy=81.771429	 loss=0.722377	 lr=0.004179
Epoch[187] Batch [0299]/[0716]	Speed: 26.165566 samples/sec	 accuracy=81.851190	 loss=0.721596	 lr=0.004112
Epoch[187] Batch [0349]/[0716]	Speed: 26.345295 samples/sec	 accuracy=81.765306	 loss=0.721053	 lr=0.004045
Epoch[187] Batch [0399]/[0716]	Speed: 26.046254 samples/sec	 accuracy=81.839286	 loss=0.720433	 lr=0.003979
Epoch[187] Batch [0449]/[0716]	Speed: 25.894062 samples/sec	 accuracy=81.809524	 loss=0.721135	 lr=0.003913
Epoch[187] Batch [0499]/[0716]	Speed: 25.973031 samples/sec	 accuracy=81.807143	 loss=0.721162	 lr=0.003848
Epoch[187] Batch [0549]/[0716]	Speed: 26.342193 samples/sec	 accuracy=81.896104	 loss=0.718057	 lr=0.003784
Epoch[187] Batch [0599]/[0716]	Speed: 26.178603 samples/sec	 accuracy=81.943452	 loss=0.717896	 lr=0.003720
Epoch[187] Batch [0649]/[0716]	Speed: 26.066402 samples/sec	 accuracy=81.901099	 loss=0.718658	 lr=0.003656
Epoch[187] Batch [0699]/[0716]	Speed: 26.364072 samples/sec	 accuracy=81.964286	 loss=0.715548	 lr=0.003593
Batch [0049]/[0057]: acc-top1=68.714286 acc-top5=87.607143
[Epoch 187] training: accuracy=82.010674	 loss=0.713721
[Epoch 187] speed: 26 samples/sec	time cost: 1599.388023
[Epoch 187] validation: acc-top1=68.609024 acc-top5=87.557434 loss=1.576458
Epoch[188] Batch [0049]/[0716]	Speed: 22.995169 samples/sec	 accuracy=82.178571	 loss=0.704695	 lr=0.003511
Epoch[188] Batch [0099]/[0716]	Speed: 25.785898 samples/sec	 accuracy=82.053571	 loss=0.704515	 lr=0.003449
Epoch[188] Batch [0149]/[0716]	Speed: 26.312914 samples/sec	 accuracy=81.952381	 loss=0.705470	 lr=0.003388
Epoch[188] Batch [0199]/[0716]	Speed: 25.957840 samples/sec	 accuracy=82.178571	 loss=0.698651	 lr=0.003327
Epoch[188] Batch [0249]/[0716]	Speed: 26.360784 samples/sec	 accuracy=82.542857	 loss=0.692621	 lr=0.003267
Epoch[188] Batch [0299]/[0716]	Speed: 25.968680 samples/sec	 accuracy=82.488095	 loss=0.693035	 lr=0.003208
Epoch[188] Batch [0349]/[0716]	Speed: 25.969638 samples/sec	 accuracy=82.188776	 loss=0.701929	 lr=0.003149
Epoch[188] Batch [0399]/[0716]	Speed: 26.564467 samples/sec	 accuracy=82.285714	 loss=0.699613	 lr=0.003090
Epoch[188] Batch [0449]/[0716]	Speed: 25.937794 samples/sec	 accuracy=82.261905	 loss=0.700566	 lr=0.003032
Epoch[188] Batch [0499]/[0716]	Speed: 26.640014 samples/sec	 accuracy=82.357143	 loss=0.699658	 lr=0.002975
Epoch[188] Batch [0549]/[0716]	Speed: 25.545522 samples/sec	 accuracy=82.331169	 loss=0.699631	 lr=0.002918
Epoch[188] Batch [0599]/[0716]	Speed: 25.916934 samples/sec	 accuracy=82.380952	 loss=0.696112	 lr=0.002862
Epoch[188] Batch [0649]/[0716]	Speed: 26.154036 samples/sec	 accuracy=82.447802	 loss=0.693039	 lr=0.002806
Epoch[188] Batch [0699]/[0716]	Speed: 25.822874 samples/sec	 accuracy=82.443878	 loss=0.694522	 lr=0.002751
Batch [0049]/[0057]: acc-top1=68.785714 acc-top5=88.035714
[Epoch 188] training: accuracy=82.452115	 loss=0.693630
[Epoch 188] speed: 26 samples/sec	time cost: 1603.318520
[Epoch 188] validation: acc-top1=68.823097 acc-top5=87.813278 loss=1.581650
Epoch[189] Batch [0049]/[0716]	Speed: 23.158514 samples/sec	 accuracy=84.392857	 loss=0.609884	 lr=0.002679
Epoch[189] Batch [0099]/[0716]	Speed: 25.828187 samples/sec	 accuracy=83.875000	 loss=0.632964	 lr=0.002625
Epoch[189] Batch [0149]/[0716]	Speed: 26.089401 samples/sec	 accuracy=83.845238	 loss=0.637180	 lr=0.002572
Epoch[189] Batch [0199]/[0716]	Speed: 25.986464 samples/sec	 accuracy=83.526786	 loss=0.654980	 lr=0.002519
Epoch[189] Batch [0249]/[0716]	Speed: 25.946488 samples/sec	 accuracy=83.485714	 loss=0.661462	 lr=0.002467
Epoch[189] Batch [0299]/[0716]	Speed: 26.021622 samples/sec	 accuracy=83.232143	 loss=0.667648	 lr=0.002415
Epoch[189] Batch [0349]/[0716]	Speed: 26.124853 samples/sec	 accuracy=83.178571	 loss=0.671236	 lr=0.002364
Epoch[189] Batch [0399]/[0716]	Speed: 25.833599 samples/sec	 accuracy=83.165179	 loss=0.673204	 lr=0.002313
Epoch[189] Batch [0449]/[0716]	Speed: 26.379219 samples/sec	 accuracy=83.079365	 loss=0.672556	 lr=0.002263
Epoch[189] Batch [0499]/[0716]	Speed: 26.018913 samples/sec	 accuracy=83.071429	 loss=0.669775	 lr=0.002214
Epoch[189] Batch [0549]/[0716]	Speed: 26.148380 samples/sec	 accuracy=83.058442	 loss=0.669257	 lr=0.002165
Epoch[189] Batch [0599]/[0716]	Speed: 25.875534 samples/sec	 accuracy=83.101190	 loss=0.669772	 lr=0.002116
Epoch[189] Batch [0649]/[0716]	Speed: 26.325263 samples/sec	 accuracy=83.016484	 loss=0.671543	 lr=0.002068
Epoch[189] Batch [0699]/[0716]	Speed: 26.050288 samples/sec	 accuracy=83.040816	 loss=0.671272	 lr=0.002021
Batch [0049]/[0057]: acc-top1=70.142857 acc-top5=88.250000
[Epoch 189] training: accuracy=83.043196	 loss=0.670811
[Epoch 189] speed: 25 samples/sec	time cost: 1605.412790
[Epoch 189] validation: acc-top1=69.037178 acc-top5=87.677528 loss=1.572701
Epoch[190] Batch [0049]/[0716]	Speed: 22.977969 samples/sec	 accuracy=83.678571	 loss=0.645087	 lr=0.001959
Epoch[190] Batch [0099]/[0716]	Speed: 26.258232 samples/sec	 accuracy=83.500000	 loss=0.650214	 lr=0.001913
Epoch[190] Batch [0149]/[0716]	Speed: 26.155424 samples/sec	 accuracy=83.595238	 loss=0.654394	 lr=0.001868
Epoch[190] Batch [0199]/[0716]	Speed: 26.358674 samples/sec	 accuracy=83.875000	 loss=0.643371	 lr=0.001823
Epoch[190] Batch [0249]/[0716]	Speed: 26.162155 samples/sec	 accuracy=83.471429	 loss=0.656445	 lr=0.001778
Epoch[190] Batch [0299]/[0716]	Speed: 25.948517 samples/sec	 accuracy=83.404762	 loss=0.660025	 lr=0.001734
Epoch[190] Batch [0349]/[0716]	Speed: 25.871642 samples/sec	 accuracy=83.438776	 loss=0.655483	 lr=0.001691
Epoch[190] Batch [0399]/[0716]	Speed: 25.834861 samples/sec	 accuracy=83.312500	 loss=0.659272	 lr=0.001648
Epoch[190] Batch [0449]/[0716]	Speed: 25.922155 samples/sec	 accuracy=83.210317	 loss=0.660733	 lr=0.001606
Epoch[190] Batch [0499]/[0716]	Speed: 26.247922 samples/sec	 accuracy=83.267857	 loss=0.658950	 lr=0.001564
Epoch[190] Batch [0549]/[0716]	Speed: 25.637838 samples/sec	 accuracy=83.357143	 loss=0.655966	 lr=0.001523
Epoch[190] Batch [0599]/[0716]	Speed: 25.694042 samples/sec	 accuracy=83.336310	 loss=0.654351	 lr=0.001482
Epoch[190] Batch [0649]/[0716]	Speed: 25.919442 samples/sec	 accuracy=83.288462	 loss=0.655069	 lr=0.001442
Epoch[190] Batch [0699]/[0716]	Speed: 26.228962 samples/sec	 accuracy=83.321429	 loss=0.653926	 lr=0.001403
Batch [0049]/[0057]: acc-top1=67.250000 acc-top5=86.214286
[Epoch 190] training: accuracy=83.357442	 loss=0.652224
[Epoch 190] speed: 25 samples/sec	time cost: 1606.145962
[Epoch 190] validation: acc-top1=69.110275 acc-top5=87.865494 loss=1.562394
Epoch[191] Batch [0049]/[0717]	Speed: 23.151846 samples/sec	 accuracy=82.285714	 loss=0.688888	 lr=0.001352
Epoch[191] Batch [0099]/[0717]	Speed: 26.048993 samples/sec	 accuracy=82.857143	 loss=0.668270	 lr=0.001313
Epoch[191] Batch [0149]/[0717]	Speed: 26.562095 samples/sec	 accuracy=83.023810	 loss=0.657671	 lr=0.001276
Epoch[191] Batch [0199]/[0717]	Speed: 25.932075 samples/sec	 accuracy=83.116071	 loss=0.656103	 lr=0.001238
Epoch[191] Batch [0249]/[0717]	Speed: 26.216303 samples/sec	 accuracy=83.385714	 loss=0.652665	 lr=0.001202
Epoch[191] Batch [0299]/[0717]	Speed: 26.158299 samples/sec	 accuracy=83.392857	 loss=0.654937	 lr=0.001166
Epoch[191] Batch [0349]/[0717]	Speed: 26.438104 samples/sec	 accuracy=83.413265	 loss=0.653413	 lr=0.001130
Epoch[191] Batch [0399]/[0717]	Speed: 25.983484 samples/sec	 accuracy=83.580357	 loss=0.646646	 lr=0.001095
Epoch[191] Batch [0449]/[0717]	Speed: 26.079423 samples/sec	 accuracy=83.706349	 loss=0.642733	 lr=0.001061
Epoch[191] Batch [0499]/[0717]	Speed: 26.053760 samples/sec	 accuracy=83.657143	 loss=0.642207	 lr=0.001027
Epoch[191] Batch [0549]/[0717]	Speed: 26.153353 samples/sec	 accuracy=83.655844	 loss=0.642921	 lr=0.000994
Epoch[191] Batch [0599]/[0717]	Speed: 26.098858 samples/sec	 accuracy=83.586310	 loss=0.643650	 lr=0.000961
Epoch[191] Batch [0649]/[0717]	Speed: 26.331570 samples/sec	 accuracy=83.565934	 loss=0.645941	 lr=0.000929
Epoch[191] Batch [0699]/[0717]	Speed: 25.902284 samples/sec	 accuracy=83.589286	 loss=0.645230	 lr=0.000897
Batch [0049]/[0057]: acc-top1=69.392857 acc-top5=88.178571
[Epoch 191] training: accuracy=83.579896	 loss=0.645420
[Epoch 191] speed: 26 samples/sec	time cost: 1598.764799
[Epoch 191] validation: acc-top1=69.381790 acc-top5=87.886383 loss=1.562057
Epoch[192] Batch [0049]/[0716]	Speed: 22.753402 samples/sec	 accuracy=84.714286	 loss=0.618200	 lr=0.000856
Epoch[192] Batch [0099]/[0716]	Speed: 25.990626 samples/sec	 accuracy=84.285714	 loss=0.624977	 lr=0.000825
Epoch[192] Batch [0149]/[0716]	Speed: 26.325759 samples/sec	 accuracy=83.630952	 loss=0.651168	 lr=0.000795
Epoch[192] Batch [0199]/[0716]	Speed: 26.035651 samples/sec	 accuracy=83.991071	 loss=0.639486	 lr=0.000766
Epoch[192] Batch [0249]/[0716]	Speed: 26.116388 samples/sec	 accuracy=84.071429	 loss=0.635395	 lr=0.000737
Epoch[192] Batch [0299]/[0716]	Speed: 26.334782 samples/sec	 accuracy=83.910714	 loss=0.638828	 lr=0.000709
Epoch[192] Batch [0349]/[0716]	Speed: 26.196981 samples/sec	 accuracy=84.000000	 loss=0.640183	 lr=0.000681
Epoch[192] Batch [0399]/[0716]	Speed: 25.809160 samples/sec	 accuracy=83.843750	 loss=0.646296	 lr=0.000654
Epoch[192] Batch [0449]/[0716]	Speed: 26.575888 samples/sec	 accuracy=83.793651	 loss=0.644596	 lr=0.000628
Epoch[192] Batch [0499]/[0716]	Speed: 26.130272 samples/sec	 accuracy=83.871429	 loss=0.640279	 lr=0.000602
Epoch[192] Batch [0549]/[0716]	Speed: 26.037085 samples/sec	 accuracy=83.915584	 loss=0.638586	 lr=0.000576
Epoch[192] Batch [0599]/[0716]	Speed: 26.246647 samples/sec	 accuracy=83.830357	 loss=0.641015	 lr=0.000551
Epoch[192] Batch [0649]/[0716]	Speed: 26.137604 samples/sec	 accuracy=83.898352	 loss=0.637902	 lr=0.000527
Epoch[192] Batch [0699]/[0716]	Speed: 26.235532 samples/sec	 accuracy=83.892857	 loss=0.638157	 lr=0.000503
Batch [0049]/[0057]: acc-top1=69.392857 acc-top5=87.821429
[Epoch 192] training: accuracy=83.891161	 loss=0.637924
[Epoch 192] speed: 26 samples/sec	time cost: 1598.698677
[Epoch 192] validation: acc-top1=69.282578 acc-top5=87.896820 loss=1.561907
Epoch[193] Batch [0049]/[0716]	Speed: 23.003241 samples/sec	 accuracy=83.750000	 loss=0.641322	 lr=0.000473
Epoch[193] Batch [0099]/[0716]	Speed: 26.467954 samples/sec	 accuracy=84.071429	 loss=0.614856	 lr=0.000450
Epoch[193] Batch [0149]/[0716]	Speed: 26.181601 samples/sec	 accuracy=84.452381	 loss=0.609464	 lr=0.000428
Epoch[193] Batch [0199]/[0716]	Speed: 25.870762 samples/sec	 accuracy=84.419643	 loss=0.611768	 lr=0.000407
Epoch[193] Batch [0249]/[0716]	Speed: 26.327723 samples/sec	 accuracy=84.364286	 loss=0.619797	 lr=0.000386
Epoch[193] Batch [0299]/[0716]	Speed: 25.784654 samples/sec	 accuracy=84.375000	 loss=0.617462	 lr=0.000366
Epoch[193] Batch [0349]/[0716]	Speed: 26.101649 samples/sec	 accuracy=84.428571	 loss=0.616585	 lr=0.000346
Epoch[193] Batch [0399]/[0716]	Speed: 26.234569 samples/sec	 accuracy=84.366071	 loss=0.617709	 lr=0.000327
Epoch[193] Batch [0449]/[0716]	Speed: 25.913519 samples/sec	 accuracy=84.321429	 loss=0.621346	 lr=0.000308
Epoch[193] Batch [0499]/[0716]	Speed: 25.734700 samples/sec	 accuracy=84.153571	 loss=0.628290	 lr=0.000290
Epoch[193] Batch [0549]/[0716]	Speed: 26.678450 samples/sec	 accuracy=84.162338	 loss=0.629611	 lr=0.000272
Epoch[193] Batch [0599]/[0716]	Speed: 26.419363 samples/sec	 accuracy=84.157738	 loss=0.628663	 lr=0.000255
Epoch[193] Batch [0649]/[0716]	Speed: 26.443042 samples/sec	 accuracy=84.153846	 loss=0.627533	 lr=0.000239
Epoch[193] Batch [0699]/[0716]	Speed: 26.040205 samples/sec	 accuracy=84.147959	 loss=0.627525	 lr=0.000223
Batch [0049]/[0057]: acc-top1=68.821429 acc-top5=87.571429
[Epoch 193] training: accuracy=84.148045	 loss=0.627164
[Epoch 193] speed: 26 samples/sec	time cost: 1600.228190
[Epoch 193] validation: acc-top1=69.517540 acc-top5=87.933372 loss=1.562670
Epoch[194] Batch [0049]/[0716]	Speed: 22.898962 samples/sec	 accuracy=86.321429	 loss=0.556543	 lr=0.000203
Epoch[194] Batch [0099]/[0716]	Speed: 25.897550 samples/sec	 accuracy=84.357143	 loss=0.614094	 lr=0.000188
Epoch[194] Batch [0149]/[0716]	Speed: 25.863531 samples/sec	 accuracy=84.404762	 loss=0.609531	 lr=0.000174
Epoch[194] Batch [0199]/[0716]	Speed: 26.075986 samples/sec	 accuracy=84.303571	 loss=0.610483	 lr=0.000160
Epoch[194] Batch [0249]/[0716]	Speed: 25.938559 samples/sec	 accuracy=84.171429	 loss=0.616320	 lr=0.000147
Epoch[194] Batch [0299]/[0716]	Speed: 25.858558 samples/sec	 accuracy=84.214286	 loss=0.614754	 lr=0.000135
Epoch[194] Batch [0349]/[0716]	Speed: 26.159296 samples/sec	 accuracy=84.173469	 loss=0.618961	 lr=0.000123
Epoch[194] Batch [0399]/[0716]	Speed: 25.879362 samples/sec	 accuracy=84.075893	 loss=0.625091	 lr=0.000112
Epoch[194] Batch [0449]/[0716]	Speed: 26.334769 samples/sec	 accuracy=84.123016	 loss=0.623151	 lr=0.000101
Epoch[194] Batch [0499]/[0716]	Speed: 26.566995 samples/sec	 accuracy=84.089286	 loss=0.624867	 lr=0.000091
Epoch[194] Batch [0549]/[0716]	Speed: 25.919200 samples/sec	 accuracy=84.029221	 loss=0.622949	 lr=0.000081
Epoch[194] Batch [0599]/[0716]	Speed: 26.236148 samples/sec	 accuracy=83.946429	 loss=0.628538	 lr=0.000072
Epoch[194] Batch [0649]/[0716]	Speed: 25.931209 samples/sec	 accuracy=83.923077	 loss=0.629720	 lr=0.000063
Epoch[194] Batch [0699]/[0716]	Speed: 25.884827 samples/sec	 accuracy=83.956633	 loss=0.628572	 lr=0.000055
Batch [0049]/[0057]: acc-top1=69.357143 acc-top5=87.071429
[Epoch 194] training: accuracy=83.926077	 loss=0.630395
[Epoch 194] speed: 25 samples/sec	time cost: 1605.664904
[Epoch 194] validation: acc-top1=69.418335 acc-top5=87.975143 loss=1.565447
Epoch[195] Batch [0049]/[0716]	Speed: 23.042574 samples/sec	 accuracy=84.642857	 loss=0.626830	 lr=0.000045
Epoch[195] Batch [0099]/[0716]	Speed: 26.108248 samples/sec	 accuracy=84.267857	 loss=0.649783	 lr=0.000038
Epoch[195] Batch [0149]/[0716]	Speed: 26.134276 samples/sec	 accuracy=83.892857	 loss=0.655824	 lr=0.000032
Epoch[195] Batch [0199]/[0716]	Speed: 25.834397 samples/sec	 accuracy=83.687500	 loss=0.661442	 lr=0.000027
Epoch[195] Batch [0249]/[0716]	Speed: 26.103081 samples/sec	 accuracy=83.671429	 loss=0.656039	 lr=0.000021
Epoch[195] Batch [0299]/[0716]	Speed: 25.459328 samples/sec	 accuracy=83.750000	 loss=0.651743	 lr=0.000017
Epoch[195] Batch [0349]/[0716]	Speed: 26.158315 samples/sec	 accuracy=83.739796	 loss=0.650506	 lr=0.000013
Epoch[195] Batch [0399]/[0716]	Speed: 25.935082 samples/sec	 accuracy=83.968750	 loss=0.640583	 lr=0.000009
Epoch[195] Batch [0449]/[0716]	Speed: 26.011444 samples/sec	 accuracy=84.011905	 loss=0.638784	 lr=0.000006
Epoch[195] Batch [0499]/[0716]	Speed: 25.654128 samples/sec	 accuracy=84.035714	 loss=0.638252	 lr=0.000004
Epoch[195] Batch [0549]/[0716]	Speed: 25.772846 samples/sec	 accuracy=84.045455	 loss=0.638835	 lr=0.000002
Epoch[195] Batch [0599]/[0716]	Speed: 26.047781 samples/sec	 accuracy=84.080357	 loss=0.638423	 lr=0.000001
Epoch[195] Batch [0649]/[0716]	Speed: 26.138619 samples/sec	 accuracy=84.170330	 loss=0.636309	 lr=0.000000
Epoch[195] Batch [0699]/[0716]	Speed: 26.001809 samples/sec	 accuracy=84.160714	 loss=0.636173	 lr=0.000000
Batch [0049]/[0057]: acc-top1=70.785714 acc-top5=88.392857
[Epoch 195] training: accuracy=84.175479	 loss=0.636581
[Epoch 195] speed: 25 samples/sec	time cost: 1611.068427
[Epoch 195] validation: acc-top1=69.418335 acc-top5=87.740181 loss=1.553988
